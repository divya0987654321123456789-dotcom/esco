
import os
import json
import secrets
import re
import uuid
import sys
import shutil
import subprocess
import base64
import io
import tempfile
import zipfile
from pathlib import Path
from datetime import datetime, date, timedelta, timezone
from html import escape, unescape
from html.parser import HTMLParser
from flask import (
    Flask,
    render_template,
    request,
    jsonify,
    redirect,
    url_for,
    flash,
    send_file,
    session,
    send_from_directory,
    abort,
    g,
)
from werkzeug.utils import secure_filename
import smtplib
import ssl
import requests
import bleach
import json

from dotenv import load_dotenv
app = Flask(__name__)


def _load_dotenv_hierarchy():
    """Load environment variables from common .env locations.

    We look in the following order (later files override earlier values):
      1. Project root two levels up (handles running via different entrypoints)
      2. Directory that contains this file
      3. An `env/.env` helper directory beside the project (if present)
    """
    current_file = Path(__file__).resolve()
    candidates = [
        current_file.parent.parent / '.env',
        current_file.parent / '.env',
        current_file.parent / 'env' / '.env',
        Path.cwd() / '.env',
    ]

    loaded_any = False
    for candidate in candidates:
        if candidate.is_file():
            load_dotenv(candidate, override=True)
            loaded_any = True
    if not loaded_any:
        load_dotenv()


_load_dotenv_hierarchy()

def _apply_provider_defaults():
    provider = (os.getenv('LLM_PROVIDER') or '').strip().lower()
    if provider == 'groq':
        base = os.getenv('OPENAI_BASE_URL') or os.getenv('GROQ_BASE_URL') or 'https://api.groq.com/openai/v1'
        model = os.getenv('OPENAI_MODEL') or os.getenv('GROQ_MODEL') or 'meta-llama/llama-4-scout-17b-16e-instruct'
        key = os.getenv('OPENAI_API_KEY') or os.getenv('GROQ_API_KEY') or ''
    elif provider == 'openrouter':
        base = os.getenv('OPENAI_BASE_URL') or os.getenv('OPENROUTER_BASE_URL') or 'https://openrouter.ai/api/v1'
        model = os.getenv('OPENAI_MODEL') or os.getenv('OPENROUTER_MODEL') or 'openrouter/auto'
        key = os.getenv('OPENAI_API_KEY') or os.getenv('OPENROUTER_API_KEY') or ''
    elif provider == 'ollama':
        base = os.getenv('OPENAI_BASE_URL') or 'https://api.openai.com/v1'
        model = os.getenv('OPENAI_MODEL') or 'meta-llama/llama-4-scout-17b-16e-instruct'
        key = os.getenv('OPENAI_API_KEY') or os.getenv('GROQ_API_KEY') or ''
    else:
        base = os.getenv('OPENAI_BASE_URL') or 'https://api.openai.com/v1'
        model = os.getenv('OPENAI_MODEL') or 'meta-llama/llama-4-scout-17b-16e-instruct'
        key = os.getenv('OPENAI_API_KEY') or ''
    # Apply into app.config so downstream code reads a single place
    app.config['OPENAI_BASE_URL'] = base
    app.config['OPENAI_MODEL'] = model
    app.config['OPENAI_API_KEY'] = key

_apply_provider_defaults()

def _strip_html_tags(value):
    if not value:
        return ''
    text = re.sub(r'(<\s*br\s*/?>)', '\n', value, flags=re.IGNORECASE)
    text = re.sub(r'</p\s*>', '\n\n', text, flags=re.IGNORECASE)
    text = re.sub(r'<[^>]+>', '', text)
    # Remove stray Markdown/bullet markers that may remain in content or table cells
    # 1) Strip common bullet prefixes at the start of lines (e.g., "+ ", "- ", "* ", "??? ")
    text = re.sub(r'(?m)^\s*[\+\-\*???????????????????????]\s+', '', text)
    # 2) Remove leftover Markdown emphasis markers like '#' and '*'
    text = re.sub(r'[#*]+', '', text)
    return re.sub(r'\n{3,}', '\n\n', text).strip()

def _normalize_recipient_list(value) -> list[str]:
    """Normalize recipients input into a unique list of emails/ids."""
    if not value:
        return []
    if isinstance(value, (list, tuple, set)):
        raw = []
        for v in value:
            if v is None:
                continue
            raw.extend(str(v).split(','))
        parts = raw
    else:
        parts = re.split(r'[,\n;]+', str(value))
    out = []
    seen = set()
    for p in parts:
        s = (p or '').strip()
        if not s:
            continue
        key = s.lower()
        if key in seen:
            continue
        seen.add(key)
        out.append(s)
    return out


def _notify_custom_recipients(
    recipients: list[str],
    *,
    task_id: int | None = None,
    title: str = "Task update",
    message: str = "",
    category: str = "info",
) -> None:
    if not recipients:
        return
    seen: set[tuple[str, int | str]] = set()
    link_url = f"/task/{int(task_id)}/details" if task_id else "/notifications"
    cur = mysql.connection.cursor(DictCursor)
    try:
        for rec in recipients:
            raw = (rec or "").strip()
            if not raw:
                continue
            raw_lower = raw.lower()
            user_id = None
            employee_id = None
            email = ""
            if raw_lower.startswith("user:"):
                try:
                    user_id = int(raw.split(":", 1)[1])
                except Exception:
                    user_id = None
            elif raw_lower.startswith("employee:"):
                try:
                    employee_id = int(raw.split(":", 1)[1])
                except Exception:
                    employee_id = None
            elif "@" in raw:
                email = raw_lower
            elif raw.isdigit():
                try:
                    user_id = int(raw)
                except Exception:
                    user_id = None
            if user_id:
                key = ("user", user_id)
                if key in seen:
                    continue
                seen.add(key)
                _create_notification(
                    recipient_kind="user",
                    recipient_id=user_id,
                    title=title,
                    message=message,
                    category=category,
                    link_url=link_url,
                )
                continue
            if employee_id:
                key = ("employee", employee_id)
                if key in seen:
                    continue
                seen.add(key)
                _create_notification(
                    recipient_kind="employee",
                    recipient_id=employee_id,
                    title=title,
                    message=message,
                    category=category,
                    link_url=link_url,
                )
                continue
            if not email:
                continue
            try:
                cur.execute("SELECT id FROM users WHERE LOWER(email)=%s LIMIT 1", (email,))
                urow = cur.fetchone() or {}
            except Exception:
                urow = {}
            if urow.get("id"):
                uid = int(urow.get("id"))
                key = ("user", uid)
                if key not in seen:
                    seen.add(key)
                    _create_notification(
                        recipient_kind="user",
                        recipient_id=uid,
                        title=title,
                        message=message,
                        category=category,
                        link_url=link_url,
                    )
                    continue
            try:
                cur.execute("SELECT id FROM employees WHERE LOWER(email)=%s LIMIT 1", (email,))
                erow = cur.fetchone() or {}
            except Exception:
                erow = {}
            if erow.get("id"):
                eid = int(erow.get("id"))
                key = ("employee", eid)
                if key not in seen:
                    seen.add(key)
                    _create_notification(
                        recipient_kind="employee",
                        recipient_id=eid,
                        title=title,
                        message=message,
                        category=category,
                        link_url=link_url,
                    )
    finally:
        try:
            cur.close()
        except Exception:
            pass

try:
    import fitz as _pymupdf  # PyMuPDF
    _FITZ_AVAILABLE = hasattr(_pymupdf, "open")
except ImportError:
    _pymupdf = None
    _FITZ_AVAILABLE = False

try:
    from PyPDF2 import PdfReader as _PdfReader
except ImportError:
    _PdfReader = None
from flask_mysqldb import MySQL
from flask_socketio import SocketIO, join_room, emit
from flask_login import LoginManager, UserMixin, AnonymousUserMixin, login_user, logout_user, login_required, current_user
from MySQLdb.cursors import DictCursor
from rfp_analyzer_routes import rfp_bp 

# --- Security Module Import ---
from security import (
    init_security, hash_password, verify_password, is_password_hashed,
    password_strength_check, generate_csrf_token, validate_csrf_token,
    csrf_protect, require_role, require_permission, require_admin,
    require_supervisor_or_admin, rate_limit, login_rate_limit,
    sanitize_input, sanitize_html, validate_email, secure_filename,
    audit_log, regenerate_session, get_client_ip, get_safe_redirect,
    has_permission, has_module_access, check_module_access, get_user_role,
    MODULE_PERMISSIONS, ACTION_PERMISSIONS
)

# --- App Initialization ---
app = Flask(__name__)
app.config['SECRET_KEY'] = os.environ.get('SECRET_KEY', 'esco_secure_key_change_in_production_2024!')
# Increase upload size to handle large bid documents.
app.config['MAX_CONTENT_LENGTH'] = 1024 * 1024 * 1024  # 1GB max file upload
app.config['TEMPLATES_AUTO_RELOAD'] = True
app.jinja_env.auto_reload = True

# Session Security Configuration
app.config['SESSION_COOKIE_SECURE'] = os.environ.get('FLASK_ENV') == 'production'
app.config['SESSION_COOKIE_HTTPONLY'] = True
app.config['SESSION_COOKIE_SAMESITE'] = 'Lax'
app.config['PERMANENT_SESSION_LIFETIME'] = 28800  # 8 hours

# Ensure commonly used AI configuration keys are visible via app.config
app.config.setdefault('OPENAI_API_KEY', os.getenv('OPENAI_API_KEY', app.config.get('OPENAI_API_KEY', '')))
app.config.setdefault('OPENAI_BASE_URL', os.getenv('OPENAI_BASE_URL', app.config.get('OPENAI_BASE_URL', 'https://api.groq.com/openai/v1')))
app.config.setdefault('OPENAI_MODEL', os.getenv('OPENAI_MODEL', app.config.get('OPENAI_MODEL', 'meta-llama/llama-4-scout-17b-16e-instruct')))

# Register RFP Analyzer Blueprint
app.register_blueprint(rfp_bp)

# --- Error handling: ensure API endpoints return JSON on errors ---
@app.errorhandler(500)
def _handle_internal_server_error(e):
    try:
        path = request.path or ''
    except Exception:
        path = ''
    if isinstance(path, str) and path.startswith('/api/'):
        return jsonify({'error': 'internal_server_error', 'message': 'An unexpected error occurred.'}), 500
    # Fallback for non-API routes
    return "Internal Server Error", 500

@app.errorhandler(TypeError)
def _handle_type_error(e):
    # Catch cases like "view function did not return a valid response" and return JSON for APIs
    try:
        path = request.path or ''
    except Exception:
        path = ''
    if isinstance(path, str) and path.startswith('/api/'):
        return jsonify({'error': 'type_error', 'message': str(e)}), 500
    return str(e), 500

# --- Stage Constants ---
PIPELINE = ['analyzer', 'business', 'design', 'operations', 'engineer', 'handover']
LABELS = {
    'analyzer': 'BID Analyzer',
    'business': 'Business Development', 
    'design': 'Design Team',
    'operations': 'Operations Team',
    'engineer': 'Site Engineer',
    'handover': 'Handov'
}

def pct_for(stage: str) -> int:
    """Calculate progress percentage based on stage"""
    s = (stage or 'analyzer').lower()
    if s not in PIPELINE:
        return 0
    # Get the index of current stage
    i = PIPELINE.index(s)
    # Return percentage: analyzer=0%, business=20%, design=40%, operations=60%, engineer=80%, handover=100%
    return int(round((i + 1) * (100 / len(PIPELINE))))

def status_texts(stage: str) -> tuple[str, str]:
    """Generate project status and work status texts based on stage"""
    s = (stage or 'analyzer').lower()
    proj = 'completed' if s == 'handover' else 'ongoing'
    if s == 'analyzer':
        work = 'Initiated by BID Analyzer'
    else:
        i = PIPELINE.index(s) if s in PIPELINE else 0
        prev = PIPELINE[i-1] if i > 0 else ''
        from_txt = LABELS.get(prev, '').replace(' Team', '')
        to_txt = LABELS.get(s, '')
        work = f'Updated by {from_txt} to {to_txt}'
    return proj, work

def normalize_task_status(value) -> str:
    """Normalize status variants to canonical task states."""
    s = (value or '').strip().lower()
    s = s.replace('-', ' ').replace('_', ' ')
    s = ' '.join(s.split())
    if s in ('completed', 'complete', 'done', 'finished', 'closed'):
        return 'completed'
    if s in ('submitted', 'submit', 'submission'):
        return 'submitted'
    if s in ('rejected', 'reject'):
        return 'rejected'
    if s in ('in progress', 'inprogress', 'working', 'wip', 'started'):
        return 'in_progress'
    if s in ('pending', 'not started', 'notstarted', 'new', ''):
        return 'pending'
    return 'pending'

def _status_to_progress_pct(status: str, progress_pct=None) -> int:
    try:
        if progress_pct is not None and str(progress_pct).strip() != '':
            return max(0, min(100, int(float(progress_pct))))
    except Exception:
        pass
    st = normalize_task_status(status)
    if st == 'completed':
        return 100
    if st == 'submitted':
        return 75
    if st == 'in_progress':
        return 50
    return 0

def _compute_checklist_stage_progress(cur, g_id: int) -> dict:
    """Compute per-stage progress map from bid_checklists rows."""
    try:
        cur.execute(
            """
            SELECT stage, status, progress_pct
            FROM bid_checklists
            WHERE g_id=%s AND team_archive IS NULL
            """,
            (int(g_id),),
        )
        rows = cur.fetchall() or []
    except Exception:
        return {}
    grouped = {}
    for row in rows:
        stage_key = _normalize_department_key(row.get('stage') or '') or ''
        if not stage_key:
            continue
        grouped.setdefault(stage_key, []).append(
            _status_to_progress_pct(row.get('status'), row.get('progress_pct'))
        )
    out = {}
    for k, vals in grouped.items():
        out[k] = int(round(sum(vals) / len(vals))) if vals else 0
    return out

def _task_code_prefix(stage: str) -> str | None:
    key = (stage or '').strip().lower()
    mapping = {
        'business': 'IKBD',
        'design': 'IKMKT',
        'operations': 'IKOPS',
        'engineer': 'IKSE',
        'engineering_team': 'IKENG',
        'procurement_team': 'IKPRC',
        'accounts_finance': 'IKAF',
    }
    return mapping.get(key)


def _next_task_code_number(cur, stage: str) -> tuple[str | None, int | None]:
    prefix = _task_code_prefix(stage)
    if not prefix:
        return None, None
    like = f"{prefix}-%"
    start_pos = len(prefix) + 2
    cur.execute(
        "SELECT MAX(CAST(SUBSTRING(task_code, %s) AS UNSIGNED)) AS mx FROM bid_checklists WHERE task_code LIKE %s",
        (start_pos, like),
    )
    row = cur.fetchone() or {}
    max_num = int(row.get('mx') or 0)
    return prefix, max_num + 1


def _assign_missing_task_codes(cur, tasks: list[dict], fallback_stage: str | None = None) -> None:
    if not tasks:
        return
    staged = {}
    for t in tasks:
        if t.get('task_code'):
            continue
        stage = (t.get('stage') or fallback_stage or '').strip().lower()
        prefix = _task_code_prefix(stage)
        if not prefix:
            continue
        staged.setdefault(prefix, []).append(t)
    if not staged:
        return
    for prefix, items in staged.items():
        start_pos = len(prefix) + 2
        cur.execute(
            "SELECT MAX(CAST(SUBSTRING(task_code, %s) AS UNSIGNED)) AS mx FROM bid_checklists WHERE task_code LIKE %s",
            (start_pos, f"{prefix}-%"),
        )
        row = cur.fetchone() or {}
        next_num = int(row.get('mx') or 0) + 1
        for t in items:
            code = f"{prefix}-{next_num:03d}"
            cur.execute("UPDATE bid_checklists SET task_code=%s WHERE id=%s", (code, t.get('id')))
            t['task_code'] = code
            next_num += 1


def _backfill_task_codes_for_stage(cur, stage: str) -> None:
    stage_key = (stage or '').strip().lower()
    prefix = _task_code_prefix(stage_key)
    if not prefix:
        return
    cur.execute(
        """
        SELECT id
        FROM bid_checklists
        WHERE (task_code IS NULL OR task_code = '')
          AND LOWER(COALESCE(stage,'')) = %s
          AND team_archive IS NULL
        ORDER BY created_at ASC, id ASC
        """,
        (stage_key,),
    )
    rows = cur.fetchall() or []
    if not rows:
        return
    _, next_num = _next_task_code_number(cur, stage_key)
    if not next_num:
        return
    for row in rows:
        task_id = row.get('id') if isinstance(row, dict) else row[0]
        if not task_id:
            continue
        code = f"{prefix}-{next_num:03d}"
        cur.execute("UPDATE bid_checklists SET task_code=%s WHERE id=%s", (code, task_id))
        next_num += 1

def generate_team_checklist(cur, g_id, team):
    """Generate team-specific default checklist tasks"""
    team_tasks = {
        'business': [
            {'name': 'Market Analysis', 'description': 'Analyze market potential and competition', 'priority': 'high'},
            {'name': 'Client Communication', 'description': 'Establish communication with client', 'priority': 'high'},
            {'name': 'Proposal Preparation', 'description': 'Prepare business proposal', 'priority': 'medium'},
            {'name': 'Budget Estimation', 'description': 'Estimate project budget and timeline', 'priority': 'high'}
        ],
        'design': [
            {'name': 'Initial Design Concept', 'description': 'Create initial design concepts', 'priority': 'high'},
            {'name': 'Technical Drawings', 'description': 'Prepare detailed technical drawings', 'priority': 'high'},
            {'name': 'Material Selection', 'description': 'Select appropriate materials and specifications', 'priority': 'medium'},
            {'name': 'Design Review', 'description': 'Review and finalize design with team', 'priority': 'medium'},
            {'name': 'Client Approval', 'description': 'Get client approval on design', 'priority': 'high'}
        ],
        'operations': [
            {'name': 'Project Planning', 'description': 'Create detailed project execution plan', 'priority': 'high'},
            {'name': 'Resource Allocation', 'description': 'Allocate resources and personnel', 'priority': 'high'},
            {'name': 'Timeline Management', 'description': 'Set up project timeline and milestones', 'priority': 'medium'},
            {'name': 'Quality Control Setup', 'description': 'Establish quality control procedures', 'priority': 'medium'},
            {'name': 'Risk Assessment', 'description': 'Identify and assess project risks', 'priority': 'high'}
        ],
        'engineer': [
            {'name': 'Site Survey', 'description': 'Conduct detailed site survey', 'priority': 'high'},
            {'name': 'Technical Specifications', 'description': 'Prepare technical specifications', 'priority': 'high'},
            {'name': 'Safety Planning', 'description': 'Develop safety protocols and procedures', 'priority': 'high'},
            {'name': 'Equipment Planning', 'description': 'Plan equipment and tool requirements', 'priority': 'medium'},
            {'name': 'Implementation Plan', 'description': 'Create detailed implementation plan', 'priority': 'high'}
        ],
        'engineering_team': [
            {'name': 'Engineering Scope Review', 'description': 'Review engineering scope and constraints', 'priority': 'high'},
            {'name': 'Technical Review', 'description': 'Validate technical requirements and specs', 'priority': 'high'},
            {'name': 'Engineering Schedule', 'description': 'Draft engineering milestones', 'priority': 'medium'},
        ],
        'procurement_team': [
            {'name': 'Vendor Shortlist', 'description': 'Identify and shortlist vendors', 'priority': 'high'},
            {'name': 'RFQ Package', 'description': 'Prepare RFQ package and send', 'priority': 'high'},
            {'name': 'Quote Comparison', 'description': 'Collect and compare quotes', 'priority': 'medium'},
        ],
        'accounts_finance': [
            {'name': 'Budget Validation', 'description': 'Validate budget and cash flow', 'priority': 'high'},
            {'name': 'Cost Breakdown', 'description': 'Prepare cost breakdown and summary', 'priority': 'medium'},
            {'name': 'Financial Review', 'description': 'Finalize financial review for submission', 'priority': 'high'},
        ]
    }
    
    if team in team_tasks:
        prefix, next_num = _next_task_code_number(cur, team)
        for task in team_tasks[team]:
            # Persist a stage on each seeded task so aggregation can be stage-aware
            stage_name = team.strip().lower()
            task_code = f"{prefix}-{next_num:03d}" if prefix and next_num else None
            cur.execute("""
                INSERT INTO bid_checklists (g_id, task_code, task_name, description, priority, status, progress_pct, stage, created_by)
                VALUES (%s, %s, %s, %s, %s, 'pending', %s, %s, %s)
            """, (g_id, task_code, task['name'], task['description'], task['priority'], 0, stage_name, current_user.id))
            if prefix and next_num:
                next_num += 1

def log_write(action: str, details: str = ''):
    """Write to logs table and emit via Socket.IO"""
    try:
        cur = mysql.connection.cursor(DictCursor)
        user_id = getattr(current_user, 'id', None) if hasattr(current_user, 'id') else None
        cur.execute("INSERT INTO logs (action, user_id) VALUES (%s, %s)",
                    (f"{action} | {details}", user_id))
        mysql.connection.commit()
        cur.close()
        
        # Emit to master dashboard
        socketio.emit('master_update', {'log': {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'action': f"{action} | {details}",
            'user_email': getattr(current_user, 'email', 'System') if hasattr(current_user, 'email') else 'System',
            'user_role': getattr(current_user, 'role', '') if hasattr(current_user, 'role') else ''
        }})
    except Exception as e:
        print(f"Log write error: {e}")

# Legacy function for backward compatibility
def stage_progress_pct(stage: str) -> int:
    return pct_for(stage)

# MySQL Config
app.config['MYSQL_HOST'] = 'localhost'
app.config['MYSQL_USER'] = 'root'
app.config['MYSQL_PASSWORD'] = ''
app.config['MYSQL_DB'] = os.environ.get('ESCO_MYSQL_DB', 'esco')
app.config['MYSQL_CURSORCLASS'] = 'DictCursor'

# --------------------------------------------------------------------
# MariaDB/XAMPP safety: detect "ghost" InnoDB dictionary entries
# --------------------------------------------------------------------
# In some local installs, core InnoDB tables can be orphaned: they exist in
# `information_schema.INNODB_SYS_TABLES` but are missing from
# `information_schema.tables` (e.g. missing .frm). In that state, MariaDB
# will refuse to recreate the table name (1813/1050/1932).
# The practical, non-destructive fix is to switch the app to a clean DB.
def _select_working_database_name() -> str:
    desired_db = (app.config.get('MYSQL_DB') or 'esco').strip() or 'esco'
    fallback_db = (os.environ.get('ESCO_MYSQL_DB_FALLBACK') or f"{desired_db}_v23_clean").strip()
    host = app.config.get('MYSQL_HOST', 'localhost')
    user = app.config.get('MYSQL_USER', 'root')
    password = app.config.get('MYSQL_PASSWORD', '')

    core_tables = [
        'users',
        'companies',
        'departments',
        'user_company_access',
        'bids',
        'bid_incoming',
        'go_bids',
        'projects',
        'tasks',
        'logs',
        'role_permissions',
        'action_permissions',
        'user_module_permissions',
    ]

    try:
        import MySQLdb  # type: ignore
        from MySQLdb.cursors import DictCursor as _DictCursor  # type: ignore

        conn = MySQLdb.connect(host=host, user=user, passwd=password, charset='utf8mb4')
        cur = conn.cursor(_DictCursor)

        def _ensure_db_exists(db_name: str) -> None:
            cur.execute("SHOW DATABASES LIKE %s", (db_name,))
            if not cur.fetchone():
                cur.execute(f"CREATE DATABASE `{db_name}` DEFAULT CHARACTER SET utf8mb4")

        _ensure_db_exists(desired_db)

        # Only MariaDB exposes INNODB_SYS_TABLES; if absent, skip ghost detection.
        try:
            ghost_found = False
            for t in core_tables:
                cur.execute(
                    "SELECT 1 FROM information_schema.INNODB_SYS_TABLES WHERE NAME=%s LIMIT 1",
                    (f"{desired_db}/{t}",),
                )
                in_innodb = cur.fetchone() is not None
                if not in_innodb:
                    continue
                cur.execute(
                    "SELECT 1 FROM information_schema.tables WHERE table_schema=%s AND table_name=%s LIMIT 1",
                    (desired_db, t),
                )
                in_sql = cur.fetchone() is not None
                if in_innodb and not in_sql:
                    ghost_found = True
                    break
        except Exception:
            ghost_found = False

        if ghost_found and fallback_db and fallback_db != desired_db:
            _ensure_db_exists(fallback_db)
            try:
                conn.commit()
            except Exception:
                pass
            try:
                cur.close()
                conn.close()
            except Exception:
                pass
            print(
                f"Detected orphan InnoDB dictionary entries in `{desired_db}`; "
                f"switching app DB to `{fallback_db}`. "
                f"Set `ESCO_MYSQL_DB` to override."
            )
            return fallback_db

        # If core tables are missing entirely, switch to fallback if it has them.
        try:
            missing_tables = []
            for t in core_tables:
                cur.execute(
                    "SELECT 1 FROM information_schema.tables WHERE table_schema=%s AND table_name=%s LIMIT 1",
                    (desired_db, t),
                )
                if not cur.fetchone():
                    missing_tables.append(t)
            if missing_tables and fallback_db and fallback_db != desired_db:
                _ensure_db_exists(fallback_db)
                fallback_missing = []
                for t in missing_tables:
                    cur.execute(
                        "SELECT 1 FROM information_schema.tables WHERE table_schema=%s AND table_name=%s LIMIT 1",
                        (fallback_db, t),
                    )
                    if not cur.fetchone():
                        fallback_missing.append(t)
                if not fallback_missing:
                    try:
                        conn.commit()
                    except Exception:
                        pass
                    try:
                        cur.close()
                        conn.close()
                    except Exception:
                        pass
                    print(
                        f"Missing core tables in `{desired_db}`; "
                        f"switching app DB to `{fallback_db}`. "
                        f"Set `ESCO_MYSQL_DB` to override."
                    )
                    return fallback_db
        except Exception:
            pass

        try:
            conn.commit()
        except Exception:
            pass
        try:
            cur.close()
            conn.close()
        except Exception:
            pass
    except Exception:
        pass

    # De-duplicate won rows by project id
    try:
        uniq = []
        seen = set()
        for rr in (won_rows or []):
            key = rr.get('w_id')
            if key in seen:
                continue
            seen.add(key)
            uniq.append(rr)
        won_rows = uniq
    except Exception:
        pass

    # Final fallback: use existing project_timeline_stages if any were already seeded
    try:
        if not won_rows:
            cur.execute(
                """
                SELECT project_id, MAX(created_at) AS last_created
                FROM project_timeline_stages
                GROUP BY project_id
                ORDER BY last_created DESC
                LIMIT 5
                """
            )
            seeded_rows = cur.fetchall() or []
            for sr in seeded_rows:
                pid = sr.get('project_id')
                if not pid:
                    continue
                label = None
                company = None
                status = None
                result = None
                try:
                    cur.execute(
                        """
                        SELECT w_id, g_id, b_name, company, status, result
                        FROM win_lost_results
                        WHERE w_id=%s
                        LIMIT 1
                        """,
                        (int(pid),),
                    )
                    row = cur.fetchone() or {}
                    if row:
                        label = row.get('b_name')
                        company = row.get('company')
                        status = row.get('status')
                        result = row.get('result')
                except Exception:
                    pass
                if not label:
                    try:
                        src_id = int(pid)
                        if src_id >= 1000000000:
                            src_id = src_id - 1000000000
                        cur.execute(
                            """
                            SELECT id, b_name, comp_name, bid_status, results
                            FROM bid_incoming
                            WHERE id=%s
                            LIMIT 1
                            """,
                            (src_id,),
                        )
                        row = cur.fetchone() or {}
                        if row:
                            label = row.get('b_name')
                            company = row.get('comp_name')
                            status = row.get('bid_status')
                            result = row.get('results')
                    except Exception:
                        pass
                won_rows.append({
                    'w_id': pid,
                    'g_id': None,
                    'b_name': label or f"Project #{pid}",
                    'company': company,
                    'status': status,
                    'result': result,
                })
    except Exception:
        pass


def _ensure_bid_team_progress_table(cur) -> None:
    cur.execute("""
        CREATE TABLE IF NOT EXISTS bid_team_progress (
            id INT AUTO_INCREMENT PRIMARY KEY,
            g_id INT NOT NULL,
            stage_key VARCHAR(50) NOT NULL,
            progress_pct INT NOT NULL DEFAULT 0,
            total_tasks INT NOT NULL DEFAULT 0,
            completed_tasks INT NOT NULL DEFAULT 0,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            UNIQUE KEY uniq_bid_stage (g_id, stage_key),
            INDEX idx_bid (g_id)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    """)


def _backfill_bid_team_progress(cur) -> None:
    """Populate bid_team_progress for all known bids (best-effort)."""
    try:
        _ensure_bid_team_progress_table(cur)
    except Exception:
        return
    g_ids = set()
    try:
        cur.execute("SELECT DISTINCT g_id FROM bid_checklists")
        for r in (cur.fetchall() or []):
            try:
                g_ids.add(int(r.get('g_id') or 0))
            except Exception:
                pass
    except Exception:
        pass
    try:
        cur.execute("SELECT DISTINCT g_id FROM bid_assign_meta")
        for r in (cur.fetchall() or []):
            try:
                g_ids.add(int(r.get('g_id') or 0))
            except Exception:
                pass
    except Exception:
        pass
    try:
        cur.execute("SELECT DISTINCT g_id FROM go_bids")
        for r in (cur.fetchall() or []):
            try:
                g_ids.add(int(r.get('g_id') or 0))
            except Exception:
                pass
    except Exception:
        pass
    g_ids = [gid for gid in g_ids if gid]
    for gid in g_ids:
        try:
            _recalc_bid_team_progress(cur, int(gid))
        except Exception:
            pass


def _normalize_stage_key(raw: str | None) -> str | None:
    s = (raw or '').strip().lower()
    if not s:
        return None
    mapping = {
        'business dev': 'business',
        'business development': 'business',
        'bdm': 'business',
        'bde': 'business',
        'design': 'design',
        'design team': 'design',
        'design & marketing': 'design',
        'design and marketing': 'design',
        'marketing': 'design',
        'operations': 'operations',
        'operation': 'operations',
        'ops': 'operations',
        'operations team': 'operations',
        'site manager': 'engineer',
        'site engineer': 'engineer',
        'engineering': 'engineer',
        'engineer': 'engineer',
        'engineering team': 'engineer',
        'handover': 'handover',
        'submitted': 'handover',
        'submit': 'handover',
        'bid analyzer': 'analyzer',
        'analyzer': 'analyzer',
    }
    if s in mapping:
        return mapping[s]
    if 'design' in s or 'marketing' in s:
        return 'design'
    if 'business' in s or 'bdm' in s or 'bde' in s:
        return 'business'
    if 'operation' in s or 'ops' in s:
        return 'operations'
    if 'engineer' in s or 'site' in s:
        return 'engineer'
    if 'submit' in s or 'handover' in s or s == 'won':
        return 'handover'
    if 'analy' in s:
        return 'analyzer'
    return None


def _normalize_company_token(value: str | None) -> str:
    try:
        s = (value or '').strip().lower()
        return s.replace('.', '').replace(' ', '')
    except Exception:
        return ''


def _is_closed_bid_status(*values) -> bool:
    try:
        joined = " ".join([str(v or '') for v in values]).lower()
    except Exception:
        joined = ""
    if any(k in joined for k in ['won', 'award', 'awarded', 'win']):
        return True
    if 'lost' in joined:
        return True
    return False


def _is_won_bid_status(*values) -> bool:
    try:
        joined = " ".join([str(v or '') for v in values]).lower()
    except Exception:
        joined = ""
    return any(k in joined for k in ['won', 'award', 'awarded', 'win'])


def _ensure_project_manager_assignments_table(cur) -> None:
    try:
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS project_manager_assignments (
                id INT AUTO_INCREMENT PRIMARY KEY,
                project_id INT NOT NULL,
                g_id INT NULL,
                manager_user_id INT NOT NULL,
                assigned_by_user_id INT NULL,
                assigned_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_project_manager (project_id),
                INDEX idx_manager_user (manager_user_id),
                INDEX idx_project_gid (g_id),
                FOREIGN KEY (manager_user_id) REFERENCES users(id)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
            """
        )
    except Exception:
        pass


def _fetch_project_manager_users(cur, active_company_name: str | None = None) -> list[dict]:
    try:
        where = ["is_active=1", "LOWER(COALESCE(role,'')) LIKE '%%manager%%'"]
        params = []
        if active_company_name:
            where.append("LOWER(COALESCE(company,'')) = LOWER(%s)")
            params.append(active_company_name)
        where_sql = " AND ".join(where)
        cur.execute(
            f"""
            SELECT id, email, full_name, role, company
            FROM users
            WHERE {where_sql}
            ORDER BY full_name ASC, email ASC
            """,
            tuple(params),
        )
        return cur.fetchall() or []
    except Exception:
        return []


def _get_project_manager_map(cur, project_ids: list[int]) -> dict[int, dict]:
    _ensure_project_manager_assignments_table(cur)
    if not project_ids:
        return {}
    try:
        placeholders = ",".join(["%s"] * len(project_ids))
        cur.execute(
            f"""
            SELECT pma.project_id, pma.manager_user_id, u.full_name, u.email
            FROM project_manager_assignments pma
            LEFT JOIN users u ON u.id = pma.manager_user_id
            WHERE pma.project_id IN ({placeholders})
            """,
            tuple(project_ids),
        )
        rows = cur.fetchall() or []
        out = {}
        for r in rows:
            pid = r.get('project_id')
            if pid is None:
                continue
            out[int(pid)] = {
                'user_id': r.get('manager_user_id'),
                'name': r.get('full_name') or '',
                'email': r.get('email') or '',
            }
        return out
    except Exception:
        return {}


def _is_project_manager_for_project(user_id: int, project_id: int) -> bool:
    try:
        cur = mysql.connection.cursor(DictCursor)
        _ensure_project_manager_assignments_table(cur)
        cur.execute(
            "SELECT 1 FROM project_manager_assignments WHERE project_id=%s AND manager_user_id=%s LIMIT 1",
            (int(project_id), int(user_id)),
        )
        return cur.fetchone() is not None
    except Exception:
        return False
    finally:
        try:
            cur.close()
        except Exception:
            pass


def _basic_bid_timeline_rows(cur, company_sql_clause: str, company_params: tuple, limit: int = 200) -> list[dict]:
    try:
        cur.execute(
            f"""
            SELECT gb.g_id, gb.b_name, gb.company, gb.state, gb.due_date, gb.submission_status, gb.submission_reason
            FROM go_bids gb
            WHERE 1=1
            {company_sql_clause}
            ORDER BY gb.due_date IS NULL, gb.due_date ASC
            LIMIT %s
            """,
            tuple([*company_params, int(limit)]),
        )
        return cur.fetchall() or []
    except Exception:
        return []


def _compute_stage_progress_for_bid(cur, g_id: int, default_stages: list[str]):
    stage_map = {k: 0 for k in default_stages}
    counts = {k: {'total': 0, 'completed': 0} for k in default_stages}
    def _merge_meta(stage_map_local, counts_local):
        try:
            _ensure_bid_assign_meta_table()
            cur.execute("SELECT data FROM bid_assign_meta WHERE g_id=%s", (int(g_id),))
            row = cur.fetchone() or {}
            meta = {}
            try:
                meta = json.loads(row.get('data') or "{}")
            except Exception:
                meta = {}
            checklist = meta.get('checklist') if isinstance(meta, dict) else None
            if isinstance(checklist, list) and checklist:
                meta_buckets = {k: [] for k in default_stages}
                for item in checklist:
                    if not isinstance(item, dict):
                        continue
                    stage = _normalize_stage_key(
                        item.get('dept') or item.get('stage') or item.get('department') or item.get('team') or ''
                    )
                    if not stage or stage not in meta_buckets:
                        continue
                    st = (item.get('status') or '').strip().lower()
                    pct = item.get('progress_pct')
                    if pct is None:
                        pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
                    try:
                        pct = max(0, min(100, int(pct)))
                    except Exception:
                        pct = 0
                    meta_buckets[stage].append(pct)
                def _avg(lst):
                    return int(round(sum(lst) / len(lst))) if lst else 0
                for stage_key, vals in meta_buckets.items():
                    if vals and (counts_local.get(stage_key, {}).get('total', 0) == 0 or _avg(vals) > stage_map_local.get(stage_key, 0)):
                        stage_map_local[stage_key] = _avg(vals)
                        counts_local[stage_key]['total'] = len(vals)
                        counts_local[stage_key]['completed'] = len([v for v in vals if v >= 100])
        except Exception:
            pass
        return stage_map_local, counts_local
    try:
        _ensure_bid_team_progress_table(cur)
        cur.execute(
            """
            SELECT stage_key, progress_pct, total_tasks, completed_tasks
            FROM bid_team_progress
            WHERE g_id = %s
            """,
            (int(g_id),),
        )
        rows = cur.fetchall() or []
        if rows:
            for r in rows:
                k = r.get('stage_key')
                if k in stage_map:
                    stage_map[k] = int(r.get('progress_pct') or 0)
                    counts[k] = {
                        'total': int(r.get('total_tasks') or 0),
                        'completed': int(r.get('completed_tasks') or 0),
                    }
            stage_map, counts = _merge_meta(stage_map, counts)
            return stage_map, counts
    except Exception:
        pass

    try:
        cur.execute(
            """
            SELECT progress_pct, status, COALESCE(stage, department) AS stage_source
            FROM bid_checklists
            WHERE g_id=%s
            """,
            (int(g_id),),
        )
        rows = cur.fetchall() or []
        buckets = {k: [] for k in default_stages}
        for r in rows:
            stage = _normalize_stage_key(r.get('stage_source'))
            if not stage or stage not in buckets:
                continue
            pct = r.get('progress_pct')
            if pct is None:
                st = (r.get('status') or '').strip().lower()
                pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
            try:
                pct = max(0, min(100, int(pct)))
            except Exception:
                pct = 0
            buckets[stage].append(pct)
            counts[stage]['total'] += 1
            if pct >= 100 or (r.get('status') or '').strip().lower() in ('completed', 'submitted'):
                counts[stage]['completed'] += 1
        def _avg(lst):
            return int(round(sum(lst) / len(lst))) if lst else 0
        stage_map = {k: _avg(v) for k, v in buckets.items()}
    except Exception:
        pass

    try:
        _ensure_bid_assign_meta_table()
        cur.execute("SELECT data FROM bid_assign_meta WHERE g_id=%s", (int(g_id),))
        row = cur.fetchone() or {}
        meta = {}
        try:
            meta = json.loads(row.get('data') or "{}")
        except Exception:
            meta = {}
        checklist = meta.get('checklist') if isinstance(meta, dict) else None
        if isinstance(checklist, list) and checklist:
            buckets = {k: [] for k in default_stages}
            for item in checklist:
                if not isinstance(item, dict):
                    continue
                stage = _normalize_stage_key(item.get('dept') or item.get('stage') or '')
                if not stage or stage not in buckets:
                    continue
                st = (item.get('status') or '').strip().lower()
                pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
                buckets[stage].append(pct)
            def _avg(lst):
                return int(round(sum(lst) / len(lst))) if lst else 0
            for k, v in buckets.items():
                if v and (counts[k]['total'] == 0 or stage_map.get(k, 0) == 0):
                    stage_map[k] = _avg(v)
                    counts[k]['total'] = len(v)
                    counts[k]['completed'] = len([x for x in v if x >= 100])
    except Exception:
        pass

    return stage_map, counts


def _compute_stage_progress_from_checklists(cur, g_id: int, default_stages: list[str]):
    stage_map = {k: 0 for k in default_stages}
    counts = {k: {'total': 0, 'completed': 0} for k in default_stages}
    try:
        cur.execute(
            """
            SELECT progress_pct, status, stage
            FROM bid_checklists
            WHERE g_id=%s
            """,
            (int(g_id),),
        )
        rows = cur.fetchall() or []
    except Exception:
        return stage_map, counts
    buckets = {k: [] for k in default_stages}
    for r in rows:
        stage = _normalize_stage_key(r.get('stage'))
        if not stage or stage not in buckets:
            continue
        pct = r.get('progress_pct')
        if pct is None:
            st = (r.get('status') or '').strip().lower()
            pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
        try:
            pct = max(0, min(100, int(pct)))
        except Exception:
            pct = 0
        buckets[stage].append(pct)
        counts[stage]['total'] += 1
        if pct >= 100 or (r.get('status') or '').strip().lower() in ('completed', 'submitted'):
            counts[stage]['completed'] += 1
    for k, vals in buckets.items():
        if vals:
            stage_map[k] = int(round(sum(vals) / len(vals)))
    return stage_map, counts


def _bid_has_checklists(cur, g_id: int) -> bool:
    try:
        cur.execute("SELECT 1 FROM bid_checklists WHERE g_id=%s LIMIT 1", (int(g_id),))
        return cur.fetchone() is not None
    except Exception:
        return False


def _compute_stage_progress_from_meta(cur, g_id: int, default_stages: list[str]):
    stage_map = {k: 0 for k in default_stages}
    counts = {k: {'total': 0, 'completed': 0} for k in default_stages}
    try:
        _ensure_bid_assign_meta_table()
        cur.execute("SELECT data FROM bid_assign_meta WHERE g_id=%s", (int(g_id),))
        row = cur.fetchone() or {}
        try:
            meta = json.loads(row.get('data') or "{}")
        except Exception:
            meta = {}
        checklist = meta.get('checklist') if isinstance(meta, dict) else None
        if not isinstance(checklist, list) or not checklist:
            return stage_map, counts
        buckets = {k: [] for k in default_stages}
        for item in checklist:
            if not isinstance(item, dict):
                continue
            stage = _normalize_stage_key(
                item.get('dept') or item.get('stage') or item.get('department') or item.get('team') or ''
            )
            if not stage or stage not in buckets:
                continue
            st = (item.get('status') or '').strip().lower()
            pct = item.get('progress_pct')
            if pct is None:
                pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
            try:
                pct = max(0, min(100, int(pct)))
            except Exception:
                pct = 0
            buckets[stage].append(pct)
            counts[stage]['total'] += 1
            if pct >= 100 or st in ('completed', 'submitted'):
                counts[stage]['completed'] += 1
        for k, vals in buckets.items():
            if vals:
                stage_map[k] = int(round(sum(vals) / len(vals)))
    except Exception:
        return stage_map, counts
    return stage_map, counts


def _compute_stage_progress_for_timeline(cur, g_id: int, default_stages: list[str]):
    """Timeline-specific progress: merge bid_checklists + bid_assign_meta for stage %s."""
    stage_map = {k: 0 for k in default_stages}
    counts = {k: {'total': 0, 'completed': 0} for k in default_stages}
    try:
        chk_map, chk_counts = _compute_stage_progress_from_checklists(cur, g_id, default_stages)
        meta_map, meta_counts = _compute_stage_progress_from_meta(cur, g_id, default_stages)
        for k in default_stages:
            stage_map[k] = max(int(chk_map.get(k, 0) or 0), int(meta_map.get(k, 0) or 0))
            counts[k] = {
                'total': max(
                    int(chk_counts.get(k, {}).get('total', 0) or 0),
                    int(meta_counts.get(k, {}).get('total', 0) or 0),
                ),
                'completed': max(
                    int(chk_counts.get(k, {}).get('completed', 0) or 0),
                    int(meta_counts.get(k, {}).get('completed', 0) or 0),
                ),
            }
    except Exception:
        pass
    try:
        stage_map['analyzer'] = max(int(stage_map.get('analyzer', 0) or 0), 100)
    except Exception:
        stage_map['analyzer'] = 100
    return stage_map, counts


def _bid_timeline_progress_maps(cur, g_ids: list[int], default_stages: list[str]):
    """Compute per-team progress for bid timeline from bid_checklists + bid_assign_meta."""
    stage_map_by_gid: dict[int, dict] = {}
    counts_by_gid: dict[int, dict] = {}
    if not g_ids:
        return stage_map_by_gid, counts_by_gid
    for gid in g_ids:
        try:
            stage_map, counts = _compute_stage_progress_for_timeline(cur, int(gid), default_stages)
        except Exception:
            stage_map, counts = ({k: 0 for k in default_stages}, {k: {'total': 0, 'completed': 0} for k in default_stages})
        try:
            stage_map['analyzer'] = max(int(stage_map.get('analyzer', 0) or 0), 100)
        except Exception:
            stage_map['analyzer'] = 100
        stage_map_by_gid[int(gid)] = stage_map
        counts_by_gid[int(gid)] = counts
    return stage_map_by_gid, counts_by_gid


@app.route('/api/bid-timeline/progress')
@login_required
def api_bid_timeline_progress():
    ids_raw = (request.args.get('ids') or '').strip()
    if not ids_raw:
        return jsonify({'ok': True, 'items': {}})
    try:
        g_ids = [int(x) for x in ids_raw.split(',') if str(x).strip().isdigit()]
    except Exception:
        g_ids = []
    if not g_ids:
        return jsonify({'ok': True, 'items': {}})
    default_stages = ['analyzer', 'business', 'design', 'operations', 'engineer', 'handover']
    try:
        cur = mysql.connection.cursor(DictCursor)
        stage_map, _counts = _bid_timeline_progress_maps(cur, g_ids, default_stages)
        cur.close()
    except Exception:
        stage_map = {}

    return jsonify({'ok': True, 'items': stage_map})


def _build_basic_timeline_items(cur, rows: list[dict]) -> list[dict]:
    items = []
    default_stages = ['analyzer', 'business', 'design', 'operations', 'engineer', 'handover']
    label_map = {
        'analyzer': 'BID Analyzer',
        'business': 'Business Development',
        'design': 'Design & Marketing',
        'operations': 'Operation Team',
        'engineer': 'Engineering Team',
        'handover': 'Submitted',
    }
    for r in (rows or []):
        gid = r.get('g_id')
        stage_map, counts = _compute_stage_progress_for_bid(cur, int(gid or 0), default_stages)
        try:
            stage_map['analyzer'] = max(int(stage_map.get('analyzer', 0) or 0), 100)
        except Exception:
            stage_map['analyzer'] = 100
        stages = []
        for idx, key in enumerate(default_stages):
            stages.append({
                'name': label_map.get(key, key.title()),
                'key': key,
                'progress': int(stage_map.get(key, 0) or 0),
                'active': idx == 0,
            })
        try:
            vals = [int(stage_map.get(k, 0) or 0) for k in default_stages]
            overall_progress = int(round(sum(vals) / len(vals))) if vals else 0
        except Exception:
            overall_progress = 0
        items.append({
            'g_id': gid,
            'b_name': r.get('b_name') or 'Bid',
            'company': r.get('company') or '',
            'due_date': r.get('due_date'),
            'current_index': 0,
            'current_stage_key': 'analyzer',
            'stage_progress_map': stage_map,
            'stage_counts': counts,
            'note': '',
            'overall_progress': overall_progress,
            'stages': stages,
        })
    return items


def _augment_go_rows_with_assigned_meta(
    cur,
    go_rows: list[dict],
    *,
    active_company_name: str | None = None,
    max_total: int | None = None,
    include_closed: bool = False,
    limit: int = 200,
) -> list[dict]:
    _ensure_bid_assign_meta_table()
    existing = set()
    for r in (go_rows or []):
        try:
            if r.get('g_id'):
                existing.add(int(r.get('g_id')))
        except Exception:
            pass

    try:
        cur.execute(
            """
            SELECT
                bam.g_id,
                bam.data AS meta_json,
                bam.updated_at,
                gb.b_name,
                gb.company,
                gb.state,
                gb.due_date,
                gb.summary,
                gb.type,
                bi.b_name AS bi_name,
                bi.comp_name,
                bi.state AS bi_state,
                bi.due_date AS bi_due,
                bi.summary AS bi_summary,
                bi.bid_status,
                bi.results,
                wlr.status AS wlr_status,
                wlr.result AS wlr_result
            FROM bid_assign_meta bam
            LEFT JOIN go_bids gb ON gb.g_id = bam.g_id
            LEFT JOIN bid_incoming bi ON (bi.id = gb.id OR bi.id = bam.g_id)
            LEFT JOIN win_lost_results wlr ON wlr.g_id = bam.g_id
            ORDER BY bam.updated_at DESC, bam.g_id DESC
            LIMIT %s
            """,
            (int(limit or 200),),
        )
        rows = cur.fetchall() or []
    except Exception:
        rows = []

    if not rows:
        return go_rows

    ids = []
    for r in rows:
        gid = r.get('g_id')
        try:
            gid = int(gid)
        except Exception:
            gid = None
        if gid and gid not in existing:
            ids.append(gid)

    task_counts = {}
    try:
        if ids:
            placeholders = ",".join(["%s"] * len(ids))
            cur.execute(
                f"""
                SELECT g_id, COUNT(*) AS c
                FROM bid_checklists
                WHERE g_id IN ({placeholders})
                  AND team_archive IS NULL
                GROUP BY g_id
                """,
                tuple(ids),
            )
            for r in (cur.fetchall() or []):
                try:
                    task_counts[int(r.get('g_id'))] = int(r.get('c') or 0)
                except Exception:
                    pass
    except Exception:
        task_counts = {}

    active_company_token = _normalize_company_token(active_company_name)
    for r in rows:
        try:
            gid = int(r.get('g_id') or 0)
        except Exception:
            continue
        if not gid or gid in existing:
            continue
        try:
            meta = json.loads(r.get('meta_json') or "{}")
        except Exception:
            meta = {}
        if not include_closed:
            if _is_closed_bid_status(
                r.get('bid_status'),
                r.get('results'),
                r.get('wlr_status'),
                r.get('wlr_result'),
                meta.get('status'),
                meta.get('result'),
            ):
                continue
        checklist = meta.get('checklist') if isinstance(meta, dict) else None
        has_meta_tasks = isinstance(checklist, list) and len(checklist) > 0
        has_db_tasks = bool(task_counts.get(gid))
        if not (has_meta_tasks or has_db_tasks):
            continue
        name = r.get('b_name') or r.get('bi_name') or meta.get('name') or meta.get('bid_name') or 'Bid'
        company = r.get('company') or r.get('comp_name') or meta.get('company') or meta.get('comp_name') or ''
        if active_company_token:
            company_token = _normalize_company_token(company)
            if company_token and active_company_token not in company_token and company_token not in active_company_token:
                continue
        state = r.get('state') or r.get('bi_state') or meta.get('state') or ''
        due_date = r.get('due_date') or r.get('bi_due') or meta.get('due_date') or meta.get('assign_due_date') or meta.get('start_date') or ''
        summary = r.get('summary') or r.get('bi_summary') or meta.get('summary') or ''
        extra = dict(r)
        extra.update({
            'g_id': gid,
            'b_name': name,
            'company': company,
            'state': state,
            'due_date': due_date,
            'summary': summary,
            'type': r.get('type') or meta.get('type') or '',
            'decision': meta.get('decision') or '',
            'progress': meta.get('progress') or meta.get('scoring') or '',
        })
        go_rows.append(extra)
        existing.add(gid)
        if max_total and len(go_rows) >= max_total:
            break

    return go_rows


def _recalc_bid_team_progress(cur, g_id: int) -> None:
    if not g_id:
        return
    _ensure_bid_team_progress_table(cur)
    try:
        try:
            cur.execute(
                """
                SELECT bc.progress_pct, bc.status, COALESCE(bc.stage, bc.department, u.role) AS stage_source
                FROM bid_checklists bc
                LEFT JOIN users u ON bc.created_by = u.id
                WHERE bc.g_id = %s
                """,
                (int(g_id),),
            )
        except Exception as e:
            if "Unknown column 'department'" in str(e):
                cur.execute(
                    """
                    SELECT bc.progress_pct, bc.status, COALESCE(bc.stage, u.role) AS stage_source
                    FROM bid_checklists bc
                    LEFT JOIN users u ON bc.created_by = u.id
                    WHERE bc.g_id = %s
                    """,
                    (int(g_id),),
                )
            else:
                raise
        rows = cur.fetchall() or []
        buckets = {k: [] for k in ['analyzer', 'business', 'design', 'operations', 'engineer', 'handover']}
        counts = {k: {'total': 0, 'completed': 0} for k in buckets}
        for r in rows:
            stage = _normalize_stage_key(r.get('stage_source'))
            if not stage or stage not in buckets:
                continue
            pct = r.get('progress_pct')
            if pct is None:
                st = (r.get('status') or '').strip().lower()
                pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
            try:
                pct = max(0, min(100, int(pct)))
            except Exception:
                pct = 0
            buckets[stage].append(pct)
            counts[stage]['total'] += 1
            if pct >= 100 or (r.get('status') or '').strip().lower() == 'completed':
                counts[stage]['completed'] += 1
        def avg(lst):
            return int(round(sum(lst) / len(lst))) if lst else 0
        base_avgs = {k: avg(v) for k, v in buckets.items()}
        stage_map, counts = _merge_meta({k: avg(v) for k, v in buckets.items()}, counts)
        buckets = {k: [stage_map.get(k, 0)] for k in buckets}
        for stage_key in buckets.keys():
            progress_pct = stage_map.get(stage_key, 0)
            total = int(counts[stage_key]['total'] or 0)
            completed = int(counts[stage_key]['completed'] or 0)
            cur.execute(
                """
                INSERT INTO bid_team_progress (g_id, stage_key, progress_pct, total_tasks, completed_tasks)
                VALUES (%s, %s, %s, %s, %s)
                ON DUPLICATE KEY UPDATE
                    progress_pct=VALUES(progress_pct),
                    total_tasks=VALUES(total_tasks),
                    completed_tasks=VALUES(completed_tasks),
                    updated_at=CURRENT_TIMESTAMP
                """,
                (int(g_id), stage_key, progress_pct, total, completed),
            )
    except Exception:
        pass

    return desired_db

app.config['MYSQL_DB'] = _select_working_database_name()

mysql = MySQL(app)
# Store mysql on app for blueprint access
app.mysql = mysql  # type: ignore[attr-defined]

socketio = SocketIO(app)

# --- Initialize Security Module ---
init_security(app)

# Make CSRF token available in all templates
@app.context_processor
def inject_csrf_token():
    return {'csrf_token': generate_csrf_token}

_db_init_done = False

@app.before_request
def _init_db_once():
    global _db_init_done
    if not _db_init_done:
        try:
            _ensure_tables_exist()
            # Ensure permissions schema exists early so dashboards/sidebars
            # can safely query role/module permissions without depending on
            # visiting the admin dashboard first.
            ensure_permissions_table()
            # Sanity check for bid_checklists and recover from common errors (1932 orphan tablespace, 1146 missing table)
            def _ensure_bid_checklists_exists():
                create_sql = (
                    """
                    CREATE TABLE IF NOT EXISTS bid_checklists (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        g_id INT NOT NULL,
                        task_name VARCHAR(200) NOT NULL,
                        description TEXT,
                        assigned_to INT,
                        status VARCHAR(50) DEFAULT 'pending',
                        progress_pct INT DEFAULT NULL,
                        stage VARCHAR(50),
                        priority VARCHAR(20) DEFAULT 'medium',
                        due_date DATETIME,
                        attachment_path VARCHAR(255),
                        created_by INT,
                        team_archive VARCHAR(50),
                        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                        updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                        FOREIGN KEY (g_id) REFERENCES go_bids(g_id),
                        FOREIGN KEY (assigned_to) REFERENCES employees(id),
                        FOREIGN KEY (created_by) REFERENCES users(id)
                    ) ENGINE=InnoDB
                    """
                )
                try:
                    c = mysql.connection.cursor()
                    c.execute(create_sql)
                    mysql.connection.commit()
                    c.close()
                except Exception as ce:
                    try:
                        err_no2 = ce.args[0] if hasattr(ce, 'args') and ce.args else None
                    except Exception:
                        err_no2 = None
                    if err_no2 == 1813:  # Orphan tablespace
                        try:
                            c2 = mysql.connection.cursor()
                            c2.execute("SHOW VARIABLES LIKE 'datadir'")
                            row = c2.fetchone()
                            data_dir = None
                            if isinstance(row, (list, tuple)) and len(row) >= 2:
                                data_dir = row[1]
                            elif isinstance(row, dict):
                                data_dir = row.get('Value') or row.get('value')
                            c2.close()
                            if data_dir:
                                db_name = app.config.get('MYSQL_DB', 'esco')
                                ibd_path = os.path.join(data_dir, db_name, 'bid_checklists.ibd')
                                cfg_path = os.path.join(data_dir, db_name, 'bid_checklists.cfg')
                                for p in (ibd_path, cfg_path):
                                    try:
                                        if os.path.exists(p):
                                            os.remove(p)
                                    except Exception:
                                        pass
                        except Exception:
                            pass
                        try:
                            c3 = mysql.connection.cursor()
                            c3.execute("DROP TABLE IF EXISTS bid_checklists")
                            mysql.connection.commit()
                            c3.close()
                        except Exception:
                            pass
                        c4 = mysql.connection.cursor()
                        c4.execute(create_sql)
                        mysql.connection.commit()
                        c4.close()
                    else:
                        raise
            # Verify existence
            success = False
            for _ in range(2):
                try:
                    cur = mysql.connection.cursor()
                    cur.execute("SELECT 1 FROM bid_checklists LIMIT 1")
                    cur.close()
                    success = True
                    break
                except Exception as e:
                    try:
                        err_no = e.args[0] if hasattr(e, 'args') and e.args else None
                    except Exception:
                        err_no = None
                    if err_no in (1146, 1932):
                        _ensure_bid_checklists_exists()
                    else:
                        break
            if success:
                _db_init_done = True
        except Exception as e:
            print(f"Database init error: {e}")

# Removed eager import-time init to avoid referencing functions before definition

def ensure_tasks_for_team(team: str):
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute(
            """
            SELECT gb.g_id
            FROM go_bids gb
            LEFT JOIN bid_checklists bc
              ON bc.g_id = gb.g_id AND LOWER(COALESCE(bc.stage,'')) = %s
            WHERE bc.id IS NULL
            """, (team,)
        )
        missing = [row['g_id'] for row in cur.fetchall()]
        if missing:
            for g_id in missing:
                generate_team_checklist(cur, g_id, team)
            mysql.connection.commit()
    except Exception:
        mysql.connection.rollback()
    finally:
        cur.close()
def assign_bids_by_revenue():
    return None

# assign_go_bids deprecated
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = 'login'

# Ensure anonymous users have the same attribute surface as User to avoid AttributeError.
class _AnonymousUser(AnonymousUserMixin):
    is_admin = False
    role = ''

    @property
    def is_supervisor(self):
        return False

    @property
    def is_team_lead(self):
        return False

    @property
    def can_assign_stages(self):
        return False

    @property
    def can_alter_timeline(self):
        return False

login_manager.anonymous_user = _AnonymousUser

@login_manager.unauthorized_handler
def _unauthorized_handler():
    # Return JSON errors for API endpoints instead of HTML redirects
    try:
        path = request.path or ''
    except Exception:
        path = ''
    if isinstance(path, str) and path.startswith('/api/'):
        return jsonify({'error': 'unauthorized', 'message': 'Login required. Please sign in and try again.'}), 401
    return redirect(url_for('login'))

# Custom User class
class User(UserMixin):
    def __init__(self, id, email, password, is_admin, role):
        self.id = id
        self.email = email
        self.password = password
        self.is_admin = bool(is_admin)
        self.role = role
    
    @property
    def is_supervisor(self):
        return self.role.lower() == 'supervisor'
    
    @property
    def is_team_lead(self):
        return (get_user_role() or '').strip().lower() == 'teamlead'
    
    @property
    def can_assign_stages(self):
        # "Assign stages" means the user can assign/route bids (action: assign_bids).
        # Keep legacy behavior for Admin/Supervisor, but also honor DB/default action permissions.
        if self.is_admin or self.is_supervisor:
            return True
        try:
            perms = get_user_action_permissions(get_user_role() or 'member', is_admin=False)
            return bool(perms.get('assign_bids', False))
        except Exception:
            return False
    
    @property
    def can_alter_timeline(self):
        # Timeline modifications are gated by action permission: manage_timeline
        if self.is_admin or self.is_supervisor:
            return True
        try:
            perms = get_user_action_permissions(get_user_role() or 'member', is_admin=False)
            return bool(perms.get('manage_timeline', False))
        except Exception:
            return False
# --- User Loader for Flask-Login ---
@login_manager.user_loader
def load_user(user_id):
    cur = mysql.connection.cursor(DictCursor)
    cur.execute("SELECT * FROM users WHERE id=%s", (user_id,))
    data = cur.fetchone()
    cur.close()
    if data:
        return User(data['id'], data['email'], data['password'], data['is_admin'], data['role'])
    return None

# --------------------------------------------------------------------
def get_user_company_access(user_id):
    """Return all active company/department/role access rows for a user."""
    cur = mysql.connection.cursor(DictCursor)
    cur.execute("""
        SELECT uca.*, c.name as company_name
        FROM user_company_access uca
        JOIN companies c ON uca.company_id = c.id
        WHERE uca.user_id = %s AND uca.is_active = 1
    """, (user_id,))
    return cur.fetchall()

def user_has_access(user_id, company_id, department_key, role=None):
    """Check if user has access to a company/department/role (user_company_access mapping)."""
    cur = mysql.connection.cursor(DictCursor)
    try:
        sql = """
            SELECT 1 FROM user_company_access
            WHERE user_id=%s AND company_id=%s AND is_active=1
        """
        params = [user_id, company_id]

        dept_key = (department_key or "").strip()
        if dept_key:
            # dept_key match OR "all departments" scope (NULL/empty)
            sql += " AND (department_key=%s OR COALESCE(department_key,'')='')"
            params.append(dept_key)
        else:
            # Explicitly require all-departments scope when no department selected
            sql += " AND COALESCE(department_key,'')=''"

        if role:
            sql += " AND role=%s"
            params.append(role)
        cur.execute(sql, params)
        return cur.fetchone() is not None
    finally:
        try:
            cur.close()
        except Exception:
            pass
# Context-scoped access: active company + department
# --------------------------------------------------------------------
def _fetch_user_access_rows(user_id: int):
    """Return all (company, department, role) access rows for a user."""
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute(
            """
            SELECT
                uca.role,
                uca.department_key,
                uca.company_id,
                c.name AS company_name
            FROM user_company_access uca
            JOIN companies c ON c.id = uca.company_id
            WHERE uca.user_id = %s AND COALESCE(uca.is_active, TRUE) = TRUE
            ORDER BY c.name ASC
            """,
            (user_id,),
        )
        return cur.fetchall() or []
    except Exception:
        return []
    finally:
        cur.close()

def _user_has_any_scoped_rows(user_id: int) -> bool:
    """
    Return True if the user has *any* user_company_access rows (active or inactive).
    If False, we treat the user as "legacy/unrestricted" for company listing UX.
    """
    try:
        total_rows, _active_rows = _scoped_access_counts(int(user_id))
        return int(total_rows) > 0
    except Exception:
        return False

def _denied_company_ids_for_user(user_id: int) -> set[int]:
    """
    "Explicit deny" list for a user: any user_company_access rows with is_active=FALSE.
    We use this to hide companies for Business Managers only when an Admin has explicitly denied them.
    """
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute(
            """
            SELECT DISTINCT company_id
            FROM user_company_access
            WHERE user_id=%s AND COALESCE(is_active, TRUE)=FALSE AND company_id IS NOT NULL
            """,
            (int(user_id),),
        )
        rows = cur.fetchall() or []
        out: set[int] = set()
        for r in rows:
            cid = r.get('company_id')
            if cid is None:
                continue
            try:
                out.add(int(cid))
            except Exception:
                pass
        return out
    except Exception:
        return set()
    finally:
        try:
            cur.close()
        except Exception:
            pass

def _is_company_denied_for_user(user_id: int, company_id: int) -> bool:
    try:
        return int(company_id) in _denied_company_ids_for_user(int(user_id))
    except Exception:
        return False

def _get_visible_companies_for_user(user_id: int, *, is_admin: bool = False):
    def get_visible_companies_for_user(user_id, is_admin=False):
        """Return companies the user should see in dropdowns/menus."""
        cur = mysql.connection.cursor(DictCursor)
        if is_admin:
            cur.execute("SELECT * FROM companies")
            return cur.fetchall()
        cur.execute("""
            SELECT c.* FROM companies c
            JOIN user_company_access uca ON uca.company_id = c.id
            WHERE uca.user_id = %s AND uca.is_active = 1
            GROUP BY c.id
        """, (user_id,))
        return cur.fetchall()
    """
    Return companies the user should see in company dropdowns/menus ("slicers").

    Rules:
    - IT Admins see all companies.
    - If the user has NO scoped rows at all (legacy/unrestricted), show all companies.
    - If the user has scoped rows, show only companies present in user_company_access for that user.
      Include an 'is_active' flag (max over rows) so UI can gray out disabled scopes.
    - If session is locked to a company, return only that company.
    """
    cur = mysql.connection.cursor(DictCursor)
    try:
        # IT Admin: always all companies
        if is_admin:
            cur.execute("SELECT id, name FROM companies ORDER BY name")
            rows = cur.fetchall() or []
            try:
                locked_company_id = session.get('locked_company_id')
                if locked_company_id:
                    rows = [c for c in rows if str(c.get('id')) == str(locked_company_id)]
            except Exception:
                pass
            return rows

        # Business Manager: default = all companies, only restrict when explicitly denied.
        # (Admin-style visibility unless an Admin denies specific orgs.)
        try:
            if int(user_id) == int(getattr(current_user, 'id', -1)) and _is_business_manager_user():
                cur.execute("SELECT id, name FROM companies ORDER BY name")
                rows = cur.fetchall() or []
                denied_ids = _denied_company_ids_for_user(int(user_id))
                if denied_ids:
                    rows = [c for c in rows if int(c.get('id') or 0) not in denied_ids]
                return rows
        except Exception:
            pass

        # Legacy/unrestricted users (no scoped rows at all): show all companies
        if not _user_has_any_scoped_rows(int(user_id)):
            cur.execute("SELECT id, name FROM companies ORDER BY name")
            rows = cur.fetchall() or []
            try:
                locked_company_id = session.get('locked_company_id')
                if locked_company_id:
                    rows = [c for c in rows if str(c.get('id')) == str(locked_company_id)]
            except Exception:
                pass
            return rows

        cur.execute(
            """
            SELECT
              c.id,
              c.name,
              MAX(CASE WHEN COALESCE(uca.is_active, TRUE)=TRUE THEN 1 ELSE 0 END) AS is_active
            FROM user_company_access uca
            JOIN companies c ON c.id = uca.company_id
            WHERE uca.user_id = %s
            GROUP BY c.id, c.name
            ORDER BY c.name ASC
            """,
            (int(user_id),),
        )
        rows = cur.fetchall() or []
        try:
            locked_company_id = session.get('locked_company_id')
            if locked_company_id:
                rows = [c for c in rows if str(c.get('id')) == str(locked_company_id)]
        except Exception:
            pass
        return rows
    except Exception:
        return []
    finally:
        try:
            cur.close()
        except Exception:
            pass

def _scoped_access_counts(user_id: int) -> tuple[int, int]:
    """
    Return (total_rows, active_rows) from user_company_access for a user.
    Used to enforce "Disable" blocking login while staying backwards-compatible
    for legacy users who have zero scoped rows at all.
    """
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute(
            """
            SELECT
              COUNT(*) AS total_rows,
              COALESCE(SUM(CASE WHEN COALESCE(is_active, TRUE)=TRUE THEN 1 ELSE 0 END), 0) AS active_rows
            FROM user_company_access
            WHERE user_id=%s
            """,
            (int(user_id),),
        )
        row = cur.fetchone() or {}
        total_rows = int(row.get('total_rows') or 0)
        active_rows = int(row.get('active_rows') or 0)
        return (total_rows, active_rows)
    except Exception:
        return (0, 0)
    finally:
        try:
            cur.close()
        except Exception:
            pass

def _infer_company_id_for_email(email: str) -> int | None:
    """
    Infer a default/locked company from the user's email.
    Enables per-company credentials like:
      - business_manager@ikio... -> IKIO scope only
      - business_manager@metco... -> METCO scope only
      - business_manager@sunsprint... -> Sunsprint scope only
    """
    try:
        e = (email or '').strip().lower()
    except Exception:
        e = ''
    key = None
    if 'ikio' in e:
        key = 'ikio'
    elif 'metco' in e:
        key = 'metco'
    elif 'sunsprint' in e:
        key = 'sunsprint'
    if not key:
        return None
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute(
            "SELECT id FROM companies WHERE LOWER(COALESCE(name,'')) LIKE %s ORDER BY id ASC LIMIT 1",
            (f"%{key}%",),
        )
        row = cur.fetchone() or {}
        cid = row.get('id')
        return int(cid) if cid is not None else None
    except Exception:
        return None
    finally:
        try:
            cur.close()
        except Exception:
            pass

def _has_active_scope_for_company(user_id: int, company_id: int) -> bool:
    """Return True if user has at least one active scoped access row for the company."""
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute(
            """
            SELECT COUNT(*) AS cnt
            FROM user_company_access
            WHERE user_id=%s AND company_id=%s AND COALESCE(is_active, TRUE)=TRUE
            """,
            (int(user_id), int(company_id)),
        )
        row = cur.fetchone() or {}
        return int(row.get('cnt') or 0) > 0
    except Exception:
        return False
    finally:
        try:
            cur.close()
        except Exception:
            pass

def _resolve_context_role(access_rows, active_company_id, active_department_key):
    """Pick the best matching role given the active company/department."""
    # Priority: manager > team_lead > member > supervisor/top_level_admin (handled elsewhere)
    prio = {'manager': 3, 'teamlead': 2, 'member': 1}
    best = None
    best_score = -1
    for r in access_rows:
        if active_company_id and int(r.get('company_id') or 0) != int(active_company_id):
            continue
        dept = r.get('department_key')
        # NULL dept_key means applies to all depts
        if active_department_key and dept and str(dept) != str(active_department_key):
            continue
        role = (r.get('role') or 'member').strip().lower()
        score = prio.get(role, 0)
        if score > best_score:
            best_score = score
            best = role
    return best or 'member'

@app.before_request
def _apply_active_context():
    """Attach active company/department context + scoped role for the current request."""
    if not current_user.is_authenticated:
        return
    # IT admins are global
    if getattr(current_user, 'is_admin', False):
        current_user.context_role = 'itadmin'
        return

    # Global roles (stored on users.role) override scoped resolver
    try:
        global_role = (getattr(current_user, 'role', '') or '').strip().lower().replace(' ', '').replace('_', '').replace('-', '')
    except Exception:
        global_role = ''
    if global_role in ['topleveladmin', 'topleveladmin']:
        current_user.context_role = 'topleveladmin'
        # Still allow company list + context switching below
    elif global_role in ['supervisor']:
        current_user.context_role = 'supervisor'
        # Still allow company list + context switching below

    # Enforce scoped access disabling for already-authenticated non-admin users.
    # Backwards-compat: only enforce if the user has at least one scoped row (total_rows > 0).
    # Exempt admin-like global roles from scoped access disabling.
    try:
        # Treat legacy role strings like "admin"/"it_admin" as admin-like to avoid lockouts
        exempt_global_roles = {'topleveladmin', 'supervisor', 'itadmin', 'admin', 'itadministrator', 'itadminlogin'}
        if global_role not in exempt_global_roles:
            # Business Managers should NOT be forced into an allow-list model.
            # They can still have explicit denied companies (handled in slicers/switch_context),
            # but should not be logged out just because they have zero "active" scoped rows.
            try:
                if _is_business_manager_user():
                    exempt_global_roles = set(exempt_global_roles) | {'businessmanager'}
            except Exception:
                pass
            # If the session is credential-bound to a company, enforce that company scope.
            locked_company_id = session.get('locked_company_id')
            try:
                locked_company_id = int(locked_company_id) if locked_company_id is not None else None
            except Exception:
                locked_company_id = None

            if locked_company_id is not None:
                # Business Managers should not be pinned to a credential-inferred company.
                try:
                    if _is_business_manager_user():
                        locked_company_id = None
                except Exception:
                    pass
            if locked_company_id is not None:
                if not _has_active_scope_for_company(int(current_user.id), int(locked_company_id)):
                    try:
                        logout_user()
                    except Exception:
                        pass
                    try:
                        session.pop('active_company_id', None)
                        session.pop('active_department_key', None)
                        session.pop('locked_company_id', None)
                    except Exception:
                        pass
                    try:
                        flash('Your login has been disabled for this company by Access Control.', 'error')
                    except Exception:
                        pass
                    return redirect(url_for('login'))
                # Keep active company pinned to the locked company
                session['active_company_id'] = int(locked_company_id)
            else:
                total_rows, active_rows = _scoped_access_counts(int(current_user.id))
                # Do not auto-logout Business Managers for allow-list rows being absent/disabled.
                try:
                    bm = _is_business_manager_user()
                except Exception:
                    bm = False
                if (not bm) and total_rows > 0 and active_rows == 0:
                    try:
                        logout_user()
                    except Exception:
                        pass
                    try:
                        session.pop('active_company_id', None)
                        session.pop('active_department_key', None)
                    except Exception:
                        pass
                    try:
                        flash('Your login has been disabled by Access Control. Please contact an administrator.', 'error')
                    except Exception:
                        pass
                    return redirect(url_for('login'))
    except Exception:
        pass

    access_rows = _fetch_user_access_rows(int(current_user.id))
    # Set default active company/department if missing or invalid
    company_ids = [int(r.get('company_id')) for r in access_rows if r.get('company_id') is not None]
    active_company_id = session.get('active_company_id')
    if company_ids and (not active_company_id or int(active_company_id) not in company_ids):
        session['active_company_id'] = company_ids[0]
        active_company_id = company_ids[0]

    # Department can be NULL (all). If user has only one explicit dept for active company, default to it.
    active_department_key = session.get('active_department_key') or None
    if access_rows and active_company_id:
        depts = [r.get('department_key') for r in access_rows if int(r.get('company_id') or 0) == int(active_company_id)]
        depts = [d for d in depts if d]  # explicit only
        if depts and (not active_department_key or active_department_key not in depts):
            session['active_department_key'] = depts[0]
            active_department_key = depts[0]

    # Expose in g for handlers/templates
    try:
        g.active_company_id = session.get('active_company_id')
        g.active_department_key = session.get('active_department_key')
    except Exception:
        pass

    # Compute effective scoped role (only if not already a global override above)
    if not getattr(current_user, 'context_role', None) or getattr(current_user, 'context_role', None) in ['member', None]:
        current_user.context_role = _resolve_context_role(access_rows, session.get('active_company_id'), session.get('active_department_key'))

def _company_filter_for_go_bids(cur) -> tuple[str, tuple]:
    """
    Build SQL filter for go_bids.company (TEXT) based on the ACTIVE company context.
    Returns (sql_clause, params_tuple).

    NOTE: go_bids stores company as free-text, so we use a LIKE pattern based on
    companies.name. This replaces the old email-domain heuristic.
    """
    try:
        active_company_id = session.get('active_company_id') or getattr(g, 'active_company_id', None)
    except Exception:
        active_company_id = None
    if not active_company_id:
        return ("", tuple())
    try:
        cur.execute("SELECT name FROM companies WHERE id=%s", (int(active_company_id),))
        row = cur.fetchone() or {}
        cname = (row.get('name') or '').strip()
    except Exception:
        cname = ''
    if not cname:
        return ("", tuple())
    name_lower = cname.lower()
    pattern = None
    if 'metco' in name_lower:
        pattern = '%metco%'
    elif 'ikio' in name_lower:
        pattern = '%ikio%'
    elif 'sunsprint' in name_lower:
        pattern = '%sunsprint%'
    else:
        pattern = f"%{name_lower}%"
    return (" AND LOWER(COALESCE(gb.company,'')) LIKE %s", (pattern,))

# --- Auto NO-GO: move overdue bid_incoming rows into nogo_bids + mark decision as NO-GO ---
def _ensure_nogo_bids_table(cur) -> None:
    """
    Create the nogo_bids table (snapshot of bid_incoming rows that became NO-GO due to due_date rules).

    NOTE: We keep bid_incoming rows, but mark decision='NO-GO' and mirror the record into nogo_bids
    for auditing/reporting. go_bids cleanup is handled by sync_go_bids.
    """
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS nogo_bids (
            id INT AUTO_INCREMENT PRIMARY KEY,
            bid_incoming_id INT NOT NULL,
            b_name VARCHAR(100),
            due_date DATE,
            state VARCHAR(100),
            scope TEXT,
            type VARCHAR(100),
            scoring INT,
            comp_name VARCHAR(100),
            original_decision VARCHAR(100),
            summary TEXT,
            moved_reason VARCHAR(255),
            moved_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE KEY uniq_bid_incoming (bid_incoming_id)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """
    )


def _auto_mark_overdue_bids_as_nogo(cur) -> int:
    """
    Any bid_incoming with due_date <= today OR due_date < created_at date will be marked NO-GO
    and mirrored into nogo_bids (one row per bid_incoming.id).
    """
    try:
        _ensure_nogo_bids_table(cur)
        mysql.connection.commit()
    except Exception:
        # Best effort: if DDL fails, don't block the app.
        return 0

    # Only act on bids that are not already terminal states.
    results_guard = ""
    try:
        cur.execute("SHOW COLUMNS FROM bid_incoming LIKE 'results'")
        if cur.fetchone():
            results_guard = "AND UPPER(TRIM(COALESCE(bi.results,''))) NOT IN ('WON','LOST')"
    except Exception:
        results_guard = ""
    where_sql = f"""
        WHERE bi.due_date IS NOT NULL
          AND (
                bi.due_date <= CURDATE()
             OR (bi.created_at IS NOT NULL AND bi.due_date < DATE(bi.created_at))
          )
          AND UPPER(TRIM(COALESCE(bi.decision,''))) NOT IN ('NO-GO','WON','LOST')
          {results_guard}
    """

    try:
        # Mirror into nogo_bids (idempotent via uniq_bid_incoming)
        cur.execute(
            f"""
            INSERT INTO nogo_bids (
                bid_incoming_id,
                b_name,
                due_date,
                state,
                scope,
                type,
                scoring,
                comp_name,
                original_decision,
                summary,
                moved_reason,
                moved_at
            )
            SELECT
                bi.id,
                bi.b_name,
                bi.due_date,
                bi.state,
                bi.scope,
                bi.type,
                bi.scoring,
                bi.comp_name,
                bi.decision,
                bi.summary,
                CASE
                    WHEN bi.due_date <= CURDATE() THEN 'due_date_passed'
                    ELSE 'due_date_before_created'
                END AS moved_reason,
                CURRENT_TIMESTAMP
            FROM bid_incoming bi
            {where_sql}
            ON DUPLICATE KEY UPDATE
                b_name = VALUES(b_name),
                due_date = VALUES(due_date),
                state = VALUES(state),
                scope = VALUES(scope),
                type = VALUES(type),
                scoring = VALUES(scoring),
                comp_name = VALUES(comp_name),
                original_decision = VALUES(original_decision),
                summary = VALUES(summary),
                moved_reason = VALUES(moved_reason),
                moved_at = CURRENT_TIMESTAMP
            """
        )
        mirrored = int(cur.rowcount or 0)

        # Mark as NO-GO in bid_incoming
        cur.execute(
            f"""
            UPDATE bid_incoming bi
            SET bi.decision = 'NO-GO'
            {where_sql}
            """
        )
        updated = int(cur.rowcount or 0)

        # Commit; downstream sync_go_bids will remove any now-non-GO rows from go_bids.
        mysql.connection.commit()
        return max(mirrored, updated)
    except Exception:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        return 0

# --- Utility: ensure GO bids from bid_incoming are mirrored in go_bids ---
def sync_go_bids() -> int:
    """Synchronize GO decisions from bid_incoming into go_bids.

    - Inserts any missing GO bids.
    - Updates existing go_bids rows with the latest information.
    - Removes entries that are no longer marked as GO.

    Returns number of newly inserted rows.
    """
    cur = mysql.connection.cursor(DictCursor)
    inserted = 0
    try:
        # First, auto-mark any overdue bid_incoming rows as NO-GO and mirror to nogo_bids.
        # This keeps the "incoming" table clean and prevents expired bids from staying GO.
        try:
            _auto_mark_overdue_bids_as_nogo(cur)
        except Exception:
            pass

        # Insert new GO bids that do not yet exist in go_bids
        cur.execute(
            """
            INSERT INTO go_bids (id, b_name, due_date, state, scope, type, scoring, company, decision, summary)
            SELECT bi.id,
                   bi.b_name,
                   bi.due_date,
                   COALESCE(NULLIF(TRIM(bi.state), ''), 'business'),
                   bi.scope,
                   bi.type,
                   bi.scoring,
                   bi.comp_name,
                   bi.decision,
                   bi.summary
            FROM bid_incoming bi
            LEFT JOIN go_bids gb ON gb.id = bi.id
            WHERE gb.id IS NULL
              AND UPPER(TRIM(COALESCE(bi.decision, ''))) = 'GO'
            """
        )
        inserted = cur.rowcount or 0

        # Update existing go_bids rows to reflect latest bid_incoming data
        cur.execute(
            """
            UPDATE go_bids gb
            JOIN bid_incoming bi ON bi.id = gb.id
            SET gb.b_name   = bi.b_name,
                gb.due_date = COALESCE(bi.due_date, gb.due_date),
                gb.state    = COALESCE(NULLIF(TRIM(bi.state), ''), gb.state),
                gb.scope    = bi.scope,
                gb.type     = bi.type,
                gb.scoring  = bi.scoring,
                -- Preserve manual company assignment in go_bids (e.g., set by Business Manager).
                -- Only backfill from bid_incoming when go_bids.company is empty.
                gb.company  = COALESCE(NULLIF(TRIM(gb.company), ''), bi.comp_name),
                gb.decision = bi.decision,
                gb.summary  = bi.summary
            WHERE UPPER(TRIM(COALESCE(bi.decision, ''))) = 'GO'
            """
        )

        # Keep submission status aligned with bid_incoming
        try:
            cur.execute("SHOW COLUMNS FROM go_bids LIKE 'submission_status'")
            has_submission_status = cur.fetchone() is not None
        except Exception:
            has_submission_status = False
        if has_submission_status:
            try:
                cur.execute(
                    """
                    UPDATE go_bids gb
                    JOIN bid_incoming bi ON bi.id = gb.id
                    SET gb.submission_status = CASE
                        WHEN LOWER(COALESCE(bi.results,'')) LIKE '%%won%%'
                          OR LOWER(COALESCE(bi.results,'')) LIKE '%%award%%'
                          THEN 'Submitted'
                        WHEN LOWER(COALESCE(bi.bid_status,'')) IN ('submitted','under review','under_review')
                          THEN 'Submitted'
                        WHEN LOWER(COALESCE(bi.bid_status,'')) IN ('pending','in progress','in_progress','work progress','work_progress')
                          THEN 'Work Progress'
                        ELSE gb.submission_status
                    END,
                    gb.submission_reason = CASE
                        WHEN LOWER(COALESCE(bi.results,'')) LIKE '%%won%%'
                          OR LOWER(COALESCE(bi.results,'')) LIKE '%%award%%'
                          THEN 'Won'
                        ELSE gb.submission_reason
                    END
                    WHERE UPPER(TRIM(COALESCE(bi.decision, ''))) = 'GO'
                    """
                )
            except Exception:
                pass

        # Remove duplicate go_bids entries for the same bid_incoming id (keep latest g_id).
        try:
            cur.execute(
                """
                DELETE gb_dup
                FROM go_bids gb_dup
                JOIN go_bids gb_keep
                  ON gb_dup.id = gb_keep.id
                 AND gb_dup.g_id < gb_keep.g_id
                WHERE gb_dup.id IS NOT NULL
                """
            )
        except Exception:
            pass

        # Remove go_bids entries that are no longer GO decisions or missing source
        # First, get the g_id values that need to be deleted
        cur.execute(
            """
            SELECT gb.g_id
            FROM go_bids gb
            LEFT JOIN bid_incoming bi ON bi.id = gb.id
            WHERE gb.id IS NOT NULL
              AND (
                    bi.id IS NULL
                 OR UPPER(TRIM(COALESCE(bi.decision, ''))) <> 'GO'
              )
            """
        )
        g_ids_to_delete = [row['g_id'] for row in cur.fetchall()]
        
        if g_ids_to_delete:
            # Keep bids that are actively managed (have bid_assign_meta)
            try:
                _ensure_bid_assign_meta_table()
                placeholders = ','.join(['%s'] * len(g_ids_to_delete))
                cur.execute(
                    f"SELECT g_id FROM bid_assign_meta WHERE g_id IN ({placeholders})",
                    g_ids_to_delete,
                )
                protected = {int(r.get('g_id')) for r in (cur.fetchall() or []) if r.get('g_id')}
                if protected:
                    g_ids_to_delete = [g for g in g_ids_to_delete if int(g) not in protected]
            except Exception:
                pass
        if g_ids_to_delete:
            # Delete from all tables that have foreign key constraints
            placeholders = ','.join(['%s'] * len(g_ids_to_delete))
            
            # Delete from bid_checklists
            try:
                cur.execute(f"DELETE FROM bid_checklists WHERE g_id IN ({placeholders})", g_ids_to_delete)
            except Exception:
                pass
            
            # Delete from bid_stage_exclusions
            try:
                cur.execute(f"DELETE FROM bid_stage_exclusions WHERE g_id IN ({placeholders})", g_ids_to_delete)
            except Exception:
                pass
            
            # Delete from bid_custom_stages
            try:
                cur.execute(f"DELETE FROM bid_custom_stages WHERE g_id IN ({placeholders})", g_ids_to_delete)
            except Exception:
                pass

            # Delete from bid_comments (FK to go_bids)
            try:
                cur.execute(f"DELETE FROM bid_comments WHERE g_id IN ({placeholders})", g_ids_to_delete)
            except Exception:
                pass
            
            # Delete from bid_assignment_members
            try:
                cur.execute(f"DELETE FROM bid_assignment_members WHERE g_id IN ({placeholders})", g_ids_to_delete)
            except Exception:
                pass
            
            # Get a_id values from bid_assign before deleting
            cur.execute(f"SELECT a_id FROM bid_assign WHERE g_id IN ({placeholders})", g_ids_to_delete)
            a_ids = [row['a_id'] for row in cur.fetchall() if row.get('a_id')]
            
            # Delete from bid_assign
            try:
                cur.execute(f"DELETE FROM bid_assign WHERE g_id IN ({placeholders})", g_ids_to_delete)
            except Exception:
                pass
            
            # Delete related win_lost_results, won_bids_result, and work_progress_status
            if a_ids:
                a_placeholders = ','.join(['%s'] * len(a_ids))
                try:
                    cur.execute(f"SELECT w_id FROM win_lost_results WHERE a_id IN ({a_placeholders})", a_ids)
                    w_ids = [row['w_id'] for row in cur.fetchall() if row.get('w_id')]
                    
                    if w_ids:
                        w_placeholders = ','.join(['%s'] * len(w_ids))
                        try:
                            cur.execute(f"SELECT won_id FROM won_bids_result WHERE w_id IN ({w_placeholders})", w_ids)
                            won_ids = [row['won_id'] for row in cur.fetchall() if row.get('won_id')]
                            
                            if won_ids:
                                won_placeholders = ','.join(['%s'] * len(won_ids))
                                try:
                                    cur.execute(f"DELETE FROM work_progress_status WHERE won_id IN ({won_placeholders})", won_ids)
                                except Exception:
                                    pass
                            
                            try:
                                cur.execute(f"DELETE FROM won_bids_result WHERE w_id IN ({w_placeholders})", w_ids)
                            except Exception:
                                pass
                        except Exception:
                            pass
                    
                    try:
                        cur.execute(f"DELETE FROM win_lost_results WHERE a_id IN ({a_placeholders})", a_ids)
                    except Exception:
                        pass
                except Exception:
                    pass
            
            # Finally, delete from go_bids
            cur.execute(
                """
                DELETE gb FROM go_bids gb
                LEFT JOIN bid_incoming bi ON bi.id = gb.id
                WHERE gb.id IS NOT NULL
                  AND (
                        bi.id IS NULL
                     OR UPPER(TRIM(COALESCE(bi.decision, ''))) <> 'GO'
                  )
                """
            )

        # Sync won bids from bid_incoming into win_lost_results + project timeline
        try:
            _sync_won_bids_from_incoming(cur)
        except Exception:
            pass

        mysql.connection.commit()
        return inserted
    except Exception as sync_err:
        mysql.connection.rollback()
        print(f"Error synchronizing GO bids: {sync_err}")
        return 0
    finally:
        cur.close()


def _sync_won_bids_from_incoming(cur) -> None:
    """Ensure bid_incoming won rows exist in win_lost_results and project timelines."""
    try:
        _ensure_project_timeline_tables(cur)
    except Exception:
        pass

    try:
        cur.execute(
            """
            SELECT
                bi.id,
                bi.b_name,
                bi.comp_name,
                bi.state,
                bi.scope,
                bi.due_date,
                bi.results,
                bi.bid_status
            FROM bid_incoming bi
            WHERE (
                LOWER(COALESCE(bi.results,'')) LIKE '%%won%%'
                OR LOWER(COALESCE(bi.results,'')) LIKE '%%award%%'
                OR LOWER(COALESCE(bi.bid_status,'')) LIKE '%%won%%'
                OR LOWER(COALESCE(bi.bid_status,'')) LIKE '%%award%%'
            )
              AND LOWER(COALESCE(bi.results,'')) NOT LIKE '%%lost%%'
              AND LOWER(COALESCE(bi.bid_status,'')) NOT LIKE '%%lost%%'
            """
        )
        rows = cur.fetchall() or []
    except Exception:
        rows = []

    default_project_stages = [
        'Engineering Team',
        'Procurement Team',
        'Accounts & Finance Team',
    ]

    for r in rows:
        bid_id = r.get('id')
        if not bid_id:
            continue
        g_id = None
        gb = None
        try:
            g_id, gb = _ensure_go_bid_from_incoming(int(bid_id))
        except Exception:
            g_id = None
            gb = None
        if not g_id:
            continue

        company = None
        state = None
        b_name = None
        try:
            if isinstance(gb, dict):
                company = gb.get('company')
                state = gb.get('state')
                b_name = gb.get('b_name')
        except Exception:
            pass
        if not company:
            company = r.get('comp_name')
        if not state:
            state = r.get('state')
        if not b_name:
            b_name = r.get('b_name')

        w_id = None
        try:
            cur.execute("SELECT w_id, result FROM win_lost_results WHERE g_id=%s", (int(g_id),))
            existing = cur.fetchone() or {}
            w_id = existing.get('w_id')
            if w_id:
                if (existing.get('result') or '').strip().lower() not in ('won', 'awarded', 'win'):
                    cur.execute(
                        """
                        UPDATE win_lost_results
                        SET result=%s, status=%s, b_name=%s, company=%s, state=%s
                        WHERE g_id=%s
                        """,
                        ('WON', 'WON', b_name, company, state, int(g_id)),
                    )
            else:
                cur.execute("SELECT a_id FROM bid_assign WHERE g_id=%s LIMIT 1", (int(g_id),))
                assign_row = cur.fetchone() or {}
                a_id = assign_row.get('a_id')
                cur.execute(
                    """
                    INSERT INTO win_lost_results (g_id, a_id, b_name, company, state, result, status)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                    """,
                    (int(g_id), a_id, b_name, company, state, 'WON', 'WON'),
                )
                cur.execute("SELECT w_id FROM win_lost_results WHERE g_id=%s", (int(g_id),))
                w_id = (cur.fetchone() or {}).get('w_id')
        except Exception:
            continue

        if not w_id:
            continue

        try:
            cur.execute("SELECT won_id FROM won_bids_result WHERE w_id=%s", (int(w_id),))
            if not cur.fetchone():
                cur.execute(
                    """
                    INSERT INTO won_bids_result (w_id, closure_status, work_progress_status)
                    VALUES (%s, 'Open', 'Not Started')
                    """,
                    (int(w_id),),
                )
        except Exception:
            pass

        try:
            _seed_project_timeline(cur, int(w_id), default_project_stages)
        except Exception:
            pass

# ================================================================================
# SEPARATE ADMIN LOGIN PAGES
# ================================================================================

@app.route('/admin/login', methods=['GET', 'POST'])
@rate_limit(max_requests=5, window_seconds=300)  # Stricter rate limit for admin login: 5 attempts per 5 minutes
def it_admin_login():
    """IT Administrator Login - Separate login page for IT Admins (is_admin=1)"""
    if current_user.is_authenticated:
        if current_user.is_admin:
            return redirect(url_for('top_admin_overview'))
        return redirect(url_for('dashboard'))
    
    error = None
    if request.method == 'POST':
        # Validate CSRF token
        if not validate_csrf_token():
            audit_log.log_csrf_failure(get_client_ip(), '/admin/login')
            error = "Security validation failed. Please try again."
            return render_template('it_admin_login.html', error=error)
        
        email = sanitize_input(request.form.get('email', '').strip())
        password = request.form.get('password', '')
        
        if not email or not password:
            error = "Please enter both email and password."
            return render_template('it_admin_login.html', error=error)
        
        cur = mysql.connection.cursor(DictCursor)
        cur.execute("SELECT * FROM users WHERE email=%s", (email,))
        user = cur.fetchone()
        cur.close()
        
        if user:
            # Verify password securely
            if verify_password(password, user['password']):
                # Check if user is IT Admin (is_admin = 1)
                if user['is_admin']:
                    # Upgrade password if plaintext
                    if not is_password_hashed(user['password']):
                        try:
                            hashed = hash_password(password)
                            cur2 = mysql.connection.cursor()
                            cur2.execute("UPDATE users SET password=%s WHERE id=%s", (hashed, user['id']))
                            mysql.connection.commit()
                            cur2.close()
                        except Exception:
                            pass
                    
                    user_obj = User(user['id'], user['email'], user['password'], user['is_admin'], user['role'])
                    login_user(user_obj)
                    regenerate_session()
                    try:
                        cur2 = mysql.connection.cursor()
                        cur2.execute("UPDATE users SET last_active = NOW() WHERE id = %s", (user['id'],))
                        mysql.connection.commit()
                        cur2.close()
                    except Exception:
                        pass
                    
                    audit_log.log_login_attempt(email, True, get_client_ip(), request.user_agent.string)
                    audit_log.log_admin_action(email, 'it_admin_login', details=f"IP: {get_client_ip()}")
                    log_write('it_admin_login', f"IT Admin login: {email}")
                    return redirect(url_for('top_admin_overview'))
                else:
                    audit_log.log_permission_denied(email, '/admin/login', 'IT Admin access attempted by non-admin')
                    error = "Access Denied: This portal is for IT Administrators only. Please use the appropriate login."
            else:
                audit_log.log_login_attempt(email, False, get_client_ip(), request.user_agent.string)
                error = "Invalid credentials. Please check your email and password."
        else:
            audit_log.log_login_attempt(email, False, get_client_ip(), request.user_agent.string)
            error = "Invalid credentials. Please check your email and password."
    
    return render_template('it_admin_login.html', error=error)

@app.route('/top-admin/login', methods=['GET', 'POST'])
@rate_limit(max_requests=5, window_seconds=300)  # Stricter rate limit: 5 attempts per 5 minutes
def top_level_admin_login():
    """Top Level Admin Login - Separate login page for Top Level Admins (role=topleveladmin)"""
    if current_user.is_authenticated:
        user_role = getattr(current_user, 'role', '').lower().replace(' ', '_')
        if user_role.replace('_', '') in ['topleveladmin', 'topleveladmin']:
            return redirect(url_for('top_level_admin_dashboard'))
        if current_user.is_admin:
            return redirect(url_for('top_admin_overview'))
        return redirect(url_for('dashboard'))
    
    error = None
    if request.method == 'POST':
        # Validate CSRF token
        if not validate_csrf_token():
            audit_log.log_csrf_failure(get_client_ip(), '/top-admin/login')
            error = "Security validation failed. Please try again."
            return render_template('top_level_admin_login.html', error=error)
        
        email = sanitize_input(request.form.get('email', '').strip())
        password = request.form.get('password', '')
        
        if not email or not password:
            error = "Please enter both email and password."
            return render_template('top_level_admin_login.html', error=error)
        
        cur = mysql.connection.cursor(DictCursor)
        cur.execute("SELECT * FROM users WHERE email=%s", (email,))
        user = cur.fetchone()
        cur.close()
        
        if user:
            # Verify password securely
            if verify_password(password, user['password']):
                role = (user['role'] or '').lower().replace(' ', '_')
                # Check if user is Top Level Admin (role = 'topleveladmin' and is_admin = 0)
                if role.replace('_', '') in ['topleveladmin', 'topleveladmin'] and not user['is_admin']:
                    # Upgrade password if plaintext
                    if not is_password_hashed(user['password']):
                        try:
                            hashed = hash_password(password)
                            cur2 = mysql.connection.cursor()
                            cur2.execute("UPDATE users SET password=%s WHERE id=%s", (hashed, user['id']))
                            mysql.connection.commit()
                            cur2.close()
                        except Exception:
                            pass
                    
                    user_obj = User(user['id'], user['email'], user['password'], user['is_admin'], user['role'])
                    login_user(user_obj)
                    regenerate_session()
                    try:
                        cur2 = mysql.connection.cursor()
                        cur2.execute("UPDATE users SET last_active = NOW() WHERE id = %s", (user['id'],))
                        mysql.connection.commit()
                        cur2.close()
                    except Exception:
                        pass
                    
                    audit_log.log_login_attempt(email, True, get_client_ip(), request.user_agent.string)
                    log_write('top_admin_login', f"Top Level Admin login: {email}")
                    return redirect(url_for('top_level_admin_dashboard'))
                elif user['is_admin']:
                    audit_log.log_permission_denied(email, '/top-admin/login', 'IT Admin tried Top Admin portal')
                    error = "You are an IT Administrator. Please use the IT Admin Login portal."
                else:
                    audit_log.log_permission_denied(email, '/top-admin/login', f"Non-admin role: {role}")
                    error = "Access Denied: This portal is for Top Level Administrators only."
            else:
                audit_log.log_login_attempt(email, False, get_client_ip(), request.user_agent.string)
                error = "Invalid credentials. Please check your email and password."
        else:
            audit_log.log_login_attempt(email, False, get_client_ip(), request.user_agent.string)
            error = "Invalid credentials. Please check your email and password."
    
    return render_template('top_level_admin_login.html', error=error)

@app.route('/login', methods=['GET', 'POST'])
@rate_limit(max_requests=10, window_seconds=60)  # Rate limit: 10 attempts per minute
def login():
    """Secure login route with password hashing support and rate limiting."""
    if current_user.is_authenticated:
        # If user is already logged in, route them to the correct dashboard
        role_key = ((getattr(current_user, 'role', '') or '').lower().strip()).replace('_', ' ')
        if getattr(current_user, 'is_admin', False):
            return redirect(url_for('top_admin_overview'))
        if role_key.replace(' ', '') in ['topleveladmin', 'topleveladmin', 'topleveladmin']:
            return redirect(url_for('top_level_admin_dashboard'))
        if role_key.replace(' ', '') in ['teamlead', 'teamlead', 'teamlead']:
            return redirect(url_for('team_lead_dashboard'))
        return redirect(url_for('dashboard'))
    
    error = None
    if request.method == 'POST':
        # Validate CSRF token
        if not validate_csrf_token():
            audit_log.log_csrf_failure(get_client_ip(), '/login')
            error = "Security validation failed. Please try again."
            return render_template('login.html', error=error)
        
        email = sanitize_input(request.form.get('email', '').strip())
        password = request.form.get('password', '')
        
        # Input validation
        if not email or not password:
            error = "Please enter both email and password."
            return render_template('login.html', error=error)
        
        if not validate_email(email):
            error = "Please enter a valid email address."
            audit_log.log_login_attempt(email, False, get_client_ip(), request.user_agent.string)
            return render_template('login.html', error=error)
        
        cur = mysql.connection.cursor(DictCursor)
        # Fetch user by email only (we'll verify password separately)
        cur.execute("SELECT * FROM users WHERE email=%s", (email,))
        user = cur.fetchone()
        
        if user:
            stored_password = user['password']
            # Verify password (supports both hashed and legacy plaintext)
            password_valid = verify_password(password, stored_password)
            
            if password_valid:
                # Enforce account active + scoped access controls at login (non-admin only).
                try:
                    is_admin_user = bool(int(user.get('is_admin') or 0))
                except Exception:
                    is_admin_user = bool(user.get('is_admin'))

                role_raw = (user.get('role') or '')
                role_norm = role_raw.strip().lower().replace(' ', '').replace('_', '').replace('-', '')
                is_business_manager_login = (role_norm == 'businessmanager')
                # Admin must never be locked out even if their legacy role string is used.
                exempt_global_roles = {'topleveladmin', 'supervisor', 'itadmin', 'admin', 'itadministrator'}

                if not is_admin_user and role_norm not in exempt_global_roles:
                    # 1) Hard account disable flag on users table (if present)
                    try:
                        is_active_flag = user.get('is_active', True)
                        is_active_bool = bool(int(is_active_flag)) if isinstance(is_active_flag, (int, str)) else bool(is_active_flag)
                    except Exception:
                        is_active_bool = True
                    if not is_active_bool:
                        try:
                            cur.close()
                        except Exception:
                            pass
                        audit_log.log_login_attempt(email, False, get_client_ip(), request.user_agent.string)
                        error = "User not found or inactive. Please contact an administrator."
                        return render_template('login.html', error=error)

                    # 2) Scoped access rows:
                    # - If credentials imply a company, require an active scope for that company.
                    # - Otherwise (legacy), require at least one active scope overall.
                    #
                    # Business Managers are NOT company-locked by email; they default to all orgs unless explicitly denied.
                    try:
                        inferred_company_id = _infer_company_id_for_email(email)
                    except Exception:
                        inferred_company_id = None

                    if is_business_manager_login: 
                        inferred_company_id = None 
 
                    if inferred_company_id is not None: 
                        # Backwards-compat: users with zero scoped rows should not be blocked at login,
                        # even if their email implies a company key (ikio/metco/sunsprint).
                        try: 
                            total_rows, active_rows = _scoped_access_counts(int(user['id'])) 
                        except Exception: 
                            total_rows, active_rows = (0, 0) 
                        if total_rows > 0 and (not _has_active_scope_for_company(int(user['id']), int(inferred_company_id))): 
                            try: 
                                cur.close() 
                            except Exception: 
                                pass 
                            audit_log.log_login_attempt(email, False, get_client_ip(), request.user_agent.string) 
                            error = "Your access for this company is disabled by Access Control settings." 
                            return render_template('login.html', error=error) 
                    else: 
                        try: 
                            total_rows, active_rows = _scoped_access_counts(int(user['id'])) 
                        except Exception:
                            total_rows, active_rows = (0, 0)
                        if total_rows > 0 and active_rows == 0:
                            try:
                                cur.close()
                            except Exception:
                                pass
                            audit_log.log_login_attempt(email, False, get_client_ip(), request.user_agent.string)
                            error = "Your access is disabled by Access Control settings. Please contact an administrator."
                            return render_template('login.html', error=error)

                try:
                    cur.close()
                except Exception:
                    pass

                # If password was plaintext, upgrade it to hashed (only after passing access checks)
                if not is_password_hashed(stored_password):
                    try:
                        hashed = hash_password(password)
                        cur2 = mysql.connection.cursor()
                        cur2.execute("UPDATE users SET password=%s WHERE id=%s", (hashed, user['id']))
                        mysql.connection.commit()
                        cur2.close()
                        audit_log.log_admin_action('system', 'password_upgrade', f"user_id={user['id']}")
                    except Exception as e:
                        print(f"Password upgrade failed: {e}")
                
                user_obj = User(user['id'], user['email'], user['password'], user['is_admin'], user['role'])
                login_user(user_obj)
                regenerate_session()  # Prevent session fixation
                try:
                    cur2 = mysql.connection.cursor()
                    cur2.execute("UPDATE users SET last_active = NOW() WHERE id = %s", (user['id'],))
                    mysql.connection.commit()
                    cur2.close()
                except Exception:
                    pass

                # Initialize active context (company/department) for this session
                try:
                    access_rows = _fetch_user_access_rows(int(user['id']))
                    if access_rows:
                        inferred_company_id = _infer_company_id_for_email(email)
                        if inferred_company_id is not None and (not is_business_manager_login):
                            session['locked_company_id'] = int(inferred_company_id)
                            session['active_company_id'] = int(inferred_company_id)
                        else:
                            session.pop('locked_company_id', None)
                            session['active_company_id'] = int(access_rows[0].get('company_id'))
                        # Prefer explicit department if present; otherwise keep it empty (all)
                        dept_key = access_rows[0].get('department_key')
                        if dept_key:
                            session['active_department_key'] = dept_key
                        else:
                            session.pop('active_department_key', None)
                except Exception:
                    pass
                
                # Log successful login
                audit_log.log_login_attempt(email, True, get_client_ip(), request.user_agent.string)
                log_write('login', f"role={user['role']}")
                
                # IT Admin goes to admin dashboard
                if user['is_admin']:
                    return redirect(url_for('top_admin_overview'))
                
                # Role-based redirects
                # Global role redirects (users.role)
                role_raw = (user.get('role') or '')
                role_raw_key = role_raw.lower().strip()
                role_key = role_raw_key.replace('_', ' ')

                # Top Level Admin gets their own dashboard (global role)
                if role_key.replace(' ', '') in ['topleveladmin', 'top level admin'.replace(' ', '')]:
                    return redirect(url_for('top_level_admin_dashboard'))
                if role_key == 'supervisor':
                    return redirect(url_for('manager_dashboard'))
                if role_raw_key in ['business_manager', 'business manager'] or role_key == 'business manager':
                    return redirect(url_for('business_manager_team_allocation'))

                # Scoped role redirects (user_company_access)
                try:
                    access_rows = _fetch_user_access_rows(int(user['id']))
                except Exception:
                    access_rows = []
                roles = {(r.get('role') or '').strip().lower() for r in (access_rows or [])}
                # Business Manager (scoped): if user is a manager for Business dept, route to BDM pages.
                try:
                    has_business_mgr_scope = any(
                        ((r.get('role') or '').strip().lower() == 'manager')
                        and ((r.get('department_key') or '').strip().lower() in ['business', 'business_dev', 'business_development'])
                        for r in (access_rows or [])
                    )
                except Exception:
                    has_business_mgr_scope = False
                if has_business_mgr_scope:
                    return redirect(url_for('business_manager_team_allocation'))
                if 'manager' in roles:
                    return redirect(url_for('manager_dashboard'))
                if 'teamlead' in roles:
                    return redirect(url_for('team_lead_dashboard'))
                if 'member' in roles:
                    return redirect(url_for('employee_dashboard_member'))

                return redirect(url_for('dashboard'))
        
        # Fallback: try authenticating as employee
        try:
            # Ensure password column exists before querying
            cur.execute("SHOW COLUMNS FROM employees LIKE 'password'")
            if cur.fetchone() is None:
                cur.close()
                error = "Employee login temporarily unavailable."
                audit_log.log_login_attempt(email, False, get_client_ip(), request.user_agent.string)
                return render_template('login.html', error=error)
            
            cur.execute("SELECT * FROM employees WHERE email=%s", (email,))
            employee = cur.fetchone()
            
            if employee:
                try:
                    is_active_flag = employee.get('is_active', True)
                    is_active_bool = bool(int(is_active_flag)) if isinstance(is_active_flag, (int, str)) else bool(is_active_flag)
                except Exception:
                    is_active_bool = True
                if not is_active_bool:
                    try:
                        cur.close()
                    except Exception:
                        pass
                    audit_log.log_login_attempt(email, False, get_client_ip(), request.user_agent.string)
                    error = "User not found or inactive. Please contact an administrator."
                    return render_template('login.html', error=error)
                emp_password = employee.get('password', '')
                emp_password_valid = verify_password(password, emp_password)
                
                if emp_password_valid:
                    # Upgrade password if plaintext
                    if not is_password_hashed(emp_password):
                        try:
                            hashed = hash_password(password)
                            cur.execute("UPDATE employees SET password=%s WHERE id=%s", (hashed, employee['id']))
                            mysql.connection.commit()
                        except Exception:
                            pass
                    try:
                        cur.execute("UPDATE employees SET last_active = NOW() WHERE id = %s", (employee['id'],))
                        mysql.connection.commit()
                    except Exception:
                        pass
                    
                    cur.close()
                    session['employee_id'] = employee['id']
                    session['employee_name'] = employee['name']
                    session['employee_email'] = employee['email']
                    session['employee_department'] = employee['department']
                    regenerate_session()
                    
                    audit_log.log_login_attempt(email, True, get_client_ip(), request.user_agent.string)
                    log_write('employee_login', f"Employee {employee['name']} logged in via /login")
                    return redirect(url_for('employee_dashboard', employee_id=employee['id']))
        except Exception as e:
            print(f"Employee login error: {e}")
        finally:
            try:
                cur.close()
            except:
                pass
        
        # Log failed login attempt
        audit_log.log_login_attempt(email, False, get_client_ip(), request.user_agent.string)
        error = "Invalid email or password. Please try again."
    
    return render_template('login.html', error=error)

# ================================================================================
# CONTEXT SWITCHING (active company / department)
# ================================================================================

@app.route('/context/switch', methods=['POST'])
@login_required
@csrf_protect
def switch_context():
    """Switch the active company/department context for the current session."""
    company_id = request.form.get('company_id', type=int)
    department_key = (request.form.get('department_key') or '').strip() or None
    if not company_id:
        flash('Please select a company.', 'danger')
        return redirect(request.referrer or url_for('dashboard'))
    # Validate user has access using mapping table
    if not getattr(current_user, 'is_admin', False):
        if not user_has_access(current_user.id, company_id, department_key):
            flash('Access denied for selected company/department.', 'danger')
            return redirect(url_for('dashboard'))
    session['active_company_id'] = company_id
    if department_key:
        session['active_department_key'] = department_key
    else:
        session.pop('active_department_key', None)
    # Clean up legacy key if present
    session.pop('active_department', None)
    flash('Switched company/department context!', 'success')
    next_url = request.form.get('next') or request.referrer or url_for('dashboard')
    return redirect(next_url)

@app.route('/admin/users', methods=['GET', 'POST'])
@login_required
def users_admin():
    """
    Legacy user list/create page.

    - IT Admins should use the modern IT Admin dashboard user management tools.
    - Top Level Admins get read-only visibility (org/user directory) for tracking.
    """
    # Route IT Admins to the main Admin dashboard (source of truth for user management).
    if getattr(current_user, 'is_admin', False):
        return redirect(url_for('top_admin_overview'))

    # Allow Top Level Admin to view users (read-only).
    if (get_user_role() or '').lower() != 'topleveladmin':
        return "Access Denied", 403
    cur = mysql.connection.cursor(DictCursor)
    if request.method == 'POST':
        # Keep this page read-only for Top Level Admin (avoid creating users with plaintext passwords).
        return "Access Denied", 403
        email = request.form.get('email', '').strip()
        password = request.form.get('password', '').strip()
        role = request.form.get('role', 'member').strip() or 'member'
        if not email or not password:
            return 'Email and password required', 400
        # Check if email already exists
        cur.execute("SELECT id FROM users WHERE email=%s", (email,))
        if cur.fetchone():
            cur.close()
            return 'Email already exists', 400
        is_admin = 1 if role.lower() == "admin" else 0
        cur.execute("INSERT INTO users (email, password, role, is_admin) VALUES (%s, %s, %s, %s)",
                    (email, password, role, is_admin))
        mysql.connection.commit()
        cur.close()
        return redirect(url_for('users_admin'))
    cur.execute("SELECT * FROM users ORDER BY id ASC")
    users = cur.fetchall()
    cur.close()
    return render_template('users.html', users=users, view_only=True)

# ================================================================================
# IT ADMIN DASHBOARD - Complete Access Control System
# ================================================================================

# Default modules for access control
DEFAULT_MODULES = [
    {'key': 'company_dashboards', 'name': 'Company Dashboards', 'icon': 'building', 'color': 'green'},
    # NOTE: key kept as bid_analyzer for backward-compatible permissions
    {'key': 'bid_analyzer', 'name': 'Bid Dashboard', 'icon': 'chart-line', 'color': 'purple'},
    {'key': 'manager_dashboard', 'name': 'Manager Dashboards', 'icon': 'briefcase', 'color': 'teal'},
    {'key': 'project_manager_dashboard', 'name': 'Project Manager Dashboard', 'icon': 'clipboard-list', 'color': 'teal'},
    {'key': 'team_lead_dashboard', 'name': 'Team Lead Dashboard', 'icon': 'users', 'color': 'teal'},
    {'key': 'employee_dashboard', 'name': 'Employee Dashboard', 'icon': 'user', 'color': 'teal'},
    {'key': 'assigned_tasks', 'name': 'Assigned Tasks', 'icon': 'list-check', 'color': 'teal'},
    {'key': 'approvals', 'name': 'Approvals', 'icon': 'check-circle', 'color': 'emerald'},
    {'key': 'bid_timeline', 'name': 'Bid Timeline', 'icon': 'timeline', 'color': 'indigo'},
    {'key': 'business_manager_dashboard', 'name': 'Business Manager Dashboard', 'icon': 'clipboard-list', 'color': 'cyan'},
    # Business Development Manager (Business Manager) tools
    {'key': 'business_manager_team_allocation', 'name': 'BDM: Team Allocation', 'icon': 'sitemap', 'color': 'cyan'},
    {'key': 'team_management', 'name': 'Team Management', 'icon': 'users-cog', 'color': 'pink'},
    {'key': 'user_management', 'name': 'User Management', 'icon': 'users', 'color': 'red'},
    {'key': 'logs', 'name': 'Activity Logs', 'icon': 'history', 'color': 'gray'},
]

# Default actions for access control
DEFAULT_ACTIONS = [
    {'key': 'create_user', 'name': 'Create Users', 'icon': 'user-plus', 'color': 'green', 'description': 'Ability to create new user accounts'},
    {'key': 'delete_user', 'name': 'Delete Users', 'icon': 'user-minus', 'color': 'red', 'description': 'Ability to delete user accounts'},
    {'key': 'edit_permissions', 'name': 'Edit Permissions', 'icon': 'key', 'color': 'yellow', 'description': 'Ability to modify role permissions'},
    {'key': 'advance_stage', 'name': 'Advance Bid Stage', 'icon': 'forward', 'color': 'blue', 'description': 'Ability to move bids to next stage'},
    {'key': 'assign_bids', 'name': 'Assign Bids', 'icon': 'tasks', 'color': 'purple', 'description': 'Ability to assign bids to team members'},
    {'key': 'create_bid', 'name': 'Create Bid', 'icon': 'plus', 'color': 'green', 'description': 'Ability to create new bids'},
    {'key': 'analyze_bid', 'name': 'Upload & Analyze', 'icon': 'upload', 'color': 'purple', 'description': 'Ability to upload and analyze bids'},
    {'key': 'import_data', 'name': 'Import Data', 'icon': 'file-import', 'color': 'cyan', 'description': 'Ability to import data'},
    {'key': 'export_data', 'name': 'Export Data', 'icon': 'file-export', 'color': 'cyan', 'description': 'Ability to export system data'},
    {'key': 'create_record', 'name': 'Create Record', 'icon': 'plus-square', 'color': 'green', 'description': 'Ability to create database records'},
    {'key': 'edit_record', 'name': 'Edit Record', 'icon': 'pen', 'color': 'yellow', 'description': 'Ability to edit database records'},
    {'key': 'delete_record', 'name': 'Delete Record', 'icon': 'trash', 'color': 'red', 'description': 'Ability to delete database records'},
    {'key': 'view_all_logs', 'name': 'View All Logs', 'icon': 'eye', 'color': 'orange', 'description': 'Access to complete activity logs'},
    {'key': 'manage_timeline', 'name': 'Manage Timeline', 'icon': 'calendar-alt', 'color': 'pink', 'description': 'Ability to modify project timelines'},
    {'key': 'approve_item', 'name': 'Approve Items', 'icon': 'check', 'color': 'emerald', 'description': 'Approve uploads and comments'},
    {'key': 'reject_item', 'name': 'Reject Items', 'icon': 'xmark', 'color': 'rose', 'description': 'Reject uploads and comments'},
    {'key': 'revert_item', 'name': 'Revert Items', 'icon': 'rotate-left', 'color': 'amber', 'description': 'Request changes / revert items'},
    {'key': 'escalate_item', 'name': 'Escalate Items', 'icon': 'arrow-up-right', 'color': 'indigo', 'description': 'Escalate approval target'},
]

# Map actions to module CRUD requirements (module_key, permission)
ACTION_MODULE_REQUIREMENTS = {
    'create_user': ('user_management', 'create'),
    'delete_user': ('user_management', 'delete'),
    'edit_permissions': ('user_management', 'edit'),
    'advance_stage': ('bid_analyzer', 'edit'),
    'assign_bids': ('assigned_tasks', 'edit'),
    'create_bid': ('bid_analyzer', 'create'),
    'analyze_bid': ('bid_analyzer', 'create'),
    'manage_timeline': ('bid_timeline', 'edit'),
    'approve_item': ('approvals', 'edit'),
    'reject_item': ('approvals', 'edit'),
    'revert_item': ('approvals', 'edit'),
    'escalate_item': ('approvals', 'edit'),
    'import_data': ('logs', 'create'),
    'export_data': ('logs', 'view'),
    'create_record': ('logs', 'create'),
    'edit_record': ('logs', 'edit'),
    'delete_record': ('logs', 'delete'),
    'view_all_logs': ('logs', 'view'),
}

# Default role permissions - Updated to match new hierarchy
# Level 1: IT Administrator - Full system access INCLUDING User Management & Access Control
# Level 2: Top Level Admin - Full OPERATIONAL access (dashboards, bid analyzer, timelines) but NOT User Management
# Level 3: Manager - Team oversight & project management
# Level 4: Team Lead (Business Dev, Operations, Design, Site Engineer)
# Level 5: Team Members
DEFAULT_ROLE_PERMISSIONS = {
    # Level 1: IT Administrator - FULL ACCESS including user management & access control
    'admin': {
        'level': 1, 
        'all_access': True,
        'modules': ['company_dashboards', 'bid_analyzer', 'manager_dashboard', 'team_lead_dashboard', 'employee_dashboard', 'assigned_tasks', 'business_manager_dashboard', 'business_manager_team_allocation', 'team_management', 'user_management', 'logs'],
        'actions': ['create_user', 'delete_user', 'edit_permissions', 'advance_stage', 'assign_bids', 'create_bid', 'analyze_bid', 'import_data', 'export_data', 'create_record', 'edit_record', 'delete_record', 'view_all_logs', 'manage_timeline'],
        'can_manage_users': True,
        'can_manage_permissions': True
    },
    'it administrator': {
        'level': 1, 
        'all_access': True,
        'modules': ['company_dashboards', 'bid_analyzer', 'manager_dashboard', 'team_lead_dashboard', 'employee_dashboard', 'assigned_tasks', 'business_manager_dashboard', 'business_manager_team_allocation', 'team_management', 'user_management', 'logs'],
        'actions': ['create_user', 'delete_user', 'edit_permissions', 'advance_stage', 'assign_bids', 'create_bid', 'analyze_bid', 'import_data', 'export_data', 'create_record', 'edit_record', 'delete_record', 'view_all_logs', 'manage_timeline'],
        'can_manage_users': True,
        'can_manage_permissions': True
    },

    # New canonical key for IT Admin (DB role = itadmin)
    'itadmin': {
        'level': 1,
        'all_access': True,
        'modules': ['company_dashboards', 'bid_analyzer', 'manager_dashboard', 'team_lead_dashboard', 'employee_dashboard', 'assigned_tasks', 'business_manager_dashboard', 'business_manager_team_allocation', 'team_management', 'user_management', 'logs'],
        'actions': ['create_user', 'delete_user', 'edit_permissions', 'advance_stage', 'assign_bids', 'create_bid', 'analyze_bid', 'import_data', 'export_data', 'create_record', 'edit_record', 'delete_record', 'view_all_logs', 'manage_timeline'],
        'can_manage_users': True,
        'can_manage_permissions': True
    },
    
    # Level 2: Top Level Admin - Full OPERATIONAL access but NO user management/access control
    'top_level_admin': {
        'level': 2, 
        'all_access': False,  # NOT full access - restricted from user management
        'modules': ['company_dashboards', 'bid_analyzer', 'manager_dashboard', 'team_lead_dashboard', 'employee_dashboard', 'assigned_tasks', 'business_manager_dashboard', 'business_manager_team_allocation', 'team_management', 'logs', 'approvals', 'bid_timeline'],
        'actions': ['advance_stage', 'assign_bids', 'create_bid', 'analyze_bid', 'import_data', 'export_data', 'create_record', 'edit_record', 'delete_record', 'view_all_logs', 'manage_timeline', 'approve_item', 'reject_item', 'revert_item', 'escalate_item'],
        'can_manage_users': False,  # Cannot create/delete users
        'can_manage_permissions': False  # Cannot edit role permissions
    },
    'top level admin': {
        'level': 2, 
        'all_access': False,
        'modules': ['company_dashboards', 'bid_analyzer', 'manager_dashboard', 'team_lead_dashboard', 'employee_dashboard', 'assigned_tasks', 'business_manager_dashboard', 'business_manager_team_allocation', 'team_management', 'logs', 'approvals', 'bid_timeline'],
        'actions': ['advance_stage', 'assign_bids', 'create_bid', 'analyze_bid', 'import_data', 'export_data', 'create_record', 'edit_record', 'delete_record', 'view_all_logs', 'manage_timeline', 'approve_item', 'reject_item', 'revert_item', 'escalate_item'],
        'can_manage_users': False,
        'can_manage_permissions': False
    },

    # New canonical key for Top Level Admin (DB role = topleveladmin)
    'topleveladmin': {
        'level': 2,
        'all_access': False,
        'modules': ['company_dashboards', 'bid_analyzer', 'manager_dashboard', 'team_lead_dashboard', 'employee_dashboard', 'assigned_tasks', 'business_manager_dashboard', 'business_manager_team_allocation', 'team_management', 'logs', 'approvals', 'bid_timeline'],
        'actions': ['advance_stage', 'assign_bids', 'create_bid', 'analyze_bid', 'import_data', 'export_data', 'create_record', 'edit_record', 'delete_record', 'view_all_logs', 'manage_timeline', 'approve_item', 'reject_item', 'revert_item', 'escalate_item'],
        'can_manage_users': False,
        'can_manage_permissions': False
    },
    
    # Level 3: Manager
    'manager': {
        'level': 3, 
        'modules': ['company_dashboards', 'bid_analyzer', 'manager_dashboard', 'assigned_tasks', 'team_management', 'logs', 'approvals', 'bid_timeline'], 
        'actions': ['advance_stage', 'assign_bids', 'create_bid', 'analyze_bid', 'manage_timeline', 'export_data', 'approve_item', 'reject_item', 'revert_item', 'escalate_item'],
        'can_manage_users': False,
        'can_manage_permissions': False
    },
    'project_manager': {
        'level': 3,
        'modules': ['company_dashboards', 'project_manager_dashboard', 'assigned_tasks', 'approvals', 'bid_timeline'],
        'actions': ['manage_timeline', 'approve_item', 'reject_item', 'revert_item', 'escalate_item'],
        'can_manage_users': False,
        'can_manage_permissions': False
    },
    'project manager': {
        'level': 3,
        'modules': ['company_dashboards', 'project_manager_dashboard', 'assigned_tasks', 'approvals', 'bid_timeline'],
        'actions': ['manage_timeline', 'approve_item', 'reject_item', 'revert_item', 'escalate_item'],
        'can_manage_users': False,
        'can_manage_permissions': False
    },

    # Level 3: Department Managers (scoped dashboards; same baseline access as Manager)
    'business_manager': {
        'level': 3,
        'modules': ['company_dashboards', 'bid_analyzer', 'manager_dashboard', 'assigned_tasks', 'business_manager_dashboard', 'business_manager_team_allocation', 'team_management', 'logs', 'approvals', 'bid_timeline'],
        'actions': ['advance_stage', 'assign_bids', 'create_bid', 'analyze_bid', 'manage_timeline', 'export_data', 'approve_item', 'reject_item', 'revert_item', 'escalate_item'],
        'can_manage_users': False,
        'can_manage_permissions': False
    },
    'design_manager': {
        'level': 3,
        'modules': ['company_dashboards', 'bid_analyzer', 'manager_dashboard', 'assigned_tasks', 'team_management', 'logs', 'approvals', 'bid_timeline'],
        'actions': ['advance_stage', 'assign_bids', 'create_bid', 'analyze_bid', 'manage_timeline', 'export_data', 'approve_item', 'reject_item', 'revert_item', 'escalate_item'],
        'can_manage_users': False,
        'can_manage_permissions': False
    },
    'operation_manager': {
        'level': 3,
        'modules': ['company_dashboards', 'bid_analyzer', 'manager_dashboard', 'assigned_tasks', 'team_management', 'logs', 'approvals', 'bid_timeline'],
        'actions': ['advance_stage', 'assign_bids', 'create_bid', 'analyze_bid', 'manage_timeline', 'export_data', 'approve_item', 'reject_item', 'revert_item', 'escalate_item'],
        'can_manage_users': False,
        'can_manage_permissions': False
    },
    'operations_manager': {  # alias
        'level': 3,
        'modules': ['company_dashboards', 'bid_analyzer', 'manager_dashboard', 'assigned_tasks', 'team_management', 'logs', 'approvals', 'bid_timeline'],
        'actions': ['advance_stage', 'assign_bids', 'manage_timeline', 'export_data', 'approve_item', 'reject_item', 'revert_item', 'escalate_item'],
        'can_manage_users': False,
        'can_manage_permissions': False
    },
    'site_manager': {
        'level': 3,
        'modules': ['company_dashboards', 'bid_analyzer', 'manager_dashboard', 'assigned_tasks', 'team_management', 'logs', 'approvals', 'bid_timeline'],
        'actions': ['advance_stage', 'assign_bids', 'create_bid', 'analyze_bid', 'manage_timeline', 'export_data', 'approve_item', 'reject_item', 'revert_item', 'escalate_item'],
        'can_manage_users': False,
        'can_manage_permissions': False
    },
    
    # Level 4: Team Leads (new canonical key)
    'teamlead': {'level': 4, 'modules': ['company_dashboards', 'bid_analyzer', 'team_lead_dashboard', 'assigned_tasks', 'team_management', 'approvals', 'bid_timeline'], 'actions': ['advance_stage', 'assign_bids', 'create_bid', 'analyze_bid', 'approve_item', 'reject_item', 'revert_item', 'escalate_item']},

    # Keep legacy per-department roles as aliases for older installs
    'business dev': {'level': 4, 'modules': ['company_dashboards', 'bid_analyzer', 'team_lead_dashboard', 'assigned_tasks', 'team_management', 'approvals', 'bid_timeline'], 'actions': ['advance_stage', 'assign_bids', 'create_bid', 'analyze_bid', 'approve_item', 'reject_item', 'revert_item', 'escalate_item']},
    'design': {'level': 4, 'modules': ['company_dashboards', 'team_lead_dashboard', 'assigned_tasks', 'team_management', 'approvals', 'bid_timeline'], 'actions': ['advance_stage', 'approve_item', 'reject_item', 'revert_item', 'escalate_item']},
    'operations': {'level': 4, 'modules': ['company_dashboards', 'team_lead_dashboard', 'assigned_tasks', 'team_management', 'approvals', 'bid_timeline'], 'actions': ['advance_stage', 'approve_item', 'reject_item', 'revert_item', 'escalate_item']},
    'site_engineer': {'level': 4, 'modules': ['company_dashboards', 'team_lead_dashboard', 'assigned_tasks', 'team_management', 'approvals', 'bid_timeline'], 'actions': ['advance_stage', 'approve_item', 'reject_item', 'revert_item', 'escalate_item']},
    'site engineer': {'level': 4, 'modules': ['company_dashboards', 'team_lead_dashboard', 'assigned_tasks', 'team_management', 'approvals', 'bid_timeline'], 'actions': ['advance_stage', 'approve_item', 'reject_item', 'revert_item', 'escalate_item']},
    'engineering': {'level': 4, 'modules': ['company_dashboards', 'team_lead_dashboard', 'assigned_tasks', 'team_management', 'approvals', 'bid_timeline'], 'actions': ['advance_stage', 'approve_item', 'reject_item', 'revert_item', 'escalate_item']},
    
    # Level 5: Team Members
    'member': {'level': 5, 'modules': ['company_dashboards', 'employee_dashboard', 'assigned_tasks'], 'actions': []},
    
}

def ensure_permissions_table():
    """Create permissions table if it doesn't exist"""
    cur = mysql.connection.cursor(DictCursor)
    try:
        def _mysql_err_no(exc) -> int | None:
            try:
                if hasattr(exc, "args") and exc.args:
                    return int(exc.args[0])
            except Exception:
                return None
            return None

        def _mysql_datadir() -> str | None:
            c2 = None
            try:
                c2 = mysql.connection.cursor(DictCursor)
                c2.execute("SHOW VARIABLES LIKE 'datadir'")
                row = c2.fetchone()
                if isinstance(row, (list, tuple)) and len(row) >= 2:
                    return str(row[1])
                if isinstance(row, dict):
                    return str(row.get("Value") or row.get("value") or "")
            except Exception:
                return None
            finally:
                try:
                    if c2 is not None:
                        c2.close()
                except Exception:
                    pass
            return None

        def _quarantine_innodb_files(db_name: str, table_name: str) -> None:
            data_dir = _mysql_datadir()
            if not data_dir:
                return
            db_dir = os.path.join(str(data_dir), str(db_name))
            # MySQL may leave orphan tablespace files behind (Windows also may lock deletes).
            # Best effort: delete; if that fails, rename out of the way.
            for ext in (".ibd", ".cfg", ".frm"):
                p = os.path.join(db_dir, f"{table_name}{ext}")
                try:
                    if os.path.exists(p):
                        os.remove(p)
                except Exception:
                    try:
                        if os.path.exists(p):
                            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                            os.rename(p, f"{p}.bak_{ts}")
                    except Exception:
                        pass

        def _ensure_innodb_table_ok(table_name: str, create_sql: str) -> None:
            try:
                cur.execute(f"SELECT 1 FROM `{table_name}` LIMIT 1")
                cur.fetchone()
                return
            except Exception as e:
                err_no = _mysql_err_no(e)
                if err_no not in (1146, 1813, 1932):
                    raise

            db_name = app.config.get("MYSQL_DB", "esco")
            if err_no in (1813, 1932):
                _quarantine_innodb_files(str(db_name), table_name)

            try:
                cur.execute("SET FOREIGN_KEY_CHECKS=0")
            except Exception:
                pass
            try:
                cur.execute(f"DROP TABLE IF EXISTS `{table_name}`")
            except Exception:
                pass
            finally:
                try:
                    cur.execute("SET FOREIGN_KEY_CHECKS=1")
                except Exception:
                    pass

            try:
                repair_sql = re.sub(
                    r"CREATE\\s+TABLE\\s+IF\\s+NOT\\s+EXISTS",
                    "CREATE TABLE",
                    create_sql,
                    flags=re.IGNORECASE,
                )
            except Exception:
                repair_sql = create_sql.replace("CREATE TABLE IF NOT EXISTS", "CREATE TABLE")

            try:
                cur.execute(repair_sql)
            except Exception as create_err:
                create_err_no = _mysql_err_no(create_err)
                if create_err_no in (1813, 1932):
                    _quarantine_innodb_files(str(db_name), table_name)
                    # Try again after clearing any orphan tablespace files.
                    cur.execute(f"DROP TABLE IF EXISTS `{table_name}`")
                    cur.execute(repair_sql)
                else:
                    raise

        create_role_permissions_sql = """
            CREATE TABLE IF NOT EXISTS role_permissions (
                id INT AUTO_INCREMENT PRIMARY KEY,
                role VARCHAR(50) NOT NULL,
                module_key VARCHAR(50) NOT NULL,
                enabled BOOLEAN DEFAULT TRUE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                UNIQUE KEY unique_role_module (role, module_key)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        create_action_permissions_sql = """
            CREATE TABLE IF NOT EXISTS action_permissions (
                id INT AUTO_INCREMENT PRIMARY KEY,
                role VARCHAR(50) NOT NULL,
                action_key VARCHAR(50) NOT NULL,
                enabled BOOLEAN DEFAULT TRUE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                UNIQUE KEY unique_role_action (role, action_key)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        create_module_permissions_sql = """
            CREATE TABLE IF NOT EXISTS module_permissions (
                id INT AUTO_INCREMENT PRIMARY KEY,
                role VARCHAR(50) NOT NULL,
                module_key VARCHAR(50) NOT NULL,
                can_view BOOLEAN DEFAULT TRUE,
                can_create BOOLEAN DEFAULT FALSE,
                can_edit BOOLEAN DEFAULT FALSE,
                can_delete BOOLEAN DEFAULT FALSE,
                scope VARCHAR(20) DEFAULT 'all',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_role_module (role, module_key)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        create_user_module_permissions_sql = """
            CREATE TABLE IF NOT EXISTS user_module_permissions (
                id INT AUTO_INCREMENT PRIMARY KEY,
                user_id INT NOT NULL,
                module_key VARCHAR(50) NOT NULL,
                can_view BOOLEAN DEFAULT TRUE,
                can_create BOOLEAN DEFAULT FALSE,
                can_edit BOOLEAN DEFAULT FALSE,
                can_delete BOOLEAN DEFAULT FALSE,
                scope VARCHAR(20) DEFAULT 'user',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_user_module (user_id, module_key)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        create_employee_module_permissions_sql = """
            CREATE TABLE IF NOT EXISTS employee_module_permissions (
                id INT AUTO_INCREMENT PRIMARY KEY,
                employee_id INT NOT NULL,
                module_key VARCHAR(50) NOT NULL,
                enabled BOOLEAN DEFAULT TRUE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_employee_module (employee_id, module_key)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        create_user_reporting_manager_sql = """
            CREATE TABLE IF NOT EXISTS user_reporting_manager (
                id INT AUTO_INCREMENT PRIMARY KEY,
                user_id INT NOT NULL,
                manager_user_id INT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_user_manager (user_id)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        _ensure_innodb_table_ok("role_permissions", create_role_permissions_sql)
        _ensure_innodb_table_ok("action_permissions", create_action_permissions_sql)
        _ensure_innodb_table_ok("module_permissions", create_module_permissions_sql)
        _ensure_innodb_table_ok("user_module_permissions", create_user_module_permissions_sql)
        _ensure_innodb_table_ok("employee_module_permissions", create_employee_module_permissions_sql)
        _ensure_innodb_table_ok("user_reporting_manager", create_user_reporting_manager_sql)

        # Best-effort migration: if legacy `role_permissions` has values, copy them into
        # `module_permissions.can_view` so the new UI reflects existing settings.
        try:
            cur.execute("SELECT COUNT(*) AS c FROM module_permissions")
            mp_count = int((cur.fetchone() or {}).get("c") or 0)
        except Exception:
            mp_count = 0
        if mp_count == 0:
            try:
                cur.execute(
                    """
                    INSERT INTO module_permissions (role, module_key, can_view, can_create, can_edit, can_delete, scope)
                    SELECT
                        rp.role,
                        rp.module_key,
                        COALESCE(rp.enabled, 0) AS can_view,
                        CASE
                            WHEN LOWER(REPLACE(REPLACE(rp.role,'_',''),' ','')) IN ('itadmin','admin','manager','supervisor','topleveladmin')
                            THEN COALESCE(rp.enabled, 0) ELSE 0
                        END AS can_create,
                        CASE
                            WHEN LOWER(REPLACE(REPLACE(rp.role,'_',''),' ','')) IN ('itadmin','admin','manager','supervisor','topleveladmin')
                            THEN COALESCE(rp.enabled, 0) ELSE 0
                        END AS can_edit,
                        CASE
                            WHEN LOWER(REPLACE(REPLACE(rp.role,'_',''),' ','')) IN ('itadmin','admin','manager','supervisor','topleveladmin')
                            THEN COALESCE(rp.enabled, 0) ELSE 0
                        END AS can_delete,
                        'all' AS scope
                    FROM role_permissions rp
                    ON DUPLICATE KEY UPDATE
                        can_view = VALUES(can_view),
                        can_create = VALUES(can_create),
                        can_edit = VALUES(can_edit),
                        can_delete = VALUES(can_delete),
                        scope = VALUES(scope),
                        updated_at = CURRENT_TIMESTAMP
                    """
                )
            except Exception:
                pass
        # Add is_active column to users if not exists
        try:
            cur.execute("ALTER TABLE users ADD COLUMN is_active BOOLEAN DEFAULT TRUE")
        except Exception:
            pass
        # Add last_active column to users if not exists
        try:
            cur.execute("ALTER TABLE users ADD COLUMN last_active DATETIME")
        except Exception:
            pass
        mysql.connection.commit()
    except Exception as e:
        print(f"Error ensuring permissions tables: {e}")
    finally:
        cur.close()

def get_module_permissions():
    """Get all module permissions with role access status"""
    def _mysql_err_no(exc) -> int | None:
        try:
            if hasattr(exc, "args") and exc.args:
                return int(exc.args[0])
        except Exception:
            return None
        return None

    cur = mysql.connection.cursor(DictCursor)
    modules = []
    try:
        # Ensure permissions tables exist; if they're corrupt (1932/1813), best-effort repair.
        try:
            ensure_permissions_table()
        except Exception:
            pass
        for module in DEFAULT_MODULES:
            mod = dict(module)
            # Roles: topleveladmin, manager, teamlead, member
            for role_key in ['topleveladmin', 'manager', 'teamlead', 'member']:
                role_name = role_key.replace('_', ' ')
                result = None
                try:
                    cur.execute(
                        """
                        SELECT enabled FROM role_permissions
                        WHERE role = %s AND module_key = %s
                        """,
                        (role_name, module['key'])
                    )
                    result = cur.fetchone()
                except Exception as e:
                    # If the permissions table is unavailable/corrupt, fall back to defaults.
                    if _mysql_err_no(e) in (1146, 1813, 1932):
                        result = None
                    else:
                        raise
                if result:
                    mod[role_key] = result['enabled']
                else:
                    default_perms = DEFAULT_ROLE_PERMISSIONS.get(role_name, {})
                    mod[role_key] = default_perms.get('all_access', False) or module['key'] in default_perms.get('modules', [])
            modules.append(mod)
    finally:
        cur.close()
    return modules

def get_action_permissions():
    """Get all action permissions with enabled status"""
    def _mysql_err_no(exc) -> int | None:
        try:
            if hasattr(exc, "args") and exc.args:
                return int(exc.args[0])
        except Exception:
            return None
        return None

    cur = mysql.connection.cursor(DictCursor)
    actions = []
    try:
        try:
            ensure_permissions_table()
        except Exception:
            pass
        for action in DEFAULT_ACTIONS:
            act = dict(action)
            results = None
            try:
                cur.execute("""
                    SELECT role, enabled FROM action_permissions 
                    WHERE action_key = %s AND enabled = TRUE
                """, (action['key'],))
                results = cur.fetchall()
            except Exception as e:
                if _mysql_err_no(e) in (1146, 1813, 1932):
                    results = None
                else:
                    raise
            if results:
                act['enabled'] = True
                act['allowed_roles'] = [r['role'].title() for r in results]
            else:
                # Use defaults (no supervisor role label)
                act['enabled'] = True
                act['allowed_roles'] = ['Admin', 'Top Level Admin']
            actions.append(act)
    finally:
        cur.close()
    return actions

def _get_user_module_overrides(user_id: int, cur=None) -> dict:
    """Return per-user module overrides keyed by module_key."""
    if not user_id:
        return {}
    close_cur = False
    if cur is None:
        cur = mysql.connection.cursor(DictCursor)
        close_cur = True
    overrides = {}
    try:
        cur.execute(
            """
            SELECT module_key, can_view, can_create, can_edit, can_delete, scope
            FROM user_module_permissions
            WHERE user_id = %s
            """,
            (int(user_id),),
        )
        for row in (cur.fetchall() or []):
            key = row.get("module_key")
            if not key:
                continue
            overrides[key] = {
                "can_view": bool(row.get("can_view")),
                "can_create": bool(row.get("can_create")),
                "can_edit": bool(row.get("can_edit")),
                "can_delete": bool(row.get("can_delete")),
                "scope": row.get("scope") or "user",
            }
    except Exception:
        overrides = {}
    finally:
        if close_cur:
            try:
                cur.close()
            except Exception:
                pass
    return overrides

def _get_employee_module_overrides(employee_id: int, cur=None) -> dict:
    """Return per-employee module overrides keyed by module_key."""
    if not employee_id:
        return {}
    close_cur = False
    if cur is None:
        cur = mysql.connection.cursor(DictCursor)
        close_cur = True
    overrides = {}
    try:
        cur.execute(
            """
            SELECT module_key, enabled
            FROM employee_module_permissions
            WHERE employee_id = %s
            """,
            (int(employee_id),),
        )
        for row in (cur.fetchall() or []):
            key = row.get("module_key")
            if not key:
                continue
            overrides[key] = bool(row.get("enabled"))
    except Exception:
        overrides = {}
    finally:
        if close_cur:
            try:
                cur.close()
            except Exception:
                pass
    return overrides

def get_user_module_permissions(user_role, is_admin=False, user_id: int | None = None):
    """Get module permissions for a specific user role"""
    try:
        ensure_permissions_table()
    except Exception:
        pass
    
    if not user_role:
        user_role = 'member'
    
    role_name = user_role.lower().strip()
    
    # Normalize role name - handle both underscore and space variations
    # e.g., 'site_engineer' and 'site engineer' should match
    role_name_underscore = role_name.replace(' ', '_')
    role_name_space = role_name.replace('_', ' ')
    
    # IT Admin (is_admin=True) has FULL access including user_management
    if is_admin or role_name in ['itadmin', 'it_admin', 'admin', 'it administrator']:
        return {module['key']: True for module in DEFAULT_MODULES}
    
    # Top Level Admin has operational access but NOT user_management
    if role_name in ['topleveladmin', 'top_level_admin', 'top level admin']:
        permissions = {}
        for module in DEFAULT_MODULES:
            # Top Level Admin cannot access user_management
            if module['key'] == 'user_management':
                permissions[module['key']] = False
            else:
                permissions[module['key']] = True
        return permissions
    
    permissions = {}
    cur = mysql.connection.cursor(DictCursor)
    overrides = _get_user_module_overrides(int(user_id), cur=cur) if user_id else {}
    
    try:
        for module in DEFAULT_MODULES:
            # Prefer CRUD-capable module_permissions.can_view when available.
            result = None
            try:
                try:
                    cur.execute(
                        """
                        SELECT can_view AS enabled FROM module_permissions
                        WHERE (role = %s OR role = %s) AND module_key = %s
                        ORDER BY updated_at DESC
                        LIMIT 1
                        """,
                        (role_name_underscore, role_name_space, module['key']),
                    )
                    result = cur.fetchone()
                except Exception:
                    result = None

                if result is None:
                    cur.execute("""
                        SELECT enabled FROM role_permissions 
                        WHERE (role = %s OR role = %s) AND module_key = %s
                        ORDER BY updated_at DESC
                        LIMIT 1
                    """, (role_name_underscore, role_name_space, module['key']))
                    result = cur.fetchone()
            except Exception as e:
                try:
                    err_no = int(e.args[0]) if hasattr(e, "args") and e.args else None
                except Exception:
                    err_no = None
                if err_no in (1146, 1813, 1932):
                    result = None
                else:
                    raise
             
            if result is not None:
                permissions[module['key']] = bool(result['enabled'])
            else:
                # Fall back to default permissions - check both variations
                default_perms = DEFAULT_ROLE_PERMISSIONS.get(role_name_underscore, {}) or DEFAULT_ROLE_PERMISSIONS.get(role_name_space, {})
                if default_perms.get('all_access', False):
                    permissions[module['key']] = True
                else:
                    permissions[module['key']] = module['key'] in default_perms.get('modules', [])

            # Apply per-user overrides if present.
            if overrides.get(module['key']) is not None:
                permissions[module['key']] = bool(overrides[module['key']].get('can_view'))
    finally:
        cur.close()
    
    return permissions

def get_user_action_permissions(user_role, is_admin=False):
    """Get action permissions for a specific user role"""
    try:
        ensure_permissions_table()
    except Exception:
        pass
    
    if not user_role:
        user_role = 'member'
    
    role_name = user_role.lower().strip()
    # Normalize role name - handle both underscore and space variations consistently
    role_name_underscore = role_name.replace(' ', '_')
    role_name_space = role_name.replace('_', ' ')
    
    # IT Admin (is_admin=True) has ALL actions including user management
    if is_admin or role_name in ['itadmin', 'it_admin', 'admin', 'it administrator']:
        return {action['key']: True for action in DEFAULT_ACTIONS}
    
    # Top Level Admin has operational actions but NOT user management actions
    if role_name in ['topleveladmin', 'top_level_admin', 'top level admin']:
        user_management_actions = ['create_user', 'delete_user', 'edit_permissions']
        permissions = {}
        for action in DEFAULT_ACTIONS:
            if action['key'] in user_management_actions:
                permissions[action['key']] = False  # Cannot manage users/permissions
            else:
                permissions[action['key']] = True  # Can do all other actions
        return permissions
    
    permissions = {}
    cur = mysql.connection.cursor(DictCursor)
    
    try:
        for action in DEFAULT_ACTIONS:
            # Check database first - try both underscore and space versions.
            # NOTE: some deployments may have an older schema without `updated_at`.
            try:
                cur.execute(
                    """
                    SELECT enabled FROM action_permissions
                    WHERE (role = %s OR role = %s) AND action_key = %s
                    ORDER BY updated_at DESC
                    LIMIT 1
                    """,
                    (role_name_underscore, role_name_space, action['key'])
                )
            except Exception as e:
                try:
                    err_no = int(e.args[0]) if hasattr(e, "args") and e.args else None
                except Exception:
                    err_no = None
                if err_no in (1146, 1813, 1932):
                    # Table missing/corrupt: fall back to defaults
                    permissions[action['key']] = action['key'] in (DEFAULT_ROLE_PERMISSIONS.get(role_name_underscore, {}) or DEFAULT_ROLE_PERMISSIONS.get(role_name_space, {})).get('actions', [])
                    continue
                cur.execute(
                    """
                    SELECT enabled FROM action_permissions
                    WHERE (role = %s OR role = %s) AND action_key = %s
                    LIMIT 1
                    """,
                    (role_name_underscore, role_name_space, action['key'])
                )
            result = cur.fetchone()
            
            if result is not None:
                permissions[action['key']] = bool(result['enabled'])
            else:
                # Fall back to default permissions - check both variations
                default_perms = DEFAULT_ROLE_PERMISSIONS.get(role_name_underscore, {}) or DEFAULT_ROLE_PERMISSIONS.get(role_name_space, {})
                permissions[action['key']] = action['key'] in default_perms.get('actions', [])
    finally:
        cur.close()
    
    return permissions

# check_module_access is now imported from security.py
# This local function extends it with database-based permissions
def check_module_access_db(module_key):
    """Check if current user has access to a specific module (DB-based fallback)"""
    if not current_user.is_authenticated:
        return False
    
    if current_user.is_admin:
        return True
    
    user_role = get_user_role() or 'member'
    permissions = get_user_module_permissions(user_role, user_id=int(current_user.id))
    return permissions.get(module_key, False)

@app.context_processor
def inject_user_permissions():
    """Make user permissions available to all templates"""
    if current_user.is_authenticated:
        user_role = get_user_role() or 'member'
        is_admin = getattr(current_user, 'is_admin', False)
        is_top_level_admin = (user_role or '').lower() == 'topleveladmin'

        # Active context (company/department) + available companies for the user
        active_company_id = session.get('active_company_id')
        active_department_key = session.get('active_department_key')
        # Business Managers should not be treated as "company locked" (they default to all orgs unless denied)
        try:
            company_locked = bool(session.get('locked_company_id')) if (not is_admin and not _is_business_manager_user()) else False
        except Exception:
            company_locked = bool(session.get('locked_company_id')) if not is_admin else False
        available_companies = _get_visible_companies_for_user(int(current_user.id), is_admin=bool(is_admin))
        
        # IT Admin (is_admin=True) has FULL access including user management
        if is_admin:
            module_permissions = {module['key']: True for module in DEFAULT_MODULES}
            action_permissions = {action['key']: True for action in DEFAULT_ACTIONS}
            module_crud_permissions = {
                module['key']: {
                    'can_view': True,
                    'can_create': True,
                    'can_edit': True,
                    'can_delete': True,
                    'scope': 'all',
                } for module in DEFAULT_MODULES
            }
            can_manage_users = True
            can_manage_permissions = True
        # Top Level Admin has operational access but NOT user management
        elif is_top_level_admin:
            module_permissions = get_user_module_permissions(user_role, is_admin=False, user_id=int(current_user.id))
            action_permissions = get_user_action_permissions(user_role, is_admin=False)
            module_crud_permissions = get_user_module_crud_permissions(user_role, is_admin=False, user_id=int(current_user.id))
            can_manage_users = False
            can_manage_permissions = False
        else:
            module_permissions = get_user_module_permissions(user_role, is_admin=False, user_id=int(current_user.id))
            action_permissions = get_user_action_permissions(user_role, is_admin=False)
            module_crud_permissions = get_user_module_crud_permissions(user_role, is_admin=False, user_id=int(current_user.id))
            can_manage_users = False
            can_manage_permissions = False
        
        def _check_action_access(key: str) -> bool:
            base = action_permissions.get(key, False)
            if not base:
                return False
            req = ACTION_MODULE_REQUIREMENTS.get(key)
            if not req:
                return base
            mod_key, perm = req
            return bool((module_crud_permissions.get(mod_key, {}) or {}).get(f'can_{perm}', False))

        return {
            'user_permissions': module_permissions,
            'module_crud_permissions': module_crud_permissions,
            'user_actions': action_permissions,
            'user_role': user_role,
            'is_admin': is_admin,
            'is_top_level_admin': is_top_level_admin,
            'can_manage_users': can_manage_users,
            'can_manage_permissions': can_manage_permissions,
            'check_module_access': lambda key: module_permissions.get(key, False),
            'check_module_permission': lambda key, perm='view': (module_crud_permissions.get(key, {}) or {}).get(f'can_{perm}', False),
            'check_action_access': _check_action_access,
            'active_company_id': active_company_id,
            'active_department_key': active_department_key,
            'available_companies': available_companies,
            'company_locked': company_locked,
        }
    return {
        'user_permissions': {},
        'module_crud_permissions': {},
        'user_actions': {},
        'user_role': 'guest',
        'is_admin': False,
        'is_top_level_admin': False,
        'can_manage_users': False,
        'can_manage_permissions': False,
        'check_module_access': lambda key: False,
        'check_module_permission': lambda key, perm='view': False,
        'check_action_access': lambda key: False,
        'active_company_id': None,
        'active_department_key': None,
        'available_companies': [],
    }

@app.route('/top-admin/dashboard')
@login_required
def top_level_admin_dashboard():
    """Top Level Admin Dashboard - Separate from IT Admin Dashboard"""
    user_role = getattr(current_user, 'role', '')
    role_norm = (user_role or '').strip().lower().replace(' ', '_').replace('-', '_')
    
    # IT Admin (is_admin=1) can use top admin pages
    if current_user.is_admin:
        return redirect(url_for('top_admin_overview'))
    
    # Only allow Top Level Admin role (is_admin=0). Accept legacy variants.
    # NOTE: historically this deployment stored top-level admins as role='topleveladmin'.
    if role_norm not in ['topleveladmin', 'top_level_admin']:
        return "Access Denied - Top Level Admin Only", 403

    # New white-theme Top Admin UI (multi-page). Legacy dashboard still available:
    # `/top-admin/dashboard?legacy=1`
    if (request.args.get('legacy') or '').strip() != '1':
        return redirect(url_for('top_admin_overview'))
    
    ensure_permissions_table()
    
    cur = mysql.connection.cursor(DictCursor)
    
    # Active company context for optional filtering in timelines
    try:
        active_company_id = session.get('active_company_id')
    except Exception:
        active_company_id = None
    active_company_name = None
    if active_company_id:
        try:
            cur.execute("SELECT name FROM companies WHERE id=%s", (int(active_company_id),))
            active_company_name = (cur.fetchone() or {}).get('name') or None
        except Exception:
            active_company_name = None

    # Get team leads for the ACTIVE company context (scoped roles live in user_company_access)
    team_leads = []
    try:
        if active_company_id:
            cur.execute(
                """
                SELECT DISTINCT u.id, u.email, uca.department_key
                FROM user_company_access uca
                JOIN users u ON u.id = uca.user_id
                WHERE uca.company_id = %s
                  AND COALESCE(uca.is_active, TRUE) = TRUE
                  AND LOWER(COALESCE(uca.role,'')) = 'teamlead'
                ORDER BY u.email
                """,
                (int(active_company_id),),
            )
        else:
            cur.execute(
                """
                SELECT DISTINCT u.id, u.email, uca.department_key
                FROM user_company_access uca
                JOIN users u ON u.id = uca.user_id
                WHERE COALESCE(uca.is_active, TRUE) = TRUE
                  AND LOWER(COALESCE(uca.role,'')) = 'teamlead'
                ORDER BY u.email
                """
            )
        for rr in (cur.fetchall() or []):
            # Keep legacy shape used by templates: role string indicates department
            dept_key = (rr.get('department_key') or '').strip().lower().replace('_', ' ')
            team_leads.append({
                'id': rr.get('id'),
                'email': rr.get('email'),
                'role': dept_key or 'teamlead',
                'department_key': rr.get('department_key')
            })
    except Exception:
        team_leads = []
    
    # Get all team members from employees table
    try:
        cur.execute("""
            SELECT e.*, u.email as team_lead_email 
            FROM employees e
            LEFT JOIN users u ON e.team_lead_id = u.id
            ORDER BY e.department, e.name
        """)
        members = cur.fetchall()
    except Exception:
        members = []
    
    # Fallback to users table if employees table is empty
    if not members:
        try:
            cur.execute("SELECT id, email, email as name, role as department, is_active, NULL as last_active FROM users WHERE role = 'member' ORDER BY email")
            members = cur.fetchall()
        except Exception:
            members = []
    
    # Get recent logs
    try:
        cur.execute("SELECT * FROM logs ORDER BY timestamp DESC LIMIT 20")
        logs = cur.fetchall()
        recent_logs = logs
    except Exception:
        logs = []
        recent_logs = []
    
    # Get active projects count
    try:
        cur.execute("SELECT COUNT(*) as count FROM go_bids WHERE stage != 'handover'")
        active_projects = cur.fetchone()['count']
    except Exception:
        active_projects = 0
    
    # Get pending tasks count
    try:
        cur.execute("SELECT COUNT(*) as count FROM bid_checklists WHERE status = 'pending'")
        pending_tasks = cur.fetchone()['count']
    except Exception:
        pending_tasks = 0
    
    # Get all projects
    try:
        cur.execute("""
            SELECT g_id, title, b_name, company, stage, progress_pct, due_date, project_status, created_at
            FROM go_bids 
            ORDER BY created_at DESC
        """)
        projects = cur.fetchall()
    except Exception:
        projects = []
    
    # Get module permissions for team leads
    modules = get_module_permissions_for_top_admin()
    
    # Define teams with stats
    teams = [
        {'name': 'Business Development', 'icon': 'briefcase', 'color': 'cyan', 'member_count': len([t for t in team_leads if t['role'] == 'business dev']), 'progress': 75},
        {'name': 'Design', 'icon': 'paint-brush', 'color': 'pink', 'member_count': len([t for t in team_leads if t['role'] == 'design']), 'progress': 60},
        {'name': 'Operations', 'icon': 'cogs', 'color': 'orange', 'member_count': len([t for t in team_leads if t['role'] == 'operations']), 'progress': 85},
        {'name': 'Site Engineering', 'icon': 'hard-hat', 'color': 'yellow', 'member_count': len([t for t in team_leads if t['role'] in ['site_engineer', 'site engineer']]), 'progress': 40},
    ]
    
    # ========== BID Timeline and Project Timeline Data ==========
    # Stage normalization helper
    def _normalize_stage(raw_state: str) -> str:
        s = (raw_state or '').strip().lower()
        mapping = {
            'analyzer': 'analyzer',
            'business': 'business',
            'business dev': 'business',
            'bdm': 'business',
            'design': 'design',
            'operations': 'operations',
            'operation': 'operations',
            'engineer': 'engineer',
            'site_manager': 'engineer',
            'site manager': 'engineer',
            'handover': 'handover',
            'won': 'handover'
        }
        return mapping.get(s, 'analyzer')

    stage_to_percent = {
        'analyzer': 0,
        'business': 20,
        'design': 40,
        'operations': 60,
        'engineer': 80,
        'handover': 100,
    }
    default_stages = ['analyzer', 'business', 'design', 'operations', 'engineer', 'handover']
    dept_filter = (request.args.get('dept_filter') or '').strip().lower()
    # Default to ALL departments unless explicitly filtered.
    filter_selected_depts = dept_filter in ('selected', 'on', '1', 'true')

    # Dynamic timeline stages (shared with Supervisor timeline management)
    stage_exclusions = {}
    custom_stages = {}
    try:
        cur.execute("""
            CREATE TABLE IF NOT EXISTS bid_stage_exclusions (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                stage VARCHAR(120) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_g_stage (g_id, stage)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """)
        cur.execute("""
            CREATE TABLE IF NOT EXISTS bid_custom_stages (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                stage VARCHAR(120) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_g_stage (g_id, stage)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """)
        mysql.connection.commit()
    except Exception:
        # If table creation fails, dashboard should still load with default stages.
        pass
    try:
        cur.execute("SELECT g_id, stage FROM bid_stage_exclusions")
        for rr in (cur.fetchall() or []):
            stage_exclusions.setdefault(rr.get('g_id'), []).append(rr.get('stage'))
    except Exception:
        stage_exclusions = {}
    try:
        cur.execute("SELECT g_id, stage FROM bid_custom_stages")
        for rr in (cur.fetchall() or []):
            custom_stages.setdefault(rr.get('g_id'), []).append(rr.get('stage'))
    except Exception:
        custom_stages = {}

    # Dynamic stage progress helper
    def stage_progress_pct(stage_key: str) -> int:
        ordered = ['analyzer', 'business', 'design', 'operations', 'engineer', 'handover']
        try:
            idx = ordered.index(stage_key) if stage_key in ordered else 0
            return int(round((idx / (len(ordered) - 1)) * 100)) if len(ordered) > 1 else 0
        except Exception:
            return 0

    def status_texts(stage_key: str):
        stage_statuses = {
            'analyzer': ('BID Under Review', 'Pending Analysis'),
            'business': ('With Business Team', 'In Progress'),
            'design': ('With Design Team', 'In Progress'),
            'operations': ('With Operations', 'In Progress'),
            'engineer': ('With Engineering', 'In Progress'),
            'handover': ('Submitted', 'Completed'),
        }
        return stage_statuses.get(stage_key, ('In Progress', 'Ongoing'))

    def _parse_percent(value) -> int:
        try:
            if value is None:
                return 0
            s = str(value)
            import re
            m = re.search(r"(\d{1,3})", s)
            if m:
                return max(0, min(100, int(m.group(1))))
            s = s.strip().lower()
            if s in ('done','completed','closed','handover','100%'):
                return 100
            if s in ('in_progress','ongoing'):
                return 50
            return 0
        except Exception:
            return 0

    # Helper: compute stage progress map from bid_checklists per bid
    def _compute_stage_map_for_bid(g_id: int) -> dict:
        try:
            cur2 = mysql.connection.cursor(DictCursor)
            try:
                _ensure_bid_team_progress_table(cur2)
                cur2.execute(
                    """
                    SELECT stage_key, progress_pct
                    FROM bid_team_progress
                    WHERE g_id = %s
                    """,
                    (g_id,),
                )
                rows = cur2.fetchall() or []
                if rows:
                    stage_map = {r.get('stage_key'): int(r.get('progress_pct') or 0) for r in rows}
                    for k in default_stages:
                        stage_map.setdefault(k, 0)
                    cur2.close()
                    return stage_map
            except Exception:
                pass
            cur2.execute("""
                SELECT bc.progress_pct, bc.status, COALESCE(bc.stage, bc.department, u.role) AS stage_source
                FROM bid_checklists bc
                LEFT JOIN users u ON bc.created_by = u.id
                WHERE bc.g_id = %s
            """, (g_id,))
            rows = cur2.fetchall()
            cur2.close()
            role_to_stage = {
                'business dev': 'business',
                'business development': 'business',
                'bdm': 'business',
                'bde': 'business',
                'design': 'design',
                'design team': 'design',
                'design & marketing': 'design',
                'design and marketing': 'design',
                'marketing': 'design',
                'operations': 'operations',
                'operation': 'operations',
                'ops': 'operations',
                'operations team': 'operations',
                'site manager': 'engineer',
                'site engineer': 'engineer',
                'engineering': 'engineer',
                'engineer': 'engineer',
                'engineering team': 'engineer',
                'handover': 'handover',
                'submitted': 'handover',
                'submit': 'handover',
                'bid analyzer': 'analyzer',
                'analyzer': 'analyzer',
            }
            buckets = {'analyzer': [], 'business': [], 'design': [], 'operations': [], 'engineer': [], 'handover': []}
            for r in rows:
                source = (r.get('stage_source') or '').strip().lower()
                stage = role_to_stage.get(source)
                if not stage and source in buckets:
                    stage = source
                if not stage and source:
                    if 'design' in source or 'marketing' in source:
                        stage = 'design'
                    elif 'business' in source or 'bdm' in source or 'bde' in source:
                        stage = 'business'
                    elif 'operation' in source or 'ops' in source:
                        stage = 'operations'
                    elif 'engineer' in source or 'site' in source:
                        stage = 'engineer'
                    elif 'submit' in source or 'handover' in source or source == 'won':
                        stage = 'handover'
                    elif 'analy' in source:
                        stage = 'analyzer'
                if not stage:
                    continue
                pct = r.get('progress_pct')
                if pct is None:
                    s = (r.get('status') or '').strip().lower()
                    pct = 100 if s == 'completed' else 50 if s == 'in_progress' else 0
                try:
                    pct = max(0, min(100, int(pct)))
                except Exception:
                    pct = 0
                buckets[stage].append(pct)
            def avg(lst):
                return int(round(sum(lst) / len(lst))) if lst else 0
            return {
                'analyzer': avg(buckets['analyzer']),
                'business': avg(buckets['business']),
                'design': avg(buckets['design']),
                'operations': avg(buckets['operations']),
                'engineer': avg(buckets['engineer']),
                'handover': avg(buckets['handover']),
            }
        except Exception:
            return {'analyzer': 0, 'business': 0, 'design': 0, 'operations': 0, 'engineer': 0, 'handover': 0}

    # Fetch GO Bids for BID Timeline
    cur.execute(
        """
        SELECT gb.g_id,
               gb.b_name,
               gb.due_date,
               gb.state,
               gb.type,
               gb.company,
               gb.decision,
               gb.summary,
               gb.scoring AS progress,
               wps.pr_completion_status AS work_status,
               wps.dept_bde,
               wps.dept_m_d,
               wps.dept_op,
               wps.dept_site,
               wbr.closure_status AS project_status,
               wbr.work_progress_status AS work_progress_status
        FROM go_bids gb
        LEFT JOIN bid_assign ba ON ba.g_id = gb.g_id
        LEFT JOIN win_lost_results wlr ON wlr.a_id = ba.a_id
        LEFT JOIN won_bids_result wbr ON wbr.w_id = wlr.w_id
        LEFT JOIN work_progress_status wps ON wps.won_id = wbr.won_id
        ORDER BY gb.due_date ASC
        """
    )
    go_rows = cur.fetchall()

    go_projects = []
    for r in go_rows:
        bid_id = r.get('g_id')
        stage_key = _normalize_stage(r.get('state'))

        # Build dynamic stages list (default - excluded + custom)
        excluded = set(stage_exclusions.get(bid_id, []) or [])
        customs = [s for s in (custom_stages.get(bid_id, []) or []) if s not in excluded]
        stages = [s for s in default_stages if s not in excluded] + [s for s in customs if s not in default_stages]
        if not stages:
            stages = default_stages.copy()

        if stages and stage_key in stages:
            idx = stages.index(stage_key)
            stage_progress = int(round((idx / (max(1, len(stages) - 1))) * 100))
        else:
            stage_progress = stage_to_percent.get(stage_key, 0)
        
        item_pct = stage_progress_pct(stage_key)
        proj_status, work_status = status_texts(stage_key)
        
        task_stage_map = _compute_stage_map_for_bid(r.get('g_id'))
        if any(v > 0 for v in task_stage_map.values()):
            stage_progress_map = {
                'analyzer': 100,
                'business': task_stage_map.get('business', 0),
                'design': task_stage_map.get('design', 0),
                'operations': task_stage_map.get('operations', 0),
                'engineer': task_stage_map.get('engineer', 0),
                'handover': 0,
            }
        else:
            stage_progress_map = {
                'analyzer': 100,
                'business': _parse_percent(r.get('dept_bde')),
                'design': _parse_percent(r.get('dept_m_d')),
                'operations': _parse_percent(r.get('dept_op')),
                'engineer': _parse_percent(r.get('dept_site')),
                'handover': 100 if (r.get('project_status') or '').strip().lower() in ('closed','completed','handover','done') else 0,
            }

        # Estimate progress if all zeros
        if not any(v > 0 for v in stage_progress_map.values()):
            ordered = ['analyzer','business','design','operations','engineer','handover']
            cur_idx = ordered.index(stage_key) if stage_key in ordered else 0
            estimated = {}
            for i, s in enumerate(ordered):
                if i < cur_idx:
                    estimated[s] = 100
                elif i == cur_idx:
                    estimated[s] = 40
                else:
                    estimated[s] = 0
            estimated['analyzer'] = 100
            stage_progress_map.update(estimated)

        # Ensure progress-map has keys for any custom stages to avoid missing lookups in templates
        try:
            for st in stages:
                stage_progress_map.setdefault(st, 0)
        except Exception:
            pass

        go_projects.append({
            'g_id': bid_id,
            'b_name': r.get('b_name'),
            'company': r.get('company'),
            'state': r.get('state'),
            'stage_key': stage_key,
            'stage_progress': stage_progress,
            'stages': stages,
            'current_stage': stage_key,
            'due_date': r.get('due_date'),
            'type': r.get('type'),
            'decision': r.get('decision'),
            'project_status': proj_status,
            'work_status': work_status,
            'summary': r.get('summary'),
            'work_progress_pct': item_pct,
            'stage_progress_map': stage_progress_map,
        })

    # Deduplicate and sort
    from datetime import datetime
    def _date_key(item):
        try:
            dv = item.get('due_date')
            if dv is None:
                return datetime.max
            if isinstance(dv, datetime):
                return dv
            return datetime.fromisoformat(str(dv)[:19])
        except Exception:
            return datetime.max
    go_projects_sorted = sorted(go_projects, key=_date_key)
    go_projects_top5 = go_projects_sorted[:5]
    go_projects_more = go_projects_sorted[5:]  # Additional BIDs beyond top 5

    # Project Timeline (won projects with dedicated timeline data)
    project_timeline_items = []
    try:
        won_params = []
        won_where = [
            "(LOWER(COALESCE(wlr.status,'')) LIKE '%%won%%' OR LOWER(COALESCE(wlr.result,'')) LIKE '%%won%%')"
        ]
        if active_company_name:
            won_where.append(
                "("
                "REPLACE(REPLACE(LOWER(COALESCE(wlr.company,'')), '.', ''), ' ', '') = "
                "REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', '')"
                " OR REPLACE(REPLACE(LOWER(COALESCE(wlr.company,'')), '.', ''), ' ', '') LIKE "
                "CONCAT('%%', REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', ''), '%%')"
                " OR REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', '') LIKE "
                "CONCAT('%%', REPLACE(REPLACE(LOWER(COALESCE(wlr.company,'')), '.', ''), ' ', ''), '%%')"
                ")"
            )
            won_params.extend([active_company_name, active_company_name, active_company_name])
        won_where_sql = " AND ".join(won_where)
        cur.execute(
            f"""
            SELECT
                wlr.w_id,
                wlr.g_id,
                wlr.b_name,
                wlr.company,
                wlr.status,
                wlr.result
            FROM win_lost_results wlr
            WHERE {won_where_sql}
            ORDER BY wlr.w_id DESC
            LIMIT 5
            """,
            tuple(won_params),
        )
        won_rows = cur.fetchall() or []
        if not won_rows and active_company_name:
            cur.execute(
                """
                SELECT
                    wlr.w_id,
                    wlr.g_id,
                    wlr.b_name,
                    wlr.company,
                    wlr.status,
                    wlr.result
                FROM win_lost_results wlr
                WHERE (LOWER(COALESCE(wlr.status,'')) LIKE '%%won%%' OR LOWER(COALESCE(wlr.result,'')) LIKE '%%won%%')
                ORDER BY wlr.w_id DESC
                LIMIT 5
                """
            )
            won_rows = cur.fetchall() or []
    except Exception:
        won_rows = []

    # Note: bid_incoming WON rows are synced into win_lost_results by sync_go_bids().

    # De-duplicate won rows by project id and bid name
    try:
        uniq = []
        seen_ids = set()
        seen_names = set()
        for rr in (won_rows or []):
            key = rr.get('w_id')
            raw_name = (rr.get('b_name') or '').strip()
            name_key = " ".join(raw_name.split()).lower()
            if key in seen_ids or (name_key and name_key in seen_names):
                continue
            seen_ids.add(key)
            if name_key:
                seen_names.add(name_key)
            uniq.append(rr)
        won_rows = uniq
    except Exception:
        pass

    # Final fallback: use existing project_timeline_stages if any were already seeded
    try:
        if not won_rows:
            cur.execute(
                """
                SELECT project_id, MAX(created_at) AS last_created
                FROM project_timeline_stages
                GROUP BY project_id
                ORDER BY last_created DESC
                LIMIT 5
                """
            )
            seeded_rows = cur.fetchall() or []
            for sr in seeded_rows:
                pid = sr.get('project_id')
                if not pid:
                    continue
                label = None
                company = None
                status = None
                result = None
                try:
                    cur.execute(
                        """
                        SELECT w_id, g_id, b_name, company, status, result
                        FROM win_lost_results
                        WHERE w_id=%s
                        LIMIT 1
                        """,
                        (int(pid),),
                    )
                    row = cur.fetchone() or {}
                    if row:
                        label = row.get('b_name')
                        company = row.get('company')
                        status = row.get('status')
                        result = row.get('result')
                except Exception:
                    pass
                if not label:
                    try:
                        src_id = int(pid)
                        if src_id >= 1000000000:
                            src_id = src_id - 1000000000
                        cur.execute(
                            """
                            SELECT id, b_name, comp_name, bid_status, results
                            FROM bid_incoming
                            WHERE id=%s
                            LIMIT 1
                            """,
                            (src_id,),
                        )
                        row = cur.fetchone() or {}
                        if row:
                            label = row.get('b_name')
                            company = row.get('comp_name')
                            status = row.get('bid_status')
                            result = row.get('results')
                    except Exception:
                        pass
                won_rows.append({
                    'w_id': pid,
                    'g_id': None,
                    'b_name': label or f"Project #{pid}",
                    'company': company,
                    'status': status,
                    'result': result,
                })
    except Exception:
        pass

    # De-duplicate won rows again after fallback
    try:
        uniq = []
        seen_ids = set()
        seen_names = set()
        for rr in (won_rows or []):
            key = rr.get('w_id')
            raw_name = (rr.get('b_name') or '').strip()
            name_key = " ".join(raw_name.split()).lower()
            if key in seen_ids or (name_key and name_key in seen_names):
                continue
            seen_ids.add(key)
            if name_key:
                seen_names.add(name_key)
            uniq.append(rr)
        won_rows = uniq
    except Exception:
        pass

    default_project_stages = [
        'Engineering Team',
        'Procurement Team',
        'Accounts & Finance Team',
    ]
    try:
        _ensure_project_timeline_tables(cur)
        mysql.connection.commit()
    except Exception:
        pass

    seen_projects = set()
    seen_project_names = set()
    for r in (won_rows or []):
        project_id = r.get('w_id')
        if not project_id:
            continue
        name_key = " ".join(((r.get('b_name') or '').strip()).split()).lower()
        if name_key and name_key in seen_project_names:
            continue
        if project_id in seen_projects:
            continue
        seen_projects.add(project_id)
        if name_key:
            seen_project_names.add(name_key)
        try:
            _seed_project_timeline(cur, int(project_id), default_project_stages)
            mysql.connection.commit()
        except Exception:
            pass
        cur.execute(
            """
            SELECT id, stage_name, stage_order
            FROM project_timeline_stages
            WHERE project_id=%s
            ORDER BY stage_order ASC, id ASC
            """,
            (project_id,),
        )
        stage_rows = cur.fetchall() or []

        # Normalize legacy stage names to new department stages for display
        legacy_stage_map = {
            'project kickoff': 'Engineering Team',
            'planning': 'Procurement Team',
            'execution': 'Accounts & Finance Team',
            'commissioning': 'Accounts & Finance Team',
            'closeout': None,
        }
        normalized_stage_rows = []
        seen_stage_names = set()
        for sr in stage_rows:
            raw_name = (sr.get('stage_name') or '').strip()
            mapped = legacy_stage_map.get(raw_name.lower(), raw_name)
            if mapped is None:
                continue
            name_key = mapped.lower()
            if name_key in seen_stage_names:
                continue
            seen_stage_names.add(name_key)
            sr = dict(sr)
            sr['stage_name'] = mapped
            normalized_stage_rows.append(sr)
        stage_rows = normalized_stage_rows
        stage_ids = [sr.get('id') for sr in stage_rows if sr.get('id') is not None]
        progress_map = {}
        if stage_ids:
            in_clause = ','.join(['%s'] * len(stage_ids))
            cur.execute(
                f"""
                SELECT stage_id, progress_pct
                FROM project_timeline_progress
                WHERE project_id=%s AND stage_id IN ({in_clause})
                """,
                tuple([project_id] + stage_ids),
            )
            for pr in (cur.fetchall() or []):
                progress_map[int(pr.get('stage_id'))] = int(pr.get('progress_pct') or 0)

        # Compute stage progress from checklist tasks (team-wise) if available
        checklist_progress = {}
        try:
            cur.execute(
                """
                SELECT stage, status
                FROM bid_checklists
                WHERE g_id=%s AND team_archive IS NULL
                """,
                (int(r.get('g_id') or 0),),
            )
            task_rows = cur.fetchall() or []
            counts = {}
            for tr in task_rows:
                stage_key = _normalize_department_key(tr.get('stage') or '') or ''
                if not stage_key:
                    continue
                counts.setdefault(stage_key, {'total': 0, 'done': 0})
                counts[stage_key]['total'] += 1
                if normalize_task_status(tr.get('status') or '') == 'completed':
                    counts[stage_key]['done'] += 1
            for k, v in counts.items():
                total = int(v.get('total') or 0)
                done = int(v.get('done') or 0)
                checklist_progress[k] = int(round((done / total) * 100)) if total else 0
        except Exception:
            checklist_progress = {}

        cur.execute(
            "SELECT stage_id FROM project_timeline_current WHERE project_id=%s",
            (project_id,),
        )
        current_row = cur.fetchone() or {}
        current_stage_id = current_row.get('stage_id')
        if not current_stage_id and stage_rows:
            current_stage_id = stage_rows[0].get('id')

        stages = []
        current_index = 0
        for idx, sr in enumerate(stage_rows):
            sid = sr.get('id')
            if sid == current_stage_id:
                current_index = idx
            stage_name = sr.get('stage_name') or ''
            stage_key = _normalize_department_key(stage_name) or stage_name.lower().replace(' ', '_')
            computed_pct = checklist_progress.get(stage_key)
            stages.append({
                'id': sid,
                'name': stage_name,
                'order': int(sr.get('stage_order') or 0),
                'progress': int(computed_pct if computed_pct is not None else progress_map.get(int(sid), 0)) if sid is not None else 0,
            })

        stage_progress = 0
        if len(stages) > 1:
            stage_progress = int(round((current_index / (len(stages) - 1)) * 100))

        project_timeline_items.append({
            'project_id': project_id,
            'g_id': r.get('g_id'),
            'b_name': r.get('b_name') or f"Won #{r.get('w_id')}",
            'company': r.get('company'),
            'current_stage_index': current_index,
            'stage_progress': stage_progress,
            'stages': stages,
        })

    cur.close()

    # Stage display name mapping
    def get_stage_display_name(stage_key):
        mapping = {
            'analyzer': 'BID Analyzer',
            'business': 'Business Development',
            'design': 'Design & Marketing',
            'operations': 'Operation Team',
            'engineer': 'Engineering Team',
            'handover': 'Submitted',
            'won': 'Won',
            'closure': 'Closure'
        }
        return mapping.get(stage_key.lower(), stage_key.title())
    
    return render_template('top_level_admin_dashboard.html',
                         team_leads=team_leads,
                         members=members,
                         recent_logs=recent_logs,
                         active_projects=active_projects,
                         pending_tasks=pending_tasks,
                         projects=projects,
                         modules=modules,
                         teams=teams,
                         go_projects_top5=go_projects_top5,
                         go_projects_more=go_projects_more,
                         project_timeline_items=project_timeline_items,
                         get_stage_display_name=get_stage_display_name)

def _top_admin_guard():
    """Return a response if access should be denied/redirected, otherwise None."""
    try:
        if getattr(current_user, 'is_admin', False):
            return None
    except Exception:
        pass
    user_role = getattr(current_user, 'role', '')
    role_norm = (user_role or '').strip().lower().replace(' ', '_').replace('-', '_')
    if role_norm not in ['topleveladmin', 'top_level_admin']:
        return "Access Denied - Top Level Admin Only", 403
    return None


def _normalize_role_key(role_raw: str) -> str:
    r = (role_raw or "").strip().lower()
    r = r.replace("_", " ")
    r = " ".join(r.split())
    if r in ("projectmanager", "project manager", "project_manager"):
        return "project manager"
    if r in ("top level admin", "topleveladmin", "top leveladmin", "top_level_admin"):
        return "topleveladmin"
    if r in ("it admin", "it administrator", "admin", "itadmin"):
        return "itadmin"
    if r in ("team lead", "teamlead"):
        return "teamlead"
    if r in ("member", "employee"):
        return "member"
    if r in ("business", "business dev", "business development", "design", "operations", "operation", "site engineer", "site manager", "engineering", "engineer"):
        return "teamlead"
    return r


def _default_module_crud_for_role(role_key: str, module_key: str) -> dict:
    rk = _normalize_role_key(role_key)
    mk = (module_key or "").strip()
    # Reuse the existing default module access as baseline for can_view.
    default_perms = DEFAULT_ROLE_PERMISSIONS.get(rk, {}) or DEFAULT_ROLE_PERMISSIONS.get(rk.replace("_", " "), {})
    can_view = bool(default_perms.get("all_access", False) or mk in (default_perms.get("modules") or []))
    # For now, only higher roles get edit/create/delete by default.
    elevated = rk in ("itadmin", "admin", "supervisor", "manager", "topleveladmin")
    can_edit = bool(can_view and elevated)
    can_create = bool(can_view and elevated)
    can_delete = bool(can_view and elevated)
    if rk == "teamlead" and mk == "approvals":
        can_edit = bool(can_view)
    # Top Level Admin should not manage users by default (existing behavior).
    if rk == "topleveladmin" and mk == "user_management":
        can_view = False
        can_edit = False
        can_create = False
        can_delete = False
    return {
        "can_view": can_view,
        "can_create": can_create,
        "can_edit": can_edit,
        "can_delete": can_delete,
        "scope": "all",
    }


def get_user_module_crud_permissions(user_role, is_admin=False, user_id: int | None = None) -> dict:
    """Return CRUD-style module permissions for a role (with optional user overrides)."""
    try:
        ensure_permissions_table()
    except Exception:
        pass

    role_name = _normalize_role_key(user_role or "member")

    if is_admin or role_name in ["itadmin", "admin", "it administrator"]:
        return {
            module["key"]: {
                "can_view": True,
                "can_create": True,
                "can_edit": True,
                "can_delete": True,
                "scope": "all",
            }
            for module in DEFAULT_MODULES
        }

    cur = mysql.connection.cursor(DictCursor)
    permissions = {}
    role_name_underscore = role_name.replace(" ", "_")
    role_name_space = role_name.replace("_", " ")

    overrides = _get_user_module_overrides(int(user_id), cur=cur) if user_id else {}

    for module in DEFAULT_MODULES:
        row = None
        try:
            cur.execute(
                """
                SELECT can_view, can_create, can_edit, can_delete, scope
                FROM module_permissions
                WHERE (role = %s OR role = %s) AND module_key = %s
                ORDER BY updated_at DESC
                LIMIT 1
                """,
                (role_name_underscore, role_name_space, module["key"]),
            )
            row = cur.fetchone()
        except Exception:
            row = None

        if not row:
            permissions[module["key"]] = _default_module_crud_for_role(role_name, module["key"])
        else:
            permissions[module["key"]] = {
                "can_view": bool(row.get("can_view")),
                "can_create": bool(row.get("can_create")),
                "can_edit": bool(row.get("can_edit")),
                "can_delete": bool(row.get("can_delete")),
                "scope": row.get("scope") or "all",
            }

        # Team Leads should be able to approve/reject items within Approvals.
        if role_name in ("teamlead", "team lead", "team_lead") and module["key"] == "approvals":
            if permissions[module["key"]].get("can_view"):
                permissions[module["key"]]["can_edit"] = True

        # Ensure Top Level Admin has full operational CRUD (except user management).
        if role_name in ("topleveladmin", "top level admin", "top_level_admin") and module["key"] != "user_management":
            permissions[module["key"]] = {
                "can_view": True,
                "can_create": True,
                "can_edit": True,
                "can_delete": True,
                "scope": "all",
            }

        # Enforce view gating for write perms.
        if not permissions[module["key"]]["can_view"]:
            permissions[module["key"]]["can_create"] = False
            permissions[module["key"]]["can_edit"] = False
            permissions[module["key"]]["can_delete"] = False

    # Apply per-user overrides if present.
    if overrides:
        for module_key, override in overrides.items():
            if module_key not in permissions:
                continue
            permissions[module_key] = {
                "can_view": bool(override.get("can_view")),
                "can_create": bool(override.get("can_create")),
                "can_edit": bool(override.get("can_edit")),
                "can_delete": bool(override.get("can_delete")),
                "scope": override.get("scope") or "user",
            }
            if not permissions[module_key]["can_view"]:
                permissions[module_key]["can_create"] = False
                permissions[module_key]["can_edit"] = False
                permissions[module_key]["can_delete"] = False

    return permissions


@app.route('/top-admin/overview')
@login_required
def top_admin_overview():
    denied = _top_admin_guard()
    if denied:
        return denied
    # Keep GO bids table fresh for accurate overview
    try:
        sync_go_bids()
    except Exception:
        pass

    cur = mysql.connection.cursor(DictCursor)

    def _has_col(table: str, col: str) -> bool:
        try:
            cur.execute(f"SHOW COLUMNS FROM {table} LIKE %s", (col,))
            return cur.fetchone() is not None
        except Exception:
            return False

    # Active company context for display + filtering
    active_company_id = session.get('active_company_id')
    active_company_name = None
    if active_company_id:
        try:
            cur.execute("SELECT name FROM companies WHERE id=%s", (int(active_company_id),))
            active_company_name = (cur.fetchone() or {}).get('name') or None
        except Exception:
            active_company_name = None

    company_sql_clause, company_params = _company_filter_for_go_bids(cur)
    use_company_fallback = False
    company_params_fallback = tuple()
    if company_sql_clause:
        use_company_fallback = True
        company_params_fallback = company_params + company_params
    use_company_fallback = False
    company_params_fallback = tuple()
    if company_sql_clause:
        use_company_fallback = True
        # Fallback to bid_incoming.comp_name when go_bids.company is empty
        company_params_fallback = company_params + company_params

    # --- Metrics (company-aware where possible) ---
    active_projects = 0
    total_bids = 0
    bids_pending = 0
    bids_submitted = 0
    pending_tasks = 0
    overdue_tasks = 0
    approvals_pending = 0
    employees = 0
    team_leads = 0

    # Bids by status (submission_status)
    try:
        rows = []
        has_submission_status = _has_col('go_bids', 'submission_status')
        if has_submission_status:
            cur.execute(
                """
                SELECT LOWER(TRIM(COALESCE(gb.submission_status, ''))) AS submission_status, COUNT(*) AS cnt
                FROM go_bids gb
                WHERE 1=1
                """ + company_sql_clause + """
                GROUP BY LOWER(TRIM(COALESCE(gb.submission_status, '')))
                """,
                company_params,
            )
            rows = cur.fetchall() or []
        else:
            cur.execute(
                """
                SELECT LOWER(TRIM(COALESCE(bi.bid_status, ''))) AS submission_status, COUNT(*) AS cnt
                FROM go_bids gb
                LEFT JOIN bid_incoming bi ON bi.id = gb.id
                WHERE 1=1
                """ + company_sql_clause + """
                GROUP BY LOWER(TRIM(COALESCE(bi.bid_status, '')))
                """,
                company_params,
            )
            rows = cur.fetchall() or []

        def _classify_submission_status(s: str) -> str:
            s = (s or '').strip().lower()
            if not s:
                return 'unknown'
            if 'submitted' in s:
                return 'submitted'
            if s in ('work progress', 'work_progress', 'in progress', 'in_progress', 'on hold', 'hold', 'not submitted', 'not_submitted', 'pending'):
                return 'pending'
            if s in ('incoming', 'new'):
                return 'incoming'
            return 'unknown'

        bucket = {'incoming': 0, 'pending': 0, 'submitted': 0, 'unknown': 0}
        for rr in rows:
            cnt = int(rr.get('cnt') or 0)
            total_bids += cnt
            key = _classify_submission_status(rr.get('submission_status') or '')
            bucket[key] = int(bucket.get(key, 0) or 0) + cnt
        bids_pending = int(bucket.get('pending') or 0)
        bids_submitted = int(bucket.get('submitted') or 0)
        bids_by_status = bucket
        if total_bids == 0:
            try:
                incoming_where = ""
                incoming_params = tuple()
                if active_company_name:
                    name_lower = active_company_name.lower()
                    if 'metco' in name_lower:
                        incoming_where = " AND LOWER(COALESCE(bi.comp_name,'')) LIKE %s"
                        incoming_params = ('%metco%',)
                    elif 'ikio' in name_lower:
                        incoming_where = " AND LOWER(COALESCE(bi.comp_name,'')) LIKE %s"
                        incoming_params = ('%ikio%',)
                    elif 'sunsprint' in name_lower:
                        incoming_where = " AND LOWER(COALESCE(bi.comp_name,'')) LIKE %s"
                        incoming_params = ('%sunsprint%',)
                    else:
                        incoming_where = " AND LOWER(COALESCE(bi.comp_name,'')) LIKE %s"
                        incoming_params = (f"%{name_lower}%",)
                cur.execute(
                    """
                    SELECT LOWER(TRIM(COALESCE(bi.bid_status, ''))) AS submission_status, COUNT(*) AS cnt
                    FROM bid_incoming bi
                    WHERE 1=1
                    """ + incoming_where + """
                    GROUP BY LOWER(TRIM(COALESCE(bi.bid_status, '')))
                    """,
                    incoming_params,
                )
                rows = cur.fetchall() or []
                bucket = {'incoming': 0, 'pending': 0, 'submitted': 0, 'unknown': 0}
                for rr in rows:
                    cnt = int(rr.get('cnt') or 0)
                    key = _classify_submission_status(rr.get('submission_status') or '')
                    bucket[key] = int(bucket.get(key, 0) or 0) + cnt
                total_bids = sum(bucket.values())
                bids_pending = int(bucket.get('pending') or 0)
                bids_submitted = int(bucket.get('submitted') or 0)
                bids_by_status = bucket
            except Exception:
                pass
    except Exception:
        bids_by_status = {'incoming': 0, 'pending': 0, 'submitted': 0, 'unknown': 0}

    # Active projects (won bids -> projects)
    try:
        cur.execute(
            """
            SELECT COUNT(*) AS c
            FROM go_bids gb
            WHERE COALESCE(gb.stage,'') != 'handover'
            """ + company_sql_clause,
            company_params,
        )
        active_projects = int((cur.fetchone() or {}).get('c') or 0)
    except Exception:
        active_projects = 0

    # Prefer won-project count when available
    try:
        won_project_count = 0
        won_where = [
            "(LOWER(COALESCE(wlr.status,'')) LIKE '%%won%%' OR LOWER(COALESCE(wlr.result,'')) LIKE '%%won%%' OR LOWER(COALESCE(wlr.result,'')) LIKE '%%award%%')"
        ]
        won_params = []
        if active_company_name:
            won_where.append(
                "("
                "REPLACE(REPLACE(LOWER(COALESCE(wlr.company,'')), '.', ''), ' ', '') = "
                "REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', '')"
                " OR REPLACE(REPLACE(LOWER(COALESCE(wlr.company,'')), '.', ''), ' ', '') LIKE "
                "CONCAT('%%', REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', ''), '%%')"
                ")"
            )
            won_params.extend([active_company_name, active_company_name])
        won_where_sql = " AND ".join(won_where)
        cur.execute(
            f"""
            SELECT COUNT(*) AS c
            FROM win_lost_results wlr
            WHERE {won_where_sql}
            """,
            tuple(won_params),
        )
        won_project_count = int((cur.fetchone() or {}).get('c') or 0)
        if won_project_count == 0:
            incoming_where = [
                "("
                "LOWER(COALESCE(bi.results,'')) LIKE '%%won%%' "
                "OR LOWER(COALESCE(bi.results,'')) LIKE '%%award%%' "
                "OR LOWER(COALESCE(bi.bid_status,'')) LIKE '%%won%%' "
                "OR LOWER(COALESCE(bi.bid_status,'')) LIKE '%%award%%'"
                ")",
                "LOWER(COALESCE(bi.results,'')) NOT LIKE '%%lost%%'",
                "LOWER(COALESCE(bi.bid_status,'')) NOT LIKE '%%lost%%'",
            ]
            incoming_params = []
            if active_company_name:
                incoming_where.append(
                    "("
                    "REPLACE(REPLACE(LOWER(COALESCE(bi.comp_name,'')), '.', ''), ' ', '') = "
                    "REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', '')"
                    " OR REPLACE(REPLACE(LOWER(COALESCE(bi.comp_name,'')), '.', ''), ' ', '') LIKE "
                    "CONCAT('%%', REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', ''), '%%')"
                    ")"
                )
                incoming_params.extend([active_company_name, active_company_name])
            incoming_where_sql = " AND ".join(incoming_where)
            cur.execute(
                f"""
                SELECT COUNT(*) AS c
                FROM bid_incoming bi
                WHERE {incoming_where_sql}
                """,
                tuple(incoming_params),
            )
            won_project_count = int((cur.fetchone() or {}).get('c') or 0)
        if won_project_count > 0:
            active_projects = won_project_count
    except Exception:
        pass

    # Tasks (company-aware via join to go_bids)
    try:
        cur.execute(
            """
            SELECT COUNT(*) AS c
            FROM bid_checklists bc
            JOIN go_bids gb ON gb.g_id = bc.g_id
            WHERE 1=1
            """ + company_sql_clause + """
              AND LOWER(COALESCE(bc.status,'')) IN ('pending','not started','not_started','notstarted','new','')
            """,
            company_params,
        )
        pending_tasks = int((cur.fetchone() or {}).get('c') or 0)
    except Exception:
        pending_tasks = 0

    # Overdue tasks: prefer bc.due_date, else fallback to gb.due_date
    try:
        bc_has_due = _has_col('bid_checklists', 'due_date')
        if bc_has_due:
            cur.execute(
                """
                SELECT COUNT(*) AS c
                FROM bid_checklists bc
                JOIN go_bids gb ON gb.g_id = bc.g_id
                WHERE 1=1
                """ + company_sql_clause + """
                  AND bc.due_date IS NOT NULL
                  AND bc.due_date < CURDATE()
                  AND LOWER(COALESCE(bc.status,'')) NOT IN ('completed','complete','done','finished','closed')
                """,
                company_params,
            )
        else:
            cur.execute(
                """
                SELECT COUNT(*) AS c
                FROM bid_checklists bc
                JOIN go_bids gb ON gb.g_id = bc.g_id
                WHERE 1=1
                """ + company_sql_clause + """
                  AND gb.due_date IS NOT NULL
                  AND gb.due_date < CURDATE()
                  AND LOWER(COALESCE(bc.status,'')) NOT IN ('completed','complete','done','finished','closed')
                """,
                company_params,
            )
        overdue_tasks = int((cur.fetchone() or {}).get('c') or 0)
    except Exception:
        overdue_tasks = 0

    # Employees (optionally company-scoped if schema supports it)
    try:
        if active_company_id and _has_col('employees', 'company_id'):
            cur.execute("SELECT COUNT(*) AS c FROM employees WHERE company_id=%s", (int(active_company_id),))
        else:
            cur.execute("SELECT COUNT(*) AS c FROM employees")
        employees = int((cur.fetchone() or {}).get('c') or 0)
    except Exception:
        employees = 0

    # Team leads (company-aware)
    try:
        if active_company_id:
            cur.execute(
                """
                SELECT COUNT(DISTINCT user_id) AS c
                FROM user_company_access
                WHERE LOWER(COALESCE(role,''))='teamlead'
                  AND COALESCE(is_active, TRUE)=TRUE
                  AND company_id=%s
                """,
                (int(active_company_id),),
            )
        else:
            cur.execute(
                """
                SELECT COUNT(DISTINCT user_id) AS c
                FROM user_company_access
                WHERE LOWER(COALESCE(role,''))='teamlead'
                  AND COALESCE(is_active, TRUE)=TRUE
                """
            )
        team_leads = int((cur.fetchone() or {}).get('c') or 0)
    except Exception:
        team_leads = 0

    # Pending approvals (company-aware via join to go_bids)
    try:
        _ensure_document_approvals_table(cur)
        _ensure_task_work_files_table(cur)
        _ensure_task_manager_attachments_table(cur)
    except Exception:
        pass

    try:
        # Employee uploads
        cur.execute(
            """
            SELECT COUNT(*) AS c
            FROM task_work_files twf
            LEFT JOIN document_approvals da ON da.source_table='task_work_files' AND da.source_id=twf.id
            LEFT JOIN bid_checklists bc ON bc.id = twf.task_id
            LEFT JOIN go_bids gb ON gb.g_id = bc.g_id
            WHERE LOWER(COALESCE(da.status,'pending'))='pending'
            """ + company_sql_clause,
            company_params,
        )
        approvals_pending += int((cur.fetchone() or {}).get('c') or 0)
    except Exception:
        pass
    try:
        # Manager attachments
        cur.execute(
            """
            SELECT COUNT(*) AS c
            FROM task_manager_attachments tma
            LEFT JOIN document_approvals da ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
            LEFT JOIN bid_checklists bc ON bc.id = tma.task_id
            LEFT JOIN go_bids gb ON gb.g_id = bc.g_id
            WHERE LOWER(COALESCE(da.status,'pending'))='pending'
            """ + company_sql_clause,
            company_params,
        )
        approvals_pending += int((cur.fetchone() or {}).get('c') or 0)
    except Exception:
        pass

    # --- Charts (company-aware) ---
    task_labels, task_counts = [], []
    try:
        cur.execute(
            """
            SELECT LOWER(COALESCE(bc.status,'')) AS st, COUNT(*) AS c
            FROM bid_checklists bc
            JOIN go_bids gb ON gb.g_id = bc.g_id
            WHERE 1=1
            """ + company_sql_clause + """
            GROUP BY LOWER(COALESCE(bc.status,''))
            """,
            company_params,
        )
        rows = cur.fetchall() or []
        bucket = {'Pending': 0, 'In Progress': 0, 'Completed': 0, 'Other': 0}
        for r in rows:
            st = (r.get('st') or '').strip().lower().replace('-', ' ').replace('_', ' ')
            st = ' '.join(st.split())
            c = int(r.get('c') or 0)
            if st in ('completed', 'complete', 'done', 'finished', 'closed'):
                bucket['Completed'] += c
            elif st in ('in progress', 'inprogress', 'working', 'wip', 'started'):
                bucket['In Progress'] += c
            elif st in ('pending', 'not started', 'notstarted', 'new', ''):
                bucket['Pending'] += c
            else:
                bucket['Other'] += c
        task_labels = list(bucket.keys())
        task_counts = list(bucket.values())
        if sum(task_counts) == 0:
            cur.execute(
                """
                SELECT LOWER(COALESCE(bc.status,'')) AS st, COUNT(*) AS c
                FROM bid_checklists bc
                GROUP BY LOWER(COALESCE(bc.status,''))
                """
            )
            rows = cur.fetchall() or []
            bucket = {'Pending': 0, 'In Progress': 0, 'Completed': 0, 'Other': 0}
            for r in rows:
                st = (r.get('st') or '').strip().lower().replace('-', ' ').replace('_', ' ')
                st = ' '.join(st.split())
                c = int(r.get('c') or 0)
                if st in ('completed', 'complete', 'done', 'finished', 'closed'):
                    bucket['Completed'] += c
                elif st in ('in progress', 'inprogress', 'working', 'wip', 'started'):
                    bucket['In Progress'] += c
                elif st in ('pending', 'not started', 'notstarted', 'new', ''):
                    bucket['Pending'] += c
                else:
                    bucket['Other'] += c
            task_labels = list(bucket.keys())
            task_counts = list(bucket.values())
    except Exception:
        task_labels = ['Pending', 'In Progress', 'Completed', 'Other']
        task_counts = [0, 0, 0, 0]

    # Company bucket summary (only meaningful when All companies)
    company_breakdown = []
    try:
        if not active_company_id:
            cur.execute(
                """
                SELECT
                  CASE
                    WHEN LOWER(COALESCE(gb.company,'')) LIKE '%ikio%' THEN 'Ikio'
                    WHEN LOWER(COALESCE(gb.company,'')) LIKE '%metco%' THEN 'Metco'
                    WHEN LOWER(COALESCE(gb.company,'')) LIKE '%sunsprint%' THEN 'Sunsprint'
                    WHEN LOWER(COALESCE(gb.company,'')) = '' THEN 'Unknown'
                    ELSE 'Other'
                  END AS company_bucket,
                  COUNT(*) AS bids_total,
                  SUM(CASE WHEN COALESCE(gb.stage,'') != 'handover' THEN 1 ELSE 0 END) AS active_projects
                FROM go_bids gb
                GROUP BY company_bucket
                ORDER BY bids_total DESC
                """
            )
            company_breakdown = cur.fetchall() or []
    except Exception:
        company_breakdown = []

    # --- Bid Timeline (GO bids in progress) ---
    bid_timeline_items = []
    try:
        def _normalize_stage(raw_state: str) -> str:
            s = (raw_state or '').strip().lower()
            mapping = {
                'analyzer': 'analyzer',
                'business': 'business',
                'business dev': 'business',
                'bdm': 'business',
                'design': 'design',
                'operations': 'operations',
                'operation': 'operations',
                'engineer': 'engineer',
                'site_manager': 'engineer',
                'site manager': 'engineer',
                'handover': 'handover',
                'won': 'handover',
            }
            return mapping.get(s, 'analyzer')

        def _stage_label(key: str) -> str:
            return {
                'analyzer': 'BID Analyzer',
                'business': 'Business Development',
                'design': 'Design & Marketing',
                'operations': 'Operation Team',
                'engineer': 'Engineering Team',
                'handover': 'Submitted',
            }.get((key or '').lower(), (key or '').title())

        default_stages = ['analyzer', 'business', 'design', 'operations', 'engineer', 'handover']

        cur.execute(
            f"""
            SELECT
                gb.g_id,
                gb.b_name,
                gb.company,
                gb.state,
                gb.due_date,
                gb.submission_status,
                gb.submission_reason,
                bi.bid_status,
                bi.results
            FROM go_bids gb
            LEFT JOIN bid_incoming bi ON bi.id = gb.id
            WHERE 1=1
            """ + ("""
              AND (
                LOWER(COALESCE(gb.company,'')) LIKE %s
                OR (LOWER(COALESCE(gb.company,'')) = '' AND LOWER(COALESCE(bi.comp_name,'')) LIKE %s)
              )
            """ if use_company_fallback else company_sql_clause) + """
            ORDER BY gb.due_date IS NULL, gb.due_date ASC
            LIMIT 200
            """,
            (company_params_fallback if use_company_fallback else company_params),
        )
        go_rows = cur.fetchall() or []
        # Include assigned-task bids even when go_bids is missing.
        go_rows = _augment_go_rows_with_assigned_meta(
            cur,
            go_rows,
            active_company_name=active_company_name,
            max_total=None,
            include_closed=True,
        )
        go_rows = [
            rr for rr in (go_rows or [])
            if not _is_won_bid_status(
                rr.get('submission_reason'),
                rr.get('submission_status'),
                rr.get('bid_status'),
                rr.get('results'),
                rr.get('state'),
            )
        ]
        try:
            timeline_gids = [int(rr.get('g_id')) for rr in (go_rows or []) if rr.get('g_id')]
        except Exception:
            timeline_gids = []
        stage_map_by_gid, stage_counts_by_gid = _bid_timeline_progress_maps(cur, timeline_gids, default_stages)
        # Ensure stored team progress exists for these bids.
        try:
            for rr in (go_rows or []):
                gid = rr.get('g_id')
                if gid:
                    _recalc_bid_team_progress(cur, int(gid))
            try:
                mysql.connection.commit()
            except Exception:
                pass
        except Exception:
            pass

        def _compute_stage_stats_for_bid(g_id: int):
            cur2 = None
            try:
                cur2 = mysql.connection.cursor(DictCursor)
                def _merge_checklists(stage_map_local, counts_local):
                    try:
                        try:
                            cur2.execute(
                                """
                                SELECT bc.progress_pct, bc.status, COALESCE(bc.stage, bc.department, u.role) AS stage_source
                                FROM bid_checklists bc
                                LEFT JOIN users u ON bc.created_by = u.id
                                WHERE bc.g_id = %s
                                """,
                                (g_id,),
                            )
                        except Exception as e:
                            if "Unknown column 'department'" in str(e):
                                cur2.execute(
                                    """
                                    SELECT bc.progress_pct, bc.status, COALESCE(bc.stage, u.role) AS stage_source
                                    FROM bid_checklists bc
                                    LEFT JOIN users u ON bc.created_by = u.id
                                    WHERE bc.g_id = %s
                                    """,
                                    (g_id,),
                                )
                            else:
                                raise
                        rows_local = cur2.fetchall() or []
                        buckets_local = {k: [] for k in default_stages}
                        counts_local = {k: dict(counts_local.get(k, {'total': 0, 'completed': 0})) for k in default_stages}
                        for r in rows_local:
                            stage = _normalize_stage_key(r.get('stage_source'))
                            if not stage or stage not in buckets_local:
                                continue
                            pct = r.get('progress_pct')
                            if pct is None:
                                st = (r.get('status') or '').strip().lower()
                                pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
                            try:
                                pct = max(0, min(100, int(pct)))
                            except Exception:
                                pct = 0
                            buckets_local[stage].append(pct)
                            counts_local[stage]['total'] += 1
                            st = (r.get('status') or '').strip().lower()
                            if pct >= 100 or st in ('completed', 'submitted'):
                                counts_local[stage]['completed'] += 1
                        def _avg(lst):
                            return int(round(sum(lst) / len(lst))) if lst else 0
                        for k in default_stages:
                            if buckets_local[k]:
                                stage_map_local[k] = max(int(stage_map_local.get(k, 0) or 0), _avg(buckets_local[k]))
                        return stage_map_local, counts_local
                    except Exception:
                        return stage_map_local, counts_local

                def _merge_meta(stage_map_local, counts_local):
                    try:
                        _ensure_bid_assign_meta_table()
                        cur2.execute("SELECT data FROM bid_assign_meta WHERE g_id=%s", (int(g_id),))
                        row = cur2.fetchone() or {}
                        meta = {}
                        try:
                            meta = json.loads(row.get('data') or "{}")
                        except Exception:
                            meta = {}
                        checklist = meta.get('checklist') if isinstance(meta, dict) else None
                        if isinstance(checklist, list) and checklist:
                            meta_buckets = {k: [] for k in default_stages}
                            for item in checklist:
                                if not isinstance(item, dict):
                                    continue
                                stage = _normalize_stage_key(
                                    item.get('dept') or item.get('stage') or item.get('department') or item.get('team') or ''
                                )
                                if not stage or stage not in meta_buckets:
                                    continue
                                st = (item.get('status') or '').strip().lower()
                                pct = item.get('progress_pct')
                                if pct is None:
                                    pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
                                try:
                                    pct = max(0, min(100, int(pct)))
                                except Exception:
                                    pct = 0
                                meta_buckets[stage].append(pct)
                            def _avg(lst):
                                return int(round(sum(lst) / len(lst))) if lst else 0
                            for stage_key, vals in meta_buckets.items():
                                if vals and (counts_local.get(stage_key, {}).get('total', 0) == 0 or _avg(vals) > stage_map_local.get(stage_key, 0)):
                                    stage_map_local[stage_key] = _avg(vals)
                                    counts_local[stage_key]['total'] = len(vals)
                                    counts_local[stage_key]['completed'] = len([v for v in vals if v >= 100])
                    except Exception:
                        pass
                    return stage_map_local, counts_local
                try:
                    _ensure_bid_team_progress_table(cur2)
                    cur2.execute(
                        """
                        SELECT stage_key, progress_pct, total_tasks, completed_tasks
                        FROM bid_team_progress
                        WHERE g_id = %s
                        """,
                        (g_id,),
                    )
                    rows = cur2.fetchall() or []
                    if rows:
                        stage_map = {r.get('stage_key'): int(r.get('progress_pct') or 0) for r in rows}
                        counts = {
                            r.get('stage_key'): {
                                'total': int(r.get('total_tasks') or 0),
                                'completed': int(r.get('completed_tasks') or 0),
                            } for r in rows
                        }
                        for k in default_stages:
                            stage_map.setdefault(k, 0)
                            counts.setdefault(k, {'total': 0, 'completed': 0})
                        stage_map, counts = _merge_checklists(stage_map, counts)
                        stage_map, counts = _merge_meta(stage_map, counts)
                        has_signal = any((counts.get(k, {}).get('total', 0) or 0) > 0 for k in default_stages) or any(
                            int(stage_map.get(k, 0) or 0) > 0 for k in default_stages
                        )
                        if has_signal:
                            return stage_map, counts
                except Exception:
                    pass
                cur2.execute(
                    """
                    SELECT bc.progress_pct, bc.status, COALESCE(bc.stage, bc.department, u.role) AS stage_source
                    FROM bid_checklists bc
                    LEFT JOIN users u ON bc.created_by = u.id
                    WHERE bc.g_id = %s
                    """,
                    (g_id,),
                )
                rows = cur2.fetchall() or []
                role_to_stage = {
                    'business dev': 'business',
                    'business development': 'business',
                    'bdm': 'business',
                    'bde': 'business',
                    'design': 'design',
                    'design team': 'design',
                    'design & marketing': 'design',
                    'design and marketing': 'design',
                    'marketing': 'design',
                    'operations': 'operations',
                    'operation': 'operations',
                    'ops': 'operations',
                    'operations team': 'operations',
                    'site manager': 'engineer',
                    'site engineer': 'engineer',
                    'engineering': 'engineer',
                    'engineer': 'engineer',
                    'engineering team': 'engineer',
                    'handover': 'handover',
                    'submitted': 'handover',
                    'submit': 'handover',
                    'bid analyzer': 'analyzer',
                    'analyzer': 'analyzer',
                }
                buckets = {k: [] for k in default_stages}
                counts = {k: {'total': 0, 'completed': 0} for k in default_stages}
                for r in rows:
                    source = (r.get('stage_source') or '').strip().lower()
                    stage = role_to_stage.get(source)
                    if not stage and source in buckets:
                        stage = source
                    if not stage and source:
                        if 'design' in source or 'marketing' in source:
                            stage = 'design'
                        elif 'business' in source or 'bdm' in source or 'bde' in source:
                            stage = 'business'
                        elif 'operation' in source or 'ops' in source:
                            stage = 'operations'
                        elif 'engineer' in source or 'site' in source:
                            stage = 'engineer'
                        elif 'submit' in source or 'handover' in source or source == 'won':
                            stage = 'handover'
                        elif 'analy' in source:
                            stage = 'analyzer'
                    if not stage:
                        continue
                    pct = r.get('progress_pct')
                    if pct is None:
                        st = (r.get('status') or '').strip().lower()
                        pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
                    try:
                        pct = max(0, min(100, int(pct)))
                    except Exception:
                        pct = 0
                    buckets[stage].append(pct)
                    counts[stage]['total'] += 1
                    st = (r.get('status') or '').strip().lower()
                    if pct >= 100 or st in ('completed', 'submitted'):
                        counts[stage]['completed'] += 1
                def avg(lst):
                    return int(round(sum(lst) / len(lst))) if lst else 0
                stage_map = {k: avg(v) for k, v in buckets.items()}
                stage_map, counts = _merge_checklists(stage_map, counts)
                stage_map, counts = _merge_meta(stage_map, counts)
                try:
                    _recalc_bid_team_progress(cur2, int(g_id))
                except Exception:
                    pass
                cur2.close()
                return stage_map, counts
            except Exception:
                return {k: 0 for k in default_stages}, {k: {'total': 0, 'completed': 0} for k in default_stages}
            finally:
                if cur2 is not None:
                    try:
                        cur2.close()
                    except Exception:
                        pass

        for r in go_rows:
            stage_key = _normalize_stage(r.get('state'))
            if stage_key in default_stages:
                current_index = default_stages.index(stage_key)
            else:
                current_index = 0
            try:
                gid = int(r.get('g_id') or 0)
            except Exception:
                gid = 0
            if gid and gid in stage_map_by_gid:
                stage_progress_map = stage_map_by_gid.get(gid, {k: 0 for k in default_stages})
                stage_counts = stage_counts_by_gid.get(gid, {k: {'total': 0, 'completed': 0} for k in default_stages})
            elif gid:
                stage_progress_map, stage_counts = _compute_stage_progress_for_timeline(cur, gid, default_stages)
            else:
                stage_progress_map, stage_counts = ({k: 0 for k in default_stages}, {k: {'total': 0, 'completed': 0} for k in default_stages})
            try:
                if not any(int(stage_progress_map.get(k, 0) or 0) > 0 for k in default_stages):
                    gid = int(r.get('g_id') or 0)
                    if gid:
                        buckets = {k: [] for k in default_stages}
                        counts = {k: {'total': 0, 'completed': 0} for k in default_stages}
                        try:
                            cur.execute(
                                """
                                SELECT progress_pct, status, stage
                                FROM bid_checklists
                                WHERE g_id=%s
                                """,
                                (gid,),
                            )
                            for row in (cur.fetchall() or []):
                                stage = _normalize_stage_key(row.get('stage'))
                                if not stage or stage not in buckets:
                                    continue
                                pct = row.get('progress_pct')
                                if pct is None:
                                    st = (row.get('status') or '').strip().lower()
                                    pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
                                try:
                                    pct = max(0, min(100, int(pct)))
                                except Exception:
                                    pct = 0
                                buckets[stage].append(pct)
                                counts[stage]['total'] += 1
                                if pct >= 100 or (row.get('status') or '').strip().lower() in ('completed', 'submitted'):
                                    counts[stage]['completed'] += 1
                        except Exception:
                            pass
                        try:
                            if not any(v for v in buckets.values()):
                                cur.execute("SELECT data FROM bid_assign_meta WHERE g_id=%s", (gid,))
                                row = cur.fetchone() or {}
                                meta = {}
                                try:
                                    meta = json.loads(row.get('data') or "{}")
                                except Exception:
                                    meta = {}
                                checklist = meta.get('checklist') if isinstance(meta, dict) else None
                                if isinstance(checklist, list) and checklist:
                                    for item in checklist:
                                        if not isinstance(item, dict):
                                            continue
                                        stage = _normalize_stage_key(item.get('dept') or item.get('stage') or '')
                                        if not stage or stage not in buckets:
                                            continue
                                        st = (item.get('status') or '').strip().lower()
                                        pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
                                        buckets[stage].append(pct)
                                        counts[stage]['total'] += 1
                                        if pct >= 100 or st in ('completed', 'submitted'):
                                            counts[stage]['completed'] += 1
                        except Exception:
                            pass
                        def _avg(lst):
                            return int(round(sum(lst) / len(lst))) if lst else 0
                        stage_progress_map = {k: _avg(v) for k, v in buckets.items()}
                        stage_counts = counts
            except Exception:
                pass
            try:
                stage_progress_map['analyzer'] = max(int(stage_progress_map.get('analyzer', 0) or 0), 100)
            except Exception:
                stage_progress_map['analyzer'] = 100
            if any((stage_counts.get(k, {}).get('total', 0) or 0) > 0 for k in default_stages):
                stage_key = None
                ranked = []
                for idx, key in enumerate(default_stages):
                    pct = int(stage_progress_map.get(key, 0) or 0)
                    if pct > 0:
                        ranked.append((pct, idx, key))
                if ranked:
                    ranked.sort()
                    _, current_index, stage_key = ranked[-1]
                else:
                    current_index = 0
                    stage_key = 'analyzer'
            stages = []
            for idx, key in enumerate(default_stages):
                stages.append({
                    'name': _stage_label(key),
                    'key': key,
                    'progress': int(stage_progress_map.get(key, 0) or 0),
                    'active': idx <= current_index,
                })
            current_key = default_stages[current_index] if current_index < len(default_stages) else 'analyzer'
            stuck_key = None
            for key in default_stages:
                total = int((stage_counts.get(key, {}) or {}).get('total') or 0)
                pct = int(stage_progress_map.get(key, 0) or 0)
                if total > 0 and pct < 100:
                    stuck_key = key
                    break
            note = ''
            if r.get('summary'):
                note = str(r.get('summary') or '').strip()
            elif stuck_key:
                note = f"Stuck at {_stage_label(stuck_key)} ({int(stage_progress_map.get(stuck_key, 0) or 0)}%)."
            elif current_key:
                note = f"In {_stage_label(current_key)} ({int(stage_progress_map.get(current_key, 0) or 0)}%)."
            try:
                vals = [int(stage_progress_map.get(k, 0) or 0) for k in default_stages]
                overall_progress = int(round(sum(vals) / len(vals))) if vals else 0
            except Exception:
                overall_progress = 0
            bid_timeline_items.append({
                'g_id': r.get('g_id'),
                'b_name': r.get('b_name') or 'Bid',
                'company': r.get('company') or '',
                'due_date': r.get('due_date'),
                'current_index': current_index,
                'current_stage_key': current_key,
                'stage_progress_map': stage_progress_map,
                'stage_counts': stage_counts,
                'note': note,
                'overall_progress': overall_progress,
                'stages': stages,
            })
    except Exception:
        bid_timeline_items = []
        go_rows = []

    if not bid_timeline_items:
        # Hard fallback: show basic GO bids even if detailed timeline calc failed.
        try:
            fallback_rows = _basic_bid_timeline_rows(cur, company_sql_clause, company_params, limit=200)
            fallback_rows = [
                rr for rr in (fallback_rows or [])
                if not _is_won_bid_status(
                    rr.get('submission_reason'),
                    rr.get('submission_status'),
                    rr.get('state'),
                )
            ]
            bid_timeline_items = _build_basic_timeline_items(cur, fallback_rows)
            if not bid_timeline_items:
                fallback_rows = _basic_bid_timeline_rows(cur, "", tuple(), limit=200)
                fallback_rows = [
                    rr for rr in (fallback_rows or [])
                    if not _is_won_bid_status(
                        rr.get('submission_reason'),
                        rr.get('submission_status'),
                        rr.get('state'),
                    )
                ]
                bid_timeline_items = _build_basic_timeline_items(cur, fallback_rows)
        except Exception:
            pass

    # --- Project Timeline (won projects with dedicated timeline data) ---
    project_timeline_items = []
    try:
        won_params = []
        won_where = [
            "(LOWER(COALESCE(wlr.status,'')) LIKE '%%won%%' OR LOWER(COALESCE(wlr.result,'')) LIKE '%%won%%')"
        ]
        if active_company_name:
            won_where.append(
                "("
                "REPLACE(REPLACE(LOWER(COALESCE(wlr.company,'')), '.', ''), ' ', '') = "
                "REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', '')"
                " OR REPLACE(REPLACE(LOWER(COALESCE(wlr.company,'')), '.', ''), ' ', '') LIKE "
                "CONCAT('%%', REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', ''), '%%')"
                " OR REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', '') LIKE "
                "CONCAT('%%', REPLACE(REPLACE(LOWER(COALESCE(wlr.company,'')), '.', ''), ' ', ''), '%%')"
                ")"
            )
            won_params.extend([active_company_name, active_company_name, active_company_name])
        won_where_sql = " AND ".join(won_where)
        cur.execute(
            f"""
            SELECT
                wlr.w_id,
                wlr.g_id,
                wlr.b_name,
                wlr.company,
                wlr.status,
                wlr.result
            FROM win_lost_results wlr
            WHERE {won_where_sql}
            ORDER BY wlr.w_id DESC
            LIMIT 5
            """,
            tuple(won_params),
        )
        won_rows = cur.fetchall() or []
        if not won_rows and active_company_name:
            cur.execute(
                """
                SELECT
                    wlr.w_id,
                    wlr.g_id,
                    wlr.b_name,
                    wlr.company,
                    wlr.status,
                    wlr.result
                FROM win_lost_results wlr
                WHERE (LOWER(COALESCE(wlr.status,'')) LIKE '%%won%%' OR LOWER(COALESCE(wlr.result,'')) LIKE '%%won%%')
                ORDER BY wlr.w_id DESC
                LIMIT 5
                """
            )
            won_rows = cur.fetchall() or []
    except Exception:
        won_rows = []

    # Include won bids from bid_incoming results/status (bid analyzer)
    try:
        incoming_where = [
            "("
            "LOWER(COALESCE(bi.results,'')) LIKE '%%won%%' "
            "OR LOWER(COALESCE(bi.results,'')) LIKE '%%award%%' "
            "OR LOWER(COALESCE(bi.bid_status,'')) LIKE '%%won%%' "
            "OR LOWER(COALESCE(bi.bid_status,'')) LIKE '%%award%%'"
            ")",
            "LOWER(COALESCE(bi.results,'')) NOT LIKE '%%lost%%'",
            "LOWER(COALESCE(bi.bid_status,'')) NOT LIKE '%%lost%%'",
        ]
        incoming_params = []
        if active_company_name:
            incoming_where.append(
                "("
                "REPLACE(REPLACE(LOWER(COALESCE(bi.comp_name,'')), '.', ''), ' ', '') = "
                "REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', '')"
                " OR REPLACE(REPLACE(LOWER(COALESCE(bi.comp_name,'')), '.', ''), ' ', '') LIKE "
                "CONCAT('%%', REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', ''), '%%')"
                " OR REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', '') LIKE "
                "CONCAT('%%', REPLACE(REPLACE(LOWER(COALESCE(bi.comp_name,'')), '.', ''), ' ', ''), '%%')"
                ")"
            )
            incoming_params.extend([active_company_name, active_company_name, active_company_name])
        incoming_where_sql = " AND ".join(incoming_where)
        cur.execute(
            f"""
            SELECT
                bi.id AS w_id,
                bi.id AS g_id,
                bi.b_name,
                bi.comp_name AS company,
                bi.bid_status AS status,
                bi.results AS result
            FROM bid_incoming bi
            WHERE {incoming_where_sql}
            ORDER BY bi.id DESC
            LIMIT 5
            """,
            tuple(incoming_params),
        )
        incoming_won = cur.fetchall() or []
        # Offset project ids to avoid collision with win_lost_results w_id
        for r in incoming_won:
            try:
                r['w_id'] = int(r.get('w_id') or 0) + 1000000000
            except Exception:
                r['w_id'] = r.get('w_id')
        won_rows = (won_rows or []) + incoming_won
    except Exception:
        pass

    # De-duplicate won_rows by project id
    try:
        uniq = []
        seen = set()
        for rr in (won_rows or []):
            key = rr.get('w_id')
            if key in seen:
                continue
            seen.add(key)
            uniq.append(rr)
        won_rows = uniq
    except Exception:
        pass

    project_manager_map = {}
    project_manager_users = []
    default_pm = None
    try:
        project_ids = [int(r.get('w_id')) for r in (won_rows or []) if r.get('w_id')]
        project_manager_map = _get_project_manager_map(cur, project_ids)
    except Exception:
        project_manager_map = {}
    try:
        project_manager_users = _fetch_project_manager_users(cur, active_company_name)
        if project_manager_users:
            default_pm = project_manager_users[0]
    except Exception:
        project_manager_users = []
        default_pm = None

    default_project_stages = [
        'Engineering Team',
        'Procurement Team',
        'Accounts & Finance Team',
    ]

    try:
        _ensure_project_timeline_tables(cur)
        mysql.connection.commit()
    except Exception:
        pass

    seen_projects = set()
    seen_project_names = set()
    for r in (won_rows or []):
        project_id = r.get('w_id')
        if not project_id:
            continue
        name_key = " ".join(((r.get('b_name') or '').strip()).split()).lower()
        if name_key and name_key in seen_project_names:
            continue
        if project_id in seen_projects:
            continue
        seen_projects.add(project_id)
        if name_key:
            seen_project_names.add(name_key)
        try:
            _seed_project_timeline(cur, int(project_id), default_project_stages)
            mysql.connection.commit()
        except Exception:
            pass

        cur.execute(
            """
            SELECT id, stage_name, stage_order
            FROM project_timeline_stages
            WHERE project_id=%s
            ORDER BY stage_order ASC, id ASC
            """,
            (project_id,),
        )
        stage_rows = cur.fetchall() or []

        stage_ids = [sr.get('id') for sr in stage_rows if sr.get('id') is not None]
        progress_map = {}
        if stage_ids:
            in_clause = ','.join(['%s'] * len(stage_ids))
            cur.execute(
                f"""
                SELECT stage_id, progress_pct
                FROM project_timeline_progress
                WHERE project_id=%s AND stage_id IN ({in_clause})
                """,
                tuple([project_id] + stage_ids),
            )
            for pr in (cur.fetchall() or []):
                progress_map[int(pr.get('stage_id'))] = int(pr.get('progress_pct') or 0)

        # Prefer live checklist-derived progress when available.
        checklist_progress = {}
        g_id_for_progress = r.get('g_id')
        if g_id_for_progress:
            try:
                checklist_progress = _compute_checklist_stage_progress(cur, int(g_id_for_progress))
            except Exception:
                checklist_progress = {}

        cur.execute(
            "SELECT stage_id FROM project_timeline_current WHERE project_id=%s",
            (project_id,),
        )
        current_row = cur.fetchone() or {}
        current_stage_id = current_row.get('stage_id')
        if not current_stage_id and stage_rows:
            current_stage_id = stage_rows[0].get('id')

        stages = []
        current_index = 0
        for idx, sr in enumerate(stage_rows):
            sid = sr.get('id')
            if sid == current_stage_id:
                current_index = idx
            stage_name = sr.get('stage_name') or ''
            stage_key = _normalize_department_key(stage_name) or stage_name.lower().replace(' ', '_')
            computed_pct = checklist_progress.get(stage_key)
            stages.append({
                'id': sid,
                'name': stage_name,
                'order': int(sr.get('stage_order') or 0),
                'progress': int(computed_pct if computed_pct is not None else progress_map.get(int(sid), 0)) if sid is not None else 0,
            })

        stage_progress = 0
        if len(stages) > 1:
            stage_progress = int(round((current_index / (len(stages) - 1)) * 100))

        pm_info = project_manager_map.get(int(project_id)) if project_id is not None else None
        if not pm_info and default_pm:
            try:
                _ensure_project_manager_assignments_table(cur)
                cur.execute("SELECT 1 FROM project_manager_assignments WHERE project_id=%s LIMIT 1", (int(project_id),))
                if not cur.fetchone():
                    cur.execute(
                        """
                        INSERT INTO project_manager_assignments (project_id, g_id, manager_user_id, assigned_by_user_id)
                        VALUES (%s, %s, %s, %s)
                        """,
                        (int(project_id), int(r.get('g_id') or 0), int(default_pm.get('id')), int(getattr(current_user, 'id', 0))),
                    )
                    mysql.connection.commit()
                pm_info = {
                    'user_id': default_pm.get('id'),
                    'name': default_pm.get('full_name') or default_pm.get('email'),
                    'email': default_pm.get('email'),
                }
            except Exception:
                try:
                    mysql.connection.rollback()
                except Exception:
                    pass

        project_timeline_items.append({
            'project_id': project_id,
            'g_id': r.get('g_id'),
            'b_name': r.get('b_name') or f"Won #{r.get('w_id')}",
            'company': r.get('company'),
            'current_stage_index': current_index,
            'stage_progress': stage_progress,
            'stages': stages,
            'pm_user_id': (pm_info or {}).get('user_id'),
            'pm_name': (pm_info or {}).get('name'),
            'pm_email': (pm_info or {}).get('email'),
        })

    cur.close()

    if not project_manager_users:
        try:
            cur = mysql.connection.cursor(DictCursor)
            project_manager_users = _fetch_project_manager_users(cur, active_company_name)
        except Exception:
            project_manager_users = []
        finally:
            try:
                cur.close()
            except Exception:
                pass

    return render_template(
        'top_admin_overview.html',
        active_nav='overview',
        active_company_id=active_company_id,
        active_company_name=active_company_name,
        can_edit_project_timeline=bool(getattr(current_user, 'can_alter_timeline', False)),
        metrics={
            'active_projects': active_projects,
            'pending_tasks': pending_tasks,
            'overdue_tasks': overdue_tasks,
            'approvals_pending': approvals_pending,
            'employees': employees,
            'team_leads': team_leads,
            'total_bids': total_bids,
            'bids_pending': bids_pending,
            'bids_submitted': bids_submitted,
        },
        charts={
            'tasks': {'labels': task_labels, 'counts': task_counts},
            'bids_status': bids_by_status,
        },
        company_breakdown=company_breakdown,
        bid_timeline_items=bid_timeline_items,
        project_timeline_items=project_timeline_items,
        project_manager_users=project_manager_users,
    )


@app.route('/settings')
@login_required
def user_settings():
    return render_template('settings.html', active_nav='settings')


@app.route('/employee/settings')
def employee_settings():
    emp_id = session.get('employee_id')
    if not emp_id:
        return redirect(url_for('login'))
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SELECT id, name, email, department FROM employees WHERE id=%s LIMIT 1", (int(emp_id),))
        employee = cur.fetchone()
    finally:
        try:
            cur.close()
        except Exception:
            pass
    if not employee:
        return redirect(url_for('login'))
    return render_template(
        'settings.html',
        active_nav='settings',
        employee_view=True,
        employee=employee,
        sidebar_mode='employee',
        topbar_user_label=employee.get('name') or employee.get('email') or 'Employee',
        topbar_user_email=(employee.get('department') or 'Team Member'),
    )


@app.route('/top-admin/user-management')
@login_required
def top_admin_user_management():
    denied = _top_admin_guard()
    if denied:
        return denied
    return redirect(url_for('top_admin_role_access'))


@app.route('/top-admin/role-hierarchy')
@login_required
def top_admin_role_hierarchy():
    denied = _top_admin_guard()
    if denied:
        return denied
    role_hierarchy = [
        {
            'level': 1,
            'key': 'itadmin',
            'label': 'IT Administrator',
            'desc': 'Full system control: users, permissions, and all modules.',
        },
        {
            'level': 2,
            'key': 'topleveladmin',
            'label': 'Top Level Admin',
            'desc': 'Operational control across projects and teams (no user management).',
        },
        {
            'level': 3,
            'key': 'manager',
            'label': 'Manager',
            'desc': 'Owns team oversight, approvals, and delivery milestones.',
        },
        {
            'level': 3,
            'key': 'project manager',
            'label': 'Project Manager',
            'desc': 'Owns won-project delivery timelines and handoff tracking.',
        },
        {
            'level': 4,
            'key': 'teamlead',
            'label': 'Team Leads',
            'desc': 'Day-to-day execution and task coordination by department.',
            'subroles': ['Business Development', 'Operations', 'Design', 'Site Engineering'],
        },
        {
            'level': 5,
            'key': 'member',
            'label': 'Team Member',
            'desc': 'Personal tasks, updates, and assigned work.',
        },
    ]
    return render_template(
        'top_admin_role_hierarchy.html',
        active_nav='role_hierarchy',
        role_hierarchy=role_hierarchy,
    )

def _build_role_access_context() -> dict:
    access_roles = [
        {'key': 'manager', 'label': 'Manager', 'level': 3},
        {'key': 'project manager', 'label': 'Project Manager', 'level': 3},
        {'key': 'teamlead', 'label': 'Team Lead', 'level': 4},
        {'key': 'member', 'label': 'Employee', 'level': 5},
    ]
    module_order = [
        'bid_analyzer',
        'project_manager_dashboard',
        'assigned_tasks',
        'approvals',
    ]
    role_allowed_modules = {
        'manager': ['bid_analyzer', 'assigned_tasks', 'approvals'],
        'project manager': ['project_manager_dashboard', 'assigned_tasks', 'approvals'],
        'teamlead': ['assigned_tasks', 'approvals'],
        'member': ['assigned_tasks'],
    }
    module_map = {m.get('key'): m for m in DEFAULT_MODULES}
    access_modules = [module_map[k] for k in module_order if k in module_map]
    access_module_matrix = {
        role['key']: get_user_module_crud_permissions(role['key'])
        for role in access_roles
    }
    access_action_matrix = {
        role['key']: get_user_action_permissions(role['key'])
        for role in access_roles
    }

    access_users = []
    users = []
    employees = []
    reporting_managers = []
    user_manager_map = {}
    cur = mysql.connection.cursor(DictCursor)
    try:
        try:
            cur.execute(
                """
                SELECT
                    u.id,
                    u.email,
                    u.role,
                    u.is_active,
                    u.full_name,
                    GROUP_CONCAT(DISTINCT COALESCE(uca.department_key, 'all') ORDER BY COALESCE(uca.department_key, 'all') SEPARATOR ', ') AS departments
                FROM users u
                LEFT JOIN user_company_access uca
                  ON uca.user_id = u.id AND COALESCE(uca.is_active, TRUE)=TRUE
                GROUP BY u.id
                ORDER BY u.id DESC
                """
            )
        except Exception:
            cur.execute(
                """
                SELECT
                    u.id,
                    u.email,
                    u.role,
                    u.is_active,
                    GROUP_CONCAT(DISTINCT COALESCE(uca.department_key, 'all') ORDER BY COALESCE(uca.department_key, 'all') SEPARATOR ', ') AS departments
                FROM users u
                LEFT JOIN user_company_access uca
                  ON uca.user_id = u.id AND COALESCE(uca.is_active, TRUE)=TRUE
                GROUP BY u.id
                ORDER BY u.id DESC
                """
            )
        access_users = cur.fetchall() or []
        try:
            cur.execute("""
                SELECT id, email, role, is_active, full_name
                FROM users
                ORDER BY id DESC
            """)
            users = cur.fetchall() or []
        except Exception:
            users = []
        try:
            cur.execute("""
                SELECT id, email, role, full_name
                FROM users
                WHERE LOWER(COALESCE(role,'')) IN (
                    'topleveladmin','top_level_admin','top level admin',
                    'manager','project manager','project_manager','business_manager','design_manager','operation_manager','operations_manager','site_manager',
                    'teamlead','team_lead','business dev','business development','design','operations','site_engineer','site engineer','engineering','engineer'
                )
                ORDER BY email
            """)
            reporting_managers = cur.fetchall() or []
        except Exception:
            reporting_managers = []
        try:
            cur.execute("SELECT user_id, manager_user_id FROM user_reporting_manager")
            for rr in (cur.fetchall() or []):
                user_manager_map[int(rr.get('user_id'))] = rr.get('manager_user_id')
        except Exception:
            user_manager_map = {}
        try:
            cur.execute("""
                SELECT id, name, email, department, is_active, team_lead_id
                FROM employees
                ORDER BY id DESC
            """)
            employees = cur.fetchall() or []
        except Exception:
            employees = []
    finally:
        try:
            cur.close()
        except Exception:
            pass

    combined = []
    user_email_set = {((u.get('email') or '').strip().lower()) for u in (access_users or []) if (u.get('email') or '').strip()}
    for user in access_users:
        role_raw = user.get('role') or 'member'
        role_compact = (role_raw or '').strip().lower().replace('_', '').replace(' ', '')
        if role_compact == 'topleveladmin':
            # Hide Top Level Admin row from role access table (still available as reporting manager)
            continue
        role_key = _normalize_role_key(role_raw)
        is_admin_user = bool(user.get('is_admin')) if 'is_admin' in user else False
        perms = get_user_module_permissions(role_key, is_admin=is_admin_user, user_id=int(user.get('id') or 0))
        access_flags = {
            'bid_analyzer': bool(perms.get('bid_analyzer')),
            'project_manager_dashboard': bool(perms.get('project_manager_dashboard')),
            'assigned_tasks': bool(perms.get('assigned_tasks')),
            'approvals': bool(perms.get('approvals')),
        }
        pages = []
        if access_flags.get('bid_analyzer'):
            pages.append('Bid Dashboard')
        if access_flags.get('project_manager_dashboard'):
            pages.append('Project Manager Dashboard')
        if access_flags.get('assigned_tasks'):
            pages.append('Assigned Tasks')
        if access_flags.get('approvals'):
            pages.append('Approvals')
        user['pages'] = pages
        user['source'] = 'user'
        user['access_flags'] = access_flags
        user['manager_user_id'] = user_manager_map.get(int(user.get('id') or 0))
        combined.append(user)

    employees_filtered = []
    for emp in (employees or []):
        emp_email = (emp.get('email') or '').strip().lower()
        if emp_email and emp_email in user_email_set:
            # Avoid showing duplicates when a person exists as a user (manager/team lead/top admin).
            continue
        employees_filtered.append(emp)

    for emp in employees_filtered:
        role_raw = 'employee'
        role_key = _normalize_role_key(role_raw)
        overrides = _get_employee_module_overrides(int(emp.get('id') or 0), cur=None)
        perms = get_user_module_permissions(role_key, is_admin=False)
        access_flags = {
            'bid_analyzer': bool(overrides.get('bid_analyzer')) if 'bid_analyzer' in overrides else bool(perms.get('bid_analyzer')),
            'project_manager_dashboard': bool(overrides.get('project_manager_dashboard')) if 'project_manager_dashboard' in overrides else bool(perms.get('project_manager_dashboard')),
            'assigned_tasks': bool(overrides.get('assigned_tasks')) if 'assigned_tasks' in overrides else bool(perms.get('assigned_tasks')),
            'approvals': bool(overrides.get('approvals')) if 'approvals' in overrides else bool(perms.get('approvals')),
        }
        pages = []
        if access_flags.get('bid_analyzer'):
            pages.append('Bid Dashboard')
        if access_flags.get('project_manager_dashboard'):
            pages.append('Project Manager Dashboard')
        if access_flags.get('assigned_tasks'):
            pages.append('Assigned Tasks')
        if access_flags.get('approvals'):
            pages.append('Approvals')
        combined.append({
            'id': emp.get('id'),
            'email': emp.get('email') or '',
            'full_name': emp.get('name') or emp.get('email') or 'Employee',
            'role': role_raw,
            'departments': emp.get('department') or '',
            'is_active': bool(emp.get('is_active', True)),
            'team_lead_id': emp.get('team_lead_id'),
            'pages': pages,
            'access_flags': access_flags,
            'source': 'employee',
        })

    return {
        'access_roles': access_roles,
        'access_modules': access_modules,
        'access_module_matrix': access_module_matrix,
        'access_action_matrix': access_action_matrix,
        'role_allowed_modules': role_allowed_modules,
        'access_users': combined,
        'users': users,
        'employees': employees_filtered,
        'reporting_managers': reporting_managers,
    }


@app.route('/top-admin/role-access')
@login_required
def top_admin_role_access():
    denied = _top_admin_guard()
    if denied:
        return denied
    return render_template(
        'top_admin_user_management.html',
        active_nav='role_access',
        admin_tab='access',
        **_build_role_access_context(),
    )


@app.route('/top-admin/bid-dashboard')
@login_required
def top_admin_bid_dashboard():
    denied = _top_admin_guard()
    if denied:
        return denied
    return bid_analyzer()


@app.route('/top-admin/approvals')
@login_required
def top_admin_approvals():
    denied = _top_admin_guard()
    if denied:
        return denied
    team_names = {
        'business': 'Business Development',
        'design': 'Design',
        'operations': 'Operations',
        'engineer': 'Site Engineer',
    }
    team_filter_raw = (request.args.get('team') or '').strip().lower()
    if team_filter_raw in ('', 'all', '*'):
        team_filter = None
    else:
        team_filter = _normalize_department_key(team_filter_raw)
        if team_filter not in team_names:
            team_filter = None
    if team_filter is None:
        try:
            dept_key = session.get('active_department_key') or None
        except Exception:
            dept_key = None
        dept_norm = _normalize_department_key(dept_key)
        if dept_norm in team_names:
            team_filter = dept_norm

    cur = mysql.connection.cursor(DictCursor)
    try:
        items = _collect_approval_items(cur, department_key=team_filter, approval_target='admin')
    finally:
        try:
            cur.close()
        except Exception:
            pass
    return render_template(
        'manager_approvals.html',
        items=items,
        team_key=team_filter,
        team_label=team_names.get(team_filter, 'All Teams'),
        user=current_user,
        user_role=getattr(current_user, 'role', 'admin'),
    )


@app.route('/top-admin/team-chats')
@login_required
def top_admin_team_chats():
    denied = _top_admin_guard()
    if denied:
        return denied
    return team_chats()


@app.route('/api/top-admin/overview/details')
@login_required
def api_top_admin_overview_details():
    """Return row-level data for Top Admin Overview drill-down tables."""
    denied = _top_admin_guard()
    if denied:
        try:
            return jsonify({'ok': False, 'error': 'access_denied'}), 403
        except Exception:
            return ('Access denied', 403)

    key = (request.args.get('key') or '').strip().lower()
    limit = request.args.get('limit', None)
    try:
        limit_n = int(limit) if limit is not None else 200
    except Exception:
        limit_n = 200
    limit_n = max(1, min(limit_n, 500))

    from datetime import datetime, date

    def _to_jsonable(v):
        if isinstance(v, datetime):
            return v.isoformat(sep=' ', timespec='seconds')
        if isinstance(v, date):
            return v.isoformat()
        return v

    def _jsonify_rows(rows):
        out = []
        for r in (rows or []):
            rr = {}
            for k, v in (r or {}).items():
                rr[k] = _to_jsonable(v)
            out.append(rr)
        return out

    cur = mysql.connection.cursor(DictCursor)
    try:
        company_sql_clause, company_params = _company_filter_for_go_bids(cur)

        def _has_col(table: str, col: str) -> bool:
            try:
                cur.execute(f"SHOW COLUMNS FROM {table} LIKE %s", (col,))
                return cur.fetchone() is not None
            except Exception:
                return False

        # Map detail keys -> SQL
        if key in ('active_projects', 'projects'):
            stage_col = 'gb.stage' if _has_col('go_bids', 'stage') else ('gb.state' if _has_col('go_bids', 'state') else "''")
            progress_col = 'gb.progress_pct' if _has_col('go_bids', 'progress_pct') else ('COALESCE(gb.scoring, 0)' if _has_col('go_bids', 'scoring') else '0')
            cur.execute(
                f"""
                SELECT
                  gb.g_id,
                  COALESCE(gb.b_name, '') AS bid_name,
                  gb.company,
                  {stage_col} AS stage,
                  gb.due_date,
                  {progress_col} AS progress_pct
                FROM go_bids gb
                WHERE COALESCE({stage_col},'') != 'handover'
                {company_sql_clause}
                ORDER BY gb.due_date IS NULL, gb.due_date ASC
                LIMIT %s
                """,
                tuple(company_params) + (limit_n,),
            )
            rows = cur.fetchall() or []
            pretty = []
            for r in (rows or []):
                pretty.append({
                    'Bid ID': r.get('g_id'),
                    'Bid': r.get('bid_name') or '',
                    'Company': r.get('company') or '',
                    'Due Date': r.get('due_date') or '',
                })
            return jsonify({
                'ok': True,
                'title': 'Active Projects',
                'columns': ['Bid ID', 'Bid', 'Company', 'Due Date'],
                'rows': _jsonify_rows(pretty),
                'shown': len(pretty),
                'limit': limit_n,
            })

        if key in ('pending_tasks', 'tasks_pending'):
            cur.execute(
                f"""
                SELECT
                  bc.id,
                  bc.task_name,
                  bc.status,
                  bc.stage,
                  COALESCE(gb.b_name, '') AS bid_name,
                  gb.company,
                  bc.progress_pct
                FROM bid_checklists bc
                JOIN go_bids gb ON gb.g_id = bc.g_id
                WHERE 1=1
                {company_sql_clause}
                  AND LOWER(COALESCE(bc.status,'')) IN ('pending','not started','not_started','notstarted','new','')
                ORDER BY bc.id DESC
                LIMIT %s
                """,
                tuple(company_params) + (limit_n,),
            )
            rows = cur.fetchall() or []
            pretty = []
            for r in (rows or []):
                pretty.append({
                    'Task ID': r.get('id'),
                    'Task': r.get('task_name') or '',
                    'Status': r.get('status') or '',
                    'Stage': r.get('stage') or '',
                    'Bid': r.get('bid_name') or '',
                    'Company': r.get('company') or '',
                    'Progress %': r.get('progress_pct') or 0,
                })
            return jsonify({
                'ok': True,
                'title': 'Pending Tasks',
                'columns': ['Task ID', 'Task', 'Status', 'Stage', 'Bid', 'Company', 'Progress %'],
                'rows': _jsonify_rows(pretty),
                'shown': len(pretty),
                'limit': limit_n,
            })

        if key in ('overdue_tasks', 'tasks_overdue'):
            bc_has_due = _has_col('bid_checklists', 'due_date')
            if bc_has_due:
                due_col = 'bc.due_date'
            else:
                due_col = 'gb.due_date'
            cur.execute(
                f"""
                SELECT
                  bc.id,
                  bc.task_name,
                  bc.status,
                  bc.stage,
                  COALESCE(gb.b_name, '') AS bid_name,
                  gb.company,
                  {due_col} AS due_date
                FROM bid_checklists bc
                JOIN go_bids gb ON gb.g_id = bc.g_id
                WHERE 1=1
                {company_sql_clause}
                  AND {due_col} IS NOT NULL
                  AND {due_col} < CURDATE()
                  AND LOWER(COALESCE(bc.status,'')) NOT IN ('completed','complete','done','finished','closed')
                ORDER BY {due_col} ASC
                LIMIT %s
                """,
                tuple(company_params) + (limit_n,),
            )
            rows = cur.fetchall() or []
            pretty = []
            for r in (rows or []):
                pretty.append({
                    'Task ID': r.get('id'),
                    'Task': r.get('task_name') or '',
                    'Status': r.get('status') or '',
                    'Stage': r.get('stage') or '',
                    'Bid': r.get('bid_name') or '',
                    'Company': r.get('company') or '',
                    'Due Date': r.get('due_date') or '',
                })
            return jsonify({
                'ok': True,
                'title': 'Overdue Tasks',
                'columns': ['Task ID', 'Task', 'Status', 'Stage', 'Bid', 'Company', 'Due Date'],
                'rows': _jsonify_rows(pretty),
                'shown': len(pretty),
                'limit': limit_n,
            })

        if key in ('approvals_pending', 'pending_approvals'):
            try:
                _ensure_document_approvals_table(cur)
                _ensure_task_work_files_table(cur)
                _ensure_task_manager_attachments_table(cur)
            except Exception:
                pass

            rows_out = []
            try:
                cur.execute(
                    f"""
                    SELECT
                      'employee' AS source,
                      twf.id AS source_id,
                      bc.task_name,
                      COALESCE(gb.b_name, '') AS bid_name,
                      gb.company,
                      twf.original_filename,
                      twf.uploaded_at
                    FROM task_work_files twf
                    LEFT JOIN document_approvals da ON da.source_table='task_work_files' AND da.source_id=twf.id
                    LEFT JOIN bid_checklists bc ON bc.id = twf.task_id
                    LEFT JOIN go_bids gb ON gb.g_id = bc.g_id
                    WHERE LOWER(COALESCE(da.status,'pending'))='pending'
                    {company_sql_clause}
                    ORDER BY twf.uploaded_at DESC
                    LIMIT %s
                    """,
                    tuple(company_params) + (limit_n,),
                )
                rows_out.extend(cur.fetchall() or [])
            except Exception:
                pass
            try:
                cur.execute(
                    f"""
                    SELECT
                      'manager' AS source,
                      tma.id AS source_id,
                      bc.task_name,
                      COALESCE(gb.b_name, '') AS bid_name,
                      gb.company,
                      tma.original_filename,
                      tma.uploaded_at
                    FROM task_manager_attachments tma
                    LEFT JOIN document_approvals da ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
                    LEFT JOIN bid_checklists bc ON bc.id = tma.task_id
                    LEFT JOIN go_bids gb ON gb.g_id = bc.g_id
                    WHERE LOWER(COALESCE(da.status,'pending'))='pending'
                    {company_sql_clause}
                    ORDER BY tma.uploaded_at DESC
                    LIMIT %s
                    """,
                    tuple(company_params) + (limit_n,),
                )
                rows_out.extend(cur.fetchall() or [])
            except Exception:
                pass

            # newest first
            try:
                rows_out.sort(key=lambda r: r.get('uploaded_at') or '', reverse=True)
            except Exception:
                pass

            rows_out = rows_out[:limit_n]
            pretty = []
            for r in (rows_out or []):
                pretty.append({
                    'Source': r.get('source') or '',
                    'Task': r.get('task_name') or '',
                    'Bid': r.get('bid_name') or '',
                    'Company': r.get('company') or '',
                    'File': r.get('original_filename') or '',
                    'Uploaded At': r.get('uploaded_at') or '',
                })
            return jsonify({
                'ok': True,
                'title': 'Pending Approvals',
                'columns': ['Source', 'Task', 'Bid', 'Company', 'File', 'Uploaded At'],
                'rows': _jsonify_rows(pretty),
                'shown': len(pretty),
                'limit': limit_n,
            })

        if key in ('employees',):
            if _has_col('employees', 'company_id'):
                active_company_id = session.get('active_company_id')
                if active_company_id:
                    cur.execute(
                        "SELECT id, name, email, department, is_active FROM employees WHERE company_id=%s ORDER BY department, name LIMIT %s",
                        (int(active_company_id), limit_n),
                    )
                else:
                    cur.execute(
                        "SELECT id, name, email, department, is_active FROM employees ORDER BY department, name LIMIT %s",
                        (limit_n,),
                    )
            else:
                cur.execute(
                    "SELECT id, name, email, department, is_active FROM employees ORDER BY department, name LIMIT %s",
                    (limit_n,),
                )
            rows = cur.fetchall() or []
            pretty_rows = []
            for r in (rows or []):
                pretty_rows.append({
                    'ID': r.get('id'),
                    'Name': r.get('name') or '',
                    'Email': r.get('email') or '',
                    'Department': r.get('department') or '',
                    'Status': 'Active' if bool(r.get('is_active', True)) else 'Inactive',
                })
            return jsonify({
                'ok': True,
                'title': 'Employees',
                'columns': ['ID', 'Name', 'Email', 'Department', 'Status'],
                'rows': _jsonify_rows(pretty_rows),
                'shown': len(pretty_rows),
                'limit': limit_n,
            })

        if key in ('team_leads',):
            active_company_id = session.get('active_company_id')
            if active_company_id:
                cur.execute(
                    """
                    SELECT u.id, u.email, uca.department_key, uca.company_id
                    FROM user_company_access uca
                    JOIN users u ON u.id = uca.user_id
                    WHERE COALESCE(uca.is_active, TRUE)=TRUE
                      AND LOWER(COALESCE(uca.role,''))='teamlead'
                      AND uca.company_id=%s
                    ORDER BY u.email
                    LIMIT %s
                    """,
                    (int(active_company_id), limit_n),
                )
            else:
                cur.execute(
                    """
                    SELECT u.id, u.email, uca.department_key, uca.company_id
                    FROM user_company_access uca
                    JOIN users u ON u.id = uca.user_id
                    WHERE COALESCE(uca.is_active, TRUE)=TRUE
                      AND LOWER(COALESCE(uca.role,''))='teamlead'
                    ORDER BY u.email
                    LIMIT %s
                    """,
                    (limit_n,),
                )
            rows = cur.fetchall() or []
            pretty_rows = []
            for r in (rows or []):
                pretty_rows.append({
                    'ID': r.get('id'),
                    'Email': r.get('email') or '',
                    'Department': r.get('department_key') or '',
                    'Company ID': r.get('company_id') or '',
                })
            return jsonify({
                'ok': True,
                'title': 'Team Leads',
                'columns': ['ID', 'Email', 'Department', 'Company ID'],
                'rows': _jsonify_rows(pretty_rows),
                'shown': len(pretty_rows),
                'limit': limit_n,
            })

        if key in ('tasks_status',):
            status = (request.args.get('status') or '').strip().lower()
            if status in ('pending', 'not started', 'not_started', 'new'):
                status_where = "LOWER(COALESCE(bc.status,'')) IN ('pending','not started','not_started','notstarted','new','')"
            elif status in ('in progress', 'in_progress', 'working', 'started'):
                status_where = "LOWER(COALESCE(bc.status,'')) IN ('in_progress','in progress','working','started')"
            elif status in ('completed', 'complete', 'done', 'finished', 'closed'):
                status_where = "LOWER(COALESCE(bc.status,'')) IN ('completed','complete','done','finished','closed')"
            else:
                status_where = "LOWER(COALESCE(bc.status,'')) NOT IN ('pending','not started','not_started','notstarted','new','','in_progress','in progress','working','started','completed','complete','done','finished','closed')"
            cur.execute(
                f"""
                SELECT
                  bc.id AS `Task ID`,
                  bc.task_name AS `Task`,
                  bc.status AS `Status`,
                  bc.stage AS `Stage`,
                  COALESCE(gb.b_name, '') AS `Bid`,
                  gb.company AS `Company`,
                  bc.due_date AS `Due Date`,
                  bc.progress_pct AS `Progress %`
                FROM bid_checklists bc
                JOIN go_bids gb ON gb.g_id = bc.g_id
                WHERE 1=1
                {company_sql_clause}
                  AND {status_where}
                ORDER BY bc.id DESC
                LIMIT %s
                """,
                tuple(company_params) + (limit_n,),
            )
            rows = cur.fetchall() or []
            return jsonify({
                'ok': True,
                'title': 'Tasks',
                'columns': ['Task ID', 'Task', 'Status', 'Stage', 'Bid', 'Company', 'Due Date', 'Progress %'],
                'rows': _jsonify_rows(rows),
                'shown': len(rows),
                'limit': limit_n,
            })

        if key in ('bids_status',):
            status = (request.args.get('status') or '').strip().lower()
            if status in ('incoming', 'pending', 'submitted'):
                status_match = status
            else:
                status_match = 'unknown'
            cur.execute(
                f"""
                SELECT
                  gb.g_id AS `GO ID`,
                  COALESCE(gb.b_name, bi.b_name, '') AS `Bid`,
                  COALESCE(gb.company, bi.comp_name, '') AS `Company`,
                  COALESCE(gb.state, bi.state, '') AS `Stage`,
                  COALESCE(bi.bid_status, gb.submission_status, '') AS `Bid Status`,
                  COALESCE(bi.decision, gb.decision, '') AS `Decision`,
                  COALESCE(bi.results, '') AS `Result`,
                  COALESCE(gb.due_date, bi.due_date, '') AS `Due Date`
                FROM go_bids gb
                LEFT JOIN bid_incoming bi ON bi.id = gb.id
                WHERE 1=1
                {company_sql_clause}
                ORDER BY COALESCE(gb.due_date, bi.due_date) ASC
                LIMIT %s
                """,
                tuple(company_params) + (limit_n,),
            )
            rows = cur.fetchall() or []
            if not rows:
                try:
                    cur.execute(
                        """
                        SELECT
                          bi.id AS `GO ID`,
                          COALESCE(bi.b_name, '') AS `Bid`,
                          COALESCE(bi.comp_name, '') AS `Company`,
                          COALESCE(bi.state, '') AS `Stage`,
                          COALESCE(bi.bid_status, '') AS `Bid Status`,
                          COALESCE(bi.decision, '') AS `Decision`,
                          COALESCE(bi.results, '') AS `Result`,
                          COALESCE(bi.due_date, '') AS `Due Date`
                        FROM bid_incoming bi
                        ORDER BY bi.due_date ASC
                        LIMIT %s
                        """,
                        (limit_n,),
                    )
                    rows = cur.fetchall() or []
                except Exception:
                    rows = []
            def _classify_row(s: str) -> str:
                s = (s or '').strip().lower()
                if not s:
                    return 'unknown'
                if 'submitted' in s:
                    return 'submitted'
                if s in ('work progress', 'work_progress', 'in progress', 'in_progress', 'on hold', 'hold', 'not submitted', 'not_submitted', 'pending'):
                    return 'pending'
                if s in ('incoming', 'new'):
                    return 'incoming'
                return 'unknown'
            filtered = []
            for r in rows:
                label = _classify_row(r.get('Bid Status') or '')
                if label == status_match:
                    filtered.append(r)
            return jsonify({
                'ok': True,
                'title': f'Bids ({status_match.title()})',
                'columns': ['GO ID', 'Bid', 'Company', 'Stage', 'Bid Status', 'Decision', 'Result', 'Due Date'],
                'rows': _jsonify_rows(filtered),
                'shown': len(filtered),
                'limit': limit_n,
            })

        return jsonify({'ok': False, 'error': 'unknown_key', 'message': 'Unknown key'}), 400
    finally:
        try:
            cur.close()
        except Exception:
            pass


def _fetch_notifications(*, recipient_kind: str, recipient_id: int, limit: int = 20) -> list[dict]:
    recipient_kind = (recipient_kind or "").strip().lower()
    try:
        recipient_id = int(recipient_id)
    except Exception:
        return []
    limit = max(1, min(int(limit or 20), 100))
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_notifications_table(cur)
        cur.execute(
            """
            SELECT id, category, title, message, link_url, is_read, created_at, read_at
            FROM notifications
            WHERE recipient_kind=%s AND recipient_id=%s
            ORDER BY created_at DESC, id DESC
            LIMIT %s
            """,
            (recipient_kind, recipient_id, limit),
        )
        return cur.fetchall() or []
    except Exception:
        return []
    finally:
        try:
            cur.close()
        except Exception:
            pass


def _count_unread_notifications(*, recipient_kind: str, recipient_id: int) -> int:
    recipient_kind = (recipient_kind or "").strip().lower()
    try:
        recipient_id = int(recipient_id)
    except Exception:
        return 0
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_notifications_table(cur)
        cur.execute(
            """
            SELECT COUNT(*) AS c
            FROM notifications
            WHERE recipient_kind=%s AND recipient_id=%s AND is_read=0
            """,
            (recipient_kind, recipient_id),
        )
        row = cur.fetchone() or {}
        return int(row.get("c") or 0)
    except Exception:
        return 0
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/notifications')
@login_required
def notifications_page():
    # Notifications page removed: notifications are available via the bell icon only.
    # Redirect to home to avoid serving a full notifications page.
    return redirect('/')


@app.route('/api/notifications/unread-count')
@login_required
def api_notifications_unread_count():
    include_employee = (request.args.get('include_employee') or '').strip().lower() in ('1', 'true', 'yes', 'y')
    unread = _count_unread_notifications(recipient_kind="user", recipient_id=int(current_user.id))
    if include_employee:
        try:
            email = (getattr(current_user, 'email', '') or '').strip().lower()
            if email:
                cur = mysql.connection.cursor(DictCursor)
                try:
                    cur.execute("SELECT id FROM employees WHERE LOWER(email)=%s LIMIT 1", (email,))
                    row = cur.fetchone() or {}
                    emp_id = int(row.get('id') or 0)
                finally:
                    try:
                        cur.close()
                    except Exception:
                        pass
                if emp_id > 0:
                    unread += _count_unread_notifications(recipient_kind="employee", recipient_id=int(emp_id))
        except Exception:
            pass
    return jsonify({'unread': unread})


@app.route('/api/notifications/recent')
@login_required
def api_notifications_recent():
    include_employee = (request.args.get('include_employee') or '').strip().lower() in ('1', 'true', 'yes', 'y')
    try:
        limit = int(request.args.get('limit', 10))
    except Exception:
        limit = 10
    limit = max(1, min(limit, 50))
    rows = _fetch_notifications(recipient_kind="user", recipient_id=int(current_user.id), limit=limit)
    if include_employee:
        try:
            email = (getattr(current_user, 'email', '') or '').strip().lower()
        except Exception:
            email = ''
        if email:
            try:
                cur = mysql.connection.cursor(DictCursor)
                try:
                    cur.execute("SELECT id FROM employees WHERE LOWER(email)=%s LIMIT 1", (email,))
                    row = cur.fetchone() or {}
                    emp_id = int(row.get('id') or 0)
                finally:
                    try:
                        cur.close()
                    except Exception:
                        pass
                if emp_id > 0:
                    emp_rows = _fetch_notifications(recipient_kind="employee", recipient_id=int(emp_id), limit=limit)
                    rows = (rows or []) + (emp_rows or [])
            except Exception:
                pass
    items = []
    for r in rows:
        created_at = r.get('created_at')
        items.append({
            'id': r.get('id'),
            'category': r.get('category'),
            'title': r.get('title'),
            'message': r.get('message'),
            'link_url': r.get('link_url'),
            'is_read': bool(r.get('is_read')),
            'created_at': (
                created_at.strftime('%Y-%m-%d %H:%M')
                if hasattr(created_at, 'strftime')
                else (str(created_at) if created_at else '')
            ),
        })
    if items:
        try:
            # Attach raw created_at for sort
            for idx, r in enumerate(rows):
                if idx < len(items):
                    items[idx]['_created_at_raw'] = r.get('created_at')
            def _sort_key(item):
                try:
                    raw = item.get('_created_at_raw')
                    if hasattr(raw, 'timestamp'):
                        return raw.timestamp()
                except Exception:
                    pass
                return 0
            items = sorted(items, key=lambda x: (_sort_key(x), int(x.get('id') or 0)), reverse=True)
            for it in items:
                it.pop('_created_at_raw', None)
        except Exception:
            pass
    return jsonify({'items': items[:limit]})


@app.route('/api/notifications/mark-read', methods=['POST'])
@login_required
def api_notifications_mark_read():
    data = request.get_json(silent=True) if request.is_json else None
    data = data if isinstance(data, dict) else {}

    token = (data.get('_csrf_token') or '').strip()
    if not token:
        token = (request.headers.get('X-CSRF-Token') or '').strip()
    if not token:
        token = (request.form.get('_csrf_token') or '').strip()
    if not validate_csrf_token(token):
        return jsonify({'success': False, 'error': 'csrf', 'message': 'Security validation failed. Please refresh and try again.'}), 403

    include_employee = (request.args.get('include_employee') or '').strip().lower() in ('1', 'true', 'yes', 'y')
    ids = data.get('ids') if isinstance(data.get('ids'), list) else None
    id_list = []
    if ids:
        for v in ids:
            try:
                id_list.append(int(v))
            except Exception:
                continue
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_notifications_table(cur)
        if id_list:
            placeholders = ",".join(["%s"] * len(id_list))
            sql = f"""
                UPDATE notifications
                SET is_read=1, read_at=NOW()
                WHERE recipient_kind=%s AND recipient_id=%s AND id IN ({placeholders})
            """
            cur.execute(sql, ("user", int(current_user.id), *id_list))
        else:
            cur.execute(
                """
                UPDATE notifications
                SET is_read=1, read_at=NOW()
                WHERE recipient_kind=%s AND recipient_id=%s AND is_read=0
                """,
                ("user", int(current_user.id)),
            )
        if include_employee:
            try:
                email = (getattr(current_user, 'email', '') or '').strip().lower()
                if email:
                    cur.execute("SELECT id FROM employees WHERE LOWER(email)=%s LIMIT 1", (email,))
                    row = cur.fetchone() or {}
                    emp_id = int(row.get('id') or 0)
                else:
                    emp_id = 0
            except Exception:
                emp_id = 0
            if emp_id > 0:
                if id_list:
                    placeholders = ",".join(["%s"] * len(id_list))
                    sql = f"""
                        UPDATE notifications
                        SET is_read=1, read_at=NOW()
                        WHERE recipient_kind=%s AND recipient_id=%s AND id IN ({placeholders})
                    """
                    cur.execute(sql, ("employee", int(emp_id), *id_list))
                else:
                    cur.execute(
                        """
                        UPDATE notifications
                        SET is_read=1, read_at=NOW()
                        WHERE recipient_kind=%s AND recipient_id=%s AND is_read=0
                        """,
                        ("employee", int(emp_id)),
                    )
        mysql.connection.commit()
        return jsonify({'success': True})
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        return jsonify({'success': False, 'error': 'db', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


def _get_employee_session_id() -> int | None:
    try:
        emp_id = session.get('employee_id')
        if emp_id is None:
            return None
        return int(emp_id)
    except Exception:
        return None


@app.route('/api/employee/notifications/unread-count')
def api_employee_notifications_unread_count():
    emp_id = _get_employee_session_id()
    if not emp_id:
        return jsonify({'unread': 0})
    unread = _count_unread_notifications(recipient_kind="employee", recipient_id=int(emp_id))
    return jsonify({'unread': unread})


@app.route('/api/employee/notifications/recent')
def api_employee_notifications_recent():
    emp_id = _get_employee_session_id()
    if not emp_id:
        return jsonify({'items': []})
    try:
        limit = int(request.args.get('limit', 10))
    except Exception:
        limit = 10
    limit = max(1, min(limit, 50))
    rows = _fetch_notifications(recipient_kind="employee", recipient_id=int(emp_id), limit=limit)
    items = []
    for r in rows:
        created_at = r.get('created_at')
        items.append({
            'id': r.get('id'),
            'category': r.get('category'),
            'title': r.get('title'),
            'message': r.get('message'),
            'link_url': r.get('link_url'),
            'is_read': bool(r.get('is_read')),
            'created_at': (
                created_at.strftime('%Y-%m-%d %H:%M')
                if hasattr(created_at, 'strftime')
                else (str(created_at) if created_at else '')
            ),
        })
    return jsonify({'items': items})


@app.route('/api/employee/notifications/mark-read', methods=['POST'])
def api_employee_notifications_mark_read():
    emp_id = _get_employee_session_id()
    if not emp_id:
        return jsonify({'success': False, 'error': 'auth'}), 403
    data = request.get_json(silent=True) if request.is_json else None
    data = data if isinstance(data, dict) else {}
    ids = data.get('ids') if isinstance(data.get('ids'), list) else None
    id_list = []
    if ids:
        for v in ids:
            try:
                id_list.append(int(v))
            except Exception:
                continue
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_notifications_table(cur)
        if id_list:
            placeholders = ",".join(["%s"] * len(id_list))
            sql = f"""
                UPDATE notifications
                SET is_read=1, read_at=NOW()
                WHERE recipient_kind=%s AND recipient_id=%s AND id IN ({placeholders})
            """
            cur.execute(sql, ("employee", int(emp_id), *id_list))
        else:
            cur.execute(
                """
                UPDATE notifications
                SET is_read=1, read_at=NOW()
                WHERE recipient_kind=%s AND recipient_id=%s AND is_read=0
                """,
                ("employee", int(emp_id)),
            )
        mysql.connection.commit()
        return jsonify({'success': True})
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        return jsonify({'success': False, 'error': 'db', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


def _normalize_department_key(raw: str | None) -> str | None:
    val = (raw or "").strip().lower().replace("_", " ")
    val = " ".join(val.split())
    compact = val.replace(" ", "")
    if val in ("engineering team", "engineering") or compact in ("engineeringteam", "engineering"):
        return "engineering_team"
    if val in ("procurement team", "procurement") or compact in ("procurementteam", "procurement"):
        return "procurement_team"
    if val in ("accounts finance", "accounts & finance", "accounts and finance", "accounting", "finance", "accounts") or compact in ("accountsfinance", "accountsandfinance", "accounting", "finance", "accounts"):
        return "accounts_finance"
    if val in ("business", "business dev", "business development", "business manager", "business team", "business development team") or compact in ("bd", "bdm", "businessdev", "businessdevelopment"):
        return "business"
    if val in ("design", "marketing", "design manager", "design team", "marketing team") or compact in ("design", "marketing"):
        return "design"
    if val in (
        "operations",
        "operation",
        "ops",
        "operations manager",
        "operations team",
        "operation team",
        "ops team",
        "operations executive",
        "ops executive",
    ) or compact in ("operations", "operation", "ops", "opsmanager", "operationmanager", "operationsexecutive", "opsexecutive"):
        return "operations"
    if val in ("engineer", "site engineer", "site manager", "site_engineer", "site engineering", "site engineer team") or compact in ("engineer", "siteengineer", "sitemanager", "site"):
        return "engineering_team"
    if val in ("team lead", "teamlead"):
        return None
    return val or None


def _ensure_document_approvals_table(cur):
    cur.execute("""
        CREATE TABLE IF NOT EXISTS document_approvals (
            id INT AUTO_INCREMENT PRIMARY KEY,
            source_table VARCHAR(64) NOT NULL,
            source_id INT NOT NULL,
            status VARCHAR(32) NOT NULL DEFAULT 'pending',
            department_key VARCHAR(64),
            decided_by INT,
            decided_at TIMESTAMP NULL,
            decision_note TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            UNIQUE KEY uniq_source (source_table, source_id)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    """)
    try:
        cur.execute("ALTER TABLE document_approvals ADD COLUMN decision_note TEXT")
    except Exception:
        pass
    mysql.connection.commit()


def _ensure_task_comments_table(cur):
    """Task comments with optional approval-request flag."""
    cur.execute("""
        CREATE TABLE IF NOT EXISTS task_comments (
            id INT AUTO_INCREMENT PRIMARY KEY,
            task_id INT NOT NULL,
            employee_id INT,
            user_id INT,
            comment TEXT NOT NULL,
            needs_approval TINYINT(1) NOT NULL DEFAULT 0,
            approval_target VARCHAR(32) NOT NULL DEFAULT 'admin',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            INDEX idx_task_id (task_id),
            INDEX idx_needs_approval (needs_approval)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    """)
    # Backwards-compatible migration for older installs
    try:
        cur.execute("ALTER TABLE task_comments ADD COLUMN needs_approval TINYINT(1) NOT NULL DEFAULT 0")
    except Exception:
        pass
    try:
        cur.execute("ALTER TABLE task_comments ADD COLUMN approval_target VARCHAR(32) NOT NULL DEFAULT 'admin'")
    except Exception:
        pass
    try:
        cur.execute("CREATE INDEX idx_needs_approval ON task_comments (needs_approval)")
    except Exception:
        pass
    mysql.connection.commit()


def _ensure_task_team_lead_assignments_table(cur):
    """Track team lead assignments without creating employee records."""
    cur.execute("""
        CREATE TABLE IF NOT EXISTS task_team_lead_assignments (
            id INT AUTO_INCREMENT PRIMARY KEY,
            task_id INT NOT NULL,
            team_lead_user_id INT NOT NULL,
            assigned_by_user_id INT,
            department_key VARCHAR(64),
            assigned_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE KEY uniq_task_team_lead (task_id),
            KEY idx_team_lead_user (team_lead_user_id),
            CONSTRAINT fk_task_team_lead_task FOREIGN KEY (task_id) REFERENCES bid_checklists(id) ON DELETE CASCADE,
            CONSTRAINT fk_task_team_lead_user FOREIGN KEY (team_lead_user_id) REFERENCES users(id) ON DELETE CASCADE
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    """)
    mysql.connection.commit()


def _ensure_task_work_files_table(cur):
    cur.execute("""
        CREATE TABLE IF NOT EXISTS task_work_files (
            id INT AUTO_INCREMENT PRIMARY KEY,
            task_id INT NOT NULL,
            employee_id INT,
            filename VARCHAR(255) NOT NULL,
            original_filename VARCHAR(255) NOT NULL,
            file_path VARCHAR(512) NOT NULL,
            file_size INT DEFAULT 0,
            uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            description TEXT,
            approval_target VARCHAR(32) NOT NULL DEFAULT 'admin',
            INDEX idx_task_id (task_id)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    """)
    try:
        cur.execute("ALTER TABLE task_work_files ADD COLUMN approval_target VARCHAR(32) NOT NULL DEFAULT 'admin'")
    except Exception:
        pass
    mysql.connection.commit()


def _ensure_task_manager_attachments_table(cur):
    cur.execute("""
        CREATE TABLE IF NOT EXISTS task_manager_attachments (
            id INT AUTO_INCREMENT PRIMARY KEY,
            task_id INT NOT NULL,
            user_id INT,
            filename VARCHAR(255) NOT NULL,
            original_filename VARCHAR(255) NOT NULL,
            file_path VARCHAR(512) NOT NULL,
            file_size INT DEFAULT 0,
            uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            description TEXT,
            approval_target VARCHAR(32) NOT NULL DEFAULT 'admin',
            INDEX idx_task_id (task_id)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
    """)
    try:
        cur.execute("ALTER TABLE task_manager_attachments ADD COLUMN approval_target VARCHAR(32) NOT NULL DEFAULT 'admin'")
    except Exception:
        pass
    mysql.connection.commit()


def _normalize_approval_target(raw: str | None) -> str | None:
    val = (raw or "").strip().lower().replace("_", " ")
    val = " ".join(val.split())
    compact = val.replace(" ", "")
    if val in ("none", "review"):
        return None
    if val in ("team lead", "teamlead") or compact in ("teamlead", "teamleader", "bdtl", "opstl"):
        return "team_lead"
    if val in ("business manager", "manager") or compact in ("manager", "businessmanager", "designmanager", "operationsmanager", "operationmanager", "sitemanager", "bdmgr", "opsmgr", "opmgr", "projectmanager"):
        return "manager"
    if val in ("admin", "it admin", "itadmin", "top admin", "top level admin", "topleveladmin") or compact in ("admin", "itadmin", "topadmin", "topleveladmin"):
        return "admin"
    return val or None


def _department_aliases_for_compact(dept: str | None) -> list[str]:
    if not dept:
        return []
    d = _normalize_department_key(dept) or dept
    d = (d or '').strip().lower().replace("_", " ")
    d = " ".join(d.split())
    compact = d.replace(" ", "")
    if compact == "business":
        return ["business", "businessdev", "businessdevelopment", "bdm", "bd"]
    if compact == "design":
        return ["design", "marketing"]
    if compact == "operations":
        return ["operations", "operation", "ops", "opsmanager", "operationmanager"]
    if compact == "engineer":
        return ["engineer", "engineering", "siteengineer", "sitemanager", "site"]
    if compact == "engineeringteam":
        return ["engineeringteam", "engineering", "engineer", "siteengineer", "sitemanager", "site"]
    if compact == "procurementteam":
        return ["procurementteam", "procurement", "purchasing", "supplychain"]
    if compact in ("accountsfinance", "accountsandfinance", "accountingfinance"):
        return ["accountsfinance", "accountsandfinance", "accountingfinance", "accounting", "finance"]
    return [compact] if compact else []


def _approval_target_from_creator(cur, task: dict) -> str:
    try:
        creator_id = int(task.get('created_by') or 0)
    except Exception:
        creator_id = 0
    if creator_id <= 0:
        return "manager"
    try:
        cur.execute("SELECT role FROM users WHERE id=%s", (creator_id,))
        row = cur.fetchone() or {}
        role = (row.get('role') or '').strip().lower().replace('_', ' ')
    except Exception:
        role = ''
    if role in ('team lead', 'teamlead'):
        return "team_lead"
    if role in ('manager', 'business manager', 'design manager', 'operation manager', 'operations manager', 'site manager'):
        return "manager"
    if role in ('admin', 'itadmin', 'supervisor', 'top level admin', 'topleveladmin'):
        return "admin"
    return "manager"


def _allowed_approval_targets_for_request(*, is_flask_user: bool, role: str | None) -> set[str]:
    if not is_flask_user:
        return {"team_lead", "manager", "admin"}
    role_norm = _normalize_approval_target(role) or (role or "").strip().lower()
    if role_norm == "team_lead":
        return {"manager", "admin"}
    if role_norm == "manager":
        return {"team_lead", "manager", "admin"}
    if role_norm == "admin":
        return {"admin"}
    return {"admin"}


def _allowed_escalation_targets_for_role(role: str | None) -> set[str]:
    role_norm = _normalize_approval_target(role) or (role or "").strip().lower()
    if role_norm == "team_lead":
        return {"manager", "admin"}
    if role_norm == "manager":
        return {"admin"}
    return set()


def _approval_link_for_target(target: str | None, department_key: str | None = None) -> str:
    t = _normalize_approval_target(target) or "admin"
    if t == "team_lead":
        dept = _normalize_department_key(department_key)
        if dept:
            return f"/team-lead/approvals?team={dept}"
        return "/team-lead/approvals"
    if t == "manager":
        dept = _normalize_department_key(department_key)
        if dept:
            return f"/manager/approvals?team={dept}"
        return "/manager/approvals"
    return "/top-admin/approvals"


def _count_pending_approvals_for_task(cur, task_id: int) -> int:
    try:
        _ensure_document_approvals_table(cur)
        _ensure_task_comments_table(cur)
        _ensure_task_work_files_table(cur)
        _ensure_task_manager_attachments_table(cur)
    except Exception:
        pass
    pending = 0
    try:
        cur.execute(
            """
            SELECT COUNT(*) AS cnt
            FROM document_approvals da
            JOIN task_work_files twf
              ON da.source_table='task_work_files' AND da.source_id=twf.id
            WHERE twf.task_id=%s AND da.status='pending'
            """,
            (int(task_id),),
        )
        pending += int((cur.fetchone() or {}).get('cnt') or 0)
        cur.execute(
            """
            SELECT COUNT(*) AS cnt
            FROM document_approvals da
            JOIN task_comments tc
              ON da.source_table='task_comments' AND da.source_id=tc.id
            WHERE tc.task_id=%s AND da.status='pending'
            """,
            (int(task_id),),
        )
        pending += int((cur.fetchone() or {}).get('cnt') or 0)
        cur.execute(
            """
            SELECT COUNT(*) AS cnt
            FROM task_comments tc
            LEFT JOIN document_approvals da
              ON da.source_table='task_comments' AND da.source_id=tc.id
            WHERE tc.task_id=%s AND tc.needs_approval=1 AND da.id IS NULL
            """,
            (int(task_id),),
        )
        pending += int((cur.fetchone() or {}).get('cnt') or 0)
        cur.execute(
            """
            SELECT COUNT(*) AS cnt
            FROM document_approvals da
            JOIN task_manager_attachments tma
              ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
            WHERE tma.task_id=%s AND da.status='pending'
            """,
            (int(task_id),),
        )
        pending += int((cur.fetchone() or {}).get('cnt') or 0)
    except Exception:
        return pending
    return pending


def _update_task_status_from_approval(cur, task_id: int | None, decision_status: str | None) -> None:
    try:
        if not task_id:
            return
        status = (decision_status or '').strip().lower()
        if status == 'approved':
            pending = _count_pending_approvals_for_task(cur, int(task_id))
            if pending <= 0:
                new_status = 'completed'
                pct_val = 100
            else:
                new_status = 'submitted'
                pct_val = 75
        elif status == 'rejected':
            new_status = 'rejected'
            pct_val = 0
        elif status == 'reverted':
            new_status = 'pending'
            pct_val = 0
        else:
            return
        cur.execute(
            """
            UPDATE bid_checklists
            SET status=%s, progress_pct=%s, updated_at=CURRENT_TIMESTAMP
            WHERE id=%s
            """,
            (new_status, pct_val, int(task_id)),
        )
    except Exception:
        return


def _mark_task_submitted(cur, task_id: int | None) -> None:
    try:
        if not task_id:
            return
        cur.execute(
            """
            UPDATE bid_checklists
            SET status='submitted', progress_pct=75, updated_at=CURRENT_TIMESTAMP
            WHERE id=%s
              AND LOWER(COALESCE(status,'')) NOT IN ('completed','complete','done','finished','closed')
            """,
            (int(task_id),),
        )
    except Exception:
        return


def _approval_recipients_for_target(
    cur,
    *,
    employee_id: int | None,
    department_key: str | None,
    approval_target: str | None,
) -> list[int]:
    target = _normalize_approval_target(approval_target) or "admin"
    dept = _normalize_department_key(department_key)
    dept_aliases = _department_aliases_for_compact(dept)
    dept_placeholders = ", ".join(["%s"] * len(dept_aliases))
    dept_filter_sql = ""
    dept_params: tuple = tuple()
    if dept_aliases:
        dept_filter_sql = f" AND (uca.department_key IS NULL OR LOWER(REPLACE(REPLACE(COALESCE(uca.department_key,''),'_',''),' ','')) IN ({dept_placeholders}))"
        dept_params = tuple(dept_aliases)
    recipients: list[int] = []
    seen: set[int] = set()

    def _add(uid: int | None):
        try:
            if uid is None:
                return
            uid_int = int(uid)
        except Exception:
            return
        if uid_int <= 0 or uid_int in seen:
            return
        seen.add(uid_int)
        recipients.append(uid_int)

    if target == "team_lead":
        try:
            if employee_id:
                cur.execute("SELECT team_lead_id FROM employees WHERE id=%s", (int(employee_id),))
                row = cur.fetchone() or {}
                _add(row.get("team_lead_id"))
        except Exception:
            pass
        try:
            role_placeholders = ", ".join(["%s"] * 4)
            role_params = ("teamlead", "teamleader", "bdtl", "opstl")
            if dept_aliases:
                cur.execute(
                    f"""
                    SELECT DISTINCT u.id
                    FROM user_company_access uca
                    JOIN users u ON u.id = uca.user_id
                    WHERE LOWER(REPLACE(REPLACE(COALESCE(uca.role,''),'_',''),' ','')) IN ({role_placeholders})
                      AND COALESCE(uca.is_active, TRUE)=TRUE
                      {dept_filter_sql}
                    """,
                    (*role_params, *dept_params),
                )
            else:
                cur.execute(
                    f"""
                    SELECT DISTINCT u.id
                    FROM user_company_access uca
                    JOIN users u ON u.id = uca.user_id
                    WHERE LOWER(REPLACE(REPLACE(COALESCE(uca.role,''),'_',''),' ','')) IN ({role_placeholders})
                      AND COALESCE(uca.is_active, TRUE)=TRUE
                    """,
                    role_params,
                )
            for r in (cur.fetchall() or []):
                _add(r.get("id"))
        except Exception:
            pass
        if not recipients:
            try:
                cur.execute("""
                    SELECT id
                    FROM users
                    WHERE LOWER(REPLACE(REPLACE(COALESCE(role,''),'_',''),' ','')) IN ('teamlead','teamleader','bdtl','opstl')
                """)
                for r in (cur.fetchall() or []):
                    _add(r.get("id"))
            except Exception:
                pass
    elif target == "manager":
        try:
            role_placeholders = ", ".join(["%s"] * 9)
            role_params = (
                "manager",
                "businessmanager",
                "designmanager",
                "operationsmanager",
                "operationmanager",
                "sitemanager",
                "bdmgr",
                "opsmgr",
                "projectmanager",
            )
            if dept_aliases:
                cur.execute(
                    f"""
                    SELECT DISTINCT u.id
                    FROM user_company_access uca
                    JOIN users u ON u.id = uca.user_id
                    WHERE LOWER(REPLACE(REPLACE(COALESCE(uca.role,''),'_',''),' ','')) IN ({role_placeholders})
                      AND COALESCE(uca.is_active, TRUE)=TRUE
                      {dept_filter_sql}
                    """,
                    (*role_params, *dept_params),
                )
            else:
                cur.execute(
                    f"""
                    SELECT DISTINCT u.id
                    FROM user_company_access uca
                    JOIN users u ON u.id = uca.user_id
                    WHERE LOWER(REPLACE(REPLACE(COALESCE(uca.role,''),'_',''),' ','')) IN ({role_placeholders})
                      AND COALESCE(uca.is_active, TRUE)=TRUE
                    """,
                    role_params,
                )
            for r in (cur.fetchall() or []):
                _add(r.get("id"))
        except Exception:
            pass
        if not recipients:
            try:
                cur.execute("""
                    SELECT id
                    FROM users
                    WHERE LOWER(REPLACE(REPLACE(COALESCE(role,''),'_',''),' ','')) IN (
                        'manager','businessmanager','designmanager','operationsmanager','operationmanager',
                        'sitemanager','bdmgr','opsmgr','projectmanager'
                    )
                """)
                for r in (cur.fetchall() or []):
                    _add(r.get("id"))
            except Exception:
                pass
    else:
        try:
            cur.execute(
                """
                SELECT id FROM users
                WHERE COALESCE(is_admin, 0)=1
                   OR LOWER(COALESCE(role,'')) IN ('topleveladmin','top_level_admin','top level admin','itadmin','admin')
                """
            )
            for r in (cur.fetchall() or []):
                _add(r.get("id"))
        except Exception:
            pass
    return recipients


def _notify_approval_request(
    *,
    employee_id: int | None,
    department_key: str | None,
    approval_target: str | None,
    task_id: int | None = None,
    title: str,
    message: str,
) -> None:
    cur = mysql.connection.cursor(DictCursor)
    try:
        recipients = _approval_recipients_for_target(
            cur,
            employee_id=employee_id,
            department_key=department_key,
            approval_target=approval_target,
        )
        # Ensure assigned project manager receives manager-level approvals for this task.
        try:
            target_norm = _normalize_approval_target(approval_target) or "admin"
            if task_id and target_norm == "manager":
                cur.execute("SELECT g_id FROM bid_checklists WHERE id=%s", (int(task_id),))
                row = cur.fetchone() or {}
                g_id = row.get("g_id")
                if g_id:
                    _ensure_project_manager_assignments_table(cur)
                    cur.execute(
                        """
                        SELECT manager_user_id
                        FROM project_manager_assignments
                        WHERE g_id=%s
                        LIMIT 1
                        """,
                        (int(g_id),),
                    )
                    pm_row = cur.fetchone() or {}
                    pm_id = pm_row.get("manager_user_id")
                    if pm_id and pm_id not in recipients:
                        recipients.append(int(pm_id))
        except Exception:
            pass
    except Exception:
        recipients = []
    finally:
        try:
            cur.close()
        except Exception:
            pass
    link_url = _approval_link_for_target(approval_target, department_key=department_key)
    for uid in recipients:
        try:
            _create_notification(
                recipient_kind="user",
                recipient_id=uid,
                title=title,
                message=message,
                category="approval",
                link_url=link_url,
            )
        except Exception:
            pass


def _collect_approval_items(
    cur,
    *,
    department_key: str | None = None,
    approval_target: str | None = None,
    limit: int = 200,
) -> list[dict]:
    try:
        _ensure_document_approvals_table(cur)
        _ensure_task_work_files_table(cur)
        _ensure_task_manager_attachments_table(cur)
        _ensure_task_comments_table(cur)
    except Exception:
        pass

    items = []
    dept = _normalize_department_key(department_key)
    target = _normalize_approval_target(approval_target)
    dept_aliases = _department_aliases_for_compact(dept)
    if dept_aliases:
        dept_placeholders = ", ".join(["%s"] * len(dept_aliases))
        dept_clause = (
            " AND LOWER(REPLACE(REPLACE(COALESCE(da.department_key, e.department, e2.department, ''),'_',''),' ','')) IN ("
            + dept_placeholders
            + ")"
        )
        dept_params = tuple(dept_aliases)
    else:
        dept_clause = ""
        dept_params = tuple()
    target_clause = " AND LOWER(COALESCE(%s,'admin')) IN (%s)"
    target_values = []
    if target == 'team_lead':
        target_values = ['team_lead', 'teamlead', 'team lead']
    elif target == 'manager':
        target_values = [
            'manager',
            'business manager',
            'design manager',
            'operations manager',
            'operation manager',
            'site manager',
        ]
    elif target == 'admin':
        target_values = ['admin', 'it admin', 'itadmin', 'top admin', 'top level admin', 'topleveladmin']
    elif target:
        target_values = [target]
    try:
        limit_n = int(limit or 200)
    except Exception:
        limit_n = 200
    limit_n = max(1, min(limit_n, 500))

    try:
        # Employee uploads
        target_expr = "twf.approval_target"
        target_sql = ""
        target_params = tuple()
        if target_values:
            placeholders = ", ".join(["%s"] * len(target_values))
            target_sql = target_clause % (target_expr, placeholders)
            target_params = tuple(target_values)
        cur.execute(
            """
            SELECT
              twf.id AS source_id,
              'task_work_files' AS source_table,
              twf.task_id,
              twf.original_filename,
              twf.filename,
              twf.description,
              COALESCE(twf.approval_target, 'admin') AS approval_target,
              twf.uploaded_at,
              e.name AS uploader_name,
              e.email AS uploader_email,
              COALESCE(e.department, e2.department, da.department_key) AS department,
              bc.task_name,
              bc.priority AS task_priority,
              COALESCE(gb.b_name, '') AS bid_name,
              da.status AS approval_status,
              da.decided_at AS decided_at,
              da.decision_note AS decision_note
            FROM task_work_files twf
            LEFT JOIN bid_checklists bc ON bc.id = twf.task_id
            LEFT JOIN go_bids gb ON gb.g_id = bc.g_id
            LEFT JOIN employees e ON e.id = twf.employee_id
            LEFT JOIN employees e2 ON e2.id = bc.assigned_to
            LEFT JOIN document_approvals da ON da.source_table='task_work_files' AND da.source_id=twf.id
            WHERE 1=1
            """
            + dept_clause
            + target_sql
            + """
            ORDER BY twf.uploaded_at DESC
            LIMIT %s
            """,
            (*dept_params, *target_params, limit_n),
        )
        rows = cur.fetchall() or []
        for r in rows:
            st = (r.get('approval_status') or 'pending').strip().lower()
            items.append({
                'source': 'employee',
                'source_table': 'task_work_files',
                'source_id': r.get('source_id'),
                'task_id': r.get('task_id'),
                'task_name': r.get('task_name'),
                'priority': r.get('task_priority'),
                'bid_name': r.get('bid_name'),
                'department': r.get('department'),
                'uploader': r.get('uploader_name') or r.get('uploader_email'),
                'filename': r.get('filename'),
                'original_filename': r.get('original_filename'),
                'description': r.get('description'),
                'approval_target': r.get('approval_target') or 'admin',
                'uploaded_at': (r.get('uploaded_at').strftime('%Y-%m-%d %H:%M') if r.get('uploaded_at') else ''),
                'status': st,
                'decided_at': (r.get('decided_at').strftime('%Y-%m-%d %H:%M') if r.get('decided_at') else ''),
                'decision_note': r.get('decision_note') or '',
                'download_url': f"/task/file/{int(r.get('source_id') or 0)}/download",
            })
    except Exception:
        pass

    try:
        # Manager attachments
        target_expr = "tma.approval_target"
        target_sql = ""
        target_params = tuple()
        if target_values:
            placeholders = ", ".join(["%s"] * len(target_values))
            target_sql = target_clause % (target_expr, placeholders)
            target_params = tuple(target_values)
        cur.execute(
            """
            SELECT
              tma.id AS source_id,
              'task_manager_attachments' AS source_table,
              tma.task_id,
              tma.original_filename,
              tma.filename,
              tma.description,
              COALESCE(tma.approval_target, 'admin') AS approval_target,
              tma.uploaded_at,
              u.email AS uploader_email,
              COALESCE(e.department, e2.department, da.department_key) AS department,
              bc.task_name,
              bc.priority AS task_priority,
              COALESCE(gb.b_name, '') AS bid_name,
              da.status AS approval_status,
              da.decided_at AS decided_at,
              da.decision_note AS decision_note
            FROM task_manager_attachments tma
            LEFT JOIN bid_checklists bc ON bc.id = tma.task_id
            LEFT JOIN go_bids gb ON gb.g_id = bc.g_id
            LEFT JOIN users u ON u.id = tma.user_id
            LEFT JOIN employees e ON e.id = bc.assigned_to
            LEFT JOIN employees e2 ON e2.id = bc.assigned_to
            LEFT JOIN document_approvals da ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
            WHERE 1=1
            """
            + dept_clause
            + target_sql
            + """
            ORDER BY tma.uploaded_at DESC
            LIMIT %s
            """,
            (*dept_params, *target_params, limit_n),
        )
        rows = cur.fetchall() or []
        for r in rows:
            st = (r.get('approval_status') or 'pending').strip().lower()
            items.append({
                'source': 'manager',
                'source_table': 'task_manager_attachments',
                'source_id': r.get('source_id'),
                'task_id': r.get('task_id'),
                'task_name': r.get('task_name'),
                'priority': r.get('task_priority'),
                'bid_name': r.get('bid_name'),
                'department': r.get('department'),
                'uploader': r.get('uploader_email'),
                'filename': r.get('filename'),
                'original_filename': r.get('original_filename'),
                'description': r.get('description'),
                'approval_target': r.get('approval_target') or 'admin',
                'uploaded_at': (r.get('uploaded_at').strftime('%Y-%m-%d %H:%M') if r.get('uploaded_at') else ''),
                'status': st,
                'decided_at': (r.get('decided_at').strftime('%Y-%m-%d %H:%M') if r.get('decided_at') else ''),
                'decision_note': r.get('decision_note') or '',
                'download_url': f"/task/manager-file/{int(r.get('source_id') or 0)}/download",
            })
    except Exception:
        pass

    try:
        # Employee "approval-request" comments
        target_expr = "tc.approval_target"
        target_sql = ""
        target_params = tuple()
        if target_values:
            placeholders = ", ".join(["%s"] * len(target_values))
            target_sql = target_clause % (target_expr, placeholders)
            target_params = tuple(target_values)
        cur.execute(
            """
            SELECT
              tc.id AS source_id,
              'task_comments' AS source_table,
              tc.task_id,
              tc.comment,
              COALESCE(tc.approval_target, 'admin') AS approval_target,
              tc.created_at AS uploaded_at,
              e.name AS uploader_name,
              e.email AS uploader_email,
              u.email AS uploader_user_email,
              COALESCE(e.department, e2.department, da.department_key) AS department,
              bc.task_name,
              bc.priority AS task_priority,
              COALESCE(gb.b_name, '') AS bid_name,
              da.status AS approval_status,
              da.decided_at AS decided_at,
              da.decision_note AS decision_note
            FROM task_comments tc
            LEFT JOIN bid_checklists bc ON bc.id = tc.task_id
            LEFT JOIN go_bids gb ON gb.g_id = bc.g_id
            LEFT JOIN employees e ON e.id = tc.employee_id
            LEFT JOIN employees e2 ON e2.id = bc.assigned_to
            LEFT JOIN users u ON u.id = tc.user_id
            LEFT JOIN document_approvals da ON da.source_table='task_comments' AND da.source_id=tc.id
            WHERE (tc.needs_approval = 1 OR da.status IS NOT NULL)
            """
            + dept_clause
            + target_sql
            + """
            ORDER BY tc.created_at DESC
            LIMIT %s
            """,
            (*dept_params, *target_params, limit_n),
        )
        rows = cur.fetchall() or []
        for r in rows:
            st = (r.get('approval_status') or 'pending').strip().lower()
            comment_text = (r.get('comment') or '').strip()
            items.append({
                'source': 'employee',
                'source_table': 'task_comments',
                'source_id': r.get('source_id'),
                'task_id': r.get('task_id'),
                'task_name': r.get('task_name'),
                'priority': r.get('task_priority'),
                'bid_name': r.get('bid_name'),
                'department': r.get('department'),
                'uploader': r.get('uploader_name') or r.get('uploader_email') or r.get('uploader_user_email'),
                'comment': comment_text,
                'approval_target': r.get('approval_target') or 'admin',
                'uploaded_at': (r.get('uploaded_at').strftime('%Y-%m-%d %H:%M') if r.get('uploaded_at') else ''),
                'status': st,
                'decided_at': (r.get('decided_at').strftime('%Y-%m-%d %H:%M') if r.get('decided_at') else ''),
                'decision_note': r.get('decision_note') or '',
                'task_details_url': f"/task/{int(r.get('task_id') or 0)}/details",
            })
    except Exception:
        pass

    try:
        items.sort(key=lambda x: x.get('uploaded_at') or '', reverse=True)
    except Exception:
        pass
    return items


@app.route('/api/approvals/summary')
@login_required
def api_approvals_summary():
    role_raw = (get_user_role() or '').strip()
    role_norm = _normalize_approval_target(role_raw) or role_raw.lower().replace('_', ' ')
    dept_key = _normalize_department_key(request.args.get('department'))
    if role_norm == 'team_lead':
        target = 'team_lead'
    elif role_norm == 'manager' or 'manager' in role_norm:
        target = 'manager'
    elif role_norm == 'admin':
        target = 'admin'
    else:
        target = 'manager'
    if target == 'admin':
        dept_key = None
    cur = mysql.connection.cursor(DictCursor)
    try:
        items = _collect_approval_items(cur, department_key=dept_key, approval_target=target, limit=200)
    finally:
        try:
            cur.close()
        except Exception:
            pass
    pending = [i for i in items if (i.get('status') or 'pending') == 'pending']
    for item in items:
        reason = (item.get('decision_note') or item.get('description') or item.get('comment') or '').strip()
        item['reason'] = reason
    return jsonify({
        'count': len(pending),
        'items': items,
        'pending_count': len(pending),
        'target': target,
        'department': dept_key or '',
    })


@app.route('/business-manager/approvals')
@login_required
def business_manager_approvals():
    denied = _require_business_manager_access(None)
    if denied:
        return denied
    if not getattr(current_user, 'is_admin', False) and not check_module_access_db('approvals'):
        return render_template('access_denied.html', message="You don't have access to Approvals."), 403
    cur = mysql.connection.cursor(DictCursor)
    try:
        active_company_id = session.get('active_company_id')
        active_company_name = None
        if active_company_id:
            try:
                cur.execute("SELECT name FROM companies WHERE id=%s", (int(active_company_id),))
                row = cur.fetchone() or {}
                active_company_name = (row.get('name') or None)
            except Exception:
                active_company_name = None
        items = _collect_approval_items(cur, department_key='business', approval_target='manager')
    finally:
        try:
            cur.close()
        except Exception:
            pass
    return render_template(
        'business_manager_approvals.html',
        team='business',
        dark_mode=False,
        active_company_name=active_company_name,
        items=items,
        user=current_user,
        user_role=getattr(current_user, 'role', 'business_manager'),
    )


@app.route('/team-lead/approvals')
@login_required
def team_lead_approvals():
    user_role = (get_user_role() or 'member').strip().lower()
    role_target = _normalize_approval_target(user_role) or user_role
    is_top_admin = user_role == 'topleveladmin'
    is_manager_user = role_target == 'manager'
    is_team_lead_user = role_target == 'team_lead'
    if not (current_user.is_admin or current_user.is_supervisor or is_top_admin or is_manager_user or is_team_lead_user):
        return "Access Denied - Team Lead access required", 403
    if not getattr(current_user, 'is_admin', False) and not check_module_access_db('approvals'):
        return render_template('access_denied.html', message="You don't have access to Approvals."), 403

    def _team_key_from_dept_key(dept_key: str | None) -> str | None:
        d = _normalize_department_key(dept_key)
        if d in ('business', 'design', 'operations', 'engineer'):
            return d
        return None

    team_names = {
        'business': 'Business Development',
        'design': 'Design',
        'operations': 'Operations',
        'engineer': 'Site Engineer'
    }
    team_filter = request.args.get('team') or None
    if team_filter:
        team_filter = team_filter.strip().lower()
    if not team_filter:
        try:
            dept_key = session.get('active_department_key') or None
        except Exception:
            dept_key = None
        team_filter = _team_key_from_dept_key(dept_key)
        if not team_filter:
            role_lower_legacy = (getattr(current_user, 'role', '') or '').lower().strip().replace('_', ' ')
            team_filter = _team_key_from_dept_key(role_lower_legacy)
    if team_filter and team_filter not in team_names:
        team_filter = None

    cur = mysql.connection.cursor(DictCursor)
    try:
        items = _collect_approval_items(cur, department_key=team_filter, approval_target='team_lead')
    finally:
        try:
            cur.close()
        except Exception:
            pass
    return render_template(
        'team_lead_approvals.html',
        items=items,
        team_key=team_filter,
        team_label=team_names.get(team_filter, 'All Teams'),
        user=current_user,
        user_role=getattr(current_user, 'role', 'teamlead'),
        hide_notifications=True,
    )


@app.route('/approvals/action', methods=['POST'])
@login_required
def approvals_action():
    data = request.get_json(silent=True) or {}
    token = (data.get('_csrf_token') or '').strip()
    if not validate_csrf_token(token):
        return jsonify({'success': False, 'error': 'csrf', 'message': 'Security validation failed. Please refresh and try again.'}), 403
    action = (data.get('action') or '').strip().lower()
    source_table = (data.get('source_table') or '').strip()
    decision_note = (data.get('decision_note') or '').strip()
    try:
        source_id = int(data.get('source_id') or 0)
    except Exception:
        source_id = 0
    if action not in ('approve', 'reject', 'revert') or source_table not in ('task_work_files', 'task_manager_attachments', 'task_comments') or not source_id:
        return jsonify({'success': False, 'error': 'bad_request', 'message': 'Invalid request'}), 400

    role = (get_user_role() or '').strip().lower()
    is_admin_like = bool(current_user.is_admin or current_user.is_supervisor or role == 'topleveladmin')
    role_target = _normalize_approval_target(role) or role
    is_manager_like = role_target in ('manager', 'team_lead') or role in ('business_manager', 'business manager')
    if not (is_admin_like or is_manager_like):
        return jsonify({'success': False, 'error': 'forbidden', 'message': 'Access denied'}), 403

    user_dept = _normalize_department_key(session.get('active_department_key') or getattr(current_user, 'role', '') or role)
    user_target = _normalize_approval_target(role)

    cur = mysql.connection.cursor(DictCursor)
    try:
        task_id = None
        if not is_admin_like:
            item_dept = None
            item_target = None
            if source_table == 'task_work_files':
                cur.execute(
                    """
                    SELECT COALESCE(e.department, e2.department) AS department,
                           COALESCE(twf.approval_target, 'admin') AS approval_target,
                           twf.task_id AS task_id
                    FROM task_work_files twf
                    LEFT JOIN employees e ON e.id = twf.employee_id
                    LEFT JOIN bid_checklists bc ON bc.id = twf.task_id
                    LEFT JOIN employees e2 ON e2.id = bc.assigned_to
                    WHERE twf.id=%s
                    """,
                    (source_id,),
                )
                row = cur.fetchone() or {}
                item_dept = row.get('department')
                item_target = row.get('approval_target')
                task_id = row.get('task_id')
            elif source_table == 'task_manager_attachments':
                cur.execute(
                    """
                    SELECT e.department AS department,
                           COALESCE(tma.approval_target, 'admin') AS approval_target,
                           tma.task_id AS task_id
                    FROM task_manager_attachments tma
                    LEFT JOIN bid_checklists bc ON bc.id = tma.task_id
                    LEFT JOIN employees e ON e.id = bc.assigned_to
                    WHERE tma.id=%s
                    """,
                    (source_id,),
                )
                row = cur.fetchone() or {}
                item_dept = row.get('department')
                item_target = row.get('approval_target')
                task_id = row.get('task_id')
            elif source_table == 'task_comments':
                cur.execute(
                    """
                    SELECT COALESCE(e.department, e2.department) AS department,
                           COALESCE(tc.approval_target, 'admin') AS approval_target,
                           tc.task_id AS task_id
                    FROM task_comments tc
                    LEFT JOIN employees e ON e.id = tc.employee_id
                    LEFT JOIN bid_checklists bc ON bc.id = tc.task_id
                    LEFT JOIN employees e2 ON e2.id = bc.assigned_to
                    WHERE tc.id=%s
                    """,
                    (source_id,),
                )
                row = cur.fetchone() or {}
                item_dept = row.get('department')
                item_target = row.get('approval_target')
                task_id = row.get('task_id')
            if not (role in ('manager', 'business_manager', 'business manager')):
                item_dept_norm = _normalize_department_key(item_dept)
                if item_dept_norm and user_dept and user_dept != item_dept_norm:
                    return jsonify({'success': False, 'error': 'forbidden', 'message': 'Access denied'}), 403
                item_target_norm = _normalize_approval_target(item_target)
                if item_target_norm and user_target and item_target_norm != user_target:
                    return jsonify({'success': False, 'error': 'forbidden', 'message': 'Access denied'}), 403
        else:
            if source_table == 'task_work_files':
                cur.execute("SELECT task_id FROM task_work_files WHERE id=%s", (source_id,))
                task_id = (cur.fetchone() or {}).get('task_id')
            elif source_table == 'task_manager_attachments':
                cur.execute("SELECT task_id FROM task_manager_attachments WHERE id=%s", (source_id,))
                task_id = (cur.fetchone() or {}).get('task_id')
            elif source_table == 'task_comments':
                cur.execute("SELECT task_id FROM task_comments WHERE id=%s", (source_id,))
                task_id = (cur.fetchone() or {}).get('task_id')

        if action == 'approve':
            status = 'approved'
        elif action == 'revert':
            status = 'reverted'
        else:
            status = 'rejected'
        _ensure_document_approvals_table(cur)
        cur.execute(
            """
            INSERT INTO document_approvals (source_table, source_id, status, decided_by, decided_at, decision_note)
            VALUES (%s, %s, %s, %s, NOW(), %s)
            ON DUPLICATE KEY UPDATE
                status=VALUES(status),
                decided_by=VALUES(decided_by),
                decided_at=VALUES(decided_at),
                decision_note=VALUES(decision_note)
            """,
            (source_table, source_id, status, getattr(current_user, 'id', None), decision_note),
        )
        if source_table == 'task_comments':
            try:
                _ensure_task_comments_table(cur)
                cur.execute("UPDATE task_comments SET needs_approval=0 WHERE id=%s", (source_id,))
            except Exception:
                pass
        try:
            notify_emp_id = None
            notify_msg = None
            note_tail = f" Note: {decision_note}" if decision_note else ""
            if source_table == 'task_work_files':
                cur.execute(
                    "SELECT task_id, employee_id, original_filename FROM task_work_files WHERE id=%s",
                    (source_id,),
                )
                row = cur.fetchone() or {}
                task_id = task_id or row.get('task_id')
                notify_emp_id = row.get('employee_id')
                fname = (row.get('original_filename') or 'File').strip()
                notify_msg = f"Upload '{fname}' was {status}.{note_tail}"
            elif source_table == 'task_comments':
                cur.execute(
                    "SELECT task_id, employee_id, comment FROM task_comments WHERE id=%s",
                    (source_id,),
                )
                row = cur.fetchone() or {}
                task_id = task_id or row.get('task_id')
                notify_emp_id = row.get('employee_id')
                notify_msg = f"Note approval was {status}.{note_tail}"
            elif source_table == 'task_manager_attachments':
                cur.execute(
                    """
                    SELECT bc.assigned_to AS employee_id, tma.original_filename AS original_filename, tma.task_id AS task_id
                    FROM task_manager_attachments tma
                    LEFT JOIN bid_checklists bc ON bc.id = tma.task_id
                    WHERE tma.id=%s
                    """,
                    (source_id,),
                )
                row = cur.fetchone() or {}
                task_id = task_id or row.get('task_id')
                notify_emp_id = row.get('employee_id')
                fname = (row.get('original_filename') or 'File').strip()
                notify_msg = f"Manager upload '{fname}' was {status}.{note_tail}"

            if notify_emp_id and notify_msg:
                _create_notification(
                    recipient_kind="employee",
                    recipient_id=int(notify_emp_id),
                    title="Approval updated",
                    message=notify_msg,
                    category="approval",
                    link_url=None,
                )
        except Exception:
            pass
        _update_task_status_from_approval(cur, task_id, status)
        mysql.connection.commit()
        return jsonify({'success': True})
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        return jsonify({'success': False, 'error': 'db', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass

@app.route('/approvals/escalate', methods=['POST'])
@login_required
def approvals_escalate():
    data = request.get_json(silent=True) or {}
    token = (data.get('_csrf_token') or '').strip()
    if not validate_csrf_token(token):
        return jsonify({'success': False, 'error': 'csrf', 'message': 'Security validation failed. Please refresh and try again.'}), 403
    source_table = (data.get('source_table') or '').strip()
    try:
        source_id = int(data.get('source_id') or 0)
    except Exception:
        source_id = 0
    target_raw = data.get('approval_target')
    approval_target = _normalize_approval_target(target_raw) or ''
    if source_table not in ('task_work_files', 'task_manager_attachments', 'task_comments') or not source_id:
        return jsonify({'success': False, 'error': 'bad_request', 'message': 'Invalid request'}), 400

    role = (get_user_role() or '').strip().lower()
    allowed_targets = _allowed_escalation_targets_for_role(role)
    if not allowed_targets or approval_target not in allowed_targets:
        return jsonify({'success': False, 'error': 'forbidden', 'message': 'Access denied'}), 403

    is_admin_like = bool(current_user.is_admin or current_user.is_supervisor or role == 'topleveladmin')
    user_dept = _normalize_department_key(session.get('active_department_key') or getattr(current_user, 'role', '') or role)
    user_target = _normalize_approval_target(role)

    cur = mysql.connection.cursor(DictCursor)
    try:
        item_dept = None
        item_target = None
        task_id = None
        if source_table == 'task_work_files':
            cur.execute(
                """
                SELECT COALESCE(e.department, e2.department) AS department,
                       COALESCE(twf.approval_target, 'admin') AS approval_target,
                       twf.task_id AS task_id
                FROM task_work_files twf
                LEFT JOIN employees e ON e.id = twf.employee_id
                LEFT JOIN bid_checklists bc ON bc.id = twf.task_id
                LEFT JOIN employees e2 ON e2.id = bc.assigned_to
                WHERE twf.id=%s
                """,
                (source_id,),
            )
            row = cur.fetchone() or {}
            item_dept = row.get('department')
            item_target = row.get('approval_target')
            task_id = row.get('task_id')
            cur.execute(
                "UPDATE task_work_files SET approval_target=%s WHERE id=%s",
                (approval_target, source_id),
            )
        elif source_table == 'task_manager_attachments':
            cur.execute(
                """
                SELECT e.department AS department,
                       COALESCE(tma.approval_target, 'admin') AS approval_target,
                       tma.task_id AS task_id
                FROM task_manager_attachments tma
                LEFT JOIN bid_checklists bc ON bc.id = tma.task_id
                LEFT JOIN employees e ON e.id = bc.assigned_to
                WHERE tma.id=%s
                """,
                (source_id,),
            )
            row = cur.fetchone() or {}
            item_dept = row.get('department')
            item_target = row.get('approval_target')
            task_id = row.get('task_id')
            cur.execute(
                "UPDATE task_manager_attachments SET approval_target=%s WHERE id=%s",
                (approval_target, source_id),
            )
        elif source_table == 'task_comments':
            cur.execute(
                """
                SELECT COALESCE(e.department, e2.department) AS department,
                       COALESCE(tc.approval_target, 'admin') AS approval_target,
                       tc.task_id AS task_id
                FROM task_comments tc
                LEFT JOIN employees e ON e.id = tc.employee_id
                LEFT JOIN bid_checklists bc ON bc.id = tc.task_id
                LEFT JOIN employees e2 ON e2.id = bc.assigned_to
                WHERE tc.id=%s
                """,
                (source_id,),
            )
            row = cur.fetchone() or {}
            item_dept = row.get('department')
            item_target = row.get('approval_target')
            task_id = row.get('task_id')
            cur.execute(
                "UPDATE task_comments SET approval_target=%s, needs_approval=1 WHERE id=%s",
                (approval_target, source_id),
            )

        if not is_admin_like:
            item_dept_norm = _normalize_department_key(item_dept)
            if not user_dept or not item_dept_norm or user_dept != item_dept_norm:
                return jsonify({'success': False, 'error': 'forbidden', 'message': 'Access denied'}), 403
            item_target_norm = _normalize_approval_target(item_target)
            if item_target_norm and user_target and item_target_norm != user_target:
                return jsonify({'success': False, 'error': 'forbidden', 'message': 'Access denied'}), 403

        _ensure_document_approvals_table(cur)
        cur.execute(
            """
            INSERT INTO document_approvals (source_table, source_id, status, decided_by, decided_at, department_key)
            VALUES (%s, %s, 'pending', NULL, NULL, %s)
            ON DUPLICATE KEY UPDATE status='pending', decided_by=NULL, decided_at=NULL, department_key=VALUES(department_key)
            """,
            (source_table, source_id, _normalize_department_key(item_dept)),
        )

        mysql.connection.commit()

        try:
            _notify_approval_request(
                employee_id=None,
                department_key=_normalize_department_key(item_dept),
                approval_target=approval_target,
                task_id=int(task_id or 0) if task_id else None,
                title="Approval request",
                message=f"Task #{int(task_id or 0)} approval requested.",
            )
        except Exception:
            pass

        return jsonify({'success': True})
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        return jsonify({'success': False, 'error': 'db', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass

def _ensure_chat_table(cur):
    cur.execute("""
        CREATE TABLE IF NOT EXISTS team_chat_messages (
            id INT AUTO_INCREMENT PRIMARY KEY,
            room VARCHAR(64) NOT NULL,
            user_id INT,
            user_email VARCHAR(255),
            user_name VARCHAR(255),
            role VARCHAR(64),
            message TEXT NOT NULL,
            attachment_path VARCHAR(255),
            attachment_name VARCHAR(255),
            attachment_mime VARCHAR(128),
            attachment_size INT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            INDEX idx_room_created (room, created_at)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    """)
    # Best-effort schema upgrade for existing installs (MySQL won't update columns via CREATE IF NOT EXISTS)
    try:
        cur.execute("ALTER TABLE team_chat_messages ADD COLUMN attachment_path VARCHAR(255)")
    except Exception:
        pass
    try:
        cur.execute("ALTER TABLE team_chat_messages ADD COLUMN attachment_name VARCHAR(255)")
    except Exception:
        pass
    try:
        cur.execute("ALTER TABLE team_chat_messages ADD COLUMN attachment_mime VARCHAR(128)")
    except Exception:
        pass
    try:
        cur.execute("ALTER TABLE team_chat_messages ADD COLUMN attachment_size INT")
    except Exception:
        pass
    mysql.connection.commit()

def _chat_room_to_fs(room_key: str) -> str:
    """Map room key to a filesystem-safe folder name (Windows cannot contain ':')."""
    rk = (room_key or 'all').strip().lower()
    # Keep it simple + deterministic.
    rk = re.sub(r'[^a-z0-9:_\-]', '_', rk)
    return rk.replace(':', '_')

def _safe_db_name(db_name: str) -> str | None:
    try:
        db = (db_name or '').strip()
        if not db:
            return None
        if re.fullmatch(r'[A-Za-z0-9_]+', db):
            return db
    except Exception:
        return None
    return None

def _fetch_chat_messages(cur, room_key: str, db_name: str | None = None):
    table_ref = "team_chat_messages"
    safe_db = _safe_db_name(db_name) if db_name else None
    if safe_db:
        table_ref = f"{safe_db}.team_chat_messages"
    cur.execute(f"""
        SELECT room, user_id, user_email, user_name, role, message,
               attachment_path, attachment_name, attachment_mime, attachment_size,
               created_at
        FROM {table_ref}
        WHERE LOWER(REPLACE(REPLACE(REPLACE(TRIM(room), '\\r', ''), '\\n', ''), '\\t', '')) = LOWER(%s)
        ORDER BY created_at DESC
        LIMIT 120
    """, (room_key,))
    return cur.fetchall() or []

def _fetch_chat_messages_any(cur, db_name: str | None = None):
    table_ref = "team_chat_messages"
    safe_db = _safe_db_name(db_name) if db_name else None
    if safe_db:
        table_ref = f"{safe_db}.team_chat_messages"
    cur.execute(f"""
        SELECT room, user_id, user_email, user_name, role, message,
               attachment_path, attachment_name, attachment_mime, attachment_size,
               created_at
        FROM {table_ref}
        ORDER BY created_at DESC
        LIMIT 120
    """)
    return cur.fetchall() or []

def _find_chat_db_with_rows(cur, room_key: str | None = None) -> str | None:
    try:
        cur.execute("SHOW DATABASES")
        dbs = [r.get('Database') for r in (cur.fetchall() or []) if r.get('Database')]
    except Exception:
        return None
    for db in dbs:
        safe_db = _safe_db_name(db)
        if not safe_db:
            continue
        if not (safe_db.startswith('esco') or safe_db.endswith('_clean') or 'esco' in safe_db):
            continue
        try:
            if room_key:
                cur.execute(f"SELECT COUNT(*) AS c FROM {safe_db}.team_chat_messages WHERE LOWER(TRIM(room)) = LOWER(%s)", (room_key,))
            else:
                cur.execute(f"SELECT COUNT(*) AS c FROM {safe_db}.team_chat_messages")
            if int((cur.fetchone() or {}).get('c') or 0) > 0:
                return safe_db
        except Exception:
            continue
    return None
def _chat_guard():
    """Team chat is disabled in this deployment."""
    return "Not Found", 404


def _chat_rooms_for_user():
    rooms = [
        {'key': 'all', 'label': 'All Teams'},
        {'key': 'business', 'label': 'Business Team'},
        {'key': 'design', 'label': 'Design Team'},
        {'key': 'operations', 'label': 'Operations Team'},
        {'key': 'engineer', 'label': 'Site / Engineer Team'},
        {'key': 'managers', 'label': 'Managers'},
        {'key': 'teamleads', 'label': 'Team Leads'},
    ]

    # Admins/top-admins see everything.
    try:
        role_raw = (get_user_role() or '')
    except Exception:
        role_raw = (getattr(current_user, 'role', '') or '')
    role_norm = role_raw.strip().lower().replace('_', ' ')
    is_admin = bool(getattr(current_user, 'is_admin', False) or role_norm in ('topleveladmin', 'top level admin'))
    if is_admin:
        allowed = {r['key'] for r in rooms}
        return rooms, allowed

    # Dept-scoped access for managers/team leads/members.
    dept = _normalize_department_key(
        session.get('active_department_key')
        or session.get('employee_department')
        or role_norm
    )
    dept_room = None
    if dept in ('business', 'design', 'operations', 'engineer'):
        dept_room = dept

    manager_roles = {
        'manager',
        'project manager',
        'business manager',
        'design manager',
        'operation manager',
        'operations manager',
        'site manager',
    }
    team_lead_roles = {
        'teamlead',
        'team lead',
        'team leader',
        'business dev',
        'business development',
        'design',
        'operations',
        'engineering',
        'site engineer',
        'site_engineer',
    }
    is_manager = role_norm in manager_roles or 'manager' in role_norm
    is_team_lead = role_norm in team_lead_roles or 'team lead' in role_norm

    allowed = set()
    if dept_room:
        allowed.add(dept_room)

    if is_manager:
        allowed.add('managers')
    if is_team_lead:
        allowed.add('teamleads')

    # Fallback: if nothing matched, allow the main "all" room.
    if not allowed:
        allowed.add('all')

    filtered_rooms = [r for r in rooms if r['key'] in allowed]
    return filtered_rooms, allowed


def _chat_default_room(allowed: set[str], role_norm: str | None = None) -> str:
    rn = (role_norm or '').strip().lower().replace('_', ' ')
    if 'manager' in rn and 'managers' in allowed:
        return 'managers'
    if ('team lead' in rn or rn in ('teamlead', 'team leader')) and 'teamleads' in allowed:
        return 'teamleads'
    if 'all' in allowed:
        return 'all'
    for key in ('business', 'design', 'operations', 'engineer', 'managers', 'teamleads'):
        if key in allowed:
            return key
    return next(iter(allowed)) if allowed else 'all'


def _normalize_dm_room(room_key: str):
    """
    Normalize a DM room key to format: dm:<min_id>:<max_id>
    Returns normalized key if valid, else None.
    """
    try:
        rk = (room_key or '').strip().lower()
        if not rk.startswith('dm:'):
            return None
        parts = rk.split(':')
        if len(parts) != 3:
            return None
        a = int(parts[1])
        b = int(parts[2])
        if a <= 0 or b <= 0 or a == b:
            return None
        lo, hi = (a, b) if a < b else (b, a)
        return f"dm:{lo}:{hi}"
    except Exception:
        return None


def _dm_room_involves_user(room_key: str, user_id: int) -> bool:
    rk = _normalize_dm_room(room_key)
    if not rk:
        return False
    try:
        _, a, b = rk.split(':')
        return int(a) == int(user_id) or int(b) == int(user_id)
    except Exception:
        return False

@app.route('/team-chats')
@login_required
def team_chats():
    denied = _chat_guard()
    if denied:
        return denied
    if not getattr(current_user, 'is_admin', False) and not check_module_access_db('team_chats'):
        return render_template('access_denied.html', message="You don't have access to Team Chats."), 403
    rooms, allowed = _chat_rooms_for_user()
    try:
        role_raw = get_user_role()
    except Exception:
        role_raw = getattr(current_user, 'role', None)
    role_norm = (role_raw or '').strip().lower().replace('_', ' ')
    active_room = (request.args.get('room') or 'all').strip().lower()
    if active_room not in allowed:
        active_room = _chat_default_room(allowed, role_norm)
    label_map = {r['key']: r['label'] for r in rooms}
    return render_template(
        'team_chats.html',
        rooms=rooms,
        active_room=active_room,
        active_room_label=label_map.get(active_room, active_room),
    )


@app.route('/embed/chats')
@login_required
def embed_chats():
    """Embed-friendly chat view (used by Top Admin quick views)."""
    denied = _chat_guard()
    if denied:
        return denied
    if not getattr(current_user, 'is_admin', False) and not check_module_access_db('team_chats'):
        return render_template('access_denied.html', message="You don't have access to Team Chats."), 403
    rooms, allowed = _chat_rooms_for_user()
    active_room = (request.args.get('room') or 'all').strip().lower()
    if active_room not in allowed:
        active_room = 'all'
    label_map = {r['key']: r['label'] for r in rooms}
    return render_template(
        'chat_embed.html',
        rooms=rooms,
        active_room=active_room,
        active_room_label=label_map.get(active_room, active_room),
    )


@app.route('/api/chats/<room>')
@login_required
def chat_history(room):
    denied = _chat_guard()
    if denied:
        return jsonify({'messages': []}), 403
    room_key = (room or 'all').strip().lower()
    rooms, allowed = _chat_rooms_for_user()
    try:
        role_raw = get_user_role()
    except Exception:
        role_raw = getattr(current_user, 'role', None)
    role_norm = (role_raw or '').strip().lower().replace('_', ' ')
    is_admin_view = bool(getattr(current_user, 'is_admin', False) or role_norm in ('topleveladmin', 'top level admin'))
    # Allow direct messages (dm:<a>:<b>) if the current user is part of the room.
    if room_key.startswith('dm:'):
        norm = _normalize_dm_room(room_key)
        if not norm or not _dm_room_involves_user(norm, getattr(current_user, 'id', 0) or 0):
            room_key = _chat_default_room(allowed)
        else:
            room_key = norm
    elif room_key not in allowed:
        room_key = _chat_default_room(allowed)
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_chat_table(cur)
        rows = _fetch_chat_messages(cur, room_key)
        if not rows and is_admin_view:
            current_db = (app.config.get('MYSQL_DB') or 'esco').strip()
            alt_dbs = []
            for cand in ('esco_v23_clean', 'esco'):
                if cand and cand != current_db and cand not in alt_dbs:
                    alt_dbs.append(cand)
            for alt_db in alt_dbs:
                try:
                    rows = _fetch_chat_messages(cur, room_key, alt_db)
                except Exception:
                    rows = []
                if rows:
                    break
        if not rows and is_admin_view:
            # Last-resort: search for any DB that has chat rows.
            try:
                db_with_rows = _find_chat_db_with_rows(cur, room_key)
            except Exception:
                db_with_rows = None
            if db_with_rows:
                try:
                    rows = _fetch_chat_messages(cur, room_key, db_with_rows)
                except Exception:
                    rows = []
            if not rows:
                try:
                    rows = _fetch_chat_messages_any(cur)
                except Exception:
                    rows = []
            if not rows and db_with_rows:
                try:
                    rows = _fetch_chat_messages_any(cur, db_with_rows)
                except Exception:
                    rows = []
        rows.reverse()
        messages = []
        for r in rows:
            created_at = r.get('created_at')
            ap = r.get('attachment_path')
            messages.append({
                'room': r.get('room'),
                'user_id': r.get('user_id'),
                'user_email': r.get('user_email'),
                'user_name': r.get('user_name'),
                'role': r.get('role'),
                'message': r.get('message'),
                'attachment_path': ap,
                'attachment_name': r.get('attachment_name'),
                'attachment_mime': r.get('attachment_mime'),
                'attachment_size': r.get('attachment_size'),
                'attachment_url': (f"/uploads/{ap}" if ap else None),
                'created_at': (created_at.strftime('%Y-%m-%d %H:%M') if hasattr(created_at, 'strftime') else (str(created_at) if created_at else '')),
            })
        return jsonify({'messages': messages})
    except Exception:
        return jsonify({'messages': []})
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/api/chats/send', methods=['POST'])
@login_required
def chat_send():
    denied = _chat_guard()
    if denied:
        return jsonify({'success': False, 'error': 'forbidden'}), 403
    data = request.get_json(silent=True) if request.is_json else None
    data = data if isinstance(data, dict) else {}

    # Accept CSRF token from JSON body, header, or multipart form.
    token = (data.get('_csrf_token') or data.get('csrf_token') or '').strip()
    if not token:
        token = (request.headers.get('X-CSRF-Token') or '').strip()
    if not token:
        token = (request.form.get('_csrf_token') or '').strip()
    if not validate_csrf_token(token):
        return jsonify({'success': False, 'error': 'csrf', 'message': 'Security validation failed. Please refresh and try again.'}), 403

    room_key = (data.get('room') or request.form.get('room') or 'all').strip().lower()
    rooms, allowed = _chat_rooms_for_user()
    # Allow direct messages (dm:<a>:<b>) if the current user is part of the room.
    if room_key.startswith('dm:'):
        norm = _normalize_dm_room(room_key)
        if not norm or not _dm_room_involves_user(norm, getattr(current_user, 'id', 0) or 0):
            room_key = _chat_default_room(allowed)
        else:
            room_key = norm
    elif room_key not in allowed:
        room_key = _chat_default_room(allowed)
    msg = (data.get('message') or request.form.get('message') or '').strip()
    msg = msg[:2000]

    up_file = None
    try:
        up_file = request.files.get('file')
    except Exception:
        up_file = None

    if (not msg) and (not up_file):
        return jsonify({'success': False, 'error': 'missing_message'}), 400

    attachment_path = None
    attachment_name = None
    attachment_mime = None
    attachment_size = None
    if up_file and getattr(up_file, 'filename', ''):
        try:
            original = str(up_file.filename or '')
            safe_name = secure_filename(original) or 'file'
            room_dir = _chat_room_to_fs(room_key)
            base_dir = os.path.join('uploads', 'chat', room_dir)
            os.makedirs(base_dir, exist_ok=True)
            stamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            uniq = uuid.uuid4().hex[:8]
            filename = f"{stamp}_{uniq}_{safe_name}"
            disk_path = os.path.join(base_dir, filename)
            up_file.save(disk_path)
            attachment_path = os.path.join('chat', room_dir, filename).replace('\\', '/')
            attachment_name = safe_name
            attachment_mime = getattr(up_file, 'mimetype', None) or None
            try:
                attachment_size = int(os.path.getsize(disk_path))
            except Exception:
                attachment_size = None
        except Exception as e:
            return jsonify({'success': False, 'error': 'upload', 'message': str(e)}), 400

    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_chat_table(cur)
        user_email = getattr(current_user, 'email', None)
        try:
            role_raw = get_user_role()
        except Exception:
            role_raw = getattr(current_user, 'role', None)
        user_role = (role_raw or '').strip()
        cur.execute("""
            INSERT INTO team_chat_messages (room, user_id, user_email, user_name, role, message,
                                            attachment_path, attachment_name, attachment_mime, attachment_size)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """, (
            room_key,
            getattr(current_user, 'id', None),
            user_email,
            user_email,
            user_role,
            (msg or ''),
            attachment_path,
            attachment_name,
            attachment_mime,
            attachment_size,
        ))
        mysql.connection.commit()
        # Fan-out to room via socket (realtime) - emit both events for compatibility
        try:
            socketio.emit('team_chat_message', {'room': room_key}, room=room_key)
            socketio.emit('top_admin_chat_message', {'room': room_key}, room=room_key)
            # Global notify so users not currently in the chat page still get notified
            preview = (msg or '').strip()
            if not preview and attachment_name:
                preview = f"Sent {attachment_name}"
            preview = (preview[:80] + '???') if len(preview) > 80 else preview
            socketio.emit('chat_notify', {
                'room': room_key,
                'from': (user_email or 'User'),
                'preview': preview or 'New message',
                'has_attachment': bool(attachment_path),
            })
        except Exception:
            pass
        return jsonify({'success': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': 'db', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/api/chats/people')
@login_required
def chat_people():
    """Return list of users available for starting a direct chat."""
    denied = _chat_guard()
    if denied:
        return jsonify({'ok': False, 'people': []}), 403
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SELECT id, email, role, is_admin FROM users ORDER BY email ASC")
        rows = cur.fetchall() or []
        me = int(getattr(current_user, 'id', 0) or 0)
        people = []
        for r in rows:
            try:
                uid = int(r.get('id') or 0)
            except Exception:
                uid = 0
            if not uid or uid == me:
                continue
            people.append({
                'id': uid,
                'email': r.get('email'),
                'role': r.get('role'),
                'is_admin': bool(r.get('is_admin')),
            })
        return jsonify({'ok': True, 'people': people})
    except Exception:
        return jsonify({'ok': False, 'people': []})
    finally:
        try:
            cur.close()
        except Exception:
            pass

@socketio.on('team_chat_join_room')
def _team_chat_join_room(payload):
    denied = _chat_guard()
    if denied:
        emit('team_chat_join_error', {'message': 'forbidden'})
        return
    rooms, allowed = _chat_rooms_for_user()
    room = (payload or {}).get('room') if isinstance(payload, dict) else None
    room_key = (room or 'all').strip().lower()
    # Allow direct message rooms (dm:<a>:<b>) only if current user is part of it.
    if room_key.startswith('dm:'):
        norm = _normalize_dm_room(room_key)
        if not norm or not _dm_room_involves_user(norm, getattr(current_user, 'id', 0) or 0):
            room_key = 'all'
        else:
            room_key = norm
    elif room_key not in allowed:
        room_key = 'all'
    join_room(room_key)
    # Ack so clients can confirm realtime room membership
    emit('team_chat_joined', {'room': room_key})


@socketio.on('team_chat_message')
def _team_chat_message(payload):
    denied = _chat_guard()
    if denied:
        return
    if not isinstance(payload, dict):
        return
    rooms, allowed = _chat_rooms_for_user()
    room_key = (payload.get('room') or 'all').strip().lower()
    # Allow direct message rooms (dm:<a>:<b>) only if current user is part of it.
    if room_key.startswith('dm:'):
        norm = _normalize_dm_room(room_key)
        if not norm or not _dm_room_involves_user(norm, getattr(current_user, 'id', 0) or 0):
            room_key = 'all'
        else:
            room_key = norm
    elif room_key not in allowed:
        room_key = 'all'
    msg = (payload.get('message') or '').strip()
    if not msg:
        return
    msg = msg[:2000]
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_chat_table(cur)
        user_email = getattr(current_user, 'email', None)
        user_role = (get_user_role() or getattr(current_user, 'role', '') or '').strip()
        cur.execute("""
            INSERT INTO team_chat_messages (room, user_id, user_email, user_name, role, message)
            VALUES (%s, %s, %s, %s, %s, %s)
        """, (room_key, getattr(current_user, 'id', None), user_email, user_email, user_role, msg))
        mysql.connection.commit()
    except Exception:
        mysql.connection.rollback()
    finally:
        try:
            cur.close()
        except Exception:
            pass
    # Broadcast both events so all UIs update (team + top admin aliases)
    emit('team_chat_message', {'room': room_key}, room=room_key)
    emit('top_admin_chat_message', {'room': room_key}, room=room_key)
    try:
        preview = (msg or '').strip()
        preview = (preview[:80] + '???') if len(preview) > 80 else preview
        socketio.emit('chat_notify', {
            'room': room_key,
            'from': (getattr(current_user, 'email', None) or 'User'),
            'preview': preview or 'New message',
            'has_attachment': False,
        })
    except Exception:
        pass


@app.route('/admin/create-user', methods=['POST'])
@login_required
@csrf_protect
def admin_create_user():
    """Create a new user from admin dashboard with secure password hashing"""
    if not (getattr(current_user, 'is_admin', False) or (get_user_role() or '').lower() == 'topleveladmin'):
        audit_log.log_permission_denied(current_user.email, '/admin/create-user', 'admin_create_user')
        return jsonify({'success': False, 'error': 'Access denied'}), 403
    
    email = sanitize_input(request.form.get('email', '').strip())
    full_name = sanitize_input(request.form.get('full_name', '').strip()) or None
    password = request.form.get('password', '').strip()
    role = sanitize_input(request.form.get('role', 'member').strip())
    department_key = sanitize_input((request.form.get('department_key') or '').strip())
    department_key = department_key or None
    # Multi-select companies (may be empty)
    try:
        company_ids = [c for c in request.form.getlist('company_ids') if str(c).strip()]
    except Exception:
        company_ids = []
    
    if not email or not password:
        return jsonify({'success': False, 'error': 'Email and password required'}), 400
    
    # Validate email format
    if not validate_email(email):
        return jsonify({'success': False, 'error': 'Invalid email format'}), 400
    
    # Validate password strength
    pwd_check = password_strength_check(password)
    if not pwd_check['valid']:
        return jsonify({'success': False, 'error': 'Password too weak: ' + ', '.join(pwd_check['errors'])}), 400
    
    cur = mysql.connection.cursor(DictCursor)
    try:
        # Check if email exists (users or employees)
        cur.execute("SELECT id FROM users WHERE email = %s", (email,))
        if cur.fetchone():
            return jsonify({'success': False, 'error': 'Email already exists in users'}), 400
        cur.execute("SELECT id FROM employees WHERE LOWER(email)=LOWER(%s) LIMIT 1", (email,))
        if cur.fetchone():
            return jsonify({'success': False, 'error': 'Email already exists in employees'}), 400
        
        # Hash the password securely
        hashed_password = hash_password(password)
        
        # Canonicalize role for storage (multi-company model)
        role_norm = (role or '').strip().lower().replace('_', ' ')
        if role_norm in ['it administrator', 'it admin', 'admin', 'itadmin']:
            role_db = 'itadmin'
            is_admin = 1
        elif role_norm in ['top level admin', 'top_level_admin', 'topleveladmin']:
            role_db = 'topleveladmin'
            is_admin = 0
        elif role_norm in ['supervisor']:
            role_db = 'supervisor'
            is_admin = 0
        elif role_norm in ['team lead', 'team_lead', 'teamlead']:
            role_db = 'teamlead'
            is_admin = 0
        elif role_norm in ['manager']:
            role_db = 'manager'
            is_admin = 0
        else:
            role_db = 'member'
            is_admin = 0

        # Store ONLY global roles on users.role; scoped roles live in user_company_access.
        if is_admin:
            users_role_db = 'itadmin'
        elif role_db in ['topleveladmin', 'supervisor']:
            users_role_db = role_db
        else:
            users_role_db = 'member'

        if role_db == 'member' and not is_admin:
            # Employees are stored in employees table only (no users row)
            employee_name = full_name or (email.split('@')[0].replace('.', ' ').strip().title() or 'Employee')
            cur.execute(
                """
                INSERT INTO employees (name, email, password, department, is_active)
                VALUES (%s, %s, %s, %s, TRUE)
                """,
                (employee_name, email, hashed_password, department_key),
            )
        else:
            cur.execute("""
                INSERT INTO users (email, full_name, password, role, is_admin, is_active) 
                VALUES (%s, %s, %s, %s, %s, TRUE)
            """, (email, full_name, hashed_password, users_role_db, is_admin))
            new_user_id = cur.lastrowid

            # Create scoped access rows (skip for IT admin who has full access anyway)
            if not is_admin:
                # Managers/Team Leads should always be scoped via user_company_access
                # If no companies selected, default to all primary companies
                if not company_ids:
                    try:
                        cur.execute("SELECT id FROM companies WHERE name IN ('Ikio','Metco','Sunsprint')")
                        company_ids = [str(r['id']) for r in cur.fetchall()]
                    except Exception:
                        company_ids = []
                # Top Level Admin / Supervisor get company-wide access (all depts)
                access_dept = None if role_db in ['topleveladmin', 'supervisor'] else department_key
                for cid in company_ids:
                    try:
                        cur.execute(
                            """
                            INSERT IGNORE INTO user_company_access (user_id, company_id, department_key, role, is_active)
                            VALUES (%s, %s, %s, %s, TRUE)
                            """,
                            (new_user_id, int(cid), access_dept, role_db),
                        )
                    except Exception:
                        # Don't hard-fail user creation if access rows can't be inserted
                        pass
        mysql.connection.commit()
        
        log_write('admin_create_user', f"Created user {email} with role {users_role_db} (scoped={role_db})")
        audit_log.log_admin_action(current_user.email, 'create_user', target=email, details=f"users.role={users_role_db}, scoped_role={role_db}, dept={department_key}, companies={len(company_ids)}")
        
        # Check if redirect expected (form submission) or JSON response (AJAX)
        if request.headers.get('Accept', '').find('application/json') != -1:
            return jsonify({'success': True, 'message': f'User {email} created successfully'})
        return redirect(url_for('top_admin_overview') + '?tab=users')
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/admin/login-transfer', methods=['POST'])
@login_required
@csrf_protect
def admin_login_transfer():
    """Transfer an existing login to a new email while preserving access/permissions."""
    if not (getattr(current_user, 'is_admin', False) or (get_user_role() or '').lower() == 'topleveladmin'):
        audit_log.log_permission_denied(current_user.email, '/admin/login-transfer', 'admin_login_transfer')
        return jsonify({'success': False, 'error': 'Access denied'}), 403

    user_id = request.form.get('user_id', type=int)
    new_email = sanitize_input(request.form.get('new_email', '').strip())
    full_name = sanitize_input(request.form.get('full_name', '').strip()) if request.form.get('full_name') is not None else None
    note = sanitize_input(request.form.get('note', '').strip()) or None

    if not user_id or not new_email:
        return jsonify({'success': False, 'error': 'Select a user and provide the new email'}), 400

    if not validate_email(new_email):
        return jsonify({'success': False, 'error': 'Invalid email format'}), 400

    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SELECT email, full_name FROM users WHERE id = %s FOR UPDATE", (user_id,))
        user = cur.fetchone()
        if not user:
            return jsonify({'success': False, 'error': 'User not found'}), 404

        cur.execute("SELECT id FROM users WHERE LOWER(email) = LOWER(%s) AND id != %s", (new_email, user_id))
        if cur.fetchone():
            return jsonify({'success': False, 'error': 'Email is already associated with another login'}), 400

        full_name_value = full_name if full_name is not None else user.get('full_name')
        cur.execute("UPDATE users SET email = %s, full_name = %s WHERE id = %s", (new_email, full_name_value, user_id))
        try:
            # Keep employees table in sync if a matching employee exists
            cur.execute("UPDATE employees SET email = %s WHERE LOWER(email) = LOWER(%s)", (new_email, user['email']))
        except Exception:
            pass
        try:
            # Ensure new email's inferred company has an active scope (prevents login lockout)
            inferred_cid = _infer_company_id_for_email(new_email)
        except Exception:
            inferred_cid = None
        if inferred_cid:
            try:
                cur.execute(
                    """
                    SELECT COUNT(*) AS c
                    FROM user_company_access
                    WHERE user_id=%s AND company_id=%s AND COALESCE(is_active, TRUE)=TRUE
                    """,
                    (user_id, int(inferred_cid)),
                )
                has_scope = int((cur.fetchone() or {}).get('c') or 0) > 0
                if not has_scope:
                    cur.execute(
                        """
                        SELECT role, department_key
                        FROM user_company_access
                        WHERE user_id=%s
                        ORDER BY id ASC
                        LIMIT 1
                        """,
                        (user_id,),
                    )
                    row = cur.fetchone() or {}
                    role_for_scope = (row.get('role') or user.get('role') or 'member')
                    dept_for_scope = row.get('department_key')
                    cur.execute(
                        """
                        INSERT INTO user_company_access (user_id, company_id, department_key, role, is_active)
                        VALUES (%s, %s, %s, %s, TRUE)
                        """,
                        (user_id, int(inferred_cid), dept_for_scope, role_for_scope),
                    )
            except Exception:
                pass

        cur.execute("""
            INSERT INTO login_transfers (user_id, old_email, new_email, performed_by, note)
            VALUES (%s, %s, %s, %s, %s)
        """, (user_id, user['email'], new_email, getattr(current_user, 'id', None), note))

        mysql.connection.commit()
        log_write('admin_login_transfer', f"User {user_id} login transferred ({user['email']} -> {new_email})")
        audit_log.log_admin_action(
            current_user.email,
            'login_transfer',
            target=f"user_id={user_id}",
            details=f"{user['email']} -> {new_email}; full_name={full_name_value or 'N/A'}; note={note or 'N/A'}"
        )
        return jsonify({'success': True, 'new_email': new_email, 'full_name': full_name_value})
    except Exception as exc:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(exc)}), 500
    finally:
        cur.close()

@app.route('/api/admin/user/<int:user_id>', methods=['GET', 'PUT', 'DELETE'])
@login_required
def admin_user_api(user_id):
    """API for user management operations with security validation"""
    is_top_admin = (get_user_role() or '').lower() == 'topleveladmin'
    if not (getattr(current_user, 'is_admin', False) or is_top_admin):
        audit_log.log_permission_denied(current_user.email, f'/api/admin/user/{user_id}', request.method)
        return jsonify({'success': False, 'error': 'Access denied'}), 403
    
    # Validate CSRF for state-changing methods
    if request.method in ['PUT', 'DELETE']:
        csrf_token = request.headers.get('X-CSRF-Token') or request.form.get('_csrf_token')
        if not validate_csrf_token(csrf_token):
            audit_log.log_csrf_failure(get_client_ip(), f'/api/admin/user/{user_id}')
            return jsonify({'success': False, 'error': 'Invalid security token. Please refresh and try again.'}), 403
    
    cur = mysql.connection.cursor(DictCursor)
    
    try:
        if request.method == 'GET':
            cur.execute("SELECT id, email, role, is_admin, is_active, full_name FROM users WHERE id = %s", (user_id,))
            user = cur.fetchone()
            if user:
                return jsonify(user)
            return jsonify({'error': 'User not found'}), 404
        
        elif request.method == 'PUT':
            data = request.get_json()
            email = sanitize_input(data.get('email', '').strip())
            role = sanitize_input(data.get('role', 'member').strip())
            password = data.get('password', '').strip()
            full_name = sanitize_input(data.get('full_name', '').strip()) if isinstance(data.get('full_name'), str) else None
            is_active = data.get('is_active', True)
            
            # Validate email
            if not validate_email(email):
                return jsonify({'success': False, 'error': 'Invalid email format'}), 400
            
            # Canonicalize role for storage
            role_norm = (role or '').strip().lower().replace('_', ' ')
            if role_norm in ['it administrator', 'it admin', 'admin', 'itadmin']:
                role_db = 'itadmin'
                is_admin = 1
            elif role_norm in ['top level admin', 'top_level_admin', 'topleveladmin']:
                role_db = 'topleveladmin'
                is_admin = 0
            elif role_norm in ['supervisor']:
                role_db = 'supervisor'
                is_admin = 0
            elif role_norm in ['team lead', 'team_lead', 'teamlead']:
                role_db = 'teamlead'
                is_admin = 0
            elif role_norm in ['manager']:
                role_db = 'manager'
                is_admin = 0
            else:
                role_db = 'member'
                is_admin = 0

            # Build update query
            if password:
                # Validate password strength
                pwd_check = password_strength_check(password)
                if not pwd_check['valid']:
                    return jsonify({'success': False, 'error': 'Password too weak: ' + ', '.join(pwd_check['errors'])}), 400
                
                # Hash the password
                hashed_password = hash_password(password)
                
                cur.execute("""
                    UPDATE users SET email = %s, full_name = %s, password = %s, role = %s, is_admin = %s, is_active = %s
                    WHERE id = %s
                """, (email, full_name, hashed_password, role_db, is_admin, is_active, user_id))
            else:
                cur.execute("""
                    UPDATE users SET email = %s, full_name = %s, role = %s, is_admin = %s, is_active = %s
                    WHERE id = %s
                """, (email, full_name, role_db, is_admin, is_active, user_id))
            
            mysql.connection.commit()
            log_write('admin_update_user', f"Updated user {user_id}")
            audit_log.log_admin_action(current_user.email, 'update_user', target=f"user_id={user_id}", details=f"email={email}, role={role_db}")
            return jsonify({'success': True})
        
        elif request.method == 'DELETE':
            if not getattr(current_user, 'is_admin', False):
                return jsonify({'success': False, 'error': 'Access denied'}), 403
            # Prevent self-deletion
            if user_id == current_user.id:
                return jsonify({'success': False, 'error': 'Cannot delete your own account'}), 400
            
            # Get user email before deletion for logging
            cur.execute("SELECT email FROM users WHERE id = %s", (user_id,))
            user_to_delete = cur.fetchone()
            user_email = user_to_delete['email'] if user_to_delete else f'ID:{user_id}'
            
            # Remove dependent records to satisfy FK constraints (e.g., logs.user_id -> users.id)
            cur.execute("DELETE FROM logs WHERE user_id = %s", (user_id,))
            
            cur.execute("DELETE FROM users WHERE id = %s", (user_id,))
            mysql.connection.commit()
            log_write('admin_delete_user', f"Deleted user {user_id}")
            audit_log.log_admin_action(current_user.email, 'delete_user', target=user_email)
            return jsonify({'success': True})
    
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/api/admin/user/<int:user_id>/toggle-status', methods=['POST'])
@login_required
def admin_toggle_user_status(user_id):
    """Toggle user active status with CSRF validation"""
    if not (getattr(current_user, 'is_admin', False) or (get_user_role() or '').lower() == 'topleveladmin'):
        audit_log.log_permission_denied(current_user.email, f'/api/admin/user/{user_id}/toggle-status', 'POST')
        return jsonify({'success': False, 'error': 'Access denied'}), 403
    
    # Validate CSRF token
    csrf_token = request.headers.get('X-CSRF-Token') or request.form.get('_csrf_token')
    if not validate_csrf_token(csrf_token):
        audit_log.log_csrf_failure(get_client_ip(), f'/api/admin/user/{user_id}/toggle-status')
        return jsonify({'success': False, 'error': 'Invalid security token'}), 403
    
    cur = mysql.connection.cursor(DictCursor)
    try:
        # Get current status for logging
        cur.execute("SELECT email, is_active FROM users WHERE id = %s", (user_id,))
        user = cur.fetchone()
        if not user:
            return jsonify({'success': False, 'error': 'User not found'}), 404
        
        new_status = not bool(user.get('is_active', True))
        cur.execute("UPDATE users SET is_active = %s WHERE id = %s", (new_status, user_id))
        mysql.connection.commit()
        
        log_write('admin_toggle_user', f"Toggled status for user {user_id}")
        audit_log.log_admin_action(current_user.email, 'toggle_user_status', target=user['email'], 
                                  details=f"new_status={'active' if new_status else 'inactive'}")
        return jsonify({'success': True, 'new_status': new_status})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/api/admin/employee/<int:employee_id>/toggle-status', methods=['POST'])
@login_required
def admin_toggle_employee_status(employee_id):
    """Toggle employee active status with CSRF validation"""
    if not (getattr(current_user, 'is_admin', False) or (get_user_role() or '').lower() == 'topleveladmin'):
        audit_log.log_permission_denied(current_user.email, f'/api/admin/employee/{employee_id}/toggle-status', 'POST')
        return jsonify({'success': False, 'error': 'Access denied'}), 403

    csrf_token = request.headers.get('X-CSRF-Token') or request.form.get('_csrf_token')
    if not validate_csrf_token(csrf_token):
        audit_log.log_csrf_failure(get_client_ip(), f'/api/admin/employee/{employee_id}/toggle-status')
        return jsonify({'success': False, 'error': 'Invalid security token'}), 403

    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SELECT name, email, is_active FROM employees WHERE id = %s", (employee_id,))
        employee = cur.fetchone()
        if not employee:
            return jsonify({'success': False, 'error': 'Employee not found'}), 404

        new_status = not bool(employee.get('is_active', True))
        cur.execute("UPDATE employees SET is_active = %s WHERE id = %s", (new_status, employee_id))
        mysql.connection.commit()

        audit_log.log_admin_action(
            current_user.email,
            'toggle_employee_status',
            target=employee.get('email') or employee.get('name') or f"employee_id={employee_id}",
            details=f"new_status={'active' if new_status else 'inactive'}"
        )
        return jsonify({'success': True, 'new_status': new_status})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/api/admin/permissions/update', methods=['POST'])
@login_required
def admin_update_permission():
    """Update module permission for a role"""
    # Allow both IT Admin and Top Level Admin to update permissions
    if not (getattr(current_user, 'is_admin', False) or (get_user_role() or '').lower() == 'topleveladmin'):
        return jsonify({'success': False, 'error': 'Access denied'}), 403
    
    ensure_permissions_table()
    
    data = request.get_json()
    module = data.get('module')
    role = data.get('role', '')
    enabled = data.get('enabled', False)
    perm = (data.get('perm') or 'view').strip().lower()
    role_norm = _normalize_role_key(role)
    
    cur = mysql.connection.cursor(DictCursor)
    try:
        # Normalize to canonical role value for storage
        if role_norm == 'teamlead':
            role_db = role_norm
        else:
            role_db = role_norm

        # Load current CRUD row (if any)
        cur.execute(
            """
            SELECT can_view, can_create, can_edit, can_delete
            FROM module_permissions
            WHERE role = %s AND module_key = %s
            LIMIT 1
            """,
            (role_db, module),
        )
        row = cur.fetchone() or {}
        can_view = bool(row.get('can_view')) if row else False
        can_create = bool(row.get('can_create')) if row else False
        can_edit = bool(row.get('can_edit')) if row else False
        can_delete = bool(row.get('can_delete')) if row else False

        if perm == 'view':
            can_view = bool(enabled)
            if not can_view:
                can_create = False
                can_edit = False
                can_delete = False
        elif perm == 'create':
            can_create = bool(enabled)
            if can_create:
                can_view = True
        elif perm == 'edit':
            can_edit = bool(enabled)
            if can_edit:
                can_view = True
        elif perm == 'delete':
            can_delete = bool(enabled)
            if can_delete:
                can_view = True
        else:
            return jsonify({'success': False, 'error': 'Invalid permission type'}), 400

        cur.execute(
            """
            INSERT INTO module_permissions (role, module_key, can_view, can_create, can_edit, can_delete, scope)
            VALUES (%s, %s, %s, %s, %s, %s, 'all')
            ON DUPLICATE KEY UPDATE
                can_view = VALUES(can_view),
                can_create = VALUES(can_create),
                can_edit = VALUES(can_edit),
                can_delete = VALUES(can_delete),
                updated_at = NOW()
            """,
            (role_db, module, can_view, can_create, can_edit, can_delete),
        )

        # Keep legacy role_permissions in sync with view access.
        cur.execute(
            """
            INSERT INTO role_permissions (role, module_key, enabled)
            VALUES (%s, %s, %s)
            ON DUPLICATE KEY UPDATE enabled = %s, updated_at = NOW()
            """,
            (role_db, module, can_view, can_view),
        )

        log_write('admin_permission_update', f"Set {module}:{perm} for {role_db} to {enabled}")

        # Emit SocketIO event for real-time update
        try:
            socketio.emit('permission_changed', {
                'module': module,
                'roles': [role_db],
                'enabled': enabled,
                'perm': perm,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
        except Exception:
            pass
        
        mysql.connection.commit()
        return jsonify({'success': True, 'message': f'Permission updated: {module}:{perm} for {role} = {enabled}'})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/api/admin/actions/update', methods=['POST'])
@login_required
def admin_update_action():
    """Update action permission"""
    if not (getattr(current_user, 'is_admin', False) or (get_user_role() or '').lower() == 'topleveladmin'):
        return jsonify({'success': False, 'error': 'Access denied'}), 403
    
    ensure_permissions_table()
    
    data = request.get_json()
    action = data.get('action')
    enabled = data.get('enabled', False)
    role = _normalize_role_key(data.get('role', '') or '')
    
    cur = mysql.connection.cursor(DictCursor)
    try:
        if role:
            cur.execute("""
                INSERT INTO action_permissions (role, action_key, enabled)
                VALUES (%s, %s, %s)
                ON DUPLICATE KEY UPDATE enabled = %s, updated_at = NOW()
            """, (role, action, enabled, enabled))
        else:
            # Backward-compatible: update for canonical roles if role not specified.
            for role_item in ['topleveladmin', 'manager', 'teamlead', 'member']:
                cur.execute("""
                    INSERT INTO action_permissions (role, action_key, enabled)
                    VALUES (%s, %s, %s)
                    ON DUPLICATE KEY UPDATE enabled = %s, updated_at = NOW()
                """, (role_item, action, enabled, enabled))
        mysql.connection.commit()
        return jsonify({'success': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/api/admin/employee/<int:employee_id>/reporting-manager', methods=['POST'])
@login_required
def admin_update_employee_reporting_manager(employee_id):
    """Update employee's reporting manager (team_lead_id)."""
    if not (getattr(current_user, 'is_admin', False) or (get_user_role() or '').lower() == 'topleveladmin'):
        return jsonify({'success': False, 'error': 'Access denied'}), 403

    data = request.get_json() or {}
    manager_id = data.get('team_lead_id')
    try:
        manager_id = int(manager_id) if manager_id not in (None, '', 'null') else None
    except Exception:
        manager_id = None

    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SELECT id FROM employees WHERE id=%s", (employee_id,))
        if not cur.fetchone():
            return jsonify({'success': False, 'error': 'Employee not found'}), 404
        if manager_id:
            cur.execute("SELECT id FROM users WHERE id=%s", (manager_id,))
            if not cur.fetchone():
                return jsonify({'success': False, 'error': 'Manager not found'}), 404
        cur.execute("UPDATE employees SET team_lead_id=%s WHERE id=%s", (manager_id, employee_id))
        mysql.connection.commit()
        return jsonify({'success': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/api/admin/user/<int:user_id>/reporting-manager', methods=['POST'])
@login_required
def admin_update_user_reporting_manager(user_id):
    """Update a user's reporting manager."""
    if not (getattr(current_user, 'is_admin', False) or (get_user_role() or '').lower() == 'topleveladmin'):
        return jsonify({'success': False, 'error': 'Access denied'}), 403

    data = request.get_json() or {}
    manager_id = data.get('manager_user_id')
    try:
        manager_id = int(manager_id) if manager_id not in (None, '', 'null') else None
    except Exception:
        manager_id = None

    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SELECT id FROM users WHERE id=%s", (user_id,))
        if not cur.fetchone():
            return jsonify({'success': False, 'error': 'User not found'}), 404
        if manager_id:
            cur.execute("SELECT id FROM users WHERE id=%s", (manager_id,))
            if not cur.fetchone():
                return jsonify({'success': False, 'error': 'Manager not found'}), 404
        cur.execute(
            """
            INSERT INTO user_reporting_manager (user_id, manager_user_id)
            VALUES (%s, %s)
            ON DUPLICATE KEY UPDATE manager_user_id=VALUES(manager_user_id), updated_at=NOW()
            """,
            (user_id, manager_id),
        )
        mysql.connection.commit()
        return jsonify({'success': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/api/admin/employee-permissions/update', methods=['POST'])
@login_required
def admin_update_employee_permissions():
    """Update module permission override for an employee."""
    if not (getattr(current_user, 'is_admin', False) or (get_user_role() or '').lower() == 'topleveladmin'):
        return jsonify({'success': False, 'error': 'Access denied'}), 403

    data = request.get_json() or {}
    employee_id = int(data.get('employee_id') or 0)
    module_key = (data.get('module') or '').strip()
    enabled = bool(data.get('enabled'))
    valid_modules = {m.get('key') for m in DEFAULT_MODULES}
    if not employee_id or module_key not in valid_modules:
        return jsonify({'success': False, 'error': 'Invalid employee or module'}), 400

    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SELECT id FROM employees WHERE id=%s", (employee_id,))
        if not cur.fetchone():
            return jsonify({'success': False, 'error': 'Employee not found'}), 404
        cur.execute(
            """
            INSERT INTO employee_module_permissions (employee_id, module_key, enabled)
            VALUES (%s, %s, %s)
            ON DUPLICATE KEY UPDATE enabled=VALUES(enabled), updated_at=NOW()
            """,
            (employee_id, module_key, enabled),
        )
        mysql.connection.commit()
        return jsonify({'success': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/api/admin/user-permissions/<int:user_id>', methods=['GET'])
@login_required
def admin_get_user_permissions(user_id):
    """Return module permissions for a specific user (role + overrides)."""
    if not (getattr(current_user, 'is_admin', False) or (get_user_role() or '').lower() == 'topleveladmin'):
        return jsonify({'success': False, 'error': 'Access denied'}), 403

    try:
        ensure_permissions_table()
    except Exception:
        pass

    cur = mysql.connection.cursor(DictCursor)
    try:
        # Load user
        try:
            cur.execute(
                "SELECT id, email, role, is_admin, is_active, full_name FROM users WHERE id=%s",
                (int(user_id),),
            )
        except Exception:
            cur.execute(
                "SELECT id, email, role, is_admin, is_active FROM users WHERE id=%s",
                (int(user_id),),
            )
        user = cur.fetchone()
        if not user:
            return jsonify({'success': False, 'error': 'User not found'}), 404

        role_key = _normalize_role_key(user.get('role') or 'member')
        is_admin = bool(user.get('is_admin'))
        role_base = get_user_module_crud_permissions(role_key, is_admin=is_admin)
        overrides = _get_user_module_overrides(int(user_id), cur=cur)

        modules = []
        for module in DEFAULT_MODULES:
            key = module.get('key')
            base = role_base.get(key, _default_module_crud_for_role(role_key, key))
            override = overrides.get(key)
            effective = override or base
            modules.append({
                'key': key,
                'name': module.get('name') or key,
                'perms': {
                    'can_view': bool(effective.get('can_view')),
                    'can_create': bool(effective.get('can_create')),
                    'can_edit': bool(effective.get('can_edit')),
                    'can_delete': bool(effective.get('can_delete')),
                    'scope': effective.get('scope') or ('user' if override else 'role'),
                },
                'source': 'user' if override else 'role',
            })

        return jsonify({
            'success': True,
            'user': {
                'id': user.get('id'),
                'email': user.get('email'),
                'role': user.get('role'),
                'is_admin': bool(user.get('is_admin')),
                'is_active': bool(user.get('is_active', True)),
                'full_name': user.get('full_name') if 'full_name' in user else None,
            },
            'modules': modules,
        })
    finally:
        cur.close()

@app.route('/api/admin/user-permissions/update', methods=['POST'])
@login_required
def admin_update_user_permissions():
    """Update module permission overrides for a specific user."""
    if not (getattr(current_user, 'is_admin', False) or (get_user_role() or '').lower() == 'topleveladmin'):
        return jsonify({'success': False, 'error': 'Access denied'}), 403

    try:
        ensure_permissions_table()
    except Exception:
        pass

    data = request.get_json() or {}
    user_id = int(data.get('user_id') or 0)
    module_key = (data.get('module') or '').strip()
    perm = (data.get('perm') or 'view').strip().lower()
    enabled = bool(data.get('enabled'))

    valid_modules = {m.get('key') for m in DEFAULT_MODULES}
    if not user_id or module_key not in valid_modules:
        return jsonify({'success': False, 'error': 'Invalid user or module'}), 400

    if perm not in ('view', 'create', 'edit', 'delete'):
        return jsonify({'success': False, 'error': 'Invalid permission type'}), 400

    cur = mysql.connection.cursor(DictCursor)
    try:
        try:
            cur.execute(
                "SELECT id, role, is_admin FROM users WHERE id=%s",
                (int(user_id),),
            )
        except Exception:
            cur.execute(
                "SELECT id, role, is_admin FROM users WHERE id=%s",
                (int(user_id),),
            )
        user = cur.fetchone()
        if not user:
            return jsonify({'success': False, 'error': 'User not found'}), 404

        role_key = _normalize_role_key(user.get('role') or 'member')
        is_admin = bool(user.get('is_admin'))
        role_base = get_user_module_crud_permissions(role_key, is_admin=is_admin)
        overrides = _get_user_module_overrides(int(user_id), cur=cur)
        current = overrides.get(module_key) or role_base.get(module_key) or _default_module_crud_for_role(role_key, module_key)

        can_view = bool(current.get('can_view'))
        can_create = bool(current.get('can_create'))
        can_edit = bool(current.get('can_edit'))
        can_delete = bool(current.get('can_delete'))

        if perm == 'view':
            can_view = enabled
            if not can_view:
                can_create = False
                can_edit = False
                can_delete = False
        elif perm == 'create':
            can_create = enabled
            if can_create:
                can_view = True
        elif perm == 'edit':
            can_edit = enabled
            if can_edit:
                can_view = True
        elif perm == 'delete':
            can_delete = enabled
            if can_delete:
                can_view = True

        cur.execute(
            """
            INSERT INTO user_module_permissions (user_id, module_key, can_view, can_create, can_edit, can_delete, scope)
            VALUES (%s, %s, %s, %s, %s, %s, 'user')
            ON DUPLICATE KEY UPDATE
                can_view = VALUES(can_view),
                can_create = VALUES(can_create),
                can_edit = VALUES(can_edit),
                can_delete = VALUES(can_delete),
                scope = VALUES(scope),
                updated_at = NOW()
            """,
            (int(user_id), module_key, can_view, can_create, can_edit, can_delete),
        )
        mysql.connection.commit()
        return jsonify({
            'success': True,
            'module': module_key,
            'perms': {
                'can_view': bool(can_view),
                'can_create': bool(can_create),
                'can_edit': bool(can_edit),
                'can_delete': bool(can_delete),
            },
            'source': 'user',
        })
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/api/admin/user-permissions/reset', methods=['POST'])
@login_required
def admin_reset_user_permissions():
    """Clear a single module override for a user and return role defaults."""
    if not (getattr(current_user, 'is_admin', False) or (get_user_role() or '').lower() == 'topleveladmin'):
        return jsonify({'success': False, 'error': 'Access denied'}), 403

    data = request.get_json() or {}
    user_id = int(data.get('user_id') or 0)
    module_key = (data.get('module') or '').strip()
    valid_modules = {m.get('key') for m in DEFAULT_MODULES}
    if not user_id or module_key not in valid_modules:
        return jsonify({'success': False, 'error': 'Invalid user or module'}), 400

    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SELECT id, role, is_admin FROM users WHERE id=%s", (int(user_id),))
        user = cur.fetchone()
        if not user:
            return jsonify({'success': False, 'error': 'User not found'}), 404

        cur.execute(
            "DELETE FROM user_module_permissions WHERE user_id=%s AND module_key=%s",
            (int(user_id), module_key),
        )
        mysql.connection.commit()

        role_key = _normalize_role_key(user.get('role') or 'member')
        is_admin = bool(user.get('is_admin'))
        role_base = get_user_module_crud_permissions(role_key, is_admin=is_admin)
        effective = role_base.get(module_key) or _default_module_crud_for_role(role_key, module_key)

        return jsonify({
            'success': True,
            'module': module_key,
            'perms': {
                'can_view': bool(effective.get('can_view')),
                'can_create': bool(effective.get('can_create')),
                'can_edit': bool(effective.get('can_edit')),
                'can_delete': bool(effective.get('can_delete')),
            },
            'source': 'role',
        })
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/api/admin/user-permissions/clear', methods=['POST'])
@login_required
def admin_clear_user_permissions():
    """Clear all module overrides for a user."""
    if not (getattr(current_user, 'is_admin', False) or (get_user_role() or '').lower() == 'topleveladmin'):
        return jsonify({'success': False, 'error': 'Access denied'}), 403

    data = request.get_json() or {}
    user_id = int(data.get('user_id') or 0)
    if not user_id:
        return jsonify({'success': False, 'error': 'Invalid user'}), 400

    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("DELETE FROM user_module_permissions WHERE user_id=%s", (int(user_id),))
        mysql.connection.commit()
        return jsonify({'success': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/api/admin/role/<role>/permissions', methods=['GET', 'POST'])
@login_required
def admin_role_permissions(role):
    """Get or update permissions for a specific role"""
    if not current_user.is_admin:
        return jsonify({'success': False, 'error': 'Access denied'}), 403
    
    ensure_permissions_table()
    role_name = _normalize_role_key(role)
    role_name_space = role_name.replace('_', ' ')
    cur = mysql.connection.cursor(DictCursor)
    
    try:
        if request.method == 'GET':
            permissions = []
            for module in DEFAULT_MODULES:
                cur.execute("""
                    SELECT enabled FROM role_permissions 
                    WHERE (role = %s OR role = %s) AND module_key = %s
                    ORDER BY updated_at DESC
                    LIMIT 1
                """, (role_name, role_name_space, module['key']))
                result = cur.fetchone()
                if result:
                    enabled = result['enabled']
                else:
                    default_perms = DEFAULT_ROLE_PERMISSIONS.get(role_name, {}) or DEFAULT_ROLE_PERMISSIONS.get(role_name_space, {})
                    enabled = default_perms.get('all_access', False) or module['key'] in default_perms.get('modules', [])
                
                permissions.append({
                    'key': module['key'],
                    'name': module['name'],
                    'enabled': enabled
                })
            
            # Add action permissions
            for action in DEFAULT_ACTIONS:
                cur.execute("""
                    SELECT enabled FROM action_permissions 
                    WHERE (role = %s OR role = %s) AND action_key = %s
                    ORDER BY updated_at DESC
                    LIMIT 1
                """, (role_name, role_name_space, action['key']))
                result = cur.fetchone()
                if result:
                    enabled = result['enabled']
                else:
                    default_perms = DEFAULT_ROLE_PERMISSIONS.get(role_name, {}) or DEFAULT_ROLE_PERMISSIONS.get(role_name_space, {})
                    enabled = action['key'] in default_perms.get('actions', [])
                
                permissions.append({
                    'key': action['key'],
                    'name': action['name'],
                    'enabled': enabled
                })
            
            return jsonify({'permissions': permissions})
        
        elif request.method == 'POST':
            data = request.get_json()
            permissions = data.get('permissions', [])
            
            for perm in permissions:
                # Check if it's a module or action
                is_module = any(m['key'] == perm['key'] for m in DEFAULT_MODULES)
                if is_module:
                    cur.execute("""
                        INSERT INTO role_permissions (role, module_key, enabled)
                        VALUES (%s, %s, %s)
                        ON DUPLICATE KEY UPDATE enabled = %s, updated_at = NOW()
                    """, (role_name, perm['key'], perm['enabled'], perm['enabled']))
                else:
                    cur.execute("""
                        INSERT INTO action_permissions (role, action_key, enabled)
                        VALUES (%s, %s, %s)
                        ON DUPLICATE KEY UPDATE enabled = %s, updated_at = NOW()
                    """, (role_name, perm['key'], perm['enabled'], perm['enabled']))
            
            mysql.connection.commit()
            log_write('admin_role_permissions', f"Updated permissions for {role_name}")
            return jsonify({'success': True})
    
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/api/admin/users/export')
@login_required
def admin_export_users():
    """Export users to CSV"""
    if not current_user.is_admin:
        return "Access Denied", 403
    
    import csv
    from io import StringIO
    
    cur = mysql.connection.cursor(DictCursor)
    cur.execute("SELECT id, email, role, is_admin, is_active FROM users ORDER BY id")
    users = cur.fetchall()
    cur.close()
    
    output = StringIO()
    writer = csv.writer(output)
    writer.writerow(['ID', 'Email', 'Role', 'Is Admin', 'Is Active'])
    for user in users:
        writer.writerow([user['id'], user['email'], user['role'], user['is_admin'], user.get('is_active', True)])
    
    output.seek(0)
    from flask import Response
    return Response(
        output.getvalue(),
        mimetype='text/csv',
        headers={'Content-Disposition': 'attachment; filename=users_export.csv'}
    )

@app.route('/api/admin/users/bulk-import', methods=['POST'])
@login_required
def admin_bulk_import():
    """Bulk import users from CSV"""
    if not current_user.is_admin:
        return jsonify({'success': False, 'error': 'Access denied'}), 403
    
    if 'csv_file' not in request.files:
        return jsonify({'success': False, 'error': 'No file uploaded'}), 400
    
    import csv
    from io import StringIO
    
    file = request.files['csv_file']
    if file.filename == '':
        return jsonify({'success': False, 'error': 'No file selected'}), 400
    
    try:
        content = file.read().decode('utf-8')
        reader = csv.DictReader(StringIO(content))
        
        cur = mysql.connection.cursor(DictCursor)
        imported = 0
        
        for row in reader:
            email = row.get('email', '').strip()
            password = row.get('password', '').strip()
            role = row.get('role', 'member').strip()
            
            if not email or not password:
                continue
            
            # Check if email exists
            cur.execute("SELECT id FROM users WHERE email = %s", (email,))
            if cur.fetchone():
                continue
            
            is_admin = 1 if role.lower() == 'admin' else 0
            cur.execute("""
                INSERT INTO users (email, password, role, is_admin, is_active)
                VALUES (%s, %s, %s, %s, TRUE)
            """, (email, password, role, is_admin))
            imported += 1
        
        mysql.connection.commit()
        cur.close()
        
        log_write('admin_bulk_import', f"Imported {imported} users")
        return jsonify({'success': True, 'count': imported})
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

# Helper function to check user permissions
def user_has_permission(user, module_key):
    """Check if a user has access to a specific module"""
    if user.is_admin:
        return True
    company_id = session.get('active_company_id')
    active_department_key = session.get('active_department_key') or None
    if not company_id:
        return False

    # Prefer the request-scoped role computed in @app.before_request
    role = getattr(user, 'context_role', None) or getattr(user, 'role', None)
    if not role:
        try:
            access_rows = _fetch_user_access_rows(int(user.id))
            role = _resolve_context_role(access_rows, company_id, active_department_key)
        except Exception:
            role = None
    if not role:
        return False

    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute(
            """
            SELECT enabled FROM role_permissions
            WHERE role = %s AND module_key = %s
            """,
            (role, module_key),
        )
        result = cur.fetchone()
    finally:
        try:
            cur.close()
        except Exception:
            pass

    if result:
        return result['enabled']
    # Fall back to defaults
    default_perms = DEFAULT_ROLE_PERMISSIONS.get((role or '').lower(), {})
    return default_perms.get('all_access', False) or module_key in default_perms.get('modules', [])

def user_can_perform_action(user, action_key):
    """Check if a user can perform a specific action"""
    if user.is_admin:
        return True
    
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("""
            SELECT enabled FROM action_permissions 
            WHERE role = %s AND action_key = %s
        """, (user.role, action_key))
        result = cur.fetchone()
        if result:
            return result['enabled']
        
        # Fall back to defaults
        default_perms = DEFAULT_ROLE_PERMISSIONS.get(user.role.lower(), {})
        return action_key in default_perms.get('actions', [])
    finally:
        cur.close()

# ================================================================================
# END IT ADMIN DASHBOARD
# ================================================================================

@app.route('/logout')
def logout():
    log_write('logout')
    logout_user()
    return redirect(url_for('login'))

@app.route('/employee/login', methods=['POST'])
def employee_login():
    """Employee login route"""
    try:
        email = request.form.get('email', '').strip()
        password = request.form.get('password', '').strip()
        # employee_id may be provided from the UI but we don't require it for auth
        if not email or not password:
            return jsonify({'success': False, 'error': 'Missing credentials'}), 400

        cur = mysql.connection.cursor(DictCursor)
        # Ensure password column exists; if not, fail with a clear message
        try:
            cur.execute("SHOW COLUMNS FROM employees LIKE 'password'")
            has_password_col = cur.fetchone() is not None
        except Exception:
            has_password_col = False
        if not has_password_col:
            cur.close()
            return jsonify({'success': False, 'error': "employees.password column missing. Run add_password_column.sql or migration."}), 500
        cur = mysql.connection.cursor(DictCursor)
        cur.execute(
            """
            SELECT * FROM employees 
            WHERE email = %s AND password = %s AND is_active = 1
            """,
            (email, password),
        )
        employee = cur.fetchone()
        cur.close()

        if employee:
            # Create a simple session for employee (not using Flask-Login for employees)
            session['employee_id'] = employee['id']
            session['employee_name'] = employee['name']
            session['employee_email'] = employee['email']
            session['employee_department'] = employee['department']

            log_write('employee_login', f"Employee {employee['name']} logged in")
            return jsonify({'success': True, 'employee_id': employee['id']})
        else:
            return jsonify({'success': False, 'error': 'Invalid credentials'}), 401

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/employee/logout')
def employee_logout():
    """Employee logout route"""
    if 'employee_id' in session:
        log_write('employee_logout', f"Employee {session.get('employee_name', 'Unknown')} logged out")
        session.pop('employee_id', None)
        session.pop('employee_name', None)
        session.pop('employee_email', None)
        session.pop('employee_department', None)
    return redirect(url_for('login'))

# --- Dashboard Routes ---
@app.route('/')
def index():
    if current_user.is_authenticated:
        if current_user.is_admin:
            return redirect(url_for('top_admin_overview'))
        elif current_user.is_supervisor:
            return redirect(url_for('manager_dashboard'))
        return redirect(url_for('dashboard'))
    return redirect(url_for('login'))

@app.route('/dashboard')
@login_required
def dashboard():
    # Redirect non-admins to their role-specific dashboards
    if current_user.is_admin:
        return redirect(url_for('top_admin_overview'))
    elif current_user.is_supervisor:
        return redirect(url_for('manager_dashboard'))
    role_raw = (get_user_role() or '').strip() or (getattr(current_user, 'role', '') or '')
    role_key = _normalize_role_key(role_raw)
    if role_key == 'project manager':
        return redirect(url_for('project_manager_dashboard'))
    elif _is_business_manager_user():
        return redirect(url_for('business_manager_team_allocation'))
    return redirect(url_for('manager_dashboard'))

def supervisor_business_dashboard():
    """Supervisor-level access to Business Development dashboard"""
    if not (current_user.is_admin or current_user.is_supervisor):
        return "Access Denied - Supervisor access required", 403
    
    team = 'business'
    current_stage = 'business'
    
    # Ensure tasks exist
    try:
        ensure_tasks_for_team(current_stage)
    except Exception:
        pass
    
    cur = mysql.connection.cursor(DictCursor)
    
    # Sync GO bids
    try:
        sync_go_bids()
    except Exception:
        pass
    
    # Company access filter based on ACTIVE company context (user_company_access)
    company_sql_clause, company_params = _company_filter_for_go_bids(cur)

    # Fetch all bids for this company scope
    try:
        cur.execute("""
        SELECT gb.g_id AS id,
               gb.b_name AS name,
               gb.company, 
               gb.due_date,
               COALESCE(gb.scoring, 0) AS progress,
               LOWER(COALESCE(gb.state, 'analyzer')) AS current_stage,
               ba.person_name,
               ba.assignee_email AS person_email,
               ba.depart,
               wps.pr_completion_status AS work_status,
               wbr.closure_status AS project_status,
               wbr.work_progress_status AS work_progress_status,
               wlr.result AS wl_result,
               gb.summary,
               COALESCE(gb.submission_status, 'Work Progress') AS submission_status,
               COALESCE(gb.submission_reason, '') AS submission_reason
        FROM go_bids gb
        LEFT JOIN bid_assign ba ON ba.g_id = gb.g_id
        LEFT JOIN win_lost_results wlr ON wlr.a_id = ba.a_id OR wlr.g_id = gb.g_id
        LEFT JOIN won_bids_result wbr ON wbr.w_id = wlr.w_id
        LEFT JOIN work_progress_status wps ON wps.won_id = wbr.won_id
        WHERE 1=1
        """ + company_sql_clause + """
        ORDER BY gb.due_date ASC
    """, company_params)
        rows = cur.fetchall()
    except Exception as e:
        rows = []

    # Remove duplicates
    _seen_pairs = set()
    _unique_rows = []
    for _r in rows:
        _key = (((_r.get('name') or '').strip().lower()), str(_r.get('due_date') or ''))
        if _key in _seen_pairs:
            continue
        _seen_pairs.add(_key)
        _unique_rows.append(_r)
    rows = _unique_rows

    # Load stage configurations
    try:
        cur.execute("SELECT g_id, stage FROM bid_stage_exclusions")
        ex_rows = cur.fetchall()
        exclusions = {}
        for r in ex_rows:
            exclusions.setdefault(r['g_id'], set()).add((r['stage'] or '').strip().lower())

        cur.execute("SELECT g_id, stage FROM bid_custom_stages")
        cs_rows = cur.fetchall()
        customs = {}
        for r in cs_rows:
            customs.setdefault(r['g_id'], []).append((r['stage'] or '').strip().lower())
    except Exception:
        exclusions = {}
        customs = {}

    # Preload task IDs
    try:
        cur.execute("SELECT DISTINCT g_id FROM bid_checklists WHERE LOWER(COALESCE(stage,''))=%s", (current_stage,))
        task_ids = {row['g_id'] for row in cur.fetchall()}
    except Exception:
        task_ids = set()

    default_stages = ['analyzer', 'business', 'design', 'operations', 'engineer']
    bids = []
    for row in rows:
        bid_id = row.get('id')
        excl = exclusions.get(bid_id, set())
        cust = [s for s in customs.get(bid_id, []) if s not in excl]
        dyn_stages = [s for s in default_stages if s not in excl] + [s for s in cust if s not in default_stages]
        if not dyn_stages:
            dyn_stages = default_stages.copy()

        stage_now = (row.get('current_stage') or 'analyzer').lower()
        should_include = (
            stage_now == current_stage
            or bid_id in task_ids
            or current_stage in dyn_stages
        )
        if not should_include:
            continue

        row['user'] = {'email': row.get('person_email'), 'role': current_stage}
        row['next_stage'] = None
        row['work_progress_pct'] = 0
        row['project_status'], row['work_status'] = 'ongoing', 'In Progress'
        row['dyn_stages'] = dyn_stages
        bids.append(row)

    # Compute stats
    total_bids = len(bids)
    completed_bids = sum(1 for b in bids if (b.get('wl_result') == 'WON'))

    # Load assigned members
    bid_ids = [b['id'] for b in bids]
    assigned_map = {}
    try:
        if bid_ids:
            placeholders = ','.join(['%s'] * len(bid_ids))
            cur.execute(
                f"""
                SELECT bam.g_id, e.id AS employee_id, e.name, e.email
                FROM bid_assignment_members bam
                JOIN employees e ON e.id = bam.employee_id
                WHERE bam.g_id IN ({placeholders}) AND e.department = %s AND e.is_active = TRUE
                ORDER BY e.name
                """,
                (*bid_ids, team)
            )
            for r in cur.fetchall():
                assigned_map.setdefault(r['g_id'], []).append({'id': r['employee_id'], 'name': r['name'], 'email': r['email']})
        for b in bids:
            b['assigned_members'] = assigned_map.get(b['id'], [])
    except Exception:
        for b in bids:
            b['assigned_members'] = []

    # Load RFP files
    rfp_files_map = {}
    try:
        if bid_ids:
            placeholders = ','.join(['%s'] * len(bid_ids))
            cur.execute(
                f"""
                SELECT g_id, id, filename, file_path
                FROM uploaded_rfp_files
                WHERE g_id IN ({placeholders})
                ORDER BY uploaded_at DESC
                """,
                tuple(bid_ids)
            )
            for r in cur.fetchall():
                rfp_files_map.setdefault(r['g_id'], []).append({
                    'id': r['id'],
                    'filename': r['filename'],
                    'file_path': r['file_path']
                })
        for b in bids:
            b['rfp_files'] = rfp_files_map.get(b['id'], [])
    except Exception:
        for b in bids:
            b['rfp_files'] = []

    # Load employees
    cur.execute("SELECT id, name, email FROM employees WHERE department=%s AND is_active=TRUE ORDER BY name", (team,))
    employees = cur.fetchall()

    # Load buckets
    try:
        cur.execute("SELECT DISTINCT bucket FROM go_bids WHERE bucket IS NOT NULL AND bucket != '' ORDER BY bucket")
        buckets = [r['bucket'] for r in cur.fetchall()]
    except Exception:
        buckets = []

    # Load full teamlead_assign_bids table for the overview section
    try:
        cur.execute("SELECT * FROM teamlead_assign_bids ORDER BY COALESCE(due_date, created_at) DESC, id DESC")
        teamlead_assign_bids = cur.fetchall()
        if not teamlead_assign_bids:
            # If empty, backfill once from existing tables and re-read
            try:
                # Ensure a unique key on g_id so we can safely upsert
                try:
                    cur.execute("SHOW INDEX FROM teamlead_assign_bids WHERE Key_name = 'uniq_teamlead_assign_g_id'")
                    if cur.fetchone():
                        cur.execute("ALTER TABLE teamlead_assign_bids DROP INDEX uniq_teamlead_assign_g_id")
                    cur.execute("SHOW INDEX FROM teamlead_assign_bids WHERE Key_name = 'uniq_teamlead_assign_bid_lead'")
                    if not cur.fetchone():
                        cur.execute("ALTER TABLE teamlead_assign_bids ADD UNIQUE KEY uniq_teamlead_assign_bid_lead (g_id, team_lead)")
                except Exception:
                    pass

                cur.execute(
                    """
                    INSERT INTO teamlead_assign_bids (
                        g_id, b_name, due_date, state, scope, type, scoring,
                        comp_name, company, summary, submission_status, submission_reason,
                        task_completion_date, team_lead
                    )
                    SELECT
                        g.g_id,
                        g.b_name,
                        g.due_date,
                        g.state,
                        g.scope,
                        g.type,
                        g.scoring,
                        COALESCE(
                            (SELECT bi.comp_name
                             FROM bid_incoming bi
                             WHERE bi.b_name = g.b_name
                             ORDER BY bi.id DESC
                             LIMIT 1),
                            g.company
                        ) AS comp_name,
                        g.company,
                        g.summary,
                        COALESCE(g.submission_status, 'Work Progress') AS submission_status,
                        g.submission_reason,
                        (
                            SELECT DATE(MAX(bc.updated_at))
                            FROM bid_checklists bc
                            WHERE bc.g_id = g.g_id
                              AND (
                                LOWER(COALESCE(bc.status, '')) = 'completed'
                                OR COALESCE(bc.progress_pct, 0) >= 100
                              )
                        ) AS task_completion_date,
                        (
                            SELECT ba.assignee_email
                            FROM bid_assign ba
                            WHERE ba.g_id = g.g_id
                            ORDER BY ba.a_id DESC
                            LIMIT 1
                        ) AS team_lead
                    FROM go_bids g
                    ON DUPLICATE KEY UPDATE
                        b_name = VALUES(b_name),
                        due_date = VALUES(due_date),
                        state = VALUES(state),
                        scope = VALUES(scope),
                        type = VALUES(type),
                        scoring = VALUES(scoring),
                        comp_name = VALUES(comp_name),
                        company = VALUES(company),
                        summary = VALUES(summary),
                        submission_status = VALUES(submission_status),
                        submission_reason = VALUES(submission_reason),
                        task_completion_date = VALUES(task_completion_date),
                        team_lead = VALUES(team_lead),
                        updated_at = CURRENT_TIMESTAMP
                    """
                )
                mysql.connection.commit()
            except Exception:
                pass

            try:
                cur.execute("SELECT * FROM teamlead_assign_bids ORDER BY COALESCE(due_date, created_at) DESC, id DESC")
                teamlead_assign_bids = cur.fetchall()
            except Exception:
                teamlead_assign_bids = []
    except Exception:
        teamlead_assign_bids = []

    cur.close()

    return render_template('team_dashboard.html',
                         team=team,
                         team_display_name='Business Development',
                         bids=bids,
                         total_bids=total_bids,
                         completed_bids=completed_bids,
                         in_progress_bids=total_bids - completed_bids,
                         employees=employees,
                         buckets=buckets,
                         teamlead_assign_bids=teamlead_assign_bids,
                         user=current_user,
                         current_stage=current_stage,
                         is_supervisor=True)

@app.route('/team-lead/dashboard')
@login_required
def team_lead_dashboard():
    """Team Lead dashboard for managing team members and their tasks"""
    # Use scoped RBAC role (from user_company_access via current_user.context_role)
    user_role = (get_user_role() or 'member').strip().lower()
    is_top_admin = user_role == 'topleveladmin'
    is_manager_user = user_role == 'manager'
    is_team_lead_user = user_role == 'teamlead'
    has_team_lead_module = check_module_access_db('team_lead_dashboard')
    # Allow explicit module access to act like a team lead view (role access override)
    if has_team_lead_module and not (current_user.is_admin or current_user.is_supervisor or is_top_admin or is_manager_user):
        is_team_lead_user = True

    def _team_key_from_dept_key(dept_key: str | None) -> str | None:
        d = (dept_key or '').strip().lower().replace(' ', '_')
        if not d:
            return None
        if d in ['business', 'business_dev', 'business_development']:
            return 'business'
        if d in ['design', 'marketing']:
            return 'design'
        if d in ['operations', 'operation', 'ops']:
            return 'operations'
        if d in ['site_engineer', 'site_engineering', 'engineer', 'engineering']:
            return 'engineer'
        return None

    # True Team Lead (not manager/admin) should only see bids assigned by their Team Manager
    only_manager_assigned_bids = bool(is_team_lead_user and not (current_user.is_admin or current_user.is_supervisor or is_top_admin or is_manager_user))
    
    if not (current_user.is_admin or current_user.is_supervisor or is_top_admin or is_manager_user or is_team_lead_user or has_team_lead_module):
        return "Access Denied - Team Lead access required", 403
    
    # Get optional team filter from query params
    team_filter = request.args.get('team', None)
    
    # Team display names mapping
    team_names = {
        'business': 'Business Development',
        'design': 'Design',
        'operations': 'Operations',
        'engineer': 'Site Engineer'
    }
    # Default team filter to the team lead's own department (from active scoped dept)
    if not team_filter and is_team_lead_user:
        try:
            dept_key = session.get('active_department_key') or None
        except Exception:
            dept_key = None
        team_filter = _team_key_from_dept_key(dept_key)
        # Legacy fallback (older DBs stored dept names in users.role)
        if not team_filter:
            role_lower_legacy = (getattr(current_user, 'role', '') or '').lower().strip().replace('_', ' ')
            team_filter = _team_key_from_dept_key(role_lower_legacy)

    # Team leads should land on Assigned Tasks by default.
    if is_team_lead_user and not (current_user.is_admin or current_user.is_supervisor or is_top_admin or is_manager_user):
        target_team = team_filter or 'business'
        return redirect(url_for('team_lead_assigned_tasks', team=target_team))
    
    cur = mysql.connection.cursor(DictCursor)
    
    # Build query based on team filter
    if team_filter and team_filter in team_names:
        cur.execute("""
            SELECT e.*, u.email as team_lead_email,
                   (SELECT COUNT(*) FROM bid_checklists bc WHERE bc.assigned_to = e.id AND bc.status = 'pending') as pending_tasks,
                   (SELECT COUNT(*) FROM bid_checklists bc WHERE bc.assigned_to = e.id AND bc.status = 'in_progress') as in_progress_tasks,
                   (SELECT COUNT(*) FROM bid_checklists bc WHERE bc.assigned_to = e.id AND bc.status = 'completed') as completed_tasks
            FROM employees e
            LEFT JOIN users u ON e.team_lead_id = u.id
            WHERE e.is_active = TRUE AND e.department = %s
            ORDER BY e.name
        """, (team_filter,))
    else:
        cur.execute("""
            SELECT e.*, u.email as team_lead_email,
                   (SELECT COUNT(*) FROM bid_checklists bc WHERE bc.assigned_to = e.id AND bc.status = 'pending') as pending_tasks,
                   (SELECT COUNT(*) FROM bid_checklists bc WHERE bc.assigned_to = e.id AND bc.status = 'in_progress') as in_progress_tasks,
                   (SELECT COUNT(*) FROM bid_checklists bc WHERE bc.assigned_to = e.id AND bc.status = 'completed') as completed_tasks
            FROM employees e
            LEFT JOIN users u ON e.team_lead_id = u.id
            WHERE e.is_active = TRUE
            ORDER BY e.department, e.name
        """)
    employees = cur.fetchall()

    # --- Planner view data (same source as manager Team Dashboard) ---
    bids = []
    total_bids = 0
    completed_bids = 0

    if team_filter and team_filter in team_names:
        # Keep go_bids in sync with GO decisions so teams see new bids immediately
        try:
            sync_go_bids()
        except Exception:
            pass

        # Ensure seed tasks exist so all bids appear on this team planner view
        try:
            ensure_tasks_for_team(team_filter.lower())
        except Exception:
            pass

        # Company filter: active company context (multi-company support)
        company_sql_clause, company_params = _company_filter_for_go_bids(cur)

        # If Team Lead user, restrict the planner to only Manager-assigned bids (teamlead_assign_bids)
        assigned_bid_ids = []
        assigned_due_map = {}
        if only_manager_assigned_bids:
            try:
                cur.execute(
                    """
                    SELECT g_id, task_completion_date
                    FROM teamlead_assign_bids
                    WHERE LOWER(COALESCE(team_lead,'')) = LOWER(%s)
                    ORDER BY COALESCE(updated_at, created_at) DESC
                    """,
                    (current_user.email,),
                )
                for rr in (cur.fetchall() or []):
                    gid = rr.get('g_id')
                    if gid is None:
                        continue
                    try:
                        gid_int = int(gid)
                    except Exception:
                        continue
                    assigned_bid_ids.append(gid_int)
                    assigned_due_map[gid_int] = rr.get('task_completion_date')
            except Exception:
                assigned_bid_ids = []
                assigned_due_map = {}

        # Fetch all bids for this company scope; filtering by team is done in Python
        def _fetch_planner_rows(use_state=True, use_in_date=True):
            stage_sql = (
                "LOWER(COALESCE(gb.state, 'analyzer')) AS current_stage,"
                if use_state
                else "LOWER(COALESCE(ba.depart, 'analyzer')) AS current_stage,"
            )
            in_date_sql = "ba.in_date AS in_date," if use_in_date else "NULL AS in_date,"
            assign_sql_clause = ""
            assign_params = tuple()
            if only_manager_assigned_bids:
                if not assigned_bid_ids:
                    # No assigned bids => return empty without querying large tables
                    return []
                placeholders = ','.join(['%s'] * len(assigned_bid_ids))
                assign_sql_clause = f" AND gb.g_id IN ({placeholders})"
                assign_params = tuple(assigned_bid_ids)
            q = f"""
                SELECT gb.g_id AS id,
                       gb.b_name AS name,
                       gb.company,
                       gb.due_date,
                       {in_date_sql}
                       gb.created_at,
                       COALESCE(gb.scoring, 0) AS progress,
                       {stage_sql}
                       ba.person_name,
                       ba.assignee_email AS person_email,
                       ba.depart,
                       wps.pr_completion_status AS work_status,
                       wbr.closure_status AS project_status,
                       wbr.work_progress_status AS work_progress_status,
                       wlr.result AS wl_result,
                       gb.summary,
                       COALESCE(gb.submission_status, 'Work Progress') AS submission_status,
                       COALESCE(gb.submission_reason, '') AS submission_reason
                FROM go_bids gb
                LEFT JOIN bid_assign ba ON ba.g_id = gb.g_id
                LEFT JOIN win_lost_results wlr ON wlr.a_id = ba.a_id OR wlr.g_id = gb.g_id
                LEFT JOIN won_bids_result wbr ON wbr.w_id = wlr.w_id
                LEFT JOIN work_progress_status wps ON wps.won_id = wbr.won_id
                WHERE 1=1
                {company_sql_clause}
                {assign_sql_clause}
                ORDER BY gb.due_date ASC
            """
            cur.execute(q, (*company_params, *assign_params))
            return cur.fetchall()

        # Handle schema differences gracefully (older DBs may not have go_bids.state or in_date columns)
        rows = None
        last_exc = None
        for _use_state, _use_in_date in ((True, True), (False, True), (True, False), (False, False)):
            try:
                rows = _fetch_planner_rows(use_state=_use_state, use_in_date=_use_in_date)
                break
            except Exception as e:
                last_exc = e
                msg = str(e)
                # Only retry for expected schema-mismatch errors; otherwise raise immediately
                if not ("Unknown column" in msg and ("state" in msg or "in_date" in msg)):
                    raise
        if rows is None and last_exc is not None:
            raise last_exc

        # Remove duplicate bids by same name and due date (front-end filtering only)
        _seen_pairs = set()
        _unique_rows = []
        for _r in rows:
            _key = (((_r.get('name') or '').strip().lower()), str(_r.get('due_date') or ''))
            if _key in _seen_pairs:
                continue
            _seen_pairs.add(_key)
            _unique_rows.append(_r)
        rows = _unique_rows

        # Ensure dynamic stage tables exist and load per-bid configuration
        try:
            cur.execute(
                """
                CREATE TABLE IF NOT EXISTS bid_stage_exclusions (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    g_id INT NOT NULL,
                    stage VARCHAR(50) NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE KEY uniq_bid_stage (g_id, stage)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
                """
            )
            cur.execute(
                """
                CREATE TABLE IF NOT EXISTS bid_custom_stages (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    g_id INT NOT NULL,
                    stage VARCHAR(50) NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE KEY uniq_custom_stage (g_id, stage)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
                """
            )
        except Exception:
            pass

        cur.execute("SELECT g_id, stage FROM bid_stage_exclusions")
        ex_rows = cur.fetchall()
        exclusions = {}
        for r in ex_rows:
            exclusions.setdefault(r['g_id'], set()).add((r['stage'] or '').strip().lower())

        cur.execute("SELECT g_id, stage FROM bid_custom_stages")
        cs_rows = cur.fetchall()
        customs = {}
        for r in cs_rows:
            customs.setdefault(r['g_id'], []).append((r['stage'] or '').strip().lower())

        # Preload set of bids that already have tasks for this team's stage
        try:
            cur.execute("SELECT DISTINCT g_id FROM bid_checklists WHERE LOWER(COALESCE(stage,''))=%s", (team_filter.lower(),))
            task_ids = {row['g_id'] for row in cur.fetchall()}
        except Exception:
            task_ids = set()

        default_stages = ['analyzer', 'business', 'design', 'operations', 'engineer']
        current_stage = team_filter.lower()
        for row in rows:
            bid_id = row.get('id')
            stage_now = (row.get('current_stage') or 'analyzer').lower()
            if not only_manager_assigned_bids:
                if stage_now != current_stage and bid_id not in task_ids:
                    # Keep only bids relevant to this team, unless they already have tasks for this team
                    continue

            excl = exclusions.get(bid_id, set())
            cust = [s for s in customs.get(bid_id, []) if s not in excl]
            dyn_stages = [s for s in default_stages if s not in excl] + [s for s in cust if s not in default_stages]
            if not dyn_stages:
                dyn_stages = default_stages.copy()
            row['dyn_stages'] = dyn_stages
            # Manager -> Team Lead completion date used as "Due Date" on Team Lead dashboard
            if only_manager_assigned_bids and bid_id in assigned_due_map:
                try:
                    due_dt = assigned_due_map.get(bid_id)
                    row['task_completion_date'] = due_dt.strftime('%Y-%m-%d') if hasattr(due_dt, 'strftime') else (str(due_dt) if due_dt else 'N/A')
                except Exception:
                    row['task_completion_date'] = str(assigned_due_map.get(bid_id) or 'N/A')
            else:
                row['task_completion_date'] = row.get('task_completion_date') or None
            bids.append(row)

        # Stats
        total_bids = len(bids)
        completed_bids = sum(1 for b in bids if (b.get('wl_result') == 'WON'))

        # Load assigned members for each bid from bid_assignment_members table
        bid_ids = [b['id'] for b in bids]
        assigned_map = {}
        try:
            if bid_ids:
                cur.execute(
                    """
                    CREATE TABLE IF NOT EXISTS bid_assignment_members (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        g_id INT NOT NULL,
                        employee_id INT NOT NULL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        UNIQUE KEY uniq_g_emp (g_id, employee_id)
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
                    """
                )
                placeholders = ','.join(['%s'] * len(bid_ids))
                cur.execute(
                    f"""
                    SELECT bam.g_id, e.id AS employee_id, e.name, e.email
                    FROM bid_assignment_members bam
                    JOIN employees e ON e.id = bam.employee_id
                    WHERE bam.g_id IN ({placeholders}) AND e.department = %s AND e.is_active = TRUE
                    ORDER BY e.name
                    """,
                    (*bid_ids, team_filter.lower())
                )
                am_rows = cur.fetchall()
                for r in am_rows:
                    assigned_map.setdefault(r['g_id'], []).append({'id': r['employee_id'], 'name': r['name'], 'email': r['email']})
            for b in bids:
                b['assigned_members'] = assigned_map.get(b['id'], [])
        except Exception:
            for b in bids:
                b['assigned_members'] = []

        # Load RFP files for each bid from uploaded_rfp_files table
        rfp_files_map = {}
        try:
            if bid_ids:
                placeholders = ','.join(['%s'] * len(bid_ids))
                try:
                    cur.execute(
                        f"""
                        SELECT id, g_id, bid_id, filename, file_path, file_size, uploaded_at
                        FROM uploaded_rfp_files
                        WHERE g_id IN ({placeholders}) OR bid_id IN ({placeholders})
                        ORDER BY uploaded_at DESC
                        """,
                        (*bid_ids, *bid_ids)
                    )
                except Exception:
                    cur.execute(
                        f"""
                        SELECT id, bid_id, filename, file_path, file_size, uploaded_at
                        FROM uploaded_rfp_files
                        WHERE bid_id IN ({placeholders})
                        ORDER BY uploaded_at DESC
                        """,
                        bid_ids
                    )
                rf_rows = cur.fetchall()
                for r in rf_rows:
                    g_id = r.get('g_id') or r.get('bid_id')
                    if g_id and g_id in bid_ids:
                        rfp_files_map.setdefault(g_id, []).append({
                            'id': r['id'],
                            'filename': r.get('filename'),
                            'file_path': r.get('file_path'),
                            'file_size': r.get('file_size', 0),
                            'uploaded_at': r.get('uploaded_at')
                        })
            for b in bids:
                b['rfp_files'] = rfp_files_map.get(b['id'], [])
        except Exception:
            for b in bids:
                b['rfp_files'] = []

        # Load teamlead_assign_bids table for the overview section (show all teams)
        teamlead_assign_bids = []
        try:
            cur.execute("SELECT * FROM teamlead_assign_bids ORDER BY COALESCE(due_date, created_at) DESC, id DESC")
            teamlead_assign_bids = cur.fetchall() or []
        except Exception:
            teamlead_assign_bids = []

        # Load employees + buckets for planner UI (used by team_dashboard.html controls)
        planner_employees = []
        try:
            cur.execute(
                "SELECT id, name, email FROM employees WHERE department=%s AND is_active=TRUE ORDER BY name",
                (team_filter.lower(),),
            )
            planner_employees = cur.fetchall() or []
        except Exception:
            planner_employees = []

        planner_buckets = []
        try:
            cur.execute("SELECT DISTINCT bucket FROM go_bids WHERE bucket IS NOT NULL AND bucket != '' ORDER BY bucket")
            planner_buckets = [r['bucket'] for r in (cur.fetchall() or []) if r.get('bucket')]
        except Exception:
            planner_buckets = []

        # When a team is selected, show the same planner (grid/board) view used by the manager team dashboard
        # so team leads get identical functionality and can see all bids for their team.
        cur.close()
        return render_template(
            'team_dashboard.html',
            team=team_filter,
            team_display_name=team_names.get(team_filter, (team_filter or '').title()),
            bids=bids,
            total_bids=total_bids,
            completed_bids=completed_bids,
            in_progress_bids=total_bids - completed_bids,
            employees=planner_employees,
            buckets=planner_buckets,
            teamlead_assign_bids=teamlead_assign_bids,
            is_team_lead_dashboard=True,
            user=current_user,
            current_stage=team_filter.lower(),
            is_supervisor=True,
        )
    
    # Group employees by department
    departments = {}
    for emp in employees:
        dept = emp.get('department', 'unassigned') or 'unassigned'
        if dept not in departments:
            departments[dept] = []
        departments[dept].append(emp)
    
    # Get department statistics
    dept_stats = {}
    for dept, emps in departments.items():
        dept_stats[dept] = {
            'total_employees': len(emps),
            'total_pending': sum(e.get('pending_tasks', 0) or 0 for e in emps),
            'total_in_progress': sum(e.get('in_progress_tasks', 0) or 0 for e in emps),
            'total_completed': sum(e.get('completed_tasks', 0) or 0 for e in emps)
        }

    approval_items = []
    try:
        approval_dept = team_filter or _team_key_from_dept_key(session.get('active_department_key') or None)
        if (current_user.is_admin or current_user.is_supervisor or is_top_admin or is_manager_user) and not team_filter:
            approval_dept = None
        approval_target = None
        if is_team_lead_user:
            approval_target = 'team_lead'
        elif is_manager_user:
            approval_target = 'manager'
        approval_items = _collect_approval_items(cur, department_key=approval_dept, approval_target=approval_target)
    except Exception:
        approval_items = []

    cur.close()

    # Determine page title
    page_title = team_names.get(team_filter, 'All Teams') + ' - Team Lead Dashboard' if team_filter else 'Team Lead Dashboard'
    
    return render_template('team_lead_dashboard.html',
                         departments=departments,
                         dept_stats=dept_stats,
                         employees=employees,
                         bids=bids,
                         total_bids=total_bids,
                         completed_bids=completed_bids,
                         team_filter=team_filter,
                         team_names=team_names,
                         page_title=page_title,
                         approval_items=approval_items,
                         hide_notifications=True,
                         user=current_user)


@app.route('/team-lead/assign-bid', methods=['POST'])
@login_required
def team_lead_assign_bid():
    """Allow team leads to assign a bid to an employee (writes to bid_assign)."""
    if not validate_csrf_token():
        return "Security validation failed. Please refresh and try again.", 400

    role_lower = (getattr(current_user, 'role', '') or '').lower()
    is_top_admin = (get_user_role() or '').lower() == 'topleveladmin'
    is_manager_user = role_lower == 'manager'
    if not (current_user.is_admin or current_user.is_supervisor or is_top_admin or is_manager_user or getattr(current_user, 'is_team_lead', False)):
        return "Access Denied", 403

    g_id = request.form.get('g_id')
    employee_id = request.form.get('employee_id')
    team = (request.form.get('team') or '').strip().lower()

    # Infer team from role if missing
    team_for_role = {
        'business dev': 'business',
        'business development': 'business',
        'design': 'design',
        'operations': 'operations',
        'site_engineer': 'engineer',
        'site engineer': 'engineer',
        'site manager': 'engineer'
    }
    if not team:
        team = team_for_role.get(role_lower, '')

    if not g_id or not employee_id or not team:
        return "Missing required fields", 400

    try:
        g_id_int = int(g_id)
        employee_id_int = int(employee_id)
    except Exception:
        return "Invalid input", 400

    cur = mysql.connection.cursor(DictCursor)
    try:
        # Verify employee exists and belongs to the same team
        cur.execute("SELECT id, name, email, department FROM employees WHERE id=%s AND is_active=TRUE", (employee_id_int,))
        emp = cur.fetchone()
        if not emp:
            return "Employee not found", 404
        emp_dept = (emp.get('department') or '').strip().lower()
        if emp_dept != team:
            return "Employee department mismatch", 400

        # Team leads can only assign within their own team (unless admin/supervisor)
        if not (current_user.is_admin or current_user.is_supervisor):
            allowed_team = team_for_role.get(role_lower, '')
            if allowed_team and allowed_team != team:
                return "Access Denied - team mismatch", 403

        # Get bid details
        cur.execute("SELECT g_id, b_name, due_date, state, scope, type, company FROM go_bids WHERE g_id=%s", (g_id_int,))
        bid = cur.fetchone()
        if not bid:
            return "Bid not found", 404

        # Upsert bid_assign
        cur.execute("SELECT a_id FROM bid_assign WHERE g_id=%s", (g_id_int,))
        row = cur.fetchone()
        if row and row.get('a_id'):
            cur.execute(
                """
                UPDATE bid_assign
                SET b_name=%s,
                    due_date=%s,
                    state=%s,
                    scope=%s,
                    type=%s,
                    company=%s,
                    depart=%s,
                    person_name=%s,
                    assignee_email=%s,
                    status='assigned'
                WHERE g_id=%s
                """,
                (
                    bid.get('b_name'),
                    bid.get('due_date'),
                    bid.get('state'),
                    bid.get('scope'),
                    bid.get('type'),
                    bid.get('company'),
                    team,
                    emp.get('name'),
                    emp.get('email'),
                    g_id_int,
                ),
            )
        else:
            cur.execute(
                """
                INSERT INTO bid_assign (g_id, b_name, due_date, state, scope, type, company, depart, person_name, assignee_email, status)
                VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,'assigned')
                """,
                (
                    g_id_int,
                    bid.get('b_name'),
                    bid.get('due_date'),
                    bid.get('state'),
                    bid.get('scope'),
                    bid.get('type'),
                    bid.get('company'),
                    team,
                    emp.get('name'),
                    emp.get('email'),
                ),
            )

        mysql.connection.commit()
        try:
            log_write('assign_bid', f"g_id={g_id_int}, team={team}, employee={emp.get('email')} by {current_user.email}")
        except Exception:
            pass
    except Exception as e:
        mysql.connection.rollback()
        try:
            cur.close()
        except Exception:
            pass
        return f"Failed to assign bid: {str(e)}", 500
    finally:
        try:
            cur.close()
        except Exception:
            pass

    return redirect(url_for('team_lead_dashboard', team=team))

@app.route('/team-lead/<team>/overview')
@login_required
def team_lead_overview(team):
    """Team Lead Overview page for each team - accessible by authenticated users"""
    # Team display names mapping
    team_names = {
        'business': 'Business Development',
        'design': 'Design',
        'operations': 'Operations',
        'engineer': 'Site Engineer'
    }
    
    if team not in team_names:
        return "Invalid team", 404

    def _team_key_from_dept_key(dept_key: str | None) -> str | None:
        d = (dept_key or '').strip().lower().replace(' ', '_')
        if not d:
            return None
        if d in ['business', 'business_dev', 'business_development', 'bdm', 'businessdevelopment']:
            return 'business'
        if d in ['design', 'marketing']:
            return 'design'
        if d in ['operations', 'operation', 'ops']:
            return 'operations'
        if d in ['site_engineer', 'site_engineering', 'engineer', 'engineering', 'siteengineer', 'site manager', 'site_manager']:
            return 'engineer'
        return None

    # Access control: only Team Leads (for their dept), Managers (scoped), Supervisor/IT Admin, or Top Admin
    user_role = (get_user_role() or 'member').strip().lower()
    if current_user.is_admin or current_user.is_supervisor or user_role == 'topleveladmin':
        allowed = True
    else:
        allowed = False
        active_cid = session.get('active_company_id')
        access_rows = _fetch_user_access_rows(int(current_user.id))
        if user_role == 'manager':
            for r in (access_rows or []):
                if (r.get('role') or '').strip().lower() != 'manager':
                    continue
                if active_cid and int(r.get('company_id') or 0) != int(active_cid):
                    continue
                dk = r.get('department_key')
                if dk in [None, '', 'null']:
                    allowed = True
                    break
                if _team_key_from_dept_key(dk) == team:
                    allowed = True
                    break
        elif user_role == 'teamlead':
            for r in (access_rows or []):
                if (r.get('role') or '').strip().lower() != 'teamlead':
                    continue
                if active_cid and int(r.get('company_id') or 0) != int(active_cid):
                    continue
                dk = r.get('department_key')
                if dk in [None, '', 'null']:
                    allowed = True
                    break
                if _team_key_from_dept_key(dk) == team:
                    allowed = True
                    break
            # Legacy fallback: older deployments stored dept names in users.role
            if not allowed:
                role_lower_legacy = (getattr(current_user, 'role', '') or '').lower().strip()
                if _team_key_from_dept_key(role_lower_legacy) == team:
                    allowed = True
        else:
            allowed = False

    if not allowed:
        return "Access Denied - Team Lead or higher access required", 403

    # Read-only view support for Top Admin "view as" links
    is_top_admin = (get_user_role() or '').strip().lower() == 'topleveladmin'
    read_only = (request.args.get('readonly') or '').strip().lower() in ('1', 'true', 'yes', 'y')
    if is_top_admin and read_only:
        try:
            ro = session.get('readonly_team_views') or []
            if not isinstance(ro, list):
                ro = []
            if team not in ro:
                ro.append(team)
            session['readonly_team_views'] = ro[-20:]
        except Exception:
            pass
    
    cur = mysql.connection.cursor(DictCursor)
    
    # Sync GO bids
    try:
        sync_go_bids()
    except Exception:
        pass
    
    # Company filter: active company context (multi-company support)
    company_sql_clause, company_params = _company_filter_for_go_bids(cur)
    
    # Get all bids (same as team_dashboard Overview) - no stage filter
    current_stage = team
    
    query = """
        SELECT gb.g_id AS id,
               gb.b_name AS name,
               gb.company, 
               gb.due_date,
               COALESCE(gb.scoring, 0) AS progress,
               LOWER(COALESCE(gb.state, 'analyzer')) AS current_stage,
               gb.summary,
               ba.person_name,
               ba.assignee_email AS person_email,
               ba.depart,
               ba.in_date AS in_date,
               wps.pr_completion_status AS work_status,
               wbr.closure_status AS project_status,
               wbr.work_progress_status AS work_progress_status,
               wlr.result AS wl_result,
               COALESCE(gb.submission_status, 'Work Progress') AS submission_status,
               COALESCE(gb.submission_reason, '') AS submission_reason
        FROM go_bids gb
        LEFT JOIN bid_assign ba ON ba.g_id = gb.g_id
        LEFT JOIN win_lost_results wlr ON wlr.a_id = ba.a_id OR wlr.g_id = gb.g_id
        LEFT JOIN won_bids_result wbr ON wbr.w_id = wlr.w_id
        LEFT JOIN work_progress_status wps ON wps.won_id = wbr.won_id
        WHERE 1=1
    """ + company_sql_clause + " ORDER BY gb.due_date ASC"
    
    try:
        cur.execute(query, company_params)
        bids = cur.fetchall()
    except Exception as e:
        # Fallback query without in_date if column doesn't exist
        if "Unknown column" in str(e) and "in_date" in str(e):
            query = """
                SELECT gb.g_id AS id,
                       gb.b_name AS name,
                       gb.company, 
                       gb.due_date,
                       COALESCE(gb.scoring, 0) AS progress,
                       LOWER(COALESCE(gb.state, 'analyzer')) AS current_stage,
                       gb.summary,
                       ba.person_name,
                       ba.assignee_email AS person_email,
                       ba.depart,
                       wps.pr_completion_status AS work_status,
                       wbr.closure_status AS project_status,
                       wbr.work_progress_status AS work_progress_status,
                       wlr.result AS wl_result,
                       COALESCE(gb.submission_status, 'Work Progress') AS submission_status,
                       COALESCE(gb.submission_reason, '') AS submission_reason
                FROM go_bids gb
                LEFT JOIN bid_assign ba ON ba.g_id = gb.g_id
                LEFT JOIN win_lost_results wlr ON wlr.a_id = ba.a_id OR wlr.g_id = gb.g_id
                LEFT JOIN won_bids_result wbr ON wbr.w_id = wlr.w_id
                LEFT JOIN work_progress_status wps ON wps.won_id = wbr.won_id
                WHERE 1=1
            """ + company_sql_clause + " ORDER BY gb.due_date ASC"
            cur.execute(query, company_params)
            bids = cur.fetchall()
        else:
            raise
    
    # Get team stats
    total_bids = len(bids)
    completed_bids = sum(1 for b in bids if b.get('wl_result') == 'WON')
    in_progress_bids = total_bids - completed_bids
    
    # Load assigned members for bids
    bid_ids = [b['id'] for b in bids]
    assigned_map = {}
    try:
        if bid_ids:
            placeholders = ','.join(['%s'] * len(bid_ids))
            cur.execute(
                f"""
                SELECT bam.g_id, e.id AS employee_id, e.name, e.email
                FROM bid_assignment_members bam
                JOIN employees e ON e.id = bam.employee_id
                WHERE bam.g_id IN ({placeholders}) AND e.department = %s AND e.is_active = TRUE
                ORDER BY e.name
                """,
                (*bid_ids, team)
            )
            for r in cur.fetchall():
                assigned_map.setdefault(r['g_id'], []).append({'id': r['employee_id'], 'name': r['name'], 'email': r['email']})
        for b in bids:
            b['assigned_members'] = assigned_map.get(b['id'], [])
    except Exception:
        for b in bids:
            b['assigned_members'] = []
    
    # Get employees for this team
    cur.execute("""
        SELECT e.id, e.name, e.email, e.department,
               (SELECT COUNT(*) FROM bid_checklists bc WHERE bc.assigned_to = e.id AND bc.status = 'pending') as pending_tasks,
               (SELECT COUNT(*) FROM bid_checklists bc WHERE bc.assigned_to = e.id AND bc.status = 'in_progress') as in_progress_tasks,
               (SELECT COUNT(*) FROM bid_checklists bc WHERE bc.assigned_to = e.id AND bc.status = 'completed') as completed_tasks
        FROM employees e
        WHERE e.is_active = TRUE AND e.department = %s
        ORDER BY e.name
    """, (team,))
    employees = cur.fetchall()
    
    # Load buckets
    try:
        cur.execute("SELECT DISTINCT bucket FROM go_bids WHERE bucket IS NOT NULL AND bucket != '' ORDER BY bucket")
        buckets = [r['bucket'] for r in cur.fetchall()]
    except Exception:
        buckets = []
    
    cur.close()
    
    return render_template('team_lead_overview.html',
                         team=team,
                         team_display_name=team_names[team],
                         bids=bids,
                         total_bids=total_bids,
                         completed_bids=completed_bids,
                         in_progress_bids=in_progress_bids,
                         employees=employees,
                         buckets=buckets,
                         user=current_user,
                         current_stage=current_stage,
                         read_only=read_only,
                         viewer_is_top_admin=is_top_admin)

@app.route('/manager-dashboard')  
@login_required  
def manager_dashboard():  
    """Manager dashboard: access all teams, team leads, and employee dashboards."""  
    role_raw = (get_user_role() or '').strip()
    # In some flows get_user_role() defaults to "member" even when current_user.role is set.
    if not role_raw or role_raw.lower() == 'member':
        role_raw = (getattr(current_user, 'role', None) or role_raw or 'member')
    role_norm = role_raw.strip().lower().replace('_', ' ')
    if _normalize_role_key(role_raw) == 'project manager':
        return redirect(url_for('project_manager_dashboard'))
    if not current_user.is_admin and not check_module_access_db('manager_dashboard'):
        return render_template('access_denied.html', message="You don't have access to the Manager Dashboard."), 403
    # For users with a manager role, send them directly to the BDM overview
    # only when they actually have BDM access; otherwise keep them on the manager dashboard.
    try:
        if 'manager' in role_norm:
            denied = _require_business_manager_access(None)
            if not denied:
                return redirect(url_for('business_manager_dashboard'))
    except Exception:
        pass
    # --- Overview cards (same logic as business_manager_dashboard) ---
    overview_cards = {
        'new_bids_today': 0,
        'total_bid_incoming': 0,
        'pending_bids': 0,
        'bids_submitted': 0,
        'total_project': 0,
        'project_in_progress': 0,
        'project_completed': 0,
    }
    bid_timeline_items = []
    try:
        sync_go_bids()
    except Exception:
        pass

    cur = mysql.connection.cursor(DictCursor)
    try:
        active_company_id = session.get('active_company_id')
        active_company_name = None
        if active_company_id:
            try:
                cur.execute("SELECT name FROM companies WHERE id=%s", (int(active_company_id),))
                row = cur.fetchone() or {}
                active_company_name = (row.get('name') or None)
            except Exception:
                active_company_name = None

        company_sql_clause, company_params = _company_filter_for_go_bids(cur)
        use_company_fallback = False
        company_params_fallback = tuple()
        if company_sql_clause:
            # Fallback to bid_incoming.comp_name when go_bids.company is empty
            use_company_fallback = True
            company_params_fallback = company_params + company_params

        # Today's new bids (bid_incoming)
        new_bids_today = 0
        try:
            cur.execute("SHOW COLUMNS FROM bid_incoming LIKE 'created_at'")
            has_created_at = cur.fetchone() is not None
        except Exception:
            has_created_at = False
        try:
            params = []
            where = []
            if has_created_at:
                where.append("DATE(`created_at`) = CURDATE()")
            else:
                where.append("DATE(`due_date`) = CURDATE()")
            if active_company_name:
                where.append("LOWER(TRIM(`comp_name`)) = LOWER(TRIM(%s))")
                params.append(active_company_name)
            where_sql = " WHERE " + " AND ".join(where) if where else ""
            cur.execute(f"SELECT COUNT(*) AS cnt FROM bid_incoming{where_sql}", tuple(params))
            new_bids_today = int((cur.fetchone() or {}).get('cnt') or 0)
        except Exception:
            new_bids_today = 0

        # Bids by submission status
        cur.execute(
            """
            SELECT
                LOWER(TRIM(COALESCE(gb.submission_status, ''))) AS submission_status,
                COUNT(*) AS cnt
            FROM go_bids gb
            WHERE 1=1
            """ + company_sql_clause + """
            GROUP BY LOWER(TRIM(COALESCE(gb.submission_status, '')))
            """,
            company_params,
        )
        status_rows = cur.fetchall() or []

        def _classify_submission_status(s: str) -> str:
            s = (s or '').strip().lower()
            if not s:
                return 'unknown'
            if 'submitted' in s:
                return 'submitted'
            if s in ('work progress', 'work_progress', 'in progress', 'in_progress', 'on hold', 'hold', 'not submitted', 'not_submitted', 'pending'):
                return 'pending'
            if s in ('incoming', 'new'):
                return 'incoming'
            return 'unknown'

        bids_by_status = {'incoming': 0, 'pending': 0, 'submitted': 0, 'unknown': 0}
        total_bids = 0
        for rr in (status_rows or []):
            cnt = int(rr.get('cnt') or 0)
            total_bids += cnt
            key = _classify_submission_status(rr.get('submission_status') or '')
            bids_by_status[key] = int(bids_by_status.get(key, 0) or 0) + cnt

        # Project counts
        project_total = 0
        project_completed = 0
        project_on_hold = 0
        if active_company_id:
            cur.execute(
                """
                SELECT
                    COUNT(*) AS total_projects,
                    SUM(CASE WHEN LOWER(COALESCE(status,''))='completed' OR COALESCE(progress,0) >= 100 THEN 1 ELSE 0 END) AS completed_projects,
                    SUM(CASE WHEN LOWER(COALESCE(status,'')) IN ('on hold','hold') THEN 1 ELSE 0 END) AS on_hold_projects
                FROM projects
                WHERE company_id=%s
                """,
                (int(active_company_id),),
            )
            pr = cur.fetchone() or {}
            project_total = int(pr.get('total_projects') or 0)
            project_completed = int(pr.get('completed_projects') or 0)
            project_on_hold = int(pr.get('on_hold_projects') or 0)
        else:
            company_ids = []
            try:
                for c in (inject_user_permissions().get('available_companies') or []):
                    cid = c.get('id')
                    if cid is not None:
                        company_ids.append(int(cid))
            except Exception:
                company_ids = []
            if not company_ids:
                try:
                    cur.execute("SELECT id FROM companies WHERE name IN ('Ikio','Metco','Sunsprint')")
                    company_ids = [int(r.get('id')) for r in (cur.fetchall() or []) if r.get('id') is not None]
                except Exception:
                    company_ids = []
            if company_ids:
                in_clause = ','.join(['%s'] * len(company_ids))
                cur.execute(
                    f"""
                    SELECT
                        COUNT(*) AS total_projects,
                        SUM(CASE WHEN LOWER(COALESCE(status,''))='completed' OR COALESCE(progress,0) >= 100 THEN 1 ELSE 0 END) AS completed_projects,
                        SUM(CASE WHEN LOWER(COALESCE(status,'')) IN ('on hold','hold') THEN 1 ELSE 0 END) AS on_hold_projects
                    FROM projects
                    WHERE company_id IN ({in_clause})
                    """,
                    tuple(company_ids),
                )
                pr = cur.fetchone() or {}
                project_total = int(pr.get('total_projects') or 0)
                project_completed = int(pr.get('completed_projects') or 0)
                project_on_hold = int(pr.get('on_hold_projects') or 0)

        project_in_progress = max(0, project_total - project_completed - project_on_hold)

        overview_cards = {
            'new_bids_today': new_bids_today,
            'total_bid_incoming': total_bids,
            'pending_bids': bids_by_status.get('pending', 0),
            'bids_submitted': bids_by_status.get('submitted', 0),
            'total_project': project_total,
            'project_in_progress': project_in_progress,
            'project_completed': project_completed,
        }

        # --- Bid Timeline (same logic as Top Admin overview) ---
        bid_timeline_items = []
        try:
            def _normalize_stage(raw_state: str) -> str:
                s = (raw_state or '').strip().lower()
                mapping = {
                    'analyzer': 'analyzer',
                    'business': 'business',
                    'business dev': 'business',
                    'bdm': 'business',
                    'design': 'design',
                    'operations': 'operations',
                    'operation': 'operations',
                    'engineer': 'engineer',
                    'site_manager': 'engineer',
                    'site manager': 'engineer',
                    'handover': 'handover',
                    'won': 'handover',
                }
                return mapping.get(s, 'analyzer')

            def _stage_label(key: str) -> str:
                return {
                    'analyzer': 'BID Analyzer',
                    'business': 'Business Development',
                    'design': 'Design & Marketing',
                    'operations': 'Operation Team',
                    'engineer': 'Engineering Team',
                    'handover': 'Submitted',
                }.get((key or '').lower(), (key or '').title())

            default_stages = ['analyzer', 'business', 'design', 'operations', 'engineer', 'handover']

            cur.execute(
                f"""
                SELECT
                    gb.g_id,
                    gb.b_name,
                    gb.company,
                    gb.state,
                    gb.due_date,
                    gb.summary,
                    gb.submission_status,
                    gb.submission_reason,
                    bi.bid_status,
                    bi.results
                FROM go_bids gb
                LEFT JOIN bid_incoming bi ON bi.id = gb.id
                WHERE 1=1
                """ + ("""
                  AND (
                    LOWER(COALESCE(gb.company,'')) LIKE %s
                    OR (LOWER(COALESCE(gb.company,'')) = '' AND LOWER(COALESCE(bi.comp_name,'')) LIKE %s)
                  )
                """ if use_company_fallback else company_sql_clause) + """
                ORDER BY gb.due_date IS NULL, gb.due_date ASC
                LIMIT 200
                """,
                (company_params_fallback if use_company_fallback else company_params),
            )
            go_rows = cur.fetchall() or []
            # Include assigned-task bids even when go_bids is missing.
            go_rows = _augment_go_rows_with_assigned_meta(
                cur,
                go_rows,
                active_company_name=active_company_name,
                max_total=None,
                include_closed=True,
            )
            go_rows = [
                rr for rr in (go_rows or [])
                if not _is_won_bid_status(
                    rr.get('submission_reason'),
                    rr.get('submission_status'),
                    rr.get('bid_status'),
                    rr.get('results'),
                    rr.get('state'),
                )
            ]
            try:
                timeline_gids = [int(rr.get('g_id')) for rr in (go_rows or []) if rr.get('g_id')]
            except Exception:
                timeline_gids = []
            stage_map_by_gid, stage_counts_by_gid = _bid_timeline_progress_maps(cur, timeline_gids, default_stages)
            # Ensure stored team progress exists for these bids.
            try:
                for rr in (go_rows or []):
                    gid = rr.get('g_id')
                    if gid:
                        _recalc_bid_team_progress(cur, int(gid))
                try:
                    mysql.connection.commit()
                except Exception:
                    pass
            except Exception:
                pass

            def _compute_stage_stats_for_bid(g_id: int):
                cur2 = None
                try:
                    cur2 = mysql.connection.cursor(DictCursor)
                    def _merge_meta(stage_map_local, counts_local):
                        try:
                            _ensure_bid_assign_meta_table()
                            cur2.execute("SELECT data FROM bid_assign_meta WHERE g_id=%s", (int(g_id),))
                            row = cur2.fetchone() or {}
                            meta = {}
                            try:
                                meta = json.loads(row.get('data') or "{}")
                            except Exception:
                                meta = {}
                            checklist = meta.get('checklist') if isinstance(meta, dict) else None
                            if isinstance(checklist, list) and checklist:
                                meta_buckets = {k: [] for k in default_stages}
                                for item in checklist:
                                    if not isinstance(item, dict):
                                        continue
                                    stage = _normalize_stage_key(
                                        item.get('dept') or item.get('stage') or item.get('department') or item.get('team') or ''
                                    )
                                    if not stage or stage not in meta_buckets:
                                        continue
                                    st = (item.get('status') or '').strip().lower()
                                    pct = item.get('progress_pct')
                                    if pct is None:
                                        pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
                                    try:
                                        pct = max(0, min(100, int(pct)))
                                    except Exception:
                                        pct = 0
                                    meta_buckets[stage].append(pct)
                                def _avg(lst):
                                    return int(round(sum(lst) / len(lst))) if lst else 0
                                for stage_key, vals in meta_buckets.items():
                                    if vals and (counts_local.get(stage_key, {}).get('total', 0) == 0 or _avg(vals) > stage_map_local.get(stage_key, 0)):
                                        stage_map_local[stage_key] = _avg(vals)
                                        counts_local[stage_key]['total'] = len(vals)
                                        counts_local[stage_key]['completed'] = len([v for v in vals if v >= 100])
                        except Exception:
                            pass
                        return stage_map_local, counts_local
                    def _merge_checklists(stage_map_local, counts_local):
                        try:
                            try:
                                cur2.execute(
                                    """
                                    SELECT bc.progress_pct, bc.status, COALESCE(bc.stage, bc.department, u.role) AS stage_source
                                    FROM bid_checklists bc
                                    LEFT JOIN users u ON bc.created_by = u.id
                                    WHERE bc.g_id = %s
                                    """,
                                    (g_id,),
                                )
                            except Exception as e:
                                if "Unknown column 'department'" in str(e):
                                    cur2.execute(
                                        """
                                        SELECT bc.progress_pct, bc.status, COALESCE(bc.stage, u.role) AS stage_source
                                        FROM bid_checklists bc
                                        LEFT JOIN users u ON bc.created_by = u.id
                                        WHERE bc.g_id = %s
                                        """,
                                        (g_id,),
                                    )
                                else:
                                    raise
                            rows_local = cur2.fetchall() or []
                            buckets_local = {k: [] for k in default_stages}
                            counts_local = {k: dict(counts_local.get(k, {'total': 0, 'completed': 0})) for k in default_stages}
                            for r in rows_local:
                                stage = _normalize_stage_key(r.get('stage_source'))
                                if not stage or stage not in buckets_local:
                                    continue
                                pct = r.get('progress_pct')
                                if pct is None:
                                    st = (r.get('status') or '').strip().lower()
                                    pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
                                try:
                                    pct = max(0, min(100, int(pct)))
                                except Exception:
                                    pct = 0
                                buckets_local[stage].append(pct)
                                counts_local[stage]['total'] += 1
                                st = (r.get('status') or '').strip().lower()
                                if pct >= 100 or st in ('completed', 'submitted'):
                                    counts_local[stage]['completed'] += 1
                            def _avg(lst):
                                return int(round(sum(lst) / len(lst))) if lst else 0
                            for k in default_stages:
                                if buckets_local[k]:
                                    stage_map_local[k] = max(int(stage_map_local.get(k, 0) or 0), _avg(buckets_local[k]))
                            return stage_map_local, counts_local
                        except Exception:
                            return stage_map_local, counts_local
                    try:
                        _ensure_bid_team_progress_table(cur2)
                        cur2.execute(
                            """
                            SELECT stage_key, progress_pct, total_tasks, completed_tasks
                            FROM bid_team_progress
                            WHERE g_id = %s
                            """,
                            (g_id,),
                        )
                        rows = cur2.fetchall() or []
                        if rows:
                            stage_map = {r.get('stage_key'): int(r.get('progress_pct') or 0) for r in rows}
                            counts = {
                                r.get('stage_key'): {
                                    'total': int(r.get('total_tasks') or 0),
                                    'completed': int(r.get('completed_tasks') or 0),
                                } for r in rows
                            }
                            # Ensure all stages exist
                            for k in default_stages:
                                stage_map.setdefault(k, 0)
                                counts.setdefault(k, {'total': 0, 'completed': 0})
                            stage_map, counts = _merge_checklists(stage_map, counts)
                            stage_map, counts = _merge_meta(stage_map, counts)
                            has_signal = any((counts.get(k, {}).get('total', 0) or 0) > 0 for k in default_stages) or any(
                                int(stage_map.get(k, 0) or 0) > 0 for k in default_stages
                            )
                            if has_signal:
                                return stage_map, counts
                    except Exception:
                        pass
                    try:
                        cur2.execute(
                            """
                            SELECT bc.progress_pct, bc.status, COALESCE(bc.stage, bc.department, u.role) AS stage_source
                            FROM bid_checklists bc
                            LEFT JOIN users u ON bc.created_by = u.id
                            WHERE bc.g_id = %s
                            """,
                            (g_id,),
                        )
                    except Exception as e:
                        if "Unknown column 'department'" in str(e):
                            cur2.execute(
                                """
                                SELECT bc.progress_pct, bc.status, COALESCE(bc.stage, u.role) AS stage_source
                                FROM bid_checklists bc
                                LEFT JOIN users u ON bc.created_by = u.id
                                WHERE bc.g_id = %s
                                """,
                                (g_id,),
                            )
                        else:
                            raise
                    rows = cur2.fetchall() or []
                    role_to_stage = {
                        'business dev': 'business',
                        'business development': 'business',
                        'bdm': 'business',
                        'bde': 'business',
                        'design': 'design',
                        'design team': 'design',
                        'design & marketing': 'design',
                        'design and marketing': 'design',
                        'marketing': 'design',
                        'operations': 'operations',
                        'operation': 'operations',
                        'ops': 'operations',
                        'operations team': 'operations',
                        'site manager': 'engineer',
                        'site engineer': 'engineer',
                        'engineering': 'engineer',
                        'engineer': 'engineer',
                        'engineering team': 'engineer',
                        'handover': 'handover',
                        'submitted': 'handover',
                        'submit': 'handover',
                        'bid analyzer': 'analyzer',
                        'analyzer': 'analyzer',
                    }
                    buckets = {k: [] for k in default_stages}
                    counts = {k: {'total': 0, 'completed': 0} for k in default_stages}
                    for r in rows:
                        source = (r.get('stage_source') or '').strip().lower()
                        stage = role_to_stage.get(source)
                        if not stage and source in buckets:
                            stage = source
                        if not stage and source:
                            if 'design' in source or 'marketing' in source:
                                stage = 'design'
                            elif 'business' in source or 'bdm' in source or 'bde' in source:
                                stage = 'business'
                            elif 'operation' in source or 'ops' in source:
                                stage = 'operations'
                            elif 'engineer' in source or 'site' in source:
                                stage = 'engineer'
                            elif 'submit' in source or 'handover' in source or source == 'won':
                                stage = 'handover'
                            elif 'analy' in source:
                                stage = 'analyzer'
                        if not stage:
                            continue
                        pct = r.get('progress_pct')
                        if pct is None:
                            st = (r.get('status') or '').strip().lower()
                            pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
                        try:
                            pct = max(0, min(100, int(pct)))
                        except Exception:
                            pct = 0
                        buckets[stage].append(pct)
                        counts[stage]['total'] += 1
                        st = (r.get('status') or '').strip().lower()
                        if pct >= 100 or st in ('completed', 'submitted'):
                            counts[stage]['completed'] += 1
                    def avg(lst):
                        return int(round(sum(lst) / len(lst))) if lst else 0
                    stage_map = {k: avg(v) for k, v in buckets.items()}
                    stage_map, counts = _merge_checklists(stage_map, counts)
                    stage_map, counts = _merge_meta(stage_map, counts)
                    try:
                        _recalc_bid_team_progress(cur2, int(g_id))
                    except Exception:
                        pass
                    cur2.close()
                    return stage_map, counts
                except Exception:
                    return {k: 0 for k in default_stages}, {k: {'total': 0, 'completed': 0} for k in default_stages}
                finally:
                    if cur2 is not None:
                        try:
                            cur2.close()
                        except Exception:
                            pass

            for r in go_rows:
                stage_key = _normalize_stage(r.get('state'))
                if stage_key in default_stages:
                    current_index = default_stages.index(stage_key)
                else:
                    current_index = 0
                try:
                    gid = int(r.get('g_id') or 0)
                except Exception:
                    gid = 0
                if gid and gid in stage_map_by_gid:
                    stage_progress_map = stage_map_by_gid.get(gid, {k: 0 for k in default_stages})
                    stage_counts = stage_counts_by_gid.get(gid, {k: {'total': 0, 'completed': 0} for k in default_stages})
                elif gid:
                    stage_progress_map, stage_counts = _compute_stage_progress_for_timeline(cur, gid, default_stages)
                else:
                    stage_progress_map, stage_counts = ({k: 0 for k in default_stages}, {k: {'total': 0, 'completed': 0} for k in default_stages})
                # Hard fallback: compute directly from bid_checklists / bid_assign_meta if still all zero.
                try:
                    if not any(int(stage_progress_map.get(k, 0) or 0) > 0 for k in default_stages):
                        gid = int(r.get('g_id') or 0)
                        if gid:
                            buckets = {k: [] for k in default_stages}
                            counts = {k: {'total': 0, 'completed': 0} for k in default_stages}
                            try:
                                cur.execute(
                                    """
                                    SELECT progress_pct, status, stage
                                    FROM bid_checklists
                                    WHERE g_id=%s
                                    """,
                                    (gid,),
                                )
                                for row in (cur.fetchall() or []):
                                    stage = _normalize_stage_key(row.get('stage'))
                                    if not stage or stage not in buckets:
                                        continue
                                    pct = row.get('progress_pct')
                                    if pct is None:
                                        st = (row.get('status') or '').strip().lower()
                                        pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
                                    try:
                                        pct = max(0, min(100, int(pct)))
                                    except Exception:
                                        pct = 0
                                    buckets[stage].append(pct)
                                    counts[stage]['total'] += 1
                                    if pct >= 100 or (row.get('status') or '').strip().lower() in ('completed', 'submitted'):
                                        counts[stage]['completed'] += 1
                            except Exception:
                                pass
                            # Fallback to assign meta if still empty/zero.
                            try:
                                if not any(v for v in buckets.values()):
                                    cur.execute("SELECT data FROM bid_assign_meta WHERE g_id=%s", (gid,))
                                    row = cur.fetchone() or {}
                                    meta = {}
                                    try:
                                        meta = json.loads(row.get('data') or "{}")
                                    except Exception:
                                        meta = {}
                                    checklist = meta.get('checklist') if isinstance(meta, dict) else None
                                    if isinstance(checklist, list) and checklist:
                                        for item in checklist:
                                            if not isinstance(item, dict):
                                                continue
                                            stage = _normalize_stage_key(item.get('dept') or item.get('stage') or '')
                                            if not stage or stage not in buckets:
                                                continue
                                            st = (item.get('status') or '').strip().lower()
                                            pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
                                            buckets[stage].append(pct)
                                            counts[stage]['total'] += 1
                                            if pct >= 100 or st in ('completed', 'submitted'):
                                                counts[stage]['completed'] += 1
                            except Exception:
                                pass
                            def _avg(lst):
                                return int(round(sum(lst) / len(lst))) if lst else 0
                            stage_progress_map = {k: _avg(v) for k, v in buckets.items()}
                            stage_counts = counts
                except Exception:
                    pass
                # Default analyzer progress to 100 as requested.
                try:
                    stage_progress_map['analyzer'] = max(int(stage_progress_map.get('analyzer', 0) or 0), 100)
                except Exception:
                    stage_progress_map['analyzer'] = 100
                if any((stage_counts.get(k, {}).get('total', 0) or 0) > 0 for k in default_stages):
                    stage_key = None
                    ranked = []
                    for idx, key in enumerate(default_stages):
                        pct = int(stage_progress_map.get(key, 0) or 0)
                        if pct > 0:
                            ranked.append((pct, idx, key))
                    if ranked:
                        ranked.sort()
                        _, current_index, stage_key = ranked[-1]
                    else:
                        # if tasks exist but all 0%, show analyzer as current
                        current_index = 0
                        stage_key = 'analyzer'
                stages = []
                for idx, key in enumerate(default_stages):
                    stages.append({
                        'name': _stage_label(key),
                        'key': key,
                        'progress': int(stage_progress_map.get(key, 0) or 0),
                        'active': idx <= current_index,
                    })
                current_key = default_stages[current_index] if current_index < len(default_stages) else 'analyzer'
                stuck_key = None
                for key in default_stages:
                    total = int((stage_counts.get(key, {}) or {}).get('total') or 0)
                    pct = int(stage_progress_map.get(key, 0) or 0)
                    if total > 0 and pct < 100:
                        stuck_key = key
                        break
                note = ''
                if r.get('summary'):
                    note = str(r.get('summary') or '').strip()
                elif stuck_key:
                    note = f"Stuck at {_stage_label(stuck_key)} ({int(stage_progress_map.get(stuck_key, 0) or 0)}%)."
                elif current_key:
                    note = f"In {_stage_label(current_key)} ({int(stage_progress_map.get(current_key, 0) or 0)}%)."
                try:
                    vals = [int(stage_progress_map.get(k, 0) or 0) for k in default_stages]
                    overall_progress = int(round(sum(vals) / len(vals))) if vals else 0
                except Exception:
                    overall_progress = 0
                bid_timeline_items.append({
                    'g_id': r.get('g_id'),
                    'b_name': r.get('b_name') or 'Bid',
                    'company': r.get('company') or '',
                    'due_date': r.get('due_date'),
                    'current_index': current_index,
                    'current_stage_key': current_key,
                    'stage_progress_map': stage_progress_map,
                    'stage_counts': stage_counts,
                    'note': note,
                    'overall_progress': overall_progress,
                    'stages': stages,
                })
        except Exception:
            bid_timeline_items = []

        if not bid_timeline_items:
            # Hard fallback: show basic GO bids even if detailed timeline calc failed.
            try:
                fallback_rows = _basic_bid_timeline_rows(cur, company_sql_clause, company_params, limit=200)
                fallback_rows = [
                    rr for rr in (fallback_rows or [])
                    if not _is_won_bid_status(
                        rr.get('submission_reason'),
                        rr.get('submission_status'),
                        rr.get('state'),
                    )
                ]
                bid_timeline_items = _build_basic_timeline_items(cur, fallback_rows)
                if not bid_timeline_items:
                    # Final fallback: ignore company filter and show all GO bids.
                    fallback_rows = _basic_bid_timeline_rows(cur, "", tuple(), limit=200)
                    fallback_rows = [
                        rr for rr in (fallback_rows or [])
                        if not _is_won_bid_status(
                            rr.get('submission_reason'),
                            rr.get('submission_status'),
                            rr.get('state'),
                        )
                    ]
                    bid_timeline_items = _build_basic_timeline_items(cur, fallback_rows)
            except Exception:
                pass
    finally:
        try:
            cur.close()
        except Exception:
            pass

    return render_template(
        'manager_dashboard.html',
        user=current_user,
        user_role=role_norm,
        overview_cards=overview_cards,
        bid_timeline_items=bid_timeline_items,
    )
 
 
@app.route('/manager/approvals') 
@login_required 
def manager_approvals(): 
    """Role-smart shortcut to the correct approvals inbox for managers/admins.""" 
    role_raw = (get_user_role() or '').strip()
    if not role_raw or role_raw.lower() == 'member':
        role_raw = (getattr(current_user, 'role', None) or role_raw or 'member')
    role_norm = role_raw.strip().lower().replace('_', ' ')
    role_compact = role_norm.replace(' ', '')
    sidebar = (request.args.get('sidebar') or '').strip()
    manager_role_compacts = {
        'manager',
        'businessmanager',
        'designmanager',
        'operationsmanager',
        'operationmanager',
        'sitemanager',
        'bdmgr',
        'opsmgr',
        'projectmanager',
    }
 
    is_top_admin_like = bool(current_user.is_admin or current_user.is_supervisor or role_compact in ('itadmin', 'supervisor', 'topleveladmin'))
    if not getattr(current_user, 'is_admin', False) and not check_module_access_db('approvals'):
        return render_template('access_denied.html', message="You don't have access to Approvals."), 403
    if is_top_admin_like:
        # Top Admins should see admin-level approvals (all teams by default).
        team_names = {
            'business': 'Business Development',
            'design': 'Design',
            'operations': 'Operations',
            'engineer': 'Site Engineer',
        }
        team_filter_raw = (request.args.get('team') or '').strip().lower()
        if team_filter_raw in ('', 'all', '*'):
            team_filter = None
        else:
            team_filter = _normalize_department_key(team_filter_raw)
            if team_filter not in team_names:
                team_filter = None
        if team_filter is None:
            try:
                dept_key = session.get('active_department_key') or None
            except Exception:
                dept_key = None
            dept_norm = _normalize_department_key(dept_key)
            if dept_norm in team_names:
                team_filter = dept_norm

        cur = mysql.connection.cursor(DictCursor)
        try:
            items = _collect_approval_items(cur, department_key=team_filter, approval_target='admin')
        finally:
            try:
                cur.close()
            except Exception:
                pass
        return render_template(
            'manager_approvals.html',
            items=items,
            team_key=team_filter,
            team_label=team_names.get(team_filter, 'All Teams'),
            user=current_user,
            user_role=getattr(current_user, 'role', 'admin'),
        )
 
    if role_compact in manager_role_compacts:
        team_names = {
            'business': 'Business Development',
            'design': 'Design',
            'operations': 'Operations',
            'engineer': 'Site Engineer',
        }
        team_filter_raw = (request.args.get('team') or '').strip().lower()
        if team_filter_raw in ('', 'all', '*'):
            team_filter = None
        else:
            team_filter = _normalize_department_key(team_filter_raw)
            if team_filter not in team_names:
                team_filter = None

        if team_filter is None:
            try:
                dept_key = session.get('active_department_key') or None
            except Exception:
                dept_key = None
            dept_norm = _normalize_department_key(dept_key)
            if dept_norm in team_names:
                team_filter = dept_norm

        cur = mysql.connection.cursor(DictCursor)
        try:
            items = _collect_approval_items(cur, department_key=team_filter, approval_target='manager')
        finally:
            try:
                cur.close()
            except Exception:
                pass
        return render_template(
            'manager_approvals.html',
            items=items,
            team_key=team_filter,
            team_label=team_names.get(team_filter, 'All Teams'),
            user=current_user,
            user_role=getattr(current_user, 'role', 'manager'),
        )

    denied = None
    try:
        denied = _require_business_manager_access(None)
    except Exception:
        denied = None

    if denied is None:
        return redirect(url_for('business_manager_approvals', sidebar=sidebar) if sidebar else url_for('business_manager_approvals'))

    return redirect(url_for('team_lead_approvals', sidebar=sidebar) if sidebar else url_for('team_lead_approvals'))


@app.route('/manager/assigned-tasks')
@login_required
def manager_assigned_tasks():
    """Manager view of assigned tasks (department-aware)."""
    role_raw = (get_user_role() or '').strip() or (getattr(current_user, 'role', '') or '')
    role_norm = role_raw.strip().lower().replace('_', ' ')
    role_compact = role_norm.replace(' ', '')
    is_allowed = bool(
        current_user.is_admin
        or current_user.is_supervisor
        or role_compact in ('manager', 'itadmin', 'topleveladmin', 'supervisor')
    )
    if not is_allowed:
        return render_template('access_denied.html', message="You don't have access to Assigned Tasks."), 403

    team_map = {
        'business': 'Business Development',
        'operations': 'Operations',
        'design': 'Design',
        'engineer': 'Engineer',
    }

    team_arg = (request.args.get('team') or '').strip().lower().replace(' ', '_')
    team_key = _normalize_department_key(team_arg) or team_arg
    if team_key not in team_map:
        try:
            team_key = _normalize_department_key(session.get('active_department_key')) or team_key
        except Exception:
            pass
    if team_key not in team_map:
        team_key = 'business'

    title = f"Assigned Tasks - {team_map.get(team_key, 'Business Development')}"
    return _render_assigned_tasks(team_key, 'assigned_tasks.html', title, sidebar_mode='manager')


@app.route('/project-manager-dashboard')
@login_required
def project_manager_dashboard():
    role_raw = (get_user_role() or '').strip() or (getattr(current_user, 'role', '') or 'member')
    role_key = _normalize_role_key(role_raw)
    role_norm = role_raw.strip().lower().replace('_', ' ')
    is_allowed = bool(
        getattr(current_user, 'is_admin', False)
        or getattr(current_user, 'is_supervisor', False)
        or role_key == 'project manager'
        or 'project manager' in role_norm
    )
    if not is_allowed:
        return render_template('access_denied.html', message="You don't have access to the Project Manager Dashboard."), 403
    try:
        sync_go_bids()
    except Exception:
        pass
    items = _load_assigned_projects_for_manager(int(current_user.id))
    # Auto-assign won projects to the current Project Manager if they are unassigned.
    try:
        cur = mysql.connection.cursor(DictCursor)
        _ensure_project_manager_assignments_table(cur)
        for it in (items or []):
            g_id = it.get('g_id')
            if not g_id:
                continue
            try:
                cur.execute("SELECT w_id FROM win_lost_results WHERE g_id=%s LIMIT 1", (int(g_id),))
                row = cur.fetchone() or {}
                w_id = row.get('w_id')
                if not w_id:
                    continue
                # Only assign if no manager has been assigned yet for this project_id.
                cur.execute("SELECT 1 FROM project_manager_assignments WHERE project_id=%s LIMIT 1", (int(w_id),))
                if cur.fetchone():
                    continue
                cur.execute(
                    """
                    INSERT INTO project_manager_assignments (project_id, g_id, manager_user_id, assigned_by_user_id)
                    VALUES (%s, %s, %s, %s)
                    """,
                    (int(w_id), int(g_id), int(current_user.id), int(current_user.id)),
                )
            except Exception:
                continue
        try:
            mysql.connection.commit()
        except Exception:
            mysql.connection.rollback()
    except Exception:
        pass
    finally:
        try:
            cur.close()
        except Exception:
            pass
    try:
        today = datetime.utcnow().date()
        total_bids = len(items or [])
        total_tasks = 0
        pending_tasks = 0
        in_progress_tasks = 0
        completed_tasks = 0
        overdue_tasks = 0
        today_bids = 0
        today_due_tasks = 0
        unassigned_tasks = 0
        uploaded_files = 0

        def _parse_date(dval):
            if not dval:
                return None
            try:
                s = str(dval).strip()
                s = s[:10]
                parts = s.split('-')
                if len(parts) == 3:
                    y, m, d = parts
                    return date(int(y), int(m), int(d))
            except Exception:
                return None
            return None

        for it in (items or []):
            checklist = it.get('checklist') or []
            total_tasks += len(checklist)
            uploaded_files += len(it.get('task_files') or [])
            bid_date = _parse_date(it.get('assign_due_date') or it.get('start_date') or it.get('due_date'))
            if bid_date == today:
                today_bids += 1
            for t in checklist:
                status = normalize_task_status(t.get('status') or t.get('state') or t.get('progress') or '')
                due = _parse_date(t.get('due_date') or t.get('assign_due_date') or '')
                if status == 'completed':
                    completed_tasks += 1
                elif status in ('in_progress', 'submitted'):
                    in_progress_tasks += 1
                else:
                    pending_tasks += 1
                if due and due < today:
                    overdue_tasks += 1
                if due and due == today:
                    today_due_tasks += 1
                has_assignees = bool(t.get('assignees'))
                has_direct_assignee = bool(t.get('assigned_to') or t.get('assigned_to_id') or t.get('assigned_employee_name') or t.get('employee_email'))
                has_team_lead = bool((t.get('team_lead') or '').strip())
                if not (has_assignees or has_direct_assignee or has_team_lead):
                    unassigned_tasks += 1
                if t.get('attachment') or t.get('attachment_url'):
                    uploaded_files += 1
        kpis = {
            'total_bids': total_bids,
            'total_tasks': total_tasks,
            'pending_tasks': pending_tasks,
            'in_progress_tasks': in_progress_tasks,
            'completed_tasks': completed_tasks,
            'overdue_tasks': overdue_tasks,
            'today_bids': today_bids,
            'today_due_tasks': today_due_tasks,
            'unassigned_tasks': unassigned_tasks,
            'uploaded_files': uploaded_files,
            'approvals_pending': 0,
        }
    except Exception:
        kpis = {
            'total_bids': len(items or []),
            'total_tasks': 0,
            'pending_tasks': 0,
            'in_progress_tasks': 0,
            'completed_tasks': 0,
            'overdue_tasks': 0,
            'today_bids': 0,
            'today_due_tasks': 0,
            'unassigned_tasks': 0,
            'uploaded_files': 0,
            'approvals_pending': 0,
        }
    project_timeline_items = _load_project_timeline_items_for_manager(int(current_user.id))
    project_timeline_map = {}
    for pt in (project_timeline_items or []):
        gid = pt.get('g_id')
        if gid is None:
            continue
        project_timeline_map[str(gid)] = pt

    return render_template(
        'project_manager_dashboard.html',
        title='Project Manager Dashboard',
        dept_key='business',
        items=items,
        user={'email': current_user.email, 'name': getattr(current_user, 'full_name', '')},
        user_role='project_manager',
        is_team_lead_view=False,
        is_employee_view=False,
        sidebar_mode='manager',
        team='business',
        dept_metrics={'business': 0, 'design': 0, 'operations': 0, 'engineer': 0},
        total_assigned=len(items or []),
        kpis=kpis,
        assigned_tasks_base_url=None,
        allowed_dept_keys=['business', 'design', 'operations', 'engineer'],
        show_dept_tabs=False,
        project_timeline_items=project_timeline_items,
        project_timeline_map=project_timeline_map,
        can_edit_project_timeline=True,
    )


@app.route('/top-admin/assigned-tasks')
@login_required
def top_admin_assigned_tasks():
    denied = _top_admin_guard()
    if denied:
        return denied
    team_map = {
        'business': 'Business Development',
        'operations': 'Operations',
        'design': 'Design',
        'engineer': 'Engineer',
    }
    team_arg = (request.args.get('team') or '').strip().lower().replace(' ', '_')
    team_key = _normalize_department_key(team_arg) or team_arg
    if team_key not in team_map:
        try:
            team_key = _normalize_department_key(session.get('active_department_key')) or team_key
        except Exception:
            pass
    if team_key not in team_map:
        team_key = 'business'
    title = f"Assigned Tasks - {team_map.get(team_key, 'Business Development')}"
    return _render_assigned_tasks(
        team_key,
        'assigned_tasks.html',
        title,
        sidebar_mode='manager',
        assigned_tasks_base_url_override=url_for('top_admin_assigned_tasks'),
    )


def _render_department_manager_dashboard(restrict_team, template_name, required_role_key):
    """Render a manager-style dashboard restricted to one team."""
    if not current_user.is_admin and not check_module_access_db('manager_dashboard'):
        return render_template('access_denied.html', message="You don't have access to Manager Dashboard."), 403
    role_raw_key = (getattr(current_user, 'role', '') or '').lower().strip()
    role_norm = role_raw_key.replace('_', ' ')
    is_top_admin = role_norm.replace(' ', '') in ['topleveladmin', 'topleveladmin', 'topleveladmin'] or role_norm in ['top level admin', 'top_level_admin']
    is_manager_user = role_norm == 'manager'
    # Accept both `business_manager` and `business manager` style keys (legacy DB values).
    role_compact = role_raw_key.replace('_', '').replace(' ', '')
    required_compact = (required_role_key or '').lower().replace('_', '').replace(' ', '')
    if not (current_user.is_admin or current_user.is_supervisor or is_top_admin or is_manager_user or role_compact == required_compact):
        return render_template('access_denied.html', message="You don't have access to this dashboard."), 403

    # Top Admin: support explicit read-only mode via querystring (`?readonly=1`)
    # This is enforced by write endpoints using session['readonly_team_views'].
    is_top_admin_session = False
    read_only_flag = False
    try:
        is_top_admin_session = (get_user_role() or '').strip().lower() == 'topleveladmin'
        read_only_flag = (request.args.get('readonly') or '').strip().lower() in ('1', 'true', 'yes', 'y')
        if is_top_admin_session and read_only_flag:
            ro = session.get('readonly_team_views') or []
            if not isinstance(ro, list):
                ro = []
            if restrict_team not in ro:
                ro.append(restrict_team)
            session['readonly_team_views'] = ro[-20:]
    except Exception:
        pass

    team_display = {
        'business': 'Business Development',
        'design': 'Design',
        'operations': 'Operations',
        'engineer': 'Site Engineer',
    }
    if restrict_team not in team_display:
        return "Invalid team", 404

    teams = [{'key': restrict_team, 'display_name': team_display[restrict_team]}]
    team_names = {t['key']: t['display_name'] for t in teams}

    # Team lead role -> team mapping
    role_to_team = {
        'business dev': 'business',
        'business development': 'business',
        'design': 'design',
        'operations': 'operations',
        'site_engineer': 'engineer',
        'site engineer': 'engineer',
        'site manager': 'engineer',
        'engineering': 'engineer',
        'engineer': 'engineer',
    }
    lead_roles = [r for (r, tk) in role_to_team.items() if tk == restrict_team]

    cur = mysql.connection.cursor(DictCursor)
    try:
        # Keep go_bids fresh for accurate metrics/widgets
        try:
            sync_go_bids()
        except Exception:
            pass

        # Active company context
        active_company_id = session.get('active_company_id')
        active_company_name = None
        if active_company_id:
            try:
                cur.execute("SELECT name FROM companies WHERE id=%s", (int(active_company_id),))
                row = cur.fetchone() or {}
                active_company_name = (row.get('name') or None)
            except Exception:
                active_company_name = None

        company_sql_clause, company_params = _company_filter_for_go_bids(cur)

        # --- Overview: Bids by submission status (MATCH business_manager_dashboard logic) ---
        def _classify_submission_status(s: str) -> str:
            s = (s or '').strip().lower()
            if not s:
                return 'unknown'
            if 'submitted' in s:
                return 'submitted'
            if s in ('work progress', 'work_progress', 'in progress', 'in_progress', 'on hold', 'hold', 'not submitted', 'not_submitted', 'pending'):
                return 'pending'
            if s in ('incoming', 'new'):
                return 'incoming'
            return 'unknown'

        bids_by_status = {'incoming': 0, 'pending': 0, 'submitted': 0, 'unknown': 0}
        total_bids = 0
        # NOTE: Department manager Overview should show the SAME totals as Business Manager Overview
        # (company-scoped), not filtered to a single stage.
        cur.execute(
            """
            SELECT
                LOWER(TRIM(COALESCE(gb.submission_status, ''))) AS submission_status,
                COUNT(*) AS cnt
            FROM go_bids gb
            WHERE 1=1
            """ + company_sql_clause + """
            GROUP BY LOWER(TRIM(COALESCE(gb.submission_status, '')))
            """,
            company_params,
        )
        status_rows = cur.fetchall() or []

        for rr in (status_rows or []):
            cnt = int(rr.get('cnt') or 0)
            total_bids += cnt
            key = _classify_submission_status(rr.get('submission_status') or '')
            bids_by_status[key] = int(bids_by_status.get(key, 0) or 0) + cnt

        # --- Overview: Project counts (same logic as Business Manager overview; company-scoped) ---
        project_total = 0
        project_completed = 0
        project_on_hold = 0

        if active_company_id:
            cur.execute(
                """
                SELECT
                    COUNT(*) AS total_projects,
                    SUM(CASE WHEN LOWER(COALESCE(status,''))='completed' OR COALESCE(progress,0) >= 100 THEN 1 ELSE 0 END) AS completed_projects,
                    SUM(CASE WHEN LOWER(COALESCE(status,'')) IN ('on hold','hold') THEN 1 ELSE 0 END) AS on_hold_projects
                FROM projects
                WHERE company_id=%s
                """,
                (int(active_company_id),),
            )
            pr = cur.fetchone() or {}
            project_total = int(pr.get('total_projects') or 0)
            project_completed = int(pr.get('completed_projects') or 0)
            project_on_hold = int(pr.get('on_hold_projects') or 0)
        else:
            company_ids = []
            try:
                for c in (inject_user_permissions().get('available_companies') or []):
                    cid = c.get('id')
                    if cid is not None:
                        company_ids.append(int(cid))
            except Exception:
                company_ids = []
            if not company_ids:
                try:
                    cur.execute("SELECT id FROM companies WHERE name IN ('Ikio','Metco','Sunsprint')")
                    company_ids = [int(r.get('id')) for r in (cur.fetchall() or []) if r.get('id') is not None]
                except Exception:
                    company_ids = []
            if company_ids:
                in_clause = ','.join(['%s'] * len(company_ids))
                cur.execute(
                    f"""
                    SELECT
                        COUNT(*) AS total_projects,
                        SUM(CASE WHEN LOWER(COALESCE(status,''))='completed' OR COALESCE(progress,0) >= 100 THEN 1 ELSE 0 END) AS completed_projects,
                        SUM(CASE WHEN LOWER(COALESCE(status,'')) IN ('on hold','hold') THEN 1 ELSE 0 END) AS on_hold_projects
                    FROM projects
                    WHERE company_id IN ({in_clause})
                    """,
                    tuple(company_ids),
                )
                pr = cur.fetchone() or {}
                project_total = int(pr.get('total_projects') or 0)
                project_completed = int(pr.get('completed_projects') or 0)
                project_on_hold = int(pr.get('on_hold_projects') or 0)

        project_in_progress = max(0, project_total - project_completed - project_on_hold)

        overview_cards = {
            'total_bid_incoming': total_bids,
            'pending_bids': bids_by_status.get('pending', 0),
            'bids_submitted': bids_by_status.get('submitted', 0),
            'total_project': project_total,
            'project_in_progress': project_in_progress,
            'project_completed': project_completed,
        }

        denom = max(total_bids, 1)
        bids_by_status_pct = {k: int(round((v / denom) * 100)) for k, v in bids_by_status.items()}

        team_leads = []
        if lead_roles:
            placeholders = ','.join(['%s'] * len(lead_roles))
            cur.execute(
                f"""
                SELECT id, email, role
                FROM users
                WHERE LOWER(COALESCE(role,'')) IN ({placeholders})
                ORDER BY role, email
                """,
                tuple(lead_roles),
            )
            _leads = cur.fetchall() or []
            for u in _leads:
                r = (u.get('role') or '').lower()
                team_key = role_to_team.get(r)
                if team_key:
                    team_leads.append({'id': u.get('id'), 'email': u.get('email'), 'role': u.get('role'), 'team_key': team_key})

        # Load employees with task stats for quick access (restricted)
        cur.execute(
            """
            SELECT e.id, e.name, e.email, e.department,
                   SUM(CASE WHEN bc.status = 'pending' THEN 1 ELSE 0 END) AS pending_tasks,
                   SUM(CASE WHEN bc.status = 'in_progress' THEN 1 ELSE 0 END) AS in_progress_tasks,
                   SUM(CASE WHEN bc.status = 'completed' THEN 1 ELSE 0 END) AS completed_tasks
            FROM employees e
            LEFT JOIN bid_checklists bc ON bc.assigned_to = e.id
            WHERE e.is_active = TRUE AND e.department = %s
            GROUP BY e.id, e.name, e.email, e.department
            ORDER BY e.department, e.name
            """,
            (restrict_team,),
        )
        employees = cur.fetchall() or []

        # Build team stats
        team_stats = {restrict_team: {'employees': 0, 'team_leads': 0, 'tasks_total': 0}}
        for emp in employees:
            dept = (emp.get('department') or '').strip().lower()
            if dept == restrict_team:
                team_stats[restrict_team]['employees'] += 1
                pt = int(emp.get('pending_tasks') or 0)
                ip = int(emp.get('in_progress_tasks') or 0)
                ct = int(emp.get('completed_tasks') or 0)
                team_stats[restrict_team]['tasks_total'] += (pt + ip + ct)
        for lead in team_leads:
            if lead.get('team_key') == restrict_team:
                team_stats[restrict_team]['team_leads'] += 1
    finally:
        try:
            cur.close()
        except Exception:
            pass

    return render_template(
        template_name,
        teams=teams,
        team_names=team_names,
        team_stats=team_stats,
        team_leads=team_leads,
        employees=employees,
        active_company_name=active_company_name,
        overview_cards=overview_cards,
        bids_by_status=bids_by_status,
        bids_by_status_pct=bids_by_status_pct,
        dark_mode=True,
        user=current_user,
        user_role=getattr(current_user, 'role', required_role_key),
        read_only=bool(is_top_admin_session and read_only_flag),
        viewer_is_top_admin=bool(is_top_admin_session),
    )


@app.route('/api/department-manager/<team>/overview/details')
@login_required
def api_department_manager_overview_details(team):
    """Row-level data for a department manager Overview 'Details' panel, filtered by team stage."""
    team = (team or '').strip().lower()
    if team not in ('design', 'operations', 'engineer', 'business'):
        return jsonify({'ok': False, 'error': 'invalid_team'}), 400

    user_role = (getattr(current_user, 'role', '') or '').strip().lower()
    user_role_norm = user_role.replace('_', ' ').strip().lower()
    is_manager_user = (user_role_norm == 'manager')

    dept_manager_team = {
        'business_manager': 'business',
        'business manager': 'business',
        'design_manager': 'design',
        'design manager': 'design',
        'operation_manager': 'operations',
        'operation manager': 'operations',
        'operations_manager': 'operations',
        'operations manager': 'operations',
        'site_manager': 'engineer',
        'site manager': 'engineer',
    }

    # Access control: admins/supervisors can query any; managers can query any; dept managers only their team.
    if not (current_user.is_admin or current_user.is_supervisor or is_manager_user):
        allowed_team = dept_manager_team.get(user_role) or dept_manager_team.get(user_role_norm)
        if allowed_team != team:
            return jsonify({'ok': False, 'error': 'access_denied'}), 403

    key = (request.args.get('key') or '').strip().lower()
    limit = request.args.get('limit', None)
    try:
        limit_n = int(limit) if limit is not None else 200
    except Exception:
        limit_n = 200
    limit_n = max(1, min(limit_n, 500))

    from datetime import datetime, date

    def _to_jsonable(v):
        if isinstance(v, datetime):
            return v.isoformat(sep=' ', timespec='seconds')
        if isinstance(v, date):
            return v.isoformat()
        return v

    def _jsonify_rows(rows):
        out = []
        for r in (rows or []):
            rr = {}
            for k, v in (r or {}).items():
                rr[k] = _to_jsonable(v)
            out.append(rr)
        return out

    # Keep this CASE in sync with _render_department_manager_dashboard._classify_submission_status
    status_case_sql = (
        "CASE "
        "WHEN LOWER(TRIM(COALESCE(gb.submission_status, ''))) = '' THEN 'unknown' "
        "WHEN LOWER(TRIM(COALESCE(gb.submission_status, ''))) LIKE '%%submitted%%' THEN 'submitted' "
        "WHEN LOWER(TRIM(COALESCE(gb.submission_status, ''))) IN "
        "('work progress','work_progress','in progress','in_progress','on hold','hold','not submitted','not_submitted','pending') THEN 'pending' "
        "WHEN LOWER(TRIM(COALESCE(gb.submission_status, ''))) IN ('incoming','new') THEN 'incoming' "
        "ELSE 'unknown' END"
    )

    metric_title = None
    kind = None  # 'bids' | 'projects'
    status_filter = None
    project_filter = None

    if key in ('total_bid_incoming', 'total_bids', 'bids', 'all_bids'):
        kind = 'bids'
        metric_title = 'Total Bid Incoming'
    elif key in ('pending_bids', 'status_pending', 'pending'):
        kind = 'bids'
        status_filter = 'pending'
        metric_title = 'Pending Bids'
    elif key in ('bids_submitted', 'status_submitted', 'submitted'):
        kind = 'bids'
        status_filter = 'submitted'
        metric_title = 'Bids Submitted'
    elif key in ('status_incoming', 'incoming'):
        kind = 'bids'
        status_filter = 'incoming'
        metric_title = 'Incoming Bids'
    elif key in ('status_unknown', 'unknown'):
        kind = 'bids'
        status_filter = 'unknown'
        metric_title = 'Unknown Status Bids'
    elif key in ('total_project', 'total_projects', 'projects'):
        kind = 'projects'
        project_filter = 'all'
        metric_title = 'Total Project'
    elif key in ('project_in_progress', 'projects_in_progress', 'in_progress_projects'):
        kind = 'projects'
        project_filter = 'in_progress'
        metric_title = 'Project In Progress'
    elif key in ('project_completed', 'projects_completed', 'completed_projects'):
        kind = 'projects'
        project_filter = 'completed'
        metric_title = 'Project Completed'
    else:
        return jsonify({'ok': False, 'error': 'invalid_key', 'message': 'Unknown details key'}), 400

    cur = mysql.connection.cursor(DictCursor)
    try:
        if kind == 'bids':
            company_sql_clause, company_params = _company_filter_for_go_bids(cur)
            params = list(company_params or [])

            where_extra = ""
            if status_filter:
                where_extra += f" AND ({status_case_sql}) = %s "
                params.append(status_filter)

            # SAME details as Business Manager Overview (company-scoped; no stage filter).
            try:
                cur.execute(
                    f"""
                    SELECT
                        gb.g_id,
                        gb.b_name,
                        gb.company,
                        gb.due_date,
                        gb.submission_status,
                        LOWER(COALESCE(gb.state,'analyzer')) AS current_stage,
                        {status_case_sql} AS status_key
                    FROM go_bids gb
                    WHERE 1=1
                    {company_sql_clause}
                    {where_extra}
                    ORDER BY gb.due_date DESC, gb.g_id DESC
                    LIMIT %s
                    """,
                    tuple(params + [limit_n]),
                )
            except Exception as e:
                # Fallback when go_bids.state doesn't exist yet
                if "Unknown column 'state'" in str(e):
                    cur.execute(
                        f"""
                        SELECT
                            gb.g_id,
                            gb.b_name,
                            gb.company,
                            gb.due_date,
                            gb.submission_status,
                            LOWER(COALESCE(ba.depart,'analyzer')) AS current_stage,
                            {status_case_sql} AS status_key
                        FROM go_bids gb
                        LEFT JOIN bid_assign ba ON ba.g_id = gb.g_id
                        WHERE 1=1
                        {company_sql_clause}
                        {where_extra}
                        ORDER BY gb.due_date DESC, gb.g_id DESC
                        LIMIT %s
                        """,
                        tuple(params + [limit_n]),
                    )
                else:
                    raise

            rows = cur.fetchall() or []
            columns = ['g_id', 'b_name', 'company', 'due_date', 'submission_status', 'current_stage', 'status_key']
            return jsonify({
                'ok': True,
                'title': metric_title,
                'kind': 'bids',
                'columns': columns,
                'rows': _jsonify_rows(rows),
                'shown': len(rows),
                'limit': limit_n,
            })

        # projects (same logic as business manager overview)
        active_company_id = session.get('active_company_id')
        company_ids = []
        if active_company_id:
            try:
                company_ids = [int(active_company_id)]
            except Exception:
                company_ids = []
        else:
            try:
                for c in (inject_user_permissions().get('available_companies') or []):
                    cid = c.get('id')
                    if cid is not None:
                        company_ids.append(int(cid))
            except Exception:
                company_ids = []
            if not company_ids:
                try:
                    cur.execute("SELECT id FROM companies WHERE name IN ('Ikio','Metco','Sunsprint')")
                    company_ids = [int(r.get('id')) for r in (cur.fetchall() or []) if r.get('id') is not None]
                except Exception:
                    company_ids = []

        where_parts = []
        params = []
        if company_ids:
            in_clause = ','.join(['%s'] * len(company_ids))
            where_parts.append(f"p.company_id IN ({in_clause})")
            params.extend(company_ids)

        completed_cond = "(LOWER(COALESCE(p.status,''))='completed' OR COALESCE(p.progress,0) >= 100)"
        on_hold_cond = "(LOWER(COALESCE(p.status,'')) IN ('on hold','hold'))"
        if project_filter == 'completed':
            where_parts.append(completed_cond)
        elif project_filter == 'in_progress':
            where_parts.append(f"NOT {completed_cond}")
            where_parts.append(f"NOT {on_hold_cond}")

        where_sql = ("WHERE " + " AND ".join(where_parts)) if where_parts else ""
        cur.execute(
            f"""
            SELECT
                p.id,
                p.name,
                c.name AS company,
                p.status,
                p.progress,
                p.start_date,
                p.due_date
            FROM projects p
            LEFT JOIN companies c ON c.id = p.company_id
            {where_sql}
            ORDER BY COALESCE(p.due_date, p.start_date, p.created_at) DESC, p.id DESC
            LIMIT %s
            """,
            tuple(params + [limit_n]),
        )
        rows = cur.fetchall() or []
        columns = ['id', 'name', 'company', 'status', 'progress', 'start_date', 'due_date']
        return jsonify({
            'ok': True,
            'title': metric_title,
            'kind': 'projects',
            'columns': columns,
            'rows': _jsonify_rows(rows),
            'shown': len(rows),
            'limit': limit_n,
        })
    except Exception as e:
        return jsonify({'ok': False, 'error': 'server_error', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


def _ensure_project_timeline_tables(db_cur):
    db_cur.execute(
        """
        CREATE TABLE IF NOT EXISTS project_timeline_stages (
            id INT AUTO_INCREMENT PRIMARY KEY,
            project_id INT NOT NULL,
            stage_name VARCHAR(120) NOT NULL,
            stage_order INT NOT NULL DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE KEY uniq_project_stage (project_id, stage_name)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """
    )
    db_cur.execute(
        """
        CREATE TABLE IF NOT EXISTS project_timeline_progress (
            id INT AUTO_INCREMENT PRIMARY KEY,
            project_id INT NOT NULL,
            stage_id INT NOT NULL,
            progress_pct INT NOT NULL DEFAULT 0,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            UNIQUE KEY uniq_project_stage_progress (project_id, stage_id)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """
    )
    db_cur.execute(
        """
        CREATE TABLE IF NOT EXISTS project_timeline_current (
            project_id INT PRIMARY KEY,
            stage_id INT NOT NULL,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """
    )


def _seed_project_timeline(db_cur, project_id: int, stage_names: list):
    db_cur.execute(
        "SELECT COUNT(*) AS cnt FROM project_timeline_stages WHERE project_id=%s",
        (project_id,),
    )
    cnt = int((db_cur.fetchone() or {}).get('cnt') or 0)
    if cnt > 0:
        return
    for idx, name in enumerate(stage_names):
        db_cur.execute(
            "INSERT INTO project_timeline_stages (project_id, stage_name, stage_order) VALUES (%s,%s,%s)",
            (project_id, name, idx),
        )


@app.route('/business-manager-dashboard')
@login_required
def business_manager_dashboard():
    if not current_user.is_admin and not check_module_access_db('business_manager_dashboard'):
        return render_template('access_denied.html', message="You don't have access to Business Manager Dashboard."), 403
    denied = _require_business_manager_access(None)
    if denied:
        return denied

    # Top Admin: support explicit read-only mode via querystring (`?readonly=1`)
    # This is enforced by write endpoints using session['readonly_team_views'].
    try:
        is_top_admin_session = (get_user_role() or '').strip().lower() == 'topleveladmin'
        read_only = (request.args.get('readonly') or '').strip().lower() in ('1', 'true', 'yes', 'y')
        if is_top_admin_session and read_only:
            ro = session.get('readonly_team_views') or []
            if not isinstance(ro, list):
                ro = []
            if 'business' not in ro:
                ro.append('business')
            session['readonly_team_views'] = ro[-20:]
    except Exception:
        pass

    # Keep GO bids table fresh for accurate metrics
    try:
        sync_go_bids()
    except Exception:
        pass

    cur = mysql.connection.cursor(DictCursor)
    try:
        # Active company context
        active_company_id = session.get('active_company_id')
        active_company_name = None
        if active_company_id:
            try:
                cur.execute("SELECT name FROM companies WHERE id=%s", (int(active_company_id),))
                row = cur.fetchone() or {}
                active_company_name = (row.get('name') or None)
            except Exception:
                active_company_name = None

        company_sql_clause, company_params = _company_filter_for_go_bids(cur)

        # ----- Today's New Bids (based on bid_incoming.created_at) -----
        new_bids_today = 0
        try:
            cur.execute("SHOW COLUMNS FROM bid_incoming LIKE 'created_at'")
            has_created_at = cur.fetchone() is not None
        except Exception:
            has_created_at = False
        try:
            params = []
            where = []
            if has_created_at:
                where.append("DATE(`created_at`) = CURDATE()")
            else:
                # Fallback for older schemas (less accurate): use due_date as a proxy.
                where.append("DATE(`due_date`) = CURDATE()")
            if active_company_name:
                where.append("LOWER(TRIM(`comp_name`)) = LOWER(TRIM(%s))")
                params.append(active_company_name)
            where_sql = " WHERE " + " AND ".join(where) if where else ""
            cur.execute(f"SELECT COUNT(*) AS cnt FROM bid_incoming{where_sql}", tuple(params))
            new_bids_today = int((cur.fetchone() or {}).get('cnt') or 0)
        except Exception:
            new_bids_today = 0

        # ----- BID Status counts (based on go_bids.submission_status) -----
        cur.execute(
            """
            SELECT
                LOWER(TRIM(COALESCE(gb.submission_status, ''))) AS submission_status,
                COUNT(*) AS cnt
            FROM go_bids gb
            WHERE 1=1
            """ + company_sql_clause + """
            GROUP BY LOWER(TRIM(COALESCE(gb.submission_status, '')))
            """,
            company_params,
        )
        status_rows = cur.fetchall() or []

        def _classify_submission_status(s: str) -> str:
            s = (s or '').strip().lower()
            if not s:
                return 'unknown'
            if 'submitted' in s:
                return 'submitted'
            if s in ('work progress', 'work_progress', 'in progress', 'in_progress', 'on hold', 'hold', 'not submitted', 'not_submitted', 'pending'):
                return 'pending'
            if s in ('incoming', 'new'):
                return 'incoming'
            return 'unknown'

        bids_by_status = {'incoming': 0, 'pending': 0, 'submitted': 0, 'unknown': 0}
        total_bids = 0
        for rr in status_rows:
            cnt = int(rr.get('cnt') or 0)
            total_bids += cnt
            key = _classify_submission_status(rr.get('submission_status') or '')
            bids_by_status[key] = int(bids_by_status.get(key, 0) or 0) + cnt

        # ----- Project counts (based on projects table) -----
        project_total = 0
        project_completed = 0
        project_on_hold = 0

        # Determine company scope for projects: active company if selected, otherwise all accessible companies
        if active_company_id:
            cur.execute(
                """
                SELECT
                    COUNT(*) AS total_projects,
                    SUM(CASE WHEN LOWER(COALESCE(status,''))='completed' OR COALESCE(progress,0) >= 100 THEN 1 ELSE 0 END) AS completed_projects,
                    SUM(CASE WHEN LOWER(COALESCE(status,'')) IN ('on hold','hold') THEN 1 ELSE 0 END) AS on_hold_projects
                FROM projects
                WHERE company_id=%s
                """,
                (int(active_company_id),),
            )
            pr = cur.fetchone() or {}
            project_total = int(pr.get('total_projects') or 0)
            project_completed = int(pr.get('completed_projects') or 0)
            project_on_hold = int(pr.get('on_hold_projects') or 0)
        else:
            # Use available companies from context processor if present; fallback to the three known companies.
            company_ids = []
            try:
                for c in (inject_user_permissions().get('available_companies') or []):
                    cid = c.get('id')
                    if cid is not None:
                        company_ids.append(int(cid))
            except Exception:
                company_ids = []
            if not company_ids:
                try:
                    cur.execute("SELECT id FROM companies WHERE name IN ('Ikio','Metco','Sunsprint')")
                    company_ids = [int(r.get('id')) for r in (cur.fetchall() or []) if r.get('id') is not None]
                except Exception:
                    company_ids = []
            if company_ids:
                in_clause = ','.join(['%s'] * len(company_ids))
                cur.execute(
                    f"""
                    SELECT
                        COUNT(*) AS total_projects,
                        SUM(CASE WHEN LOWER(COALESCE(status,''))='completed' OR COALESCE(progress,0) >= 100 THEN 1 ELSE 0 END) AS completed_projects,
                        SUM(CASE WHEN LOWER(COALESCE(status,'')) IN ('on hold','hold') THEN 1 ELSE 0 END) AS on_hold_projects
                    FROM projects
                    WHERE company_id IN ({in_clause})
                    """,
                    tuple(company_ids),
                )
                pr = cur.fetchone() or {}
                project_total = int(pr.get('total_projects') or 0)
                project_completed = int(pr.get('completed_projects') or 0)
                project_on_hold = int(pr.get('on_hold_projects') or 0)

        project_in_progress = max(0, project_total - project_completed - project_on_hold)

        # ----- Project Timeline (fresh, separate from Bid Timeline) -----
        won_projects = []
        try:
            won_params = []
            won_where = [
                "(LOWER(COALESCE(wlr.status,'')) LIKE '%%won%%' OR LOWER(COALESCE(wlr.result,'')) LIKE '%%won%%')"
            ]
            if active_company_name:
                # Normalize company names (strip spaces/punctuation) to avoid mismatches like "LLC" vs "LLC."
                won_where.append(
                    "("
                    "REPLACE(REPLACE(LOWER(COALESCE(wlr.company,'')), '.', ''), ' ', '') = "
                    "REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', '')"
                    " OR REPLACE(REPLACE(LOWER(COALESCE(wlr.company,'')), '.', ''), ' ', '') LIKE "
                    "CONCAT('%%', REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', ''), '%%')"
                    " OR REPLACE(REPLACE(LOWER(%s), '.', ''), ' ', '') LIKE "
                    "CONCAT('%%', REPLACE(REPLACE(LOWER(COALESCE(wlr.company,'')), '.', ''), ' ', ''), '%%')"
                    ")"
                )
                won_params.extend([active_company_name, active_company_name, active_company_name])
            won_where_sql = " AND ".join(won_where)
            cur.execute(
                f"""
                SELECT
                    wlr.w_id,
                    wlr.g_id,
                    wlr.b_name,
                    wlr.company,
                    wlr.status,
                    wlr.result
                FROM win_lost_results wlr
                WHERE {won_where_sql}
                ORDER BY wlr.w_id DESC
                LIMIT 5
                """,
                tuple(won_params),
            )
            won_rows = cur.fetchall() or []
            if not won_rows and active_company_name:
                # Fallback to unfiltered if company name mismatch hides valid WON rows.
                cur.execute(
                    """
                    SELECT
                        wlr.w_id,
                        wlr.g_id,
                        wlr.b_name,
                        wlr.company,
                        wlr.status,
                        wlr.result
                    FROM win_lost_results wlr
                    WHERE (LOWER(COALESCE(wlr.status,'')) LIKE '%%won%%' OR LOWER(COALESCE(wlr.result,'')) LIKE '%%won%%')
                    ORDER BY wlr.w_id DESC
                    LIMIT 5
                    """
                )
                won_rows = cur.fetchall() or []
        except Exception:
            won_rows = []

        project_manager_map = {}
        project_manager_users = []
        default_pm = None
        try:
            project_ids = [int(r.get('w_id')) for r in (won_rows or []) if r.get('w_id')]
            project_manager_map = _get_project_manager_map(cur, project_ids)
        except Exception:
            project_manager_map = {}
        try:
            project_manager_users = _fetch_project_manager_users(cur, active_company_name)
            if project_manager_users:
                default_pm = project_manager_users[0]
        except Exception:
            project_manager_users = []
            default_pm = None

        default_project_stages = [
            'Engineering Team',
            'Procurement Team',
            'Accounts & Finance Team',
        ]

        try:
            _ensure_project_timeline_tables(cur)
            mysql.connection.commit()
        except Exception:
            pass

        for r in won_rows:
            project_id = r.get('w_id')
            if not project_id:
                continue
            try:
                _seed_project_timeline(cur, int(project_id), default_project_stages)
                mysql.connection.commit()
            except Exception:
                pass

            cur.execute(
                """
                SELECT id, stage_name, stage_order
                FROM project_timeline_stages
                WHERE project_id=%s
                ORDER BY stage_order ASC, id ASC
                """,
                (project_id,),
            )
            stage_rows = cur.fetchall() or []

            stage_ids = [sr.get('id') for sr in stage_rows if sr.get('id') is not None]
            progress_map = {}
            if stage_ids:
                in_clause = ','.join(['%s'] * len(stage_ids))
                cur.execute(
                    f"""
                    SELECT stage_id, progress_pct
                    FROM project_timeline_progress
                    WHERE project_id=%s AND stage_id IN ({in_clause})
                    """,
                    tuple([project_id] + stage_ids),
                )
                for pr in (cur.fetchall() or []):
                    progress_map[int(pr.get('stage_id'))] = int(pr.get('progress_pct') or 0)

            cur.execute(
                "SELECT stage_id FROM project_timeline_current WHERE project_id=%s",
                (project_id,),
            )
            current_row = cur.fetchone() or {}
            current_stage_id = current_row.get('stage_id')
            if not current_stage_id and stage_rows:
                current_stage_id = stage_rows[0].get('id')
                try:
                    cur.execute(
                        "INSERT INTO project_timeline_current (project_id, stage_id) VALUES (%s,%s) "
                        "ON DUPLICATE KEY UPDATE stage_id=VALUES(stage_id)",
                        (project_id, current_stage_id),
                    )
                    mysql.connection.commit()
                except Exception:
                    pass

            stages = []
            current_index = 0
            for idx, sr in enumerate(stage_rows):
                sid = sr.get('id')
                if sid == current_stage_id:
                    current_index = idx
                stages.append({
                    'id': sid,
                    'name': sr.get('stage_name') or '',
                    'order': int(sr.get('stage_order') or 0),
                    'progress': int(progress_map.get(int(sid), 0)) if sid is not None else 0,
                })

            stage_progress = 0
            if len(stages) > 1:
                stage_progress = int(round((current_index / (len(stages) - 1)) * 100))

            pm_info = project_manager_map.get(int(project_id)) if project_id is not None else None
            if not pm_info and default_pm:
                try:
                    _ensure_project_manager_assignments_table(cur)
                    cur.execute("SELECT 1 FROM project_manager_assignments WHERE project_id=%s LIMIT 1", (int(project_id),))
                    if not cur.fetchone():
                        cur.execute(
                            """
                            INSERT INTO project_manager_assignments (project_id, g_id, manager_user_id, assigned_by_user_id)
                            VALUES (%s, %s, %s, %s)
                            """,
                            (int(project_id), int(r.get('g_id') or 0), int(default_pm.get('id')), int(getattr(current_user, 'id', 0))),
                        )
                        mysql.connection.commit()
                    pm_info = {
                        'user_id': default_pm.get('id'),
                        'name': default_pm.get('full_name') or default_pm.get('email'),
                        'email': default_pm.get('email'),
                    }
                except Exception:
                    try:
                        mysql.connection.rollback()
                    except Exception:
                        pass

            won_projects.append({
                'project_id': project_id,
                'g_id': r.get('g_id'),
                'b_name': r.get('b_name') or f"Won #{r.get('w_id')}",
                'company': r.get('company'),
                'current_stage_id': current_stage_id,
                'current_stage_index': current_index,
                'stage_progress': stage_progress,
                'stages': stages,
                'pm_user_id': (pm_info or {}).get('user_id'),
                'pm_name': (pm_info or {}).get('name'),
                'pm_email': (pm_info or {}).get('email'),
            })

        # Stage display name mapping
        def get_stage_display_name(stage_key):
            mapping = {
                'analyzer': 'BID Analyzer',
                'business': 'Business Development',
                'design': 'Design & Marketing',
                'operations': 'Operation Team',
                'engineer': 'Engineering Team',
                'handover': 'Submitted',
                'won': 'Won',
                'closure': 'Closure'
            }
            return mapping.get((stage_key or '').lower(), (stage_key or '').title())

        # Pack for template
        overview_cards = {
            'new_bids_today': new_bids_today,
            'total_bid_incoming': total_bids,
            'pending_bids': bids_by_status.get('pending', 0),
            'bids_submitted': bids_by_status.get('submitted', 0),
            'total_project': project_total,
            'project_in_progress': project_in_progress,
            'project_completed': project_completed,
        }

        # Bar chart rendering support (percent widths)
        denom = max(total_bids, 1)
        bids_by_status_pct = {k: int(round((v / denom) * 100)) for k, v in bids_by_status.items()}

        return render_template(
            'business_manager_dashboard.html',
            team='business',
            dark_mode=False,
            bid_timeline_dark=False,
            active_company_name=active_company_name,
            overview_cards=overview_cards,
            bids_by_status=bids_by_status,
            bids_by_status_pct=bids_by_status_pct,
            user=current_user,
            user_role=getattr(current_user, 'role', 'business_manager'),
            won_projects=won_projects,
            get_stage_display_name=get_stage_display_name,
            can_edit_project_timeline=_is_business_manager_user(),
            project_manager_users=_fetch_project_manager_users(cur, active_company_name),
        )
    finally:
        try:
            cur.close()
        except Exception:
            pass


def _require_project_timeline_edit_access(project_id: int | None = None):
    role_key = (get_user_role() or 'member').strip().lower()
    is_it_admin = bool(getattr(current_user, 'is_admin', False)) or role_key == 'itadmin'
    is_top_admin = role_key == 'topleveladmin'
    if is_it_admin or is_top_admin or _is_business_manager_user():
        return None
    try:
        if project_id and _is_project_manager_for_project(int(current_user.id), int(project_id)):
            return None
    except Exception:
        pass
    return jsonify({'ok': False, 'error': 'access_denied'}), 403


@app.route('/business-manager/project-timeline/stage/add', methods=['POST'])
@login_required
def business_manager_project_timeline_add_stage():
    project_id = request.form.get('project_id')
    denied = _require_project_timeline_edit_access(project_id=int(project_id) if project_id else None)
    if denied:
        return denied
    stage_name = (request.form.get('stage_name') or '').strip()
    stage_order = request.form.get('stage_order')
    if not project_id or not stage_name:
        return jsonify({'ok': False, 'error': 'Missing parameters'}), 400
    try:
        project_id = int(project_id)
    except Exception:
        return jsonify({'ok': False, 'error': 'Invalid project id'}), 400
    order_val = None
    if stage_order is not None and str(stage_order).strip() != '':
        try:
            order_val = int(stage_order)
        except Exception:
            order_val = None
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_project_timeline_tables(cur)
        if order_val is None:
            cur.execute(
                "SELECT COALESCE(MAX(stage_order), -1) AS max_order FROM project_timeline_stages WHERE project_id=%s",
                (project_id,),
            )
            order_val = int((cur.fetchone() or {}).get('max_order') or -1) + 1
        else:
            cur.execute(
                """
                UPDATE project_timeline_stages
                SET stage_order = stage_order + 1
                WHERE project_id=%s AND stage_order >= %s
                """,
                (project_id, order_val),
            )
        cur.execute(
            "INSERT INTO project_timeline_stages (project_id, stage_name, stage_order) VALUES (%s,%s,%s)",
            (project_id, stage_name, order_val),
        )
        mysql.connection.commit()
        return jsonify({'ok': True})
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        return jsonify({'ok': False, 'error': 'db', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/admin/recalc-bid-team-progress', methods=['POST'])
@login_required
def admin_recalc_bid_team_progress():
    """Force recompute bid team progress for a bid (admin/top admin only)."""
    if not getattr(current_user, 'is_admin', False) and (get_user_role() or '').lower() not in ('topleveladmin', 'top level admin', 'top_level_admin'):
        return jsonify({'ok': False, 'error': 'forbidden'}), 403
    try:
        g_id = int(request.form.get('g_id') or request.args.get('g_id') or 0)
    except Exception:
        g_id = 0
    if not g_id:
        return jsonify({'ok': False, 'error': 'g_id_required'}), 400
    cur = mysql.connection.cursor(DictCursor)
    try:
        _recalc_bid_team_progress(cur, int(g_id))
        try:
            mysql.connection.commit()
        except Exception:
            pass
        cur.execute(
            "SELECT stage_key, progress_pct, total_tasks, completed_tasks FROM bid_team_progress WHERE g_id=%s",
            (int(g_id),),
        )
        rows = cur.fetchall() or []
        return jsonify({'ok': True, 'g_id': g_id, 'rows': rows})
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        return jsonify({'ok': False, 'error': 'db', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/business-manager/project-timeline/stage/update', methods=['POST'])
@login_required
def business_manager_project_timeline_update_stage():
    project_id = request.form.get('project_id')
    denied = _require_project_timeline_edit_access(project_id=int(project_id) if project_id else None)
    if denied:
        return denied
    stage_id = request.form.get('stage_id')
    stage_name = (request.form.get('stage_name') or '').strip()
    stage_order = request.form.get('stage_order')
    progress_pct = request.form.get('progress_pct')
    if not project_id or not stage_id:
        return jsonify({'ok': False, 'error': 'Missing parameters'}), 400
    try:
        project_id = int(project_id)
        stage_id = int(stage_id)
    except Exception:
        return jsonify({'ok': False, 'error': 'Invalid id'}), 400
    order_val = None
    if stage_order is not None and str(stage_order).strip() != '':
        try:
            order_val = int(stage_order)
        except Exception:
            order_val = None
    progress_val = None
    if progress_pct is not None and str(progress_pct).strip() != '':
        try:
            progress_val = max(0, min(100, int(progress_pct)))
        except Exception:
            progress_val = None
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_project_timeline_tables(cur)
        if stage_name or order_val is not None:
            fields = []
            params = []
            if stage_name:
                fields.append("stage_name=%s")
                params.append(stage_name)
            if order_val is not None:
                fields.append("stage_order=%s")
                params.append(order_val)
            params.extend([project_id, stage_id])
            cur.execute(
                f"UPDATE project_timeline_stages SET {', '.join(fields)} WHERE project_id=%s AND id=%s",
                tuple(params),
            )
        if progress_val is not None:
            cur.execute(
                """
                INSERT INTO project_timeline_progress (project_id, stage_id, progress_pct)
                VALUES (%s,%s,%s)
                ON DUPLICATE KEY UPDATE progress_pct=VALUES(progress_pct)
                """,
                (project_id, stage_id, progress_val),
            )
        mysql.connection.commit()
        return jsonify({'ok': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'ok': False, 'error': str(e)}), 500
    finally:
        cur.close()


@app.route('/business-manager/project-timeline/stage/delete', methods=['POST'])
@login_required
def business_manager_project_timeline_delete_stage():
    project_id = request.form.get('project_id')
    denied = _require_project_timeline_edit_access(project_id=int(project_id) if project_id else None)
    if denied:
        return denied
    stage_id = request.form.get('stage_id')
    if not project_id or not stage_id:
        return jsonify({'ok': False, 'error': 'Missing parameters'}), 400
    try:
        project_id = int(project_id)
        stage_id = int(stage_id)
    except Exception:
        return jsonify({'ok': False, 'error': 'Invalid id'}), 400
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_project_timeline_tables(cur)
        cur.execute(
            "DELETE FROM project_timeline_progress WHERE project_id=%s AND stage_id=%s",
            (project_id, stage_id),
        )
        cur.execute(
            "DELETE FROM project_timeline_stages WHERE project_id=%s AND id=%s",
            (project_id, stage_id),
        )
        cur.execute(
            "SELECT stage_id FROM project_timeline_current WHERE project_id=%s",
            (project_id,),
        )
        current_row = cur.fetchone() or {}
        if current_row.get('stage_id') == stage_id:
            cur.execute(
                """
                SELECT id
                FROM project_timeline_stages
                WHERE project_id=%s
                ORDER BY stage_order ASC, id ASC
                """,
                (project_id,),
            )
            remaining = cur.fetchall() or []
            new_stage_id = remaining[0]['id'] if remaining else None
            if new_stage_id:
                cur.execute(
                    "UPDATE project_timeline_current SET stage_id=%s WHERE project_id=%s",
                    (new_stage_id, project_id),
                )
            else:
                cur.execute(
                    "DELETE FROM project_timeline_current WHERE project_id=%s",
                    (project_id,),
                )
        mysql.connection.commit()
        return jsonify({'ok': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'ok': False, 'error': str(e)}), 500
    finally:
        cur.close()


@app.route('/business-manager/project-timeline/stage/current', methods=['POST'])
@login_required
def business_manager_project_timeline_set_current():
    project_id = request.form.get('project_id')
    denied = _require_project_timeline_edit_access(project_id=int(project_id) if project_id else None)
    if denied:
        return denied
    stage_id = request.form.get('stage_id')
    if not project_id or not stage_id:
        return jsonify({'ok': False, 'error': 'Missing parameters'}), 400
    try:
        project_id = int(project_id)
        stage_id = int(stage_id)
    except Exception:
        return jsonify({'ok': False, 'error': 'Invalid id'}), 400
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_project_timeline_tables(cur)
        cur.execute(
            """
            INSERT INTO project_timeline_current (project_id, stage_id)
            VALUES (%s,%s)
            ON DUPLICATE KEY UPDATE stage_id=VALUES(stage_id)
            """,
            (project_id, stage_id),
        )
        mysql.connection.commit()
        return jsonify({'ok': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'ok': False, 'error': str(e)}), 500
    finally:
        cur.close()


@app.route('/project-manager/project-timeline/stages/save', methods=['POST'])
@login_required
def project_manager_project_timeline_save_stages():
    project_id = request.form.get('project_id') or request.args.get('project_id')
    if not project_id:
        data = request.get_json(silent=True) or {}
        project_id = data.get('project_id')
    denied = _require_project_timeline_edit_access(project_id=int(project_id) if project_id else None)
    if denied:
        return denied
    try:
        project_id = int(project_id)
    except Exception:
        return jsonify({'ok': False, 'error': 'Invalid project id'}), 400

    data = request.get_json(silent=True) or {}
    stages = data.get('stages')
    if stages is None:
        stages_raw = request.form.get('stages') or ''
        stages = [s.strip() for s in stages_raw.split(',') if s.strip()]
    if not isinstance(stages, list):
        return jsonify({'ok': False, 'error': 'Invalid stages payload'}), 400

    # Normalize and map to display names
    stage_name_map = {
        'engineering_team': 'Engineering Team',
        'procurement_team': 'Procurement Team',
        'accounts_finance': 'Accounts & Finance Team',
    }
    normalized = []
    seen = set()
    for st in stages:
        key = _normalize_department_key(str(st)) or str(st).strip().lower().replace(' ', '_')
        if not key:
            continue
        if key in seen:
            continue
        seen.add(key)
        normalized.append(key)
    if not normalized:
        return jsonify({'ok': False, 'error': 'No stages selected'}), 400

    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_project_timeline_tables(cur)
        # Clear existing stages + progress/current
        cur.execute("DELETE FROM project_timeline_progress WHERE project_id=%s", (project_id,))
        cur.execute("DELETE FROM project_timeline_current WHERE project_id=%s", (project_id,))
        cur.execute("DELETE FROM project_timeline_stages WHERE project_id=%s", (project_id,))
        # Insert new stages
        for idx, key in enumerate(normalized):
            stage_name = stage_name_map.get(key, key.replace('_', ' ').title())
            cur.execute(
                "INSERT INTO project_timeline_stages (project_id, stage_name, stage_order) VALUES (%s,%s,%s)",
                (project_id, stage_name, idx),
            )
        # Set current stage to the first
        cur.execute(
            "SELECT id FROM project_timeline_stages WHERE project_id=%s ORDER BY stage_order ASC, id ASC LIMIT 1",
            (project_id,),
        )
        row = cur.fetchone() or {}
        if row.get('id'):
            cur.execute(
                """
                INSERT INTO project_timeline_current (project_id, stage_id)
                VALUES (%s,%s)
                ON DUPLICATE KEY UPDATE stage_id=VALUES(stage_id)
                """,
                (project_id, int(row.get('id'))),
            )
        mysql.connection.commit()
        return jsonify({'ok': True, 'stages': normalized})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'ok': False, 'error': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/api/project-manager/assign', methods=['POST'])
@login_required
def api_assign_project_manager():
    project_id = request.form.get('project_id') or request.args.get('project_id')
    manager_user_id = request.form.get('manager_user_id') or request.args.get('manager_user_id')
    g_id = request.form.get('g_id') or request.args.get('g_id')
    denied = _require_project_timeline_edit_access(project_id=int(project_id) if project_id else None)
    if denied:
        return denied
    if not project_id:
        return jsonify({'ok': False, 'error': 'missing_project_id'}), 400
    try:
        project_id = int(project_id)
    except Exception:
        return jsonify({'ok': False, 'error': 'invalid_project_id'}), 400
    manager_id_val = None
    if manager_user_id not in (None, '', 'null'):
        try:
            manager_id_val = int(manager_user_id)
        except Exception:
            manager_id_val = None
    try:
        g_id_val = int(g_id) if g_id not in (None, '', 'null') else None
    except Exception:
        g_id_val = None
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_project_manager_assignments_table(cur)
        if manager_id_val:
            cur.execute("SELECT id FROM users WHERE id=%s", (manager_id_val,))
            if not cur.fetchone():
                return jsonify({'ok': False, 'error': 'invalid_manager'}), 400
            cur.execute(
                """
                INSERT INTO project_manager_assignments (project_id, g_id, manager_user_id, assigned_by_user_id)
                VALUES (%s,%s,%s,%s)
                ON DUPLICATE KEY UPDATE
                  g_id=VALUES(g_id),
                  manager_user_id=VALUES(manager_user_id),
                  assigned_by_user_id=VALUES(assigned_by_user_id),
                  assigned_at=CURRENT_TIMESTAMP
                """,
                (project_id, g_id_val, manager_id_val, int(current_user.id)),
            )
        else:
            cur.execute("DELETE FROM project_manager_assignments WHERE project_id=%s", (project_id,))
        mysql.connection.commit()
        return jsonify({'ok': True})
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        return jsonify({'ok': False, 'error': 'db', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/api/business-manager/overview/details')
@login_required
def api_business_manager_overview_details():
    """Return row-level data for the Business Manager Overview 'Details' panel, based on a clicked metric/status."""
    denied = _require_business_manager_access(None)
    if denied:
        # For API, return JSON instead of HTML
        try:
            return jsonify({'ok': False, 'error': 'access_denied'}), 403
        except Exception:
            return ('Access denied', 403)

    key = (request.args.get('key') or '').strip().lower()
    limit = request.args.get('limit', None)
    try:
        limit_n = int(limit) if limit is not None else 200
    except Exception:
        limit_n = 200
    limit_n = max(1, min(limit_n, 500))

    from datetime import datetime, date

    def _to_jsonable(v):
        if isinstance(v, datetime):
            return v.isoformat(sep=' ', timespec='seconds')
        if isinstance(v, date):
            return v.isoformat()
        return v

    def _jsonify_rows(rows):
        out = []
        for r in (rows or []):
            rr = {}
            for k, v in (r or {}).items():
                rr[k] = _to_jsonable(v)
            out.append(rr)
        return out

    # Keep this CASE in sync with business_manager_dashboard._classify_submission_status
    status_case_sql = (
        "CASE "
        "WHEN LOWER(TRIM(COALESCE(gb.submission_status, ''))) = '' THEN 'unknown' "
        "WHEN LOWER(TRIM(COALESCE(gb.submission_status, ''))) LIKE '%%submitted%%' THEN 'submitted' "
        "WHEN LOWER(TRIM(COALESCE(gb.submission_status, ''))) IN "
        "('work progress','work_progress','in progress','in_progress','on hold','hold','not submitted','not_submitted','pending') THEN 'pending' "
        "WHEN LOWER(TRIM(COALESCE(gb.submission_status, ''))) IN ('incoming','new') THEN 'incoming' "
        "ELSE 'unknown' END"
    )

    # Normalize keys coming from the UI
    metric_title = None
    kind = None  # 'bids' | 'projects'
    status_filter = None  # incoming/pending/submitted/unknown for bids
    project_filter = None  # 'all'|'completed'|'in_progress'

    # Accept both KPI keys and status bar keys
    if key in ('new_bids_today', 'today_new_bids', 'todays_new_bids', 'new_bids'):
        kind = 'bid_incoming'
        metric_title = "Today's New Bids"
    elif key in ('total_bid_incoming', 'total_bids', 'bids', 'all_bids'):
        kind = 'bids'
        metric_title = 'Total Bid Incoming'
    elif key in ('pending_bids', 'status_pending', 'pending'):
        kind = 'bids'
        status_filter = 'pending'
        metric_title = 'Pending Bids'
    elif key in ('bids_submitted', 'status_submitted', 'submitted'):
        kind = 'bids'
        status_filter = 'submitted'
        metric_title = 'Bids Submitted'
    elif key in ('status_incoming', 'incoming'):
        kind = 'bids'
        status_filter = 'incoming'
        metric_title = 'Incoming Bids'
    elif key in ('status_unknown', 'unknown'):
        kind = 'bids'
        status_filter = 'unknown'
        metric_title = 'Unknown Status Bids'
    elif key in ('total_project', 'total_projects', 'projects'):
        kind = 'projects'
        project_filter = 'all'
        metric_title = 'Total Project'
    elif key in ('project_in_progress', 'projects_in_progress', 'in_progress_projects'):
        kind = 'projects'
        project_filter = 'in_progress'
        metric_title = 'Project In Progress'
    elif key in ('project_completed', 'projects_completed', 'completed_projects'):
        kind = 'projects'
        project_filter = 'completed'
        metric_title = 'Project Completed'
    else:
        return jsonify({'ok': False, 'error': 'invalid_key', 'message': 'Unknown details key'}), 400

    cur = mysql.connection.cursor(DictCursor)
    try:
        if kind == 'bid_incoming':
            # Active company context for filtering bid_incoming
            active_company_id = session.get('active_company_id')
            active_company_name = None
            if active_company_id:
                try:
                    cur.execute("SELECT name FROM companies WHERE id=%s", (int(active_company_id),))
                    row = cur.fetchone() or {}
                    active_company_name = (row.get('name') or None)
                except Exception:
                    active_company_name = None

            # Prefer created_at; fall back to due_date for older schemas.
            try:
                cur.execute("SHOW COLUMNS FROM bid_incoming LIKE 'created_at'")
                has_created_at = cur.fetchone() is not None
            except Exception:
                has_created_at = False

            where = []
            params = []
            if has_created_at:
                where.append("DATE(`created_at`) = CURDATE()")
            else:
                where.append("DATE(`due_date`) = CURDATE()")
            if active_company_name:
                where.append("LOWER(TRIM(`comp_name`)) = LOWER(TRIM(%s))")
                params.append(active_company_name)
            where_sql = (" WHERE " + " AND ".join(where)) if where else ""

            cur.execute(
                f"""
                SELECT
                    id,
                    b_name,
                    comp_name,
                    due_date,
                    state,
                    type,
                    scoring,
                    decision
                    {', created_at' if has_created_at else ''}
                FROM bid_incoming
                {where_sql}
                ORDER BY {('created_at DESC, ' if has_created_at else '')} id DESC
                LIMIT %s
                """,
                tuple(params + [limit_n]),
            )
            rows = cur.fetchall() or []
            columns = ['id', 'b_name', 'comp_name', 'due_date', 'state', 'type', 'scoring', 'decision'] + (['created_at'] if has_created_at else [])
            return jsonify({
                'ok': True,
                'title': metric_title,
                'columns': columns,
                'rows': _jsonify_rows(rows),
                'shown': len(rows),
                'limit': limit_n,
            })

        if kind == 'bids':
            company_sql_clause, company_params = _company_filter_for_go_bids(cur)

            where_extra = ""
            params = list(company_params or [])
            if status_filter:
                where_extra = f" AND ({status_case_sql}) = %s "
                params.append(status_filter)

            # A compact, stable set of columns (avoid SELECT * for performance + predictable UI)
            cur.execute(
                f"""
                SELECT
                    gb.g_id,
                    gb.b_name,
                    gb.company,
                    gb.due_date,
                    gb.submission_status,
                    LOWER(COALESCE(gb.state,'analyzer')) AS current_stage,
                    {status_case_sql} AS status_key
                FROM go_bids gb
                WHERE 1=1
                {company_sql_clause}
                {where_extra}
                ORDER BY gb.due_date DESC, gb.g_id DESC
                LIMIT %s
                """,
                tuple(params + [limit_n]),
            )
            rows = cur.fetchall() or []
            columns = ['g_id', 'b_name', 'company', 'due_date', 'submission_status', 'current_stage', 'status_key']
            return jsonify({
                'ok': True,
                'title': metric_title,
                'kind': 'bids',
                'columns': columns,
                'rows': _jsonify_rows(rows),
                'shown': len(rows),
                'limit': limit_n,
            })

        # ---- projects ----
        active_company_id = session.get('active_company_id')
        company_ids = []
        if active_company_id:
            try:
                company_ids = [int(active_company_id)]
            except Exception:
                company_ids = []
        else:
            # Use available companies from context processor if present; fallback to the three known companies.
            try:
                for c in (inject_user_permissions().get('available_companies') or []):
                    cid = c.get('id')
                    if cid is not None:
                        company_ids.append(int(cid))
            except Exception:
                company_ids = []
            if not company_ids:
                try:
                    cur.execute("SELECT id FROM companies WHERE name IN ('Ikio','Metco','Sunsprint')")
                    company_ids = [int(r.get('id')) for r in (cur.fetchall() or []) if r.get('id') is not None]
                except Exception:
                    company_ids = []

        where_parts = []
        params = []
        if company_ids:
            in_clause = ','.join(['%s'] * len(company_ids))
            where_parts.append(f"p.company_id IN ({in_clause})")
            params.extend(company_ids)

        # Filters matching count logic in business_manager_dashboard
        completed_cond = "(LOWER(COALESCE(p.status,''))='completed' OR COALESCE(p.progress,0) >= 100)"
        on_hold_cond = "(LOWER(COALESCE(p.status,'')) IN ('on hold','hold'))"
        if project_filter == 'completed':
            where_parts.append(completed_cond)
        elif project_filter == 'in_progress':
            where_parts.append(f"NOT {completed_cond}")
            where_parts.append(f"NOT {on_hold_cond}")

        where_sql = ("WHERE " + " AND ".join(where_parts)) if where_parts else ""
        cur.execute(
            f"""
            SELECT
                p.id,
                p.name,
                c.name AS company,
                p.status,
                p.progress,
                p.start_date,
                p.due_date
            FROM projects p
            LEFT JOIN companies c ON c.id = p.company_id
            {where_sql}
            ORDER BY COALESCE(p.due_date, p.start_date, p.created_at) DESC, p.id DESC
            LIMIT %s
            """,
            tuple(params + [limit_n]),
        )
        rows = cur.fetchall() or []
        columns = ['id', 'name', 'company', 'status', 'progress', 'start_date', 'due_date']
        return jsonify({
            'ok': True,
            'title': metric_title,
            'kind': 'projects',
            'columns': columns,
            'rows': _jsonify_rows(rows),
            'shown': len(rows),
            'limit': limit_n,
        })
    except Exception as e:
        return jsonify({'ok': False, 'error': 'server_error', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass

def _is_business_manager_user() -> bool:
    try:
        # Global role check (users.role)
        role_raw = (getattr(current_user, 'role', '') or '').strip().lower()
        role_compact = role_raw.replace('_', '').replace(' ', '')
        if role_compact == 'businessmanager':
            return True

        # Scoped check (user_company_access): treat "manager of business department"
        # as a Business Manager for the BDM pages + sidebar.
        rows = _fetch_user_access_rows(int(current_user.id))
        for r in (rows or []):
            if (r.get('role') or '').strip().lower() != 'manager':
                continue
            dept = (r.get('department_key') or '').strip().lower()
            if dept in ['business', 'business_dev', 'business_development']:
                return True
        return False
    except Exception:
        return False

def _require_business_manager_access(module_key: str | None = None):
    """BDM-only views (or admin / top admin), optionally gated by a module permission."""
    # Use canonical security role resolution (handles legacy naming and context_role)
    user_role_key = (get_user_role() or 'member').strip().lower()
    is_it_admin = bool(getattr(current_user, 'is_admin', False)) or user_role_key == 'itadmin'
    is_top_admin = user_role_key == 'topleveladmin'
    if not (is_it_admin or is_top_admin or _is_business_manager_user()):
        return render_template(
            'access_denied.html',
            message="You don't have permission to access the Business Development Manager pages.",
            module="Business Development Manager",
        ), 403
    # Allow IT admin / top admin regardless of module toggle
    if module_key and not (is_it_admin or is_top_admin):
        # Only show BDM pages when enabled for the current role (usually manager),
        # and the user is actually scoped to Business dept (enforced by _is_business_manager_user()).
        if not check_module_access_db(module_key):
            return render_template(
                'access_denied.html',
                message="Business Manager access is disabled by Access Control settings.",
                module="Business Development Manager",
            ), 403
    return None

@app.route('/business-manager/team-allocation')
@login_required
def business_manager_team_allocation():
    denied = _require_business_manager_access('business_manager_team_allocation')
    if denied:
        return denied
    return redirect(url_for('bid_analyzer'))

def business_manager_update_company():
    is_ajax = request.headers.get('X-Requested-With') == 'XMLHttpRequest' or request.accept_mimetypes.best == 'application/json'

    denied = _require_business_manager_access('business_manager_team_allocation')
    if denied:
        if is_ajax:
            return jsonify({'success': False, 'error': 'forbidden', 'message': 'Access denied.'}), 403
        return denied

    # CSRF protection (form submits _csrf_token)
    if not validate_csrf_token():
        if is_ajax:
            return jsonify({'success': False, 'error': 'csrf', 'message': 'Security validation failed. Please refresh and try again.'}), 403
        flash('Security validation failed. Please refresh and try again.', 'error')
        nxt = request.form.get('next') or ''
        if isinstance(nxt, str) and nxt.startswith('/') and not nxt.startswith('//') and '://' not in nxt:
            return redirect(nxt)
        return redirect(url_for('business_manager_team_allocation'))

    g_id = request.form.get('g_id')
    company_id = request.form.get('company_id')
    if not g_id:
        if is_ajax:
            return jsonify({'success': False, 'error': 'missing_bid', 'message': 'Missing bid id'}), 400
        flash('Missing bid id', 'error')
        nxt = request.form.get('next') or ''
        if isinstance(nxt, str) and nxt.startswith('/') and not nxt.startswith('//') and '://' not in nxt:
            return redirect(nxt)
        return redirect(url_for('business_manager_team_allocation'))

    cur = mysql.connection.cursor(DictCursor)
    try:
        # Business Manager: allow any company unless explicitly denied.
        # Other users: if scoped/restricted, block selecting companies outside their scope.
        try:
            if company_id and (not getattr(current_user, 'is_admin', False)):
                if _is_business_manager_user():
                    if _is_company_denied_for_user(int(current_user.id), int(company_id)):
                        if is_ajax:
                            return jsonify({'success': False, 'error': 'forbidden', 'message': 'Access denied for selected company.'}), 403
                        flash('Access denied for selected company.', 'error')
                        nxt = request.form.get('next') or ''
                        if isinstance(nxt, str) and nxt.startswith('/') and not nxt.startswith('//') and '://' not in nxt:
                            return redirect(nxt)
                        return redirect(url_for('business_manager_team_allocation'))
                elif _user_has_any_scoped_rows(int(current_user.id)):
                    if not _has_active_scope_for_company(int(current_user.id), int(company_id)):
                        if is_ajax:
                            return jsonify({'success': False, 'error': 'forbidden', 'message': 'Access denied for selected company.'}), 403
                        flash('Access denied for selected company.', 'error')
                        nxt = request.form.get('next') or ''
                        if isinstance(nxt, str) and nxt.startswith('/') and not nxt.startswith('//') and '://' not in nxt:
                            return redirect(nxt)
                        return redirect(url_for('business_manager_team_allocation'))
        except Exception:
            pass

        company_name = None
        if company_id:
            try:
                cur.execute("SELECT name FROM companies WHERE id=%s", (company_id,))
                row = cur.fetchone()
                if row:
                    company_name = row.get('name')
            except Exception:
                company_name = None
        if not company_name:
            company_name = (request.form.get('company_name') or '').strip()

        cur.execute("UPDATE go_bids SET company=%s WHERE g_id=%s", (company_name, g_id))

        # Ensure this bid is ready for parallel work across departments by seeding
        # default checklists for all department stages (if missing).
        try:
            team_stages = ['engineering_team', 'procurement_team', 'accounts_finance']
            for st in team_stages:
                cur.execute(
                    """
                    SELECT 1
                    FROM bid_checklists
                    WHERE g_id = %s AND LOWER(COALESCE(stage,'')) = %s
                    LIMIT 1
                    """,
                    (g_id, st),
                )
                exists = cur.fetchone() is not None
                if not exists:
                    generate_team_checklist(cur, g_id, st)
        except Exception:
            # Best effort only; company update should still succeed even if seeding fails.
            pass

        try:
            cur.execute("SELECT b_name FROM go_bids WHERE g_id=%s", (g_id,))
            bid_row = cur.fetchone() or {}
            bid_name = bid_row.get('b_name', g_id)
        except Exception:
            bid_name = g_id

        try:
            log_action = f"BDM '{current_user.email}' updated company to '{company_name}' for bid '{bid_name}' (ID: {g_id})"
            cur.execute("INSERT INTO logs (action, user_id) VALUES (%s, %s)", (log_action, current_user.id))
        except Exception:
            pass

        mysql.connection.commit()
        if is_ajax:
            return jsonify({'success': True, 'message': 'Company updated.', 'company': company_name}), 200
        flash('Company updated.', 'success')
    except Exception as e:
        mysql.connection.rollback()
        if is_ajax:
            return jsonify({'success': False, 'error': 'db', 'message': f'Failed to update company: {e}'}), 500
        flash(f'Failed to update company: {e}', 'error')
    finally:
        cur.close()

    # If this action was triggered inside the embed iframe, go back to embed so the table refreshes correctly
    nxt = request.form.get('next') or ''
    if isinstance(nxt, str) and nxt.startswith('/') and not nxt.startswith('//') and '://' not in nxt:
        return redirect(nxt)
    return redirect(url_for('business_manager_team_allocation'))

def _load_bid_task_making_context(g_id_filter=None):
    """Return bids and team options shared between bid-task-making views."""
    try:
        sync_go_bids()
    except Exception:
        pass

    team_options = [
        {'key': 'business', 'label': 'Business Development'},
        {'key': 'design', 'label': 'Design & Marketing'},
        {'key': 'operations', 'label': 'Operations'},
        {'key': 'engineer', 'label': 'Site Engineer'},
    ]

    filter_ids = None
    if g_id_filter is not None:
        seen = set()
        normalized = []
        for raw in g_id_filter:
            try:
                gid_int = int(raw)
            except Exception:
                continue
            if gid_int in seen:
                continue
            seen.add(gid_int)
            normalized.append(gid_int)
        if not normalized:
            return [], team_options
        filter_ids = normalized

    cur = mysql.connection.cursor(DictCursor)
    try:
        query = """
            SELECT gb.g_id, gb.b_name, gb.company, gb.type, gb.state,
                   gb.due_date AS due_date
            FROM go_bids gb
        """
        params = ()
        if filter_ids:
            placeholders = ','.join(['%s'] * len(filter_ids))
            query += f" WHERE gb.g_id IN ({placeholders})"
            params = tuple(filter_ids)
        query += " ORDER BY gb.g_id DESC"
        cur.execute(query, params)
        bids = cur.fetchall() or []
    finally:
        try:
            cur.close()
        except Exception:
            pass

    from datetime import datetime, date
    def _fmt_due(v):
        if v is None or v == '':
            return ''
        if isinstance(v, datetime):
            return v.strftime('%m-%d-%Y')
        if isinstance(v, date):
            return v.strftime('%m-%d-%Y')
        s = str(v).strip()
        if not s or '%' in s:
            return ''
        for fmt in ('%Y-%m-%d', '%Y-%m-%d %H:%M:%S', '%Y/%m/%d', '%m/%d/%Y', '%d-%m-%Y'):
            try:
                return datetime.strptime(s[:19], fmt).strftime('%m-%d-%Y')
            except Exception:
                continue
        return s

    for b in bids:
        try:
            b['due_date'] = _fmt_due(b.get('due_date'))
        except Exception:
            pass

    return bids, team_options

def design_manager_dashboard():
    return _render_department_manager_dashboard('design', 'design_manager_dashboard.html', 'design_manager')


@app.route('/operation-manager-dashboard')
@login_required
def operation_manager_dashboard():
    return _render_department_manager_dashboard('operations', 'operation_manager_dashboard.html', 'operation_manager')


@app.route('/site-manager-dashboard')
@login_required
def site_manager_dashboard():
    return _render_department_manager_dashboard('engineer', 'site_manager_dashboard.html', 'site_manager')
@app.route('/member/dashboard')
@login_required
def employee_dashboard_member():
    """Dashboard for team members - shows assigned tasks and projects"""
    is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
    if not is_flask_user and not session.get('employee_id'):
        return redirect(url_for('login'))
    if is_flask_user:
        role_norm = (get_user_role() or '').strip().lower().replace('_', ' ')
        if role_norm in ('itadmin', 'topleveladmin'):
            return redirect(url_for('top_admin_overview'))
        if role_norm in ('manager', 'supervisor'):
            return redirect(url_for('manager_dashboard'))
        if role_norm in ('teamlead', 'team lead', 'business dev', 'design', 'operations', 'site engineer', 'engineering'):
            dept_key = None
            try:
                dept_key = session.get('active_department_key') or None
            except Exception:
                dept_key = None
            dept_key = (dept_key or '').strip().lower().replace(' ', '_')
            team_map = {
                'business': 'business',
                'business_dev': 'business',
                'business_development': 'business',
                'design': 'design',
                'marketing': 'design',
                'operations': 'operations',
                'operation': 'operations',
                'ops': 'operations',
                'engineer': 'engineer',
                'engineering': 'engineer',
                'site_engineer': 'engineer',
                'site_engineering': 'engineer',
            }
            team_key = team_map.get(dept_key, 'business')
            return redirect(url_for('team_lead_assigned_tasks', team=team_key))
        if not getattr(current_user, 'is_admin', False) and not check_module_access_db('employee_dashboard'):
            return render_template('access_denied.html', message="You don't have access to Employee Dashboard."), 403
    user_role = getattr(current_user, 'role', 'member').lower()
    
    # Get user permissions
    permissions = get_user_module_permissions(user_role, user_id=int(current_user.id))
    
    cur = mysql.connection.cursor(DictCursor)
    
    # Resolve current employee row (needed for bid assignments)
    employee_row = None
    try:
        cur.execute(
            "SELECT id, name, email, department FROM employees WHERE LOWER(email)=LOWER(%s) AND is_active=TRUE LIMIT 1",
            (current_user.email,),
        )
        employee_row = cur.fetchone()
    except Exception:
        employee_row = None

    def _normalize_task_status(v):
        """
        Normalize task status to canonical values used across the app:
        - pending
        - in_progress
        - submitted
        - rejected
        - completed
        """
        s = (v or '').strip().lower()
        s = s.replace('-', ' ').replace('_', ' ')
        s = ' '.join(s.split())
        if s in ('completed', 'complete', 'done', 'finished', 'closed'):
            return 'completed'
        if s in ('submitted', 'submit', 'submission'):
            return 'submitted'
        if s in ('rejected', 'reject'):
            return 'rejected'
        if s in ('in progress', 'inprogress', 'working', 'wip', 'started'):
            return 'in_progress'
        if s in ('pending', 'not started', 'notstarted', 'new', ''):
            return 'pending'
        return 'pending'

    def _fmt_dt(v):
        try:
            if not v:
                return 'Not set'
            if hasattr(v, 'hour') and hasattr(v, 'minute'):
                return v.strftime('%Y-%m-%d %H:%M')
            return v.strftime('%Y-%m-%d')
        except Exception:
            return str(v) if v else 'Not set'

    def _fmt_date_short(v):
        try:
            if not v:
                return 'Not set'
            return v.strftime('%b-%d-%Y')
        except Exception:
            return str(v) if v else 'Not set'

    def _fmt_date_short(v):
        try:
            if not v:
                return 'Not set'
            return v.strftime('%b-%d-%Y')
        except Exception:
            return str(v) if v else 'Not set'

    # Get tasks assigned to this employee (bid_checklists.assigned_to points to employees.id)
    try:
        employee_id_for_tasks = (employee_row or {}).get('id')
        created_by_user_id = getattr(current_user, 'id', None)
        if not employee_id_for_tasks:
            tasks = []
        else:
            try:
                cur.execute("""
                SELECT
                    bc.*,
                    COALESCE(gb.b_name, gb.title, '') AS bid_name,
                    gb.company,
                    gb.due_date AS bid_due_date,
                    COALESCE(gb.state, ba.state, ba.depart) AS bid_state
                FROM bid_checklists bc
                LEFT JOIN go_bids gb ON gb.g_id = bc.g_id
                LEFT JOIN bid_assign ba ON ba.g_id = bc.g_id
                WHERE bc.assigned_to = %s
                ORDER BY
                    (bc.due_date IS NULL) ASC,
                    bc.due_date ASC,
                    CASE LOWER(COALESCE(bc.priority,''))
                        WHEN 'urgent' THEN 4
                        WHEN 'high' THEN 3
                        WHEN 'medium' THEN 2
                        WHEN 'low' THEN 1
                        ELSE 0
                    END DESC,
                    bc.id ASC
                LIMIT 200
                """, (employee_id_for_tasks,))
                tasks = cur.fetchall()
            except Exception as e:
                # Some DB schemas don't have go_bids.title; fall back to b_name only.
                if "Unknown column 'gb.title'" in str(e):
                    cur.execute("""
                        SELECT
                            bc.*,
                            COALESCE(gb.b_name, '') AS bid_name,
                            gb.company,
                            gb.due_date AS bid_due_date,
                            COALESCE(gb.state, ba.state, ba.depart) AS bid_state
                        FROM bid_checklists bc
                        LEFT JOIN go_bids gb ON gb.g_id = bc.g_id
                        LEFT JOIN bid_assign ba ON ba.g_id = bc.g_id
                        WHERE bc.assigned_to = %s
                        ORDER BY
                            (bc.due_date IS NULL) ASC,
                            bc.due_date ASC,
                            CASE LOWER(COALESCE(bc.priority,''))
                                WHEN 'urgent' THEN 4
                                WHEN 'high' THEN 3
                                WHEN 'medium' THEN 2
                                WHEN 'low' THEN 1
                                ELSE 0
                            END DESC,
                            bc.id ASC
                        LIMIT 200
                    """, (employee_id_for_tasks,))
                    tasks = cur.fetchall()
                else:
                    raise
    except Exception:
        tasks = []

    # Use the assigned_tasks layout for members (same as team lead view).
    try:
        dept_key = _normalize_department_key((employee_row or {}).get('department') or user_role) or 'business'
    except Exception:
        dept_key = 'business'
    return _render_employee_assigned_tasks(dept_key, (employee_row or {}).get('id'), 'Assigned Tasks')

    # Legacy employee dashboard below (replaced by assigned_tasks layout).

@app.route('/dashboard/<team>')
@login_required
def team_dashboard(team):
    """Team-specific dashboard for Business Dev, Design, Operations, Site Manager"""
    # Check permissions for team dashboard access
    user_role = getattr(current_user, 'role', 'member').lower()
    user_role_norm = user_role.replace('_', ' ')
    embed_mode = (request.args.get('embed') or '').strip().lower()
    # Embedded manager dashboards can pass flags to control extra columns.
    embed_mode_bool = bool(embed_mode)
    _role_norm = (user_role_norm or '').strip().lower()
    _manager_roles = {
        'manager',
        'top level admin',
        'top_level_admin',
        'business manager',
        'design manager',
        'operation manager',
        'operations manager',
        'site manager',
    }
    # Default: keep the grid clean (no Team column). If needed, enable explicitly:
    # /dashboard/<team>?show_team=1
    show_team_param = (request.args.get('show_team') or '').strip().lower()
    show_team_column = show_team_param in ('1', 'true', 'yes', 'y')

    # Restrict department managers to their own team dashboard
    dept_manager_team = {
        'business_manager': 'business',
        'design_manager': 'design',
        'operation_manager': 'operations',
        'operations_manager': 'operations',
        'site_manager': 'engineer',
    }
    if (not current_user.is_admin and not current_user.is_supervisor) and user_role in dept_manager_team and team != dept_manager_team[user_role]:
        return render_template('access_denied.html', message="You don't have access to this team dashboard."), 403
    
    # Allow admins and supervisors to access all team dashboards
    if not (current_user.is_admin or current_user.is_supervisor):
        # Check if user has team_management or company_dashboards permission
        permissions = get_user_module_permissions(user_role, user_id=int(current_user.id))
        if not (permissions.get('team_management', False) or permissions.get('company_dashboards', False)):
            return render_template('access_denied.html', message="You don't have access to team dashboards. Please contact your IT Administrator.")
    
    # Additional check: team leads can only access their own team's dashboard
    team_role_map = {
        'business': ['business dev', 'business development'],
        'design': ['design'],
        'operations': ['operations'],
        'engineer': ['site_engineer', 'site engineer', 'site manager', 'engineering']
    }
    
    if not current_user.is_admin and not current_user.is_supervisor:
        allowed_roles = team_role_map.get(team, [])
        allowed_roles_norm = [r.replace('_', ' ') for r in allowed_roles]
        if user_role_norm not in allowed_roles_norm and user_role_norm not in ['manager', 'top_level_admin', 'top level admin', 'business manager', 'design manager', 'operation manager', 'operations manager', 'site manager']:
            # Check if they have general access via permissions
            permissions = get_user_module_permissions(user_role, user_id=int(current_user.id))
            if not permissions.get('company_dashboards', False):
                return render_template('access_denied.html', message=f"You don't have access to the {team.title()} team dashboard.")
    
    # Keep go_bids in sync with GO decisions so teams see new bids immediately
    try:
        sync_go_bids()
    except Exception:
        pass

    # Map team names to stages
    team_to_stage = {
        'business': 'business',
        'design': 'design', 
        'operations': 'operations',
        'engineer': 'engineer'
    }
    
    if team not in team_to_stage:
        return "Invalid team", 404
    
    current_stage = team_to_stage[team]
    # Ensure seed tasks exist so all bids appear on this team dashboard
    ensure_tasks_for_team(current_stage)
    cur = mysql.connection.cursor(DictCursor)
    
    # Company access filter based on user email domain
        # Company filter: active company context
    company_sql_clause, company_params = _company_filter_for_go_bids(cur)

    # Fetch all bids for this company scope; filtering by team is done in Python
    try:
        cur.execute("""
        SELECT gb.g_id AS id,
               gb.b_name AS name,
               gb.company, 
               gb.due_date,
               gb.created_at AS created_at,
               COALESCE(gb.scoring, 0) AS progress,
               LOWER(COALESCE(gb.state, 'analyzer')) AS current_stage,
               ba.person_name,
               ba.assignee_email AS person_email,
               ba.depart,
               wps.pr_completion_status AS work_status,
               wbr.closure_status AS project_status,
               wbr.work_progress_status AS work_progress_status,
               wlr.result AS wl_result,
               gb.summary,
               COALESCE(gb.submission_status, 'Work Progress') AS submission_status,
               COALESCE(gb.submission_reason, '') AS submission_reason
        FROM go_bids gb
        LEFT JOIN bid_assign ba ON ba.g_id = gb.g_id
        LEFT JOIN win_lost_results wlr ON wlr.a_id = ba.a_id OR wlr.g_id = gb.g_id
        LEFT JOIN won_bids_result wbr ON wbr.w_id = wlr.w_id
        LEFT JOIN work_progress_status wps ON wps.won_id = wbr.won_id
        WHERE 1=1
        """ + company_sql_clause + """
        ORDER BY gb.due_date ASC
    """, company_params)
        rows = cur.fetchall()
    except Exception as e:
        # Fallback when go_bids.state column doesn't exist yet
        if "Unknown column 'state'" in str(e):
            cur.execute("""
                SELECT gb.g_id AS id,
                       gb.b_name AS name,
                       gb.company, 
                       gb.due_date,
                       gb.created_at AS created_at,
                       COALESCE(gb.scoring, 0) AS progress,
                       LOWER(COALESCE(ba.depart, 'analyzer')) AS current_stage,
                       ba.person_name,
                       ba.assignee_email AS person_email,
                       ba.depart,
                       wps.pr_completion_status AS work_status,
                       wbr.closure_status AS project_status,
                       wbr.work_progress_status AS work_progress_status,
                       wlr.result AS wl_result,
                       gb.summary,
                       COALESCE(gb.submission_status, 'Work Progress') AS submission_status,
                       COALESCE(gb.submission_reason, '') AS submission_reason
                FROM go_bids gb
                LEFT JOIN bid_assign ba ON ba.g_id = gb.g_id
                LEFT JOIN win_lost_results wlr ON wlr.a_id = ba.a_id OR wlr.g_id = gb.g_id
                LEFT JOIN won_bids_result wbr ON wbr.w_id = wlr.w_id
                LEFT JOIN work_progress_status wps ON wps.won_id = wbr.won_id
                WHERE 1=1
                """ + company_sql_clause + """
                ORDER BY gb.due_date ASC
            """, company_params)
            rows = cur.fetchall()
        else:
            raise
    # Remove duplicate bids by same name and due date (front-end filtering only)
    _seen_pairs = set()
    _unique_rows = []
    for _r in rows:
        _key = (((_r.get('name') or '').strip().lower()), str(_r.get('due_date') or ''))
        if _key in _seen_pairs:
            continue
        _seen_pairs.add(_key)
        _unique_rows.append(_r)
    rows = _unique_rows

    # Add task-level completion date + priority (based on nearest task due date for this stage)
    try:
        bid_ids_for_tasks = [r.get('id') for r in rows if r.get('id') is not None]
        task_info_map = {}
        if bid_ids_for_tasks:
            placeholders = ','.join(['%s'] * len(bid_ids_for_tasks))
            cur.execute(
                f"""
                SELECT
                    g_id,
                    MIN(CASE WHEN LOWER(COALESCE(status,'')) IN ('pending','in_progress') THEN due_date END) AS next_task_due_date,
                    MAX(CASE WHEN LOWER(COALESCE(status,'')) = 'completed' THEN updated_at END) AS last_completed_at
                FROM bid_checklists
                WHERE g_id IN ({placeholders})
                  AND LOWER(COALESCE(stage,'')) = %s
                GROUP BY g_id
                """,
                (*bid_ids_for_tasks, current_stage),
            )
            for t in (cur.fetchall() or []):
                task_info_map[int(t.get('g_id'))] = t

        from datetime import datetime, timezone

        def _fmt_dt(d):
            if not d:
                return None
            try:
                # MySQLdb returns datetime
                return d.strftime('%Y-%m-%d')
            except Exception:
                return str(d)

        today = datetime.now(timezone.utc).date()
        for r in rows:
            bid_id = r.get('id')
            info = task_info_map.get(int(bid_id)) if bid_id is not None else None
            next_due = (info or {}).get('next_task_due_date')
            last_done = (info or {}).get('last_completed_at')

            # Prefer next pending/inprogress task due date; fallback to last completed timestamp
            chosen_dt = next_due or last_done
            r['task_completion_date'] = _fmt_dt(chosen_dt) or 'N/A'

            # Priority derived from next task due date
            prio = 'Low'
            try:
                if next_due:
                    due_date_only = next_due.date() if hasattr(next_due, 'date') else today
                    days_left = (due_date_only - today).days
                    if days_left <= 0:
                        prio = 'Important'
                    elif days_left <= 3:
                        prio = 'Medium'
                    else:
                        prio = 'Low'
            except Exception:
                prio = 'Medium'
            r['priority_label'] = prio

            # Format Created At for table display
            try:
                r['created_at'] = _fmt_dt(r.get('created_at')) or 'N/A'
            except Exception:
                r['created_at'] = str(r.get('created_at')) if r.get('created_at') else 'N/A'
    except Exception:
        for r in rows:
            r['task_completion_date'] = r.get('task_completion_date') or 'N/A'
            r['priority_label'] = r.get('priority_label') or 'Medium'
            if not r.get('created_at'):
                r['created_at'] = 'N/A'

    # Ensure dynamic stage tables exist and load per-bid configuration
    try:
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS bid_stage_exclusions (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                stage VARCHAR(50) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_bid_stage (g_id, stage)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
            """
        )
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS bid_custom_stages (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                stage VARCHAR(50) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_custom_stage (g_id, stage)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
            """
        )
    except Exception:
        # If creation fails (e.g., no rights), continue ??? downstream selects may still work
        pass

    cur.execute("SELECT g_id, stage FROM bid_stage_exclusions")
    ex_rows = cur.fetchall()
    exclusions = {}
    for r in ex_rows:
        exclusions.setdefault(r['g_id'], set()).add((r['stage'] or '').strip().lower())

    cur.execute("SELECT g_id, stage FROM bid_custom_stages")
    cs_rows = cur.fetchall()
    customs = {}
    for r in cs_rows:
        customs.setdefault(r['g_id'], []).append((r['stage'] or '').strip().lower())

    # Preload set of bids that already have tasks for this team's stage
    try:
        cur.execute("SELECT DISTINCT g_id FROM bid_checklists WHERE LOWER(COALESCE(stage,''))=%s", (current_stage,))
        task_ids = {row['g_id'] for row in cur.fetchall()}
    except Exception:
        task_ids = set()

    default_stages = ['analyzer', 'business', 'design', 'operations', 'engineer']
    bids = []
    for row in rows:
        bid_id = row.get('id')
        excl = exclusions.get(bid_id, set())
        cust = [s for s in customs.get(bid_id, []) if s not in excl]
        dyn_stages = [s for s in default_stages if s not in excl] + [s for s in cust if s not in default_stages]
        # If no dynamic config exists, keep default stages
        if not dyn_stages:
            dyn_stages = default_stages.copy()

        stage_now = (row.get('current_stage') or 'analyzer').lower()
        should_include = (
            stage_now == current_stage
            or bid_id in task_ids
            or current_stage in dyn_stages
        )
        if not should_include:
            continue

        # Shape bid dict like before and attach dynamic stages
        row['user'] = {'email': row.get('person_email'), 'role': current_stage}
        row['next_stage'] = None  # resolved in template via get_next_stage
        stage_key = stage_now
        row['work_progress_pct'] = stage_progress_pct(stage_key)
        row['project_status'], row['work_status'] = status_texts(stage_key)
        row['dyn_stages'] = dyn_stages
        bids.append(row)

    # Compute stats from filtered bids
    total_bids = len(bids)
    completed_bids = sum(1 for b in bids if (b.get('wl_result') == 'WON'))

    # Load assigned members for each bid from bid_assignment_members table
    bid_ids = [b['id'] for b in bids]
    assigned_map = {}
    try:
        if bid_ids:
            # Ensure mapping table exists
            cur.execute(
                """
                CREATE TABLE IF NOT EXISTS bid_assignment_members (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    g_id INT NOT NULL,
                    employee_id INT NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE KEY uniq_g_emp (g_id, employee_id)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
                """
            )
            placeholders = ','.join(['%s'] * len(bid_ids))
            # In manager-embedded mode, don't restrict by department so we can show cross-team assignees.
            sql = f"""
                SELECT bam.g_id,
                       e.id AS employee_id,
                       e.name,
                       e.email,
                       e.department,
                       u.role AS user_role
                FROM bid_assignment_members bam
                JOIN employees e ON e.id = bam.employee_id
                LEFT JOIN users u ON LOWER(COALESCE(u.email,'')) = LOWER(COALESCE(e.email,''))
                WHERE bam.g_id IN ({placeholders})
                  AND e.is_active = TRUE
            """
            params = list(bid_ids)
            if not show_team_column:
                sql += " AND e.department = %s"
                params.append(team)
            sql += " ORDER BY e.name"
            cur.execute(sql, tuple(params))
            rows = cur.fetchall()

            role_to_team = {
                'business dev': 'business',
                'business development': 'business',
                'design': 'design',
                'operations': 'operations',
                'site_engineer': 'engineer',
                'site engineer': 'engineer',
                'site manager': 'engineer',
                'engineering': 'engineer',
                'engineer': 'engineer',
            }

            def _map_team_key(dept, role):
                r = (role or '').lower().strip().replace('_', ' ')
                if r in role_to_team:
                    return role_to_team[r]
                d = (dept or '').lower().strip()
                if d in ('business', 'design', 'operations', 'engineer'):
                    return d
                return None

            for r in rows:
                tk = _map_team_key(r.get('department'), r.get('user_role'))
                assigned_map.setdefault(r['g_id'], []).append({
                    'id': r.get('employee_id'),
                    'name': r.get('name'),
                    'email': r.get('email'),
                    'department': r.get('department'),
                    'user_role': r.get('user_role'),
                    'team_key': tk,
                })
        # Attach to bid rows
        for b in bids:
            b['assigned_members'] = assigned_map.get(b['id'], [])
    except Exception:
        # If there's an error, just set empty list for each bid
        for b in bids:
            b['assigned_members'] = []
    
    # Load RFP files for each bid from uploaded_rfp_files table
    rfp_files_map = {}
    try:
        if bid_ids:
            # Ensure uploaded_rfp_files table exists
            cur.execute(
                """
                CREATE TABLE IF NOT EXISTS uploaded_rfp_files (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    bid_id INT,
                    g_id INT,
                    filename VARCHAR(500) NOT NULL,
                    file_path VARCHAR(1000) NOT NULL,
                    file_size BIGINT,
                    uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    uploaded_by INT,
                    INDEX idx_bid_id (bid_id),
                    INDEX idx_g_id (g_id)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
                """
            )
            # Check if g_id column exists, if not add it
            try:
                cur.execute("SHOW COLUMNS FROM uploaded_rfp_files LIKE 'g_id'")
                if not cur.fetchone():
                    cur.execute("ALTER TABLE uploaded_rfp_files ADD COLUMN g_id INT, ADD INDEX idx_g_id (g_id)")
                    mysql.connection.commit()
            except Exception:
                pass
            
            placeholders = ','.join(['%s'] * len(bid_ids))
            # Try to query with g_id first, fallback to bid_id if g_id doesn't exist in results
            try:
                cur.execute(
                    f"""
                    SELECT id, g_id, bid_id, filename, file_path, file_size, uploaded_at
                    FROM uploaded_rfp_files
                    WHERE g_id IN ({placeholders}) OR bid_id IN ({placeholders})
                    ORDER BY uploaded_at DESC
                    """,
                    (*bid_ids, *bid_ids)
                )
            except Exception:
                # Fallback if g_id column doesn't exist in query results
                cur.execute(
                    f"""
                    SELECT id, bid_id, filename, file_path, file_size, uploaded_at
                    FROM uploaded_rfp_files
                    WHERE bid_id IN ({placeholders})
                    ORDER BY uploaded_at DESC
                    """,
                    bid_ids
                )
            rows = cur.fetchall()
            for r in rows:
                # bid_ids contains g_id values from go_bids (aliased as 'id')
                g_id = r.get('g_id') or r.get('bid_id')
                if g_id and g_id in bid_ids:
                    if g_id not in rfp_files_map:
                        rfp_files_map[g_id] = []
                    rfp_files_map[g_id].append({
                        'id': r['id'],
                        'filename': r['filename'],
                        'file_path': r['file_path'],
                        'file_size': r.get('file_size', 0),
                        'uploaded_at': r.get('uploaded_at')
                    })
        # Attach RFP files to bid rows
        for b in bids:
            b['rfp_files'] = rfp_files_map.get(b['id'], [])
    except Exception as e:
        # If there's an error, just set empty list for each bid
        print(f"Error loading RFP files: {str(e)}")
        for b in bids:
            b['rfp_files'] = []

    # Load full teamlead_assign_bids table for the overview section
    try:
        cur.execute("SELECT * FROM teamlead_assign_bids ORDER BY COALESCE(due_date, created_at) DESC, id DESC")
        teamlead_assign_bids = cur.fetchall()
        if not teamlead_assign_bids:
            # If empty, backfill once from existing tables and re-read
            try:
                # Ensure a unique key on g_id so we can safely upsert
                try:
                    cur.execute("SHOW INDEX FROM teamlead_assign_bids WHERE Key_name = 'uniq_teamlead_assign_g_id'")
                    if cur.fetchone():
                        cur.execute("ALTER TABLE teamlead_assign_bids DROP INDEX uniq_teamlead_assign_g_id")
                    cur.execute("SHOW INDEX FROM teamlead_assign_bids WHERE Key_name = 'uniq_teamlead_assign_bid_lead'")
                    if not cur.fetchone():
                        cur.execute("ALTER TABLE teamlead_assign_bids ADD UNIQUE KEY uniq_teamlead_assign_bid_lead (g_id, team_lead)")
                except Exception:
                    pass

                cur.execute(
                    """
                    INSERT INTO teamlead_assign_bids (
                        g_id, b_name, due_date, state, scope, type, scoring,
                        comp_name, company, summary, submission_status, submission_reason,
                        task_completion_date, team_lead
                    )
                    SELECT
                        g.g_id,
                        g.b_name,
                        g.due_date,
                        g.state,
                        g.scope,
                        g.type,
                        g.scoring,
                        COALESCE(
                            (SELECT bi.comp_name
                             FROM bid_incoming bi
                             WHERE bi.b_name = g.b_name
                             ORDER BY bi.id DESC
                             LIMIT 1),
                            g.company
                        ) AS comp_name,
                        g.company,
                        g.summary,
                        COALESCE(g.submission_status, 'Work Progress') AS submission_status,
                        g.submission_reason,
                        (
                            SELECT DATE(MAX(bc.updated_at))
                            FROM bid_checklists bc
                            WHERE bc.g_id = g.g_id
                              AND (
                                LOWER(COALESCE(bc.status, '')) = 'completed'
                                OR COALESCE(bc.progress_pct, 0) >= 100
                              )
                        ) AS task_completion_date,
                        (
                            SELECT ba.assignee_email
                            FROM bid_assign ba
                            WHERE ba.g_id = g.g_id
                            ORDER BY ba.a_id DESC
                            LIMIT 1
                        ) AS team_lead
                    FROM go_bids g
                    ON DUPLICATE KEY UPDATE
                        b_name = VALUES(b_name),
                        due_date = VALUES(due_date),
                        state = VALUES(state),
                        scope = VALUES(scope),
                        type = VALUES(type),
                        scoring = VALUES(scoring),
                        comp_name = VALUES(comp_name),
                        company = VALUES(company),
                        summary = VALUES(summary),
                        submission_status = VALUES(submission_status),
                        submission_reason = VALUES(submission_reason),
                        task_completion_date = VALUES(task_completion_date),
                        team_lead = VALUES(team_lead),
                        updated_at = CURRENT_TIMESTAMP
                    """
                )
                mysql.connection.commit()
            except Exception:
                pass

            try:
                cur.execute("SELECT * FROM teamlead_assign_bids ORDER BY COALESCE(due_date, created_at) DESC, id DESC")
                teamlead_assign_bids = cur.fetchall()
            except Exception:
                teamlead_assign_bids = []
    except Exception:
        teamlead_assign_bids = []

    cur.close()
    
    # Map stage names for display
    stage_display_names = {
        'business': 'Business Development',
        'design': 'Design Team', 
        'operations': 'Operations Team',
        'engineer': 'Site Engineer'
    }
    
    team_display_name = stage_display_names.get(team, team.title())
    
    # Add dynamic progress and status texts to each bid
    for bid in bids:
        stage_key = (bid.get('current_stage') or 'analyzer').lower()
        bid['work_progress_pct'] = stage_progress_pct(stage_key)
        bid['project_status'], bid['work_status'] = status_texts(stage_key)
    
    # Define next stage mapping for template
    def get_next_stage(current_stage):
        stage_flow = {
            'analyzer': 'business',
            'business': 'design',
            'design': 'operations',
            'operations': 'engineer',
            'engineer': 'handover'
        }
        return stage_flow.get(current_stage, None)
    
    # Check if supervisor is accessing business dashboard
    is_supervisor_access = (team == 'business' and (current_user.is_admin or current_user.is_supervisor))
    
    return render_template('team_dashboard.html', 
                         bids=bids, 
                         team=team,
                         team_display_name=team_display_name,
                         current_stage=current_stage,
                         total_bids=total_bids,
                         completed_bids=completed_bids,
                         user=current_user,
                         get_next_stage=get_next_stage,
                         embed_mode=embed_mode,
                         show_team_column=show_team_column,
                         is_supervisor=is_supervisor_access,
                         teamlead_assign_bids=teamlead_assign_bids)

main_stats = {
    'total_bids': 350, 'live_bids': 75, 'bids_won': 120, 'projects_completed': 95,
}

# Assuming you have a Log model, e.g., from SQLAlchemy


# ... other imports and app setup

@app.route('/logs')
@login_required
def logs_page():
    if not current_user.is_admin and not check_module_access_db('logs'):
        return render_template('access_denied.html',
                             message="You don't have permission to access Activity Logs.",
                             module="Activity Logs"), 403
    # Query all logs, ordering by the most recent first
    cur = mysql.connection.cursor(DictCursor)
    cur.execute("SELECT * FROM logs ORDER BY timestamp DESC")
    all_logs = cur.fetchall()
    cur.close()
    return render_template('logs.html', logs=all_logs)

def supervisor_assign_stage():
    if not current_user.can_assign_stages:
        return "Access Denied", 403
    
    g_id = request.form.get('g_id')
    new_stage = request.form.get('stage')
    person_name = request.form.get('person_name', '').strip()
    department = request.form.get('department', '').strip()
    
    if not g_id or not new_stage:
        flash('Missing required fields', 'error')
        return redirect(url_for('manager_dashboard'))
    
    cur = mysql.connection.cursor(DictCursor)
    try:
        # Update go_bids state
        cur.execute("UPDATE go_bids SET state=%s WHERE g_id=%s", (new_stage, g_id))

        # Ensure tasks exist for all departments so they can work in parallel on this bid.
        try:
            team_stages = ['engineering_team', 'procurement_team', 'accounts_finance']
            for st in team_stages:
                cur.execute(
                    """
                    SELECT 1
                    FROM bid_checklists
                    WHERE g_id = %s AND LOWER(COALESCE(stage,'')) = %s
                    LIMIT 1
                    """,
                    (g_id, st),
                )
                exists = cur.fetchone() is not None
                if not exists:
                    generate_team_checklist(cur, g_id, st)
        except Exception:
            pass
        
        # Update or create bid_assign entry
        cur.execute("SELECT a_id FROM bid_assign WHERE g_id=%s", (g_id,))
        row = cur.fetchone()
        
        if row:
            # Update existing assignment
            cur.execute("""
                UPDATE bid_assign 
                SET state=%s, depart=%s, person_name=%s, status='assigned' 
                WHERE g_id=%s
            """, (new_stage, department, person_name, g_id))
        else:
            # Create new assignment
            cur.execute("""
                INSERT INTO bid_assign (g_id, b_name, due_date, state, scope, type, company, depart, person_name, status)
                SELECT g_id, b_name, due_date, %s, scope, type, company, %s, %s, 'assigned'
                FROM go_bids WHERE g_id=%s
            """, (new_stage, department, person_name, g_id))
        
        # Log the action
        cur.execute("SELECT b_name FROM go_bids WHERE g_id=%s", (g_id,))
        bid_name = cur.fetchone()['b_name']
        log_action = f"Supervisor '{current_user.email}' assigned bid '{bid_name}' (ID: {g_id}) to {new_stage} stage"
        cur.execute("INSERT INTO logs (action, user_id) VALUES (%s, %s)", (log_action, current_user.id))
        
        mysql.connection.commit()
        flash(f'Bid "{bid_name}" assigned to {new_stage} stage successfully!', 'success')
        
    except Exception as e:
        mysql.connection.rollback()
        flash(f'Assignment failed: {str(e)}', 'error')
    finally:
        cur.close()
    
    return redirect(url_for('manager_dashboard'))

@app.route('/supervisor/update-company', methods=['POST'])
@login_required
def supervisor_update_company():
    if not current_user.can_alter_timeline:
        return "Access Denied", 403
    g_id = request.form.get('g_id')
    company_id = request.form.get('company_id')
    if not g_id:
        flash('Missing bid id', 'error')
        return redirect(url_for('manager_dashboard'))
    cur = mysql.connection.cursor(DictCursor)
    try:
        # If the user is scoped/restricted, block selecting companies outside their scope.
        try:
            if company_id and (not getattr(current_user, 'is_admin', False)) and _user_has_any_scoped_rows(int(current_user.id)):
                if not _has_active_scope_for_company(int(current_user.id), int(company_id)):
                    flash('Access denied for selected company.', 'error')
                    return redirect(url_for('manager_dashboard'))
        except Exception:
            pass

        company_name = None
        if company_id:
            cur.execute("SELECT name FROM companies WHERE id=%s", (company_id,))
            row = cur.fetchone()
            if row:
                company_name = row['name']
        if not company_name:
            # allow free text fallback
            company_name = (request.form.get('company_name') or '').strip()
        cur.execute("UPDATE go_bids SET company=%s WHERE g_id=%s", (company_name, g_id))

        # Best-effort: seed default checklist tasks for all departments so they can work in parallel.
        try:
            team_stages = ['engineering_team', 'procurement_team', 'accounts_finance']
            for st in team_stages:
                cur.execute(
                    """
                    SELECT 1
                    FROM bid_checklists
                    WHERE g_id = %s AND LOWER(COALESCE(stage,'')) = %s
                    LIMIT 1
                    """,
                    (g_id, st),
                )
                exists = cur.fetchone() is not None
                if not exists:
                    generate_team_checklist(cur, g_id, st)
        except Exception:
            pass

        mysql.connection.commit()
        flash('Company updated.', 'success')
    except Exception as e:
        mysql.connection.rollback()
        flash(f'Failed to update company: {e}', 'error')
    finally:
        cur.close()
    return redirect(url_for('manager_dashboard'))

@app.route('/uploads/<path:subpath>')
@login_required
def serve_uploads(subpath):
    base_dir = os.path.join(os.getcwd(), 'uploads')
    return send_from_directory(base_dir, subpath)

# [REMOVED duplicate /profiling handler consolidated above]

@app.route('/team/stage/add', methods=['POST'])
@login_required
def team_add_stage():
    """Allow team members to add a custom stage for a bid without supervisor role.
    The stage is stored in bid_custom_stages and un-excluded if previously excluded.
    """
    g_id = request.form.get('g_id')
    stage = (request.form.get('new_stage') or '').strip().lower()
    if not g_id or not stage:
        return jsonify({'ok': False, 'error': 'Missing parameters'}), 400
    cur = mysql.connection.cursor(DictCursor)
    try:
        # Ensure required tables exist
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS bid_stage_exclusions (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                stage VARCHAR(50) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_bid_stage (g_id, stage)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
            """
        )
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS bid_custom_stages (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                stage VARCHAR(50) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_custom_stage (g_id, stage)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
            """
        )
        cur.execute("INSERT IGNORE INTO bid_custom_stages (g_id, stage) VALUES (%s, %s)", (g_id, stage))
        cur.execute("DELETE FROM bid_stage_exclusions WHERE g_id=%s AND stage=%s", (g_id, stage))
        mysql.connection.commit()
        return jsonify({'ok': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'ok': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/team/stage/delete', methods=['POST'])
@login_required
def team_delete_stage():
    """Allow team members to delete a stage that comes after the current stage."""
    g_id = request.form.get('g_id')
    stage = (request.form.get('stage') or '').strip().lower()
    if not g_id or not stage:
        return jsonify({'ok': False, 'error': 'Missing parameters'}), 400
    cur = mysql.connection.cursor(DictCursor)
    try:
        # Ensure required tables exist
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS bid_stage_exclusions (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                stage VARCHAR(50) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_bid_stage (g_id, stage)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
            """
        )
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS bid_custom_stages (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                stage VARCHAR(50) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_custom_stage (g_id, stage)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
            """
        )
        # Determine current stage and dynamic stage ordering
        cur.execute("SELECT state FROM go_bids WHERE g_id=%s", (g_id,))
        row = cur.fetchone()
        current_stage = (row.get('state') or 'analyzer').strip().lower() if row else 'analyzer'

        cur.execute("SELECT stage FROM bid_stage_exclusions WHERE g_id=%s", (g_id,))
        excluded = { (r['stage'] or '').strip().lower() for r in cur.fetchall() }
        cur.execute("SELECT stage FROM bid_custom_stages WHERE g_id=%s", (g_id,))
        customs = [ (r['stage'] or '').strip().lower() for r in cur.fetchall() ]
        default_stages = ['analyzer', 'business', 'design', 'operations', 'engineer']
        stages = [s for s in default_stages if s not in excluded] + [s for s in customs if s not in excluded and s not in default_stages]

        if stage not in stages:
            return jsonify({'ok': False, 'error': 'Stage not found for this bid.'}), 400
        try:
            curr_idx = stages.index(current_stage)
        except ValueError:
            curr_idx = 0
        target_idx = stages.index(stage)
        if target_idx <= curr_idx:
            return jsonify({'ok': False, 'error': 'Cannot delete current or previous stages.'}), 400

        cur.execute("INSERT IGNORE INTO bid_stage_exclusions (g_id, stage) VALUES (%s, %s)", (g_id, stage))
        cur.execute("DELETE FROM bid_custom_stages WHERE g_id=%s AND stage=%s", (g_id, stage))
        mysql.connection.commit()
        return jsonify({'ok': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'ok': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/supervisor/delete-stage', methods=['POST'])
@login_required
def supervisor_delete_stage():
    if not current_user.can_alter_timeline:
        return "Access Denied", 403
    g_id = request.form.get('g_id')
    deleted_stage = request.form.get('stage')
    if not g_id:
        flash('Missing bid id', 'error')
        return redirect(url_for('manager_dashboard'))
    cur = mysql.connection.cursor(DictCursor)
    try:
        # Remove explicit assignment for this bid; keep current go_bids.state unchanged
        cur.execute("DELETE FROM bid_assign WHERE g_id=%s", (g_id,))
        # Persist exclusion so UI can hide this stage next time
        if deleted_stage:
            cur.execute(
                "INSERT IGNORE INTO bid_stage_exclusions (g_id, stage) VALUES (%s, %s)",
                (g_id, deleted_stage)
            )
        # Log action
        cur.execute("SELECT b_name FROM go_bids WHERE g_id=%s", (g_id,))
        row = cur.fetchone()
        bid_name = row['b_name'] if row else g_id
        stage_info = f" (stage: {deleted_stage})" if deleted_stage else ""
        log_action = f"Supervisor '{current_user.email}' deleted stage assignment for bid '{bid_name}' (ID: {g_id}){stage_info}"
        cur.execute("INSERT INTO logs (action, user_id) VALUES (%s, %s)", (log_action, current_user.id))
        mysql.connection.commit()
        flash('Stage assignment deleted.', 'success')
    except Exception as e:
        mysql.connection.rollback()
        flash(f'Could not delete stage: {e}', 'error')
    finally:
        cur.close()
    return redirect(url_for('manager_dashboard'))
@app.route('/supervisor/delete-bid', methods=['POST'])
@login_required
def supervisor_delete_bid():
    if not current_user.can_alter_timeline:
        return "Access Denied", 403
    g_id = request.form.get('g_id')
    if not g_id:
        flash('Missing bid id', 'error')
        return redirect(url_for('manager_dashboard'))
    cur = mysql.connection.cursor(DictCursor)
    try:
        # Fetch name for logs
        cur.execute("SELECT b_name FROM go_bids WHERE g_id=%s", (g_id,))
        row = cur.fetchone()
        bid_name = (row or {}).get('b_name', g_id)

        # Delete related records to avoid foreign key constraint errors
        cur.execute("DELETE FROM bid_checklists WHERE g_id=%s", (g_id,))
        cur.execute("DELETE FROM bid_stage_exclusions WHERE g_id=%s", (g_id,))
        cur.execute("DELETE FROM bid_custom_stages WHERE g_id=%s", (g_id,))
        
        # Delete from bid_assign and cascading tables
        cur.execute("SELECT a_id FROM bid_assign WHERE g_id=%s", (g_id,))
        assign_ids = [r['a_id'] for r in cur.fetchall()]
        
        for a_id in assign_ids:
            cur.execute("SELECT w_id FROM win_lost_results WHERE a_id=%s", (a_id,))
            w_ids = [r['w_id'] for r in cur.fetchall()]
            
            for w_id in w_ids:
                cur.execute("SELECT won_id FROM won_bids_result WHERE w_id=%s", (w_id,))
                won_ids = [r['won_id'] for r in cur.fetchall()]
                
                for won_id in won_ids:
                    cur.execute("DELETE FROM work_progress_status WHERE won_id=%s", (won_id,))
                
                cur.execute("DELETE FROM won_bids_result WHERE w_id=%s", (w_id,))
            
            cur.execute("DELETE FROM win_lost_results WHERE a_id=%s", (a_id,))
        
        cur.execute("DELETE FROM bid_assign WHERE g_id=%s", (g_id,))
        cur.execute("DELETE FROM go_bids WHERE g_id=%s", (g_id,))

        # Log
        log_action = f"Supervisor '{current_user.email}' deleted bid '{bid_name}' (ID: {g_id})"
        cur.execute("INSERT INTO logs (action, user_id) VALUES (%s, %s)", (log_action, current_user.id))
        mysql.connection.commit()
        flash('Bid deleted successfully.', 'success')
    except Exception as e:
        mysql.connection.rollback()
        flash(f'Failed to delete bid: {e}', 'error')
    finally:
        cur.close()
    return redirect(url_for('manager_dashboard'))

@app.route('/supervisor/set-stage', methods=['POST'])
@login_required
def supervisor_set_stage():
    if not current_user.can_alter_timeline:
        return "Access Denied", 403
    g_id = request.form.get('g_id')
    new_stage = (request.form.get('new_stage') or '').strip().lower()
    if not g_id or not new_stage:
        flash('Missing bid id or stage.', 'error')
        return redirect(url_for('manager_dashboard'))
    cur = mysql.connection.cursor(DictCursor)
    try:
        # Update go_bids current stage only
        cur.execute("UPDATE go_bids SET state=%s WHERE g_id=%s", (new_stage, g_id))
        # Log
        cur.execute("SELECT b_name FROM go_bids WHERE g_id=%s", (g_id,))
        bid_name = (cur.fetchone() or {}).get('b_name', g_id)
        log_action = f"Supervisor '{current_user.email}' set stage to '{new_stage}' for bid '{bid_name}' (ID: {g_id})"
        cur.execute("INSERT INTO logs (action, user_id) VALUES (%s, %s)", (log_action, current_user.id))
        mysql.connection.commit()
        flash('Stage updated.', 'success')
    except Exception as e:
        mysql.connection.rollback()
        flash(f'Could not update stage: {e}', 'error')
    finally:
        cur.close()
    return redirect(url_for('manager_dashboard'))

@app.route('/supervisor/add-stage', methods=['POST'])
@login_required
def supervisor_add_stage():
    if not current_user.can_alter_timeline:
        return "Access Denied", 403
    g_id = request.form.get('g_id')
    stage = (request.form.get('new_stage') or '').strip().lower()
    if not g_id or not stage:
        flash('Bid id and stage name are required.', 'error')
        return redirect(url_for('manager_dashboard'))
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("INSERT IGNORE INTO bid_custom_stages (g_id, stage) VALUES (%s, %s)", (g_id, stage))
        # If stage was previously excluded, un-exclude it
        cur.execute("DELETE FROM bid_stage_exclusions WHERE g_id=%s AND stage=%s", (g_id, stage))
        cur.execute("SELECT b_name FROM go_bids WHERE g_id=%s", (g_id,))
        bid_name = (cur.fetchone() or {}).get('b_name', g_id)
        log_action = f"Supervisor '{current_user.email}' added custom stage '{stage}' for bid '{bid_name}' (ID: {g_id})"
        cur.execute("INSERT INTO logs (action, user_id) VALUES (%s, %s)", (log_action, current_user.id))
        mysql.connection.commit()
        flash('Stage added.', 'success')
    except Exception as e:
        mysql.connection.rollback()
        flash(f'Could not add stage: {e}', 'error')
    finally:
        cur.close()
    return redirect(url_for('manager_dashboard'))

@app.route('/supervisor/remove-stage', methods=['POST'])
@login_required
def supervisor_remove_stage():
    if not current_user.can_alter_timeline:
        return jsonify({"ok": False, "error": "Access Denied"}), 403
    g_id = request.form.get('g_id')
    stage = (request.form.get('stage') or '').strip().lower()
    if not g_id or not stage:
        return {"ok": False, "error": "Missing parameters"}, 400
    cur = mysql.connection.cursor(DictCursor)
    try:
        # Fetch current stage and dynamic stages for this bid
        cur.execute("SELECT state FROM go_bids WHERE g_id=%s", (g_id,))
        row = cur.fetchone()
        current_stage = (row.get('state') or 'analyzer').strip().lower() if row else 'analyzer'

        # Build dynamic stages order (defaults - exclusions + customs)
        cur.execute("SELECT stage FROM bid_stage_exclusions WHERE g_id=%s", (g_id,))
        excluded = { (r['stage'] or '').strip().lower() for r in cur.fetchall() }
        cur.execute("SELECT stage FROM bid_custom_stages WHERE g_id=%s", (g_id,))
        customs = [ (r['stage'] or '').strip().lower() for r in cur.fetchall() ]
        default_stages = ['analyzer', 'business', 'design', 'operations', 'engineer']
        stages = [s for s in default_stages if s not in excluded] + [s for s in customs if s not in excluded and s not in default_stages]

        if stage not in stages:
            return {"ok": False, "error": "Stage not found for this bid."}, 400
        try:
            curr_idx = stages.index(current_stage)
        except ValueError:
            curr_idx = 0
        target_idx = stages.index(stage)
        if target_idx <= curr_idx:
            return {"ok": False, "error": "Cannot delete current or previous stages."}, 400

        # Mark as excluded and remove from custom if present
        cur.execute("INSERT IGNORE INTO bid_stage_exclusions (g_id, stage) VALUES (%s, %s)", (g_id, stage))
        cur.execute("DELETE FROM bid_custom_stages WHERE g_id=%s AND stage=%s", (g_id, stage))
        mysql.connection.commit()
        return {"ok": True, "message": "Stage deleted."}
    except Exception as e:
        mysql.connection.rollback()
        return {"ok": False, "error": str(e)}, 500
    finally:
        cur.close()
@app.route('/bid-analyzer')
@login_required
def bid_analyzer():
    # IT Admin and Top Level Admin always have access
    user_role = getattr(current_user, 'role', '').lower()
    is_top_admin = user_role in ['top_level_admin', 'top level admin', 'topleveladmin']
    
    # Check module permission for other users
    if not getattr(current_user, 'is_admin', False) and not is_top_admin and not check_module_access_db('bid_analyzer'):
        return render_template('access_denied.html', 
                             message="You don't have permission to access the Bid Analyzer.",
                             module="Bid Analyzer"), 403
    
    # Ensure latest GO bids are mirrored into go_bids whenever analyzer loads
    try:
        sync_go_bids()
    except Exception:
        pass
    
    cur = mysql.connection.cursor(DictCursor)
    
    # Get bid_incoming data for the table
    try:
        cur.execute("SELECT * FROM bid_incoming ORDER BY created_at DESC, id DESC")
    except Exception:
        cur.execute("SELECT * FROM bid_incoming ORDER BY id DESC")
    bid_incoming_data = cur.fetchall()
    
    # Calculate bid stats from bid_incoming table
    has_bid_status = False
    has_results = False
    try:
        cur.execute("SHOW COLUMNS FROM bid_incoming LIKE 'bid_status'")
        has_bid_status = cur.fetchone() is not None
        cur.execute("SHOW COLUMNS FROM bid_incoming LIKE 'results'")
        has_results = cur.fetchone() is not None
    except Exception:
        has_bid_status = False
        has_results = False

    cur.execute("SELECT COUNT(*) AS total_bids FROM bid_incoming")
    total_bids = cur.fetchone()['total_bids']
    
    cur.execute("SELECT COUNT(*) AS bids_go FROM bid_incoming WHERE decision = 'GO'")
    bids_go = cur.fetchone()['bids_go']
    
    cur.execute("SELECT COUNT(*) AS bids_no_go FROM bid_incoming WHERE decision = 'NO-GO'")
    bids_no_go = cur.fetchone()['bids_no_go']
    
    if has_bid_status:
        cur.execute(
            """
            SELECT COUNT(*) AS bids_submitted
            FROM bid_incoming
            WHERE (
                LOWER(COALESCE(bid_status,'')) IN ('submitted','under review','under_review')
                OR LOWER(COALESCE(results,'')) LIKE '%%won%%'
                OR LOWER(COALESCE(results,'')) LIKE '%%award%%'
            )
              AND LOWER(COALESCE(results,'')) NOT LIKE '%%lost%%'
            """
        )
    else:
        cur.execute(
            """
            SELECT COUNT(*) AS bids_submitted
            FROM bid_incoming
            WHERE LOWER(COALESCE(state,'')) IN ('submitted','under_review','under review')
            """
        )
    bids_submitted = cur.fetchone()['bids_submitted']

    if has_results:
        cur.execute(
            """
            SELECT COUNT(*) AS bids_won
            FROM bid_incoming
            WHERE LOWER(COALESCE(results,'')) LIKE '%%won%%'
               OR LOWER(COALESCE(results,'')) LIKE '%%award%%'
            """
        )
        bids_won = cur.fetchone()['bids_won']
        cur.execute(
            """
            SELECT COUNT(*) AS bids_lost
            FROM bid_incoming
            WHERE LOWER(COALESCE(results,'')) LIKE '%%lost%%'
            """
        )
        bids_lost = cur.fetchone()['bids_lost']
    else:
        cur.execute("SELECT COUNT(*) AS bids_won FROM bid_incoming WHERE decision = 'WON'")
        bids_won = cur.fetchone()['bids_won']
        cur.execute("SELECT COUNT(*) AS bids_lost FROM bid_incoming WHERE decision = 'LOST'")
        bids_lost = cur.fetchone()['bids_lost']

    try:
        _ensure_bid_assign_meta_table()
        _ensure_bid_incoming_project_code_column(cur)
        bid_ids = []
        bid_gid_map = {}
        g_ids = []
        for bid in (bid_incoming_data or []):
            bid_id = bid.get('id') or bid.get('b_id')
            try:
                bid_id = int(bid_id)
            except Exception:
                bid_id = None
            if bid_id:
                bid_ids.append(bid_id)
            try:
                gid = int(bid.get('g_id') or bid.get('gid') or bid.get('go_id') or 0)
            except Exception:
                gid = None
            if gid:
                g_ids.append(gid)
                bid_gid_map[bid_id] = gid
        g_ids = [g for g in (bid_gid_map.values() or []) if g]
        meta_map = {}
        code_map = {}
        if g_ids:
            meta_placeholders = ",".join(["%s"] * len(g_ids))
            cur.execute(
                f"SELECT g_id, data FROM bid_assign_meta WHERE g_id IN ({meta_placeholders})",
                tuple(g_ids),
            )
            for row in (cur.fetchall() or []):
                try:
                    meta = json.loads(row.get('data') or "{}")
                except Exception:
                    meta = {}
                meta_map[int(row.get('g_id'))] = meta
                code = (meta.get('ik_project_code') or '').strip()
                if code:
                    code_map[int(row.get('g_id'))] = code
        for bid in (bid_incoming_data or []):
            bid_id = bid.get('id') or bid.get('b_id')
            try:
                bid_id = int(bid_id)
            except Exception:
                bid_id = None
            gid = bid_gid_map.get(bid_id)
            if gid and gid in code_map:
                bid['ik_project_code'] = code_map[gid]
                _set_bid_incoming_project_code(cur, bid_id, code_map[gid])
                continue
            code = (bid.get('ik_project_code') or '').strip()
            if code:
                continue
            meta = meta_map.get(gid) or {}
            scope_text = bid.get('scope') or ''
            type_text = bid.get('type') or ''
            if gid:
                try:
                    code = _ensure_ik_project_code(cur, gid, meta, scope_text, type_text)
                    if code:
                        bid['ik_project_code'] = code
                except Exception:
                    code = ''
            if not code:
                prefix = _infer_ik_project_prefix(scope_text, type_text)
                if prefix:
                    seq_num = _next_ik_project_number(cur, prefix)
                    if seq_num:
                        code = f"IK-P/{prefix}/{seq_num:06d}"
                        bid['ik_project_code'] = code
            if code:
                _set_bid_incoming_project_code(cur, bid_id, code)
        try:
            mysql.connection.commit()
        except Exception:
            mysql.connection.rollback()
    except Exception:
        pass
    
    cur.close()

    return render_template('bid_analyzer_landing.html', bid_cards={
        'total_bids': total_bids,
        'bids_go': bids_go,
        'bids_no_go': bids_no_go,
        'bids_submitted': bids_submitted,
        'bids_won': bids_won,
        'bids_lost': bids_lost
    }, bid_incoming_data=bid_incoming_data)


@app.route('/bid-analyzer/open')
@login_required
def bid_analyzer_streamlit_open():
    user_role = getattr(current_user, 'role', '').lower()
    is_top_admin = user_role in ['top_level_admin', 'top level admin']
    if not current_user.is_admin and not is_top_admin and not check_module_access_db('bid_analyzer'):
        return render_template(
            'access_denied.html',
            message="You don't have permission to access the Bid Analyzer.",
            module="Bid Analyzer"
        ), 403
    streamlit_url = app.config.get('BID_ANALYZER_STREAMLIT_URL') or 'http://localhost:8501'
    # Preserve query params (e.g. ?popup=1) when redirecting to Streamlit.
    try:
        qs = request.query_string.decode('utf-8', errors='ignore').lstrip('?')
    except Exception:
        qs = ''
    if qs:
        streamlit_url = f"{streamlit_url}{'&' if '?' in streamlit_url else '?'}{qs}"
    return redirect(streamlit_url)


@app.route('/bid-analyzer/latest-id')
@login_required
def bid_analyzer_latest_id():
    user_role = getattr(current_user, 'role', '').lower()
    is_top_admin = user_role in ['top_level_admin', 'top level admin']
    if not current_user.is_admin and not is_top_admin and not check_module_access_db('bid_analyzer'):
        return jsonify({'latest_id': 0})
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SELECT MAX(id) AS latest_id FROM bid_incoming")
        row = cur.fetchone() or {}
        latest_id = int(row.get('latest_id') or 0)
    except Exception:
        latest_id = 0
    finally:
        try:
            cur.close()
        except Exception:
            pass
    return jsonify({'latest_id': latest_id})


def _bid_analyzer_batch_already_processed(batch_label: str) -> bool:
    if not batch_label:
        return False
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute(
            "SELECT 1 FROM evaluation_runs WHERE file_name = %s ORDER BY created_at DESC LIMIT 1",
            (batch_label,),
        )
        return cur.fetchone() is not None
    except Exception:
        return False
    finally:
        try:
            cur.close()
        except Exception:
            pass


def _start_bid_analyzer_job(file_paths: list[str], batch_label: str | None = None) -> str:
    script_path = Path(app.root_path) / 'appcopy copy 5.py'
    if not script_path.is_file():
        raise FileNotFoundError('Analyzer script not found: appcopy copy 5.py')

    job_id = uuid.uuid4().hex
    log_dir = Path(app.root_path) / 'logs'
    log_dir.mkdir(parents=True, exist_ok=True)
    log_path = log_dir / f"bid_analyzer_job_{job_id}.log"

    cmd = [sys.executable, str(script_path), '--batch', '--files', *file_paths]
    if batch_label:
        cmd.extend(['--batch-label', batch_label])

    with open(log_path, 'w', encoding='utf-8', errors='replace') as logf:
        env = os.environ.copy()
        env['BID_ANALYZER_CLI'] = '1'
        env['MYSQL_HOST'] = str(app.config.get('MYSQL_HOST', env.get('MYSQL_HOST', 'localhost')))
        env['MYSQL_USER'] = str(app.config.get('MYSQL_USER', env.get('MYSQL_USER', 'root')))
        env['MYSQL_PASSWORD'] = str(app.config.get('MYSQL_PASSWORD', env.get('MYSQL_PASSWORD', '')))
        env['MYSQL_DB'] = str(app.config.get('MYSQL_DB', env.get('MYSQL_DB', 'esco')))
        env.setdefault('MYSQL_CONNECT_TIMEOUT', '5')
        subprocess.Popen(
            cmd,
            stdout=logf,
            stderr=subprocess.STDOUT,
            cwd=str(Path(app.root_path)),
            env=env,
        )

    return job_id


def _normalize_upload_parts(filename: str) -> list[str]:
    parts = re.split(r"[\\/]+", filename or "")
    cleaned = [p for p in parts if p and p not in (".", "..")]
    safe_parts = []
    for part in cleaned:
        safe = secure_filename(part) or "file"
        safe_parts.append(safe)
    return safe_parts


def _derive_batch_label_from_parts(parts: list[str]) -> str:
    if len(parts) >= 3:
        return parts[1]
    if len(parts) == 2:
        return parts[0]
    return "UPLOAD"


def _relative_parts_for_storage(parts: list[str]) -> list[str]:
    if len(parts) >= 3:
        return parts[1:]
    return parts


@app.route('/bid-analyzer/analyze-upload', methods=['POST'])
@login_required
def bid_analyzer_analyze_upload():
    def _wants_json() -> bool:
        try:
            accept = (request.headers.get('Accept') or '').lower()
            if 'application/json' in accept:
                return True
        except Exception:
            pass
        return (request.headers.get('X-Requested-With') or '') == 'XMLHttpRequest'

    user_role = getattr(current_user, 'role', '').lower()
    is_top_admin = user_role in ['top_level_admin', 'top level admin']

    if not current_user.is_admin and not is_top_admin and not check_module_access_db('bid_analyzer'):
        if _wants_json():
            return jsonify({'success': False, 'error': "You don't have permission to access the Bid Analyzer."}), 403
        return render_template(
            'access_denied.html',
            message="You don't have permission to access the Bid Analyzer.",
            module="Bid Analyzer"
        ), 403

    files = request.files.getlist('rfp_files')
    files = [f for f in (files or []) if f and getattr(f, 'filename', '')]
    if not files:
        if _wants_json():
            return jsonify({'success': False, 'error': 'Please select one or more files to upload.'}), 400
        flash('Please select one or more files to upload.', 'error')
        return redirect(url_for('bid_analyzer'))

    jobs_root = Path(app.root_path) / 'uploads' / '_web_bid_analyzer_jobs'
    jobs_root.mkdir(parents=True, exist_ok=True)
    job_root = jobs_root / uuid.uuid4().hex
    job_root.mkdir(parents=True, exist_ok=True)

    is_folder_upload = any(("/" in (f.filename or "")) or ("\\" in (f.filename or "")) for f in files)
    saved_paths: list[str] = []
    saved_groups: dict[str, list[str]] = {}
    started_jobs: list[str] = []
    errors: list[str] = []
    try:
        # Best-effort cleanup of old job folders (keeps disk tidy without needing a scheduler)
        try:
            cutoff = datetime.utcnow().timestamp() - (7 * 24 * 60 * 60)
            for child in jobs_root.iterdir():
                if not child.is_dir():
                    continue
                try:
                    if child.stat().st_mtime < cutoff:
                        shutil.rmtree(str(child), ignore_errors=True)
                except Exception:
                    pass
        except Exception:
            pass

        for f in files:
            filename = f.filename or ''
            if not filename.strip():
                continue

            if is_folder_upload:
                parts = _normalize_upload_parts(filename)
                if not parts:
                    continue
                rel_parts = _relative_parts_for_storage(parts)
                out_path = job_root.joinpath(*rel_parts)
                out_path.parent.mkdir(parents=True, exist_ok=True)
                f.save(str(out_path))
                saved_paths.append(str(out_path))
                batch_label = _derive_batch_label_from_parts(parts)
                saved_groups.setdefault(batch_label, []).append(str(out_path))
            else:
                safe_name = secure_filename(filename)
                if not safe_name:
                    continue
                out_path = job_root / safe_name
                f.save(str(out_path))
                saved_paths.append(str(out_path))

        if not saved_paths:
            if _wants_json():
                return jsonify({'success': False, 'error': 'No valid files were uploaded.'}), 400
            flash('No valid files were uploaded.', 'error')
            return redirect(url_for('bid_analyzer'))

        if is_folder_upload:
            for batch_label, group_paths in saved_groups.items():
                try:
                    job_id = _start_bid_analyzer_job(group_paths, batch_label=batch_label)
                    started_jobs.append(job_id)
                except Exception as e:
                    errors.append(f'Upload/analyze error for "{batch_label}": {str(e)}')
            if started_jobs:
                msg = f'Upload received. Analysis started for {len(started_jobs)} folder(s).'
                if _wants_json():
                    return jsonify({'success': True, 'job_ids': started_jobs, 'message': msg}), 200
                flash(f'{msg} Refresh in a few minutes to see results.', 'success')
            elif errors and _wants_json():
                return jsonify({'success': False, 'error': errors[0]}), 500
        else:
            job_id = _start_bid_analyzer_job(saved_paths)
            started_jobs.append(job_id)
            msg = 'Upload received. Analysis started in background.'
            if _wants_json():
                return jsonify({'success': True, 'job_ids': [job_id], 'message': msg}), 200
            flash(f'{msg} (job {job_id}). Refresh in a few minutes to see results.', 'success')

    except Exception as e:
        if _wants_json():
            return jsonify({'success': False, 'error': f'Upload/analyze error: {str(e)}'}), 500
        flash(f'Upload/analyze error: {str(e)}', 'error')

    # Note: job files are retained for troubleshooting; they are auto-cleaned after 7 days.

    if errors:
        if _wants_json():
            return jsonify({'success': False, 'error': errors[0]}), 500
        for msg in errors[:3]:
            flash(msg, 'error')
    return redirect(url_for('bid_analyzer'))


@app.route('/bid-timeline')
@login_required
def bid_timeline():
    """Deprecated: Bid Timeline page removed. Use overview timeline section."""
    return redirect(url_for('top_admin_overview'))
    # IT Admin and Top Level Admin always have access
    is_top_admin = (get_user_role() or '').lower() == 'topleveladmin'

    if not getattr(current_user, 'is_admin', False) and not is_top_admin and not check_module_access_db('bid_timeline'):
        return render_template(
            'access_denied.html',
            message="You don't have permission to access the Bid Timeline.",
            module="Bid Timeline"
        ), 403

    # Ensure latest GO bids are mirrored into go_bids
    try:
        sync_go_bids()
    except Exception:
        pass

    cur = mysql.connection.cursor(DictCursor)
    # Apply active company context (same filter used across dashboards)
    company_sql_clause, company_params = _company_filter_for_go_bids(cur)
    use_company_fallback = False
    company_params_fallback = tuple()
    if company_sql_clause:
        use_company_fallback = True
        company_params_fallback = company_params + company_params
    active_company_name = None
    try:
        active_company_id = session.get('active_company_id')
    except Exception:
        active_company_id = None
    if active_company_id:
        try:
            cur.execute("SELECT name FROM companies WHERE id=%s", (int(active_company_id),))
            row = cur.fetchone() or {}
            active_company_name = (row.get('name') or None)
        except Exception:
            active_company_name = None

    # ========== BID Timeline Data (same model used by dashboards) ==========
    def _normalize_stage(raw_state: str) -> str:
        s = (raw_state or '').strip().lower()
        mapping = {
            'analyzer': 'analyzer',
            'business': 'business',
            'business dev': 'business',
            'bdm': 'business',
            'design': 'design',
            'operations': 'operations',
            'operation': 'operations',
            'engineer': 'engineer',
            'site_manager': 'engineer',
            'site manager': 'engineer',
            'handover': 'handover',
            'won': 'handover'
        }
        return mapping.get(s, 'analyzer')

    default_stages = ['analyzer', 'business', 'design', 'operations', 'engineer', 'handover']

    stage_exclusions = {}
    custom_stages = {}
    try:
        cur.execute("""
            CREATE TABLE IF NOT EXISTS bid_stage_exclusions (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                stage VARCHAR(120) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_g_stage (g_id, stage)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """)
        cur.execute("""
            CREATE TABLE IF NOT EXISTS bid_custom_stages (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                stage VARCHAR(120) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_g_stage (g_id, stage)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """)
        mysql.connection.commit()
    except Exception:
        # If table creation fails, page should still load with default stages.
        pass

    try:
        cur.execute("SELECT g_id, stage FROM bid_stage_exclusions")
        for rr in (cur.fetchall() or []):
            stage_exclusions.setdefault(rr.get('g_id'), []).append(rr.get('stage'))
    except Exception:
        stage_exclusions = {}

    try:
        cur.execute("SELECT g_id, stage FROM bid_custom_stages")
        for rr in (cur.fetchall() or []):
            custom_stages.setdefault(rr.get('g_id'), []).append(rr.get('stage'))
    except Exception:
        custom_stages = {}

    def stage_progress_pct(stage_key: str) -> int:
        ordered = ['analyzer', 'business', 'design', 'operations', 'engineer', 'handover']
        try:
            idx = ordered.index(stage_key) if stage_key in ordered else 0
            return int(round((idx / (len(ordered) - 1)) * 100)) if len(ordered) > 1 else 0
        except Exception:
            return 0

    def status_texts(stage_key: str):
        stage_statuses = {
            'analyzer': ('BID Under Review', 'Pending Analysis'),
            'business': ('With Business Team', 'In Progress'),
            'design': ('With Design Team', 'In Progress'),
            'operations': ('With Operations', 'In Progress'),
            'engineer': ('With Engineering', 'In Progress'),
            'handover': ('Submitted', 'Completed'),
        }
        return stage_statuses.get(stage_key, ('In Progress', 'Ongoing'))

    def _parse_percent(value) -> int:
        try:
            if value is None:
                return 0
            s = str(value)
            import re
            m = re.search(r"(\d{1,3})", s)
            if m:
                return max(0, min(100, int(m.group(1))))
            s = s.strip().lower()
            if s in ('done', 'completed', 'closed', 'handover', '100%'):
                return 100
            if s in ('in_progress', 'ongoing'):
                return 50
            return 0
        except Exception:
            return 0

    def _compute_stage_map_for_bid(g_id: int) -> dict:
        try:
            cur2 = mysql.connection.cursor(DictCursor)
            cur2.execute("""
                SELECT bc.progress_pct, bc.status, COALESCE(bc.stage, u.role) AS stage_source
                FROM bid_checklists bc
                LEFT JOIN users u ON bc.created_by = u.id
                WHERE bc.g_id = %s
            """, (g_id,))
            rows = cur2.fetchall()
            cur2.close()
            role_to_stage = {
                'business dev': 'business',
                'business development': 'business',
                'bdm': 'business',
                'bde': 'business',
                'design': 'design',
                'design team': 'design',
                'design & marketing': 'design',
                'design and marketing': 'design',
                'marketing': 'design',
                'operations': 'operations',
                'operation': 'operations',
                'ops': 'operations',
                'operations team': 'operations',
                'site manager': 'engineer',
                'site engineer': 'engineer',
                'engineering': 'engineer',
                'engineer': 'engineer',
                'engineering team': 'engineer',
                'handover': 'handover',
                'submitted': 'handover',
                'submit': 'handover',
                'bid analyzer': 'analyzer',
                'analyzer': 'analyzer',
            }
            buckets = {'analyzer': [], 'business': [], 'design': [], 'operations': [], 'engineer': [], 'handover': []}
            for r in rows:
                source = (r.get('stage_source') or '').strip().lower()
                stage = role_to_stage.get(source)
                if not stage and source in buckets:
                    stage = source
                if not stage and source:
                    if 'design' in source or 'marketing' in source:
                        stage = 'design'
                    elif 'business' in source or 'bdm' in source or 'bde' in source:
                        stage = 'business'
                    elif 'operation' in source or 'ops' in source:
                        stage = 'operations'
                    elif 'engineer' in source or 'site' in source:
                        stage = 'engineer'
                    elif 'submit' in source or 'handover' in source or source == 'won':
                        stage = 'handover'
                    elif 'analy' in source:
                        stage = 'analyzer'
                if not stage:
                    continue
                pct = r.get('progress_pct')
                if pct is None:
                    st = (r.get('status') or '').strip().lower()
                    pct = 100 if st in ('completed', 'submitted') else 50 if st in ('in_progress', 'in progress') else 0
                try:
                    pct = max(0, min(100, int(pct)))
                except Exception:
                    pct = 0
                buckets[stage].append(pct)
            def avg(lst):
                return int(round(sum(lst) / len(lst))) if lst else 0
            return {
                'analyzer': avg(buckets['analyzer']),
                'business': avg(buckets['business']),
                'design': avg(buckets['design']),
                'operations': avg(buckets['operations']),
                'engineer': avg(buckets['engineer']),
                'handover': avg(buckets['handover']),
            }
        except Exception:
            return {'analyzer': 0, 'business': 0, 'design': 0, 'operations': 0, 'engineer': 0, 'handover': 0}

    go_projects = []
    meta_dept_map = {}
    try:
        cur.execute(
            """
            SELECT gb.g_id,
                   gb.b_name,
                   gb.due_date,
                   gb.state,
                   gb.type,
                   gb.company,
                   gb.decision,
                   gb.summary,
                   gb.scoring AS progress,
                   wps.pr_completion_status AS work_status,
                   wps.dept_bde,
                   wps.dept_m_d,
                   wps.dept_op,
                   wps.dept_site,
                   wbr.closure_status AS project_status,
                   wbr.work_progress_status AS work_progress_status
            FROM go_bids gb
            LEFT JOIN bid_incoming bi ON bi.id = gb.id
            LEFT JOIN bid_assign ba ON ba.g_id = gb.g_id
            LEFT JOIN win_lost_results wlr ON wlr.a_id = ba.a_id OR wlr.g_id = gb.g_id
            LEFT JOIN won_bids_result wbr ON wbr.w_id = wlr.w_id
            LEFT JOIN work_progress_status wps ON wps.won_id = wbr.won_id
            WHERE 1=1
            """ + ("""
              AND (
                LOWER(COALESCE(gb.company,'')) LIKE %s
                OR (LOWER(COALESCE(gb.company,'')) = '' AND LOWER(COALESCE(bi.comp_name,'')) LIKE %s)
              )
            """ if use_company_fallback else company_sql_clause) + """
            ORDER BY gb.due_date ASC
            """
            ,
            (company_params_fallback if use_company_fallback else company_params)
        )
        go_rows = cur.fetchall() or []
        if not go_rows:
            go_rows = _basic_bid_timeline_rows(cur, company_sql_clause, company_params, limit=200)
        if not go_rows:
            go_rows = _basic_bid_timeline_rows(cur, "", tuple(), limit=200)
        # Ensure stored team progress exists for these bids.
        try:
            for rr in (go_rows or []):
                gid = rr.get('g_id')
                if gid:
                    _recalc_bid_team_progress(cur, int(gid))
            try:
                mysql.connection.commit()
            except Exception:
                pass
        except Exception:
            pass
        if not go_rows:
            try:
                cur.execute(
                    """
                    SELECT
                        bi.id AS g_id,
                        bi.b_name,
                        bi.due_date,
                        bi.state,
                        bi.type,
                        bi.comp_name AS company,
                        bi.decision,
                        bi.summary,
                        bi.scoring AS progress,
                        NULL AS work_status,
                        NULL AS dept_bde,
                        NULL AS dept_m_d,
                        NULL AS dept_op,
                        NULL AS dept_site,
                        NULL AS project_status,
                        NULL AS work_progress_status
                    FROM bid_incoming bi
                    WHERE UPPER(COALESCE(bi.decision,'')) <> 'NO GO'
                    ORDER BY bi.due_date ASC
                    """
                )
                go_rows = cur.fetchall() or []
            except Exception:
                go_rows = []
        # Ensure assigned-task bids also appear on the timeline.
        go_rows = _augment_go_rows_with_assigned_meta(
            cur,
            go_rows,
            active_company_name=active_company_name,
            max_total=None,
            include_closed=True,
        )
        if filter_selected_depts and go_rows:
            try:
                g_ids = [int(r.get('g_id')) for r in go_rows if r.get('g_id')]
                if g_ids:
                    _ensure_bid_assign_meta_table()
                    meta_placeholders = ",".join(["%s"] * len(g_ids))
                    cur.execute(
                        f"SELECT g_id, data FROM bid_assign_meta WHERE g_id IN ({meta_placeholders})",
                        tuple(g_ids),
                    )
                    for row in (cur.fetchall() or []):
                        try:
                            meta = json.loads(row.get('data') or "{}")
                        except Exception:
                            meta = {}
                        meta_dept_map[int(row.get('g_id'))] = meta
            except Exception:
                meta_dept_map = {}

        for r in go_rows:
            bid_id = r.get('g_id')
            stage_key = _normalize_stage(r.get('state'))

            excluded = set(stage_exclusions.get(bid_id, []) or [])
            customs = [s for s in (custom_stages.get(bid_id, []) or []) if s not in excluded]
            if filter_selected_depts:
                meta = meta_dept_map.get(bid_id) or {}
                raw_depts = meta.get('departments') or []
                if not raw_depts:
                    try:
                        raw_depts = list({
                            (c or {}).get('dept')
                            for c in (meta.get('checklist') or [])
                            if isinstance(c, dict) and (c.get('dept') or '')
                        })
                    except Exception:
                        raw_depts = []
                stage_set = []
                for d in (raw_depts or []):
                    try:
                        nd = _normalize_department_key(d)
                    except Exception:
                        nd = (d or '').strip().lower()
                    if nd in ('business', 'design', 'operations', 'engineer'):
                        stage_set.append(nd)
                # Preserve canonical order
                stages = [s for s in default_stages if s in stage_set]
                # Ensure current stage is visible (especially analyzer/handover)
                if stage_key and stage_key not in stages:
                    if stage_key == 'analyzer':
                        stages = [stage_key] + stages
                    else:
                        stages = stages + [stage_key]
                # Apply exclusions if any
                stages = [s for s in stages if s not in excluded]
                if not stages:
                    stages = default_stages.copy()
            else:
                stages = [s for s in default_stages if s not in excluded] + [s for s in customs if s not in default_stages]
                if not stages:
                    stages = default_stages.copy()

            if stages and stage_key in stages:
                idx = stages.index(stage_key)
                stage_progress = int(round((idx / (max(1, len(stages) - 1))) * 100))
            else:
                stage_progress = stage_progress_pct(stage_key)

            item_pct = stage_progress_pct(stage_key)
            proj_status, work_status = status_texts(stage_key)

            task_stage_map = _compute_stage_map_for_bid(bid_id)
            if any(v > 0 for v in task_stage_map.values()):
                stage_progress_map = {
                    'analyzer': 100,
                    'business': task_stage_map.get('business', 0),
                    'design': task_stage_map.get('design', 0),
                    'operations': task_stage_map.get('operations', 0),
                    'engineer': task_stage_map.get('engineer', 0),
                    'handover': 0,
                }
            else:
                stage_progress_map = {
                    'analyzer': 100,
                    'business': _parse_percent(r.get('dept_bde')),
                    'design': _parse_percent(r.get('dept_m_d')),
                    'operations': _parse_percent(r.get('dept_op')),
                    'engineer': _parse_percent(r.get('dept_site')),
                    'handover': 100 if (r.get('project_status') or '').strip().lower() in ('closed', 'completed', 'handover', 'done') else 0,
                }

            if not any(v > 0 for v in stage_progress_map.values()):
                ordered = ['analyzer', 'business', 'design', 'operations', 'engineer', 'handover']
                cur_idx = ordered.index(stage_key) if stage_key in ordered else 0
                estimated = {}
                for i, s in enumerate(ordered):
                    if i < cur_idx:
                        estimated[s] = 100
                    elif i == cur_idx:
                        estimated[s] = 40
                    else:
                        estimated[s] = 0
                estimated['analyzer'] = 100
                stage_progress_map.update(estimated)

            try:
                # Keep only stages currently displayed (overview filter)
                stage_progress_map = {k: v for k, v in (stage_progress_map or {}).items() if k in stages}
                for st in stages:
                    stage_progress_map.setdefault(st, 0)
            except Exception:
                pass

            go_projects.append({
                'g_id': bid_id,
                'b_name': r.get('b_name'),
                'company': r.get('company'),
                'state': r.get('state'),
                'stage_key': stage_key,
                'stage_progress': stage_progress,
                'stages': stages,
                'current_stage': stage_key,
                'due_date': r.get('due_date'),
                'type': r.get('type'),
                'decision': r.get('decision'),
                'project_status': proj_status,
                'work_status': work_status,
                'summary': r.get('summary'),
                'work_progress_pct': item_pct,
                'stage_progress_map': stage_progress_map,
            })
    except Exception:
        go_projects = []
    finally:
        try:
            cur.close()
        except Exception:
            pass

    go_projects_top5 = go_projects[:5]
    go_projects_more = go_projects[5:]

    # Stage display name mapping (kept consistent with dashboards)
    def get_stage_display_name(stage_key):
        mapping = {
            'analyzer': 'BID Analyzer',
            'business': 'Business Development',
            'design': 'Design & Marketing',
            'operations': 'Operation Team',
            'engineer': 'Engineering Team',
            'handover': 'Submitted'
        }
        try:
            return mapping.get((stage_key or '').lower(), (stage_key or '').title())
        except Exception:
            return stage_key

    embed_mode = (request.args.get('embed') or '').strip().lower() in ('1', 'true', 'yes')
    dark_mode = (request.args.get('dark') or '').strip().lower() in ('1', 'true', 'yes')

    return render_template(
        'bid_timeline.html',
        go_projects_top5=go_projects_top5,
        go_projects_more=go_projects_more,
        get_stage_display_name=get_stage_display_name,
        embed_mode=embed_mode,
        dark_mode=dark_mode,
    )
def _normalize_bid_status(value: str) -> str | None:
    val = (value or '').strip().lower()
    allowed = {'not started', 'started', 'under review', 'submitted'}
    return val if val in allowed else None


def _normalize_bid_result(value: str) -> str | None:
    val = (value or '').strip().lower()
    allowed = {'won', 'lost'}
    return val if val in allowed else None


def _get_bid_analyzer_sidebar() -> str:
    sidebar = (request.form.get('sidebar') or request.args.get('sidebar') or '').strip().lower()
    return 'minimal' if sidebar == 'minimal' else ''


def _redirect_bid_analyzer():
    sidebar = _get_bid_analyzer_sidebar()
    return redirect(url_for('bid_analyzer', sidebar=sidebar) if sidebar else url_for('bid_analyzer'))


# --- Bid Incoming CRUD Routes ---
@app.route('/bid-analyzer/create', methods=['POST'])
@login_required
def create_bid_incoming():
    if not current_user.is_admin and not check_module_access_db('bid_analyzer'):
        return "Access Denied", 403
    
    try:
        cur = mysql.connection.cursor()
        
        b_name = request.form.get('b_name', '').strip()
        issue_date = request.form.get('issue_date', '').strip()
        due_date = request.form.get('due_date', '').strip()
        state = request.form.get('state', '').strip()
        scope = request.form.get('scope', '').strip()
        type_val = request.form.get('type', '').strip()
        scoring = int(request.form.get('scoring', 0)) if request.form.get('scoring') else None
        comp_name = request.form.get('comp_name', '').strip()
        decision = request.form.get('decision', '').strip()
        bid_status = _normalize_bid_status(request.form.get('bid_status', ''))
        bid_result = _normalize_bid_result(request.form.get('results', ''))
        summary = request.form.get('summary', '').strip()
        
        if not b_name or not issue_date or not due_date:
            return 'Bid name, incoming date and due date are required', 400
        
        cur.execute("""
            INSERT INTO bid_incoming (b_name, issue_date, due_date, state, scope, type, scoring, comp_name, decision, bid_status, results, summary)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """, (b_name, issue_date, due_date, state, scope, type_val, scoring, comp_name, decision, bid_status, bid_result, summary))
        
        bid_id = cur.lastrowid
        mysql.connection.commit()
        
        # Automatically sync GO decisions from bid_incoming to go_bids
        if (decision or '').upper() == 'GO':
            cur2 = mysql.connection.cursor(DictCursor)
            cur2.execute("SELECT g_id FROM go_bids WHERE id=%s", (bid_id,))
            row = cur2.fetchone()
            args = (b_name, due_date, state if state else 'business', scope, type_val, scoring, comp_name, decision, summary)
            if row:
                cur2.execute("""UPDATE go_bids SET b_name=%s,due_date=%s,state=%s,scope=%s,
                                type=%s,scoring=%s,company=%s,decision=%s,summary=%s WHERE id=%s""", (*args, bid_id))
            else:
                cur2.execute("""INSERT INTO go_bids (id,b_name,due_date,state,scope,type,scoring,company,decision,summary)
                                VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)""",
                             (bid_id, *args))
            mysql.connection.commit()
            cur2.close()
            log_write('sync', f"Auto-synced GO bid '{b_name}' (id={bid_id}) from bid_incoming to go_bids")
        
        # Optional: upload and link multiple bid documents at create time.
        upload_files = request.files.getlist('rfp_files')
        upload_files = [f for f in (upload_files or []) if f and getattr(f, 'filename', '').strip()]
        uploaded_count = 0
        if upload_files:
            g_id_val = None
            try:
                cur_gid = mysql.connection.cursor(DictCursor)
                cur_gid.execute("SELECT g_id FROM go_bids WHERE id=%s LIMIT 1", (bid_id,))
                g_row = cur_gid.fetchone() or {}
                g_id_val = g_row.get('g_id')
            except Exception:
                g_id_val = None
            finally:
                try:
                    cur_gid.close()
                except Exception:
                    pass

            folder_key = str(g_id_val) if g_id_val else f"bid_{bid_id}"
            folder = os.path.join(app.root_path, 'static', 'bid_documents', folder_key)
            os.makedirs(folder, exist_ok=True)

            cur_files = mysql.connection.cursor(DictCursor)
            try:
                _ensure_uploaded_rfp_table_exists(cur_files)
                cur_files.execute("SHOW COLUMNS FROM uploaded_rfp_files")
                available_columns = {row['Field'] for row in (cur_files.fetchall() or []) if 'Field' in row}

                def add_col(cols, vals, col_name, val):
                    if col_name in available_columns:
                        cols.append(col_name)
                        vals.append(val)

                for f in upload_files:
                    safe_original = secure_filename(f.filename) or f"file_{uuid.uuid4().hex}.bin"
                    saved_filename = f"{uuid.uuid4().hex}_{safe_original}"
                    file_path = os.path.join(folder, saved_filename)
                    try:
                        f.save(file_path)
                    except Exception:
                        continue
                    try:
                        file_size = os.path.getsize(file_path)
                    except Exception:
                        file_size = 0

                    cols = []
                    vals = []
                    add_col(cols, vals, 'bid_id', bid_id)
                    add_col(cols, vals, 'g_id', g_id_val)
                    add_col(cols, vals, 'filename', safe_original)
                    add_col(cols, vals, 'original_filename', f.filename)
                    add_col(cols, vals, 'saved_filename', saved_filename)
                    add_col(cols, vals, 'file_path', file_path)
                    add_col(cols, vals, 'file_size', file_size)
                    add_col(cols, vals, 'file_type', (f.mimetype or ''))
                    add_col(cols, vals, 'uploaded_by', getattr(current_user, 'id', None))
                    if not cols:
                        continue
                    placeholders = ','.join(['%s'] * len(cols))
                    cur_files.execute(
                        f"INSERT INTO uploaded_rfp_files ({','.join(cols)}) VALUES ({placeholders})",
                        tuple(vals),
                    )
                    uploaded_count += 1

                mysql.connection.commit()
            except Exception:
                mysql.connection.rollback()
            finally:
                try:
                    cur_files.close()
                except Exception:
                    pass

        cur.close()
        log_write('create', f"table=bid_incoming, id={bid_id}")
        if uploaded_count > 0:
            flash(f'Bid "{b_name}" created successfully with {uploaded_count} attachment(s)!', 'success')
        else:
            flash(f'Bid "{b_name}" created successfully!', 'success')
        
    except Exception as e:
        mysql.connection.rollback()
        cur.close()
        flash(f'Error creating bid: {str(e)}', 'error')
    
    return _redirect_bid_analyzer()

@app.route('/bid-analyzer/update/<int:bid_id>', methods=['POST'])
@login_required
def update_bid_incoming(bid_id):
    if not current_user.is_admin and not check_module_access_db('bid_analyzer'):
        return "Access Denied", 403
    
    try:
        cur = mysql.connection.cursor()
        
        # Check if bid exists
        cur.execute("SELECT * FROM bid_incoming WHERE id=%s", (bid_id,))
        bid = cur.fetchone()
        if not bid:
            cur.close()
            return "Bid not found", 404
        
        b_name = request.form.get('b_name', bid['b_name']).strip()
        issue_date = request.form.get('issue_date', str(bid.get('issue_date') or '')).strip()
        due_date = request.form.get('due_date', str(bid['due_date'])).strip()
        state = request.form.get('state', bid['state'] or '').strip()
        scope = request.form.get('scope', bid['scope'] or '').strip()
        type_val = request.form.get('type', bid['type'] or '').strip()
        scoring = int(request.form.get('scoring', 0)) if request.form.get('scoring') else bid['scoring']
        comp_name = request.form.get('comp_name', bid['comp_name'] or '').strip()
        decision = request.form.get('decision', bid['decision'] or '').strip()
        bid_status = _normalize_bid_status(request.form.get('bid_status', bid.get('bid_status') or ''))
        bid_result = _normalize_bid_result(request.form.get('results', bid.get('results') or ''))
        summary = request.form.get('summary', bid['summary'] or '').strip()
        
        cur.execute("""
            UPDATE bid_incoming 
            SET b_name=%s, issue_date=%s, due_date=%s, state=%s, scope=%s, type=%s, scoring=%s, comp_name=%s, decision=%s,
                bid_status=%s, results=%s, summary=%s
            WHERE id=%s
        """, (b_name, issue_date, due_date, state, scope, type_val, scoring, comp_name, decision, bid_status, bid_result, summary, bid_id))
        
        mysql.connection.commit()
        
        # Automatically sync GO decisions from bid_incoming to go_bids
        if (decision or '').upper() == 'GO':
            cur2 = mysql.connection.cursor(DictCursor)
            cur2.execute("SELECT g_id FROM go_bids WHERE id=%s", (bid_id,))
            row = cur2.fetchone()
            args = (b_name, due_date, state if state else 'business', scope, type_val, scoring, comp_name, decision, summary)
            if row:
                cur2.execute("""UPDATE go_bids SET b_name=%s,due_date=%s,state=%s,scope=%s,
                                type=%s,scoring=%s,company=%s,decision=%s,summary=%s WHERE id=%s""", (*args, bid_id))
            else:
                cur2.execute("""INSERT INTO go_bids (id,b_name,due_date,state,scope,type,scoring,company,decision,summary)
                                VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)""",
                             (bid_id, *args))
            mysql.connection.commit()
            cur2.close()
            log_write('sync', f"Auto-synced GO bid '{b_name}' (id={bid_id}) from bid_incoming to go_bids")
        else:
            # If decision changed from GO to something else, remove from go_bids
            # unless this bid is actively managed in the assign modal.
            cur2 = mysql.connection.cursor(DictCursor)
            try:
                keep_go = False
                g_row = None
                try:
                    cur2.execute("SELECT g_id FROM go_bids WHERE id=%s", (bid_id,))
                    g_row = cur2.fetchone()
                except Exception:
                    g_row = None
                try:
                    _ensure_bid_assign_meta_table()
                    g_id = (g_row or {}).get('g_id')
                    if g_id:
                        cur2.execute(
                            "SELECT 1 FROM bid_assign_meta WHERE g_id IN (%s,%s) LIMIT 1",
                            (int(g_id), int(bid_id))
                        )
                    else:
                        cur2.execute("SELECT 1 FROM bid_assign_meta WHERE g_id=%s LIMIT 1", (bid_id,))
                    keep_go = cur2.fetchone() is not None
                except Exception:
                    keep_go = False

                if not keep_go:
                    cur2.execute("DELETE FROM go_bids WHERE id=%s", (bid_id,))
                    mysql.connection.commit()
                    log_write('sync', f"Removed bid '{b_name}' (id={bid_id}) from go_bids (decision changed from GO)")
            finally:
                cur2.close()
        
        cur.close()
        log_write('update', f"table=bid_incoming, id={bid_id}")
        flash(f'Bid "{b_name}" updated successfully!', 'success')
        
    except Exception as e:
        mysql.connection.rollback()
        cur.close()
        flash(f'Error updating bid: {str(e)}', 'error')
    
    return _redirect_bid_analyzer()

@app.route('/api/bid-analyzer/update-status', methods=['POST'])
@login_required
def bid_analyzer_update_status():
    user_role = getattr(current_user, 'role', '').lower()
    is_top_admin = user_role in ['top_level_admin', 'top level admin']
    if not current_user.is_admin and not is_top_admin and not check_module_access_db('bid_analyzer'):
        return jsonify({'success': False, 'error': 'Access denied'}), 403

    payload = request.get_json(silent=True) or {}
    bid_id = payload.get('bid_id')
    bid_status = _normalize_bid_status(payload.get('bid_status', ''))

    if not bid_id:
        return jsonify({'success': False, 'error': 'Missing bid_id'}), 400

    cur = mysql.connection.cursor()
    try:
        cur.execute("UPDATE bid_incoming SET bid_status=%s WHERE id=%s", (bid_status, bid_id))
        mysql.connection.commit()
        return jsonify({'success': True, 'bid_status': bid_status or ''})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        cur.close()


@app.route('/api/bid-analyzer/update-result', methods=['POST'])
@login_required
def bid_analyzer_update_result():
    user_role = getattr(current_user, 'role', '').lower()
    is_top_admin = user_role in ['top_level_admin', 'top level admin']
    if not current_user.is_admin and not is_top_admin and not check_module_access_db('bid_analyzer'):
        return jsonify({'success': False, 'error': 'Access denied'}), 403

    payload = request.get_json(silent=True) or {}
    bid_id = payload.get('bid_id')
    bid_result = _normalize_bid_result(payload.get('results', ''))

    if not bid_id:
        return jsonify({'success': False, 'error': 'Missing bid_id'}), 400

    cur = mysql.connection.cursor()
    try:
        cur.execute("UPDATE bid_incoming SET results=%s WHERE id=%s", (bid_result, bid_id))
        mysql.connection.commit()
        # Auto-assign won bids to a project manager (if unassigned).
        try:
            if _is_won_bid_status(bid_result):
                # Ensure GO + won syncs are up to date (creates win_lost_results + timeline).
                try:
                    sync_go_bids()
                except Exception:
                    pass

                g_id = None
                try:
                    g_id, _ = _ensure_go_bid_from_incoming(int(bid_id))
                except Exception:
                    g_id = None
                if g_id:
                    cur2 = mysql.connection.cursor(DictCursor)
                    try:
                        _ensure_project_manager_assignments_table(cur2)
                        cur2.execute("SELECT w_id FROM win_lost_results WHERE g_id=%s LIMIT 1", (int(g_id),))
                        row = cur2.fetchone() or {}
                        w_id = row.get('w_id')
                        if w_id:
                            cur2.execute("SELECT 1 FROM project_manager_assignments WHERE project_id=%s LIMIT 1", (int(w_id),))
                            if not cur2.fetchone():
                                # Prefer explicit Project Manager role; fallback to any manager-like user.
                                cur2.execute(
                                    """
                                    SELECT id, full_name, email
                                    FROM users
                                    WHERE is_active=1
                                      AND (
                                        LOWER(REPLACE(REPLACE(role,'_',''),' ','')) = 'projectmanager'
                                        OR LOWER(role) LIKE '%project manager%'
                                      )
                                    ORDER BY full_name ASC, email ASC
                                    LIMIT 1
                                    """
                                )
                                pm = cur2.fetchone()
                                if not pm:
                                    pm_list = _fetch_project_manager_users(cur2, None) or []
                                    pm = pm_list[0] if pm_list else None
                                if pm:
                                    cur2.execute(
                                        """
                                        INSERT INTO project_manager_assignments (project_id, g_id, manager_user_id, assigned_by_user_id)
                                        VALUES (%s, %s, %s, %s)
                                        """,
                                        (int(w_id), int(g_id), int(pm.get('id')), int(getattr(current_user, 'id', 0))),
                                    )
                                    mysql.connection.commit()
                    finally:
                        try:
                            cur2.close()
                        except Exception:
                            pass
        except Exception:
            pass
        return jsonify({'success': True, 'results': bid_result or ''})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        cur.close()

@app.route('/bid-analyzer/delete/<int:bid_id>')
@login_required
def delete_bid_incoming(bid_id):
    if not current_user.is_admin and not check_module_access_db('bid_analyzer'):
        return "Access Denied", 403
    
    try:
        cur = mysql.connection.cursor()
        
        # Get bid name before deletion
        cur.execute("SELECT b_name FROM bid_incoming WHERE id=%s", (bid_id,))
        bid = cur.fetchone()
        if not bid:
            cur.close()
            return "Bid not found", 404
        
        bid_name = bid['b_name']
        
        # Delete bid
        cur.execute("DELETE FROM bid_incoming WHERE id=%s", (bid_id,))
        mysql.connection.commit()
        cur.close()
        
        log_write('delete', f"table=bid_incoming, id={bid_id}")
        flash(f'Bid "{bid_name}" deleted successfully!', 'success')
        
    except Exception as e:
        mysql.connection.rollback()
        cur.close()
        flash(f'Error deleting bid: {str(e)}', 'error')
    
    return _redirect_bid_analyzer()

def send_assignment_email(email_to: str, bid_name: str, depart: str, person_name: str, company: str):
    subject = f"Bid Assignment: {bid_name or ''}"
    body = f"You have been assigned to bid '{bid_name or ''}' for company '{company or ''}'.\nDepartment: {depart}\nAssignee: {person_name}\n\nPlease log in to the ESCO suite to proceed."
    message = f"Subject: {subject}\n\n{body}"
    context = ssl.create_default_context()
    server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)
    try:
        server.starttls(context=context)
        server.login(EMAIL_FROM, EMAIL_PASSWORD)
        server.sendmail(EMAIL_FROM, email_to, message)
    finally:
        try:
            server.quit()
        except Exception:
            pass
# --- Employee Management Routes ---
@app.route('/team/<team>/employees')
@login_required
def team_employees(team):
    """Manage employees for a specific team"""
    # Map team names to stages
    team_to_stage = {
        'business': 'business',
        'design': 'design', 
        'operations': 'operations',
        'engineer': 'engineer'
    }
    
    if team not in team_to_stage:
        return "Invalid team", 404
    
    cur = mysql.connection.cursor(DictCursor)
    
    # Get employees for this team
    cur.execute("""
        SELECT e.*, u.email as team_lead_email
        FROM employees e
        LEFT JOIN users u ON e.team_lead_id = u.id
        WHERE e.department = %s AND e.is_active = TRUE
        ORDER BY e.name
    """, (team,))
    employees = cur.fetchall()
    
    # Get team leads. Map team -> acceptable user roles, and for non-admins
    # restrict to the current manager so the dropdown shows their email only.
    roles_for_team = {
        'business': ('business dev', 'business development', 'business', 'bdm'),
        'design': ('design',),
        'operations': ('operations',),
        'engineer': ('site manager', 'site_engineer', 'site engineer', 'engineering', 'engineer'),
    }
    acceptable_roles = roles_for_team.get(team, (team,))
    role_lower = (getattr(current_user, 'role', '') or '').lower()
    is_top_admin = (get_user_role() or '').lower() == 'topleveladmin'
    is_manager_user = role_lower == 'manager'
    if getattr(current_user, 'is_admin', False) or getattr(current_user, 'is_supervisor', False) or is_top_admin or is_manager_user:
        placeholders = ','.join(['%s'] * len(acceptable_roles))
        cur.execute(f"SELECT * FROM users WHERE role IN ({placeholders})", acceptable_roles)
        team_leads = cur.fetchall()
    else:
        # Only the current manager on their own dashboard
        cur.execute("SELECT * FROM users WHERE id=%s", (current_user.id,))
        team_leads = cur.fetchall()
    
    cur.close()
    
    return render_template('team_employees.html', 
                         team=team, 
                         employees=employees, 
                         team_leads=team_leads,
                         user=current_user)

@app.route('/team/<team>/employees/create', methods=['POST'])
@login_required
def create_employee(team):
    """Create a new employee for the team"""
    try:
        name = request.form.get('name', '').strip()
        email = request.form.get('email', '').strip()
        password = request.form.get('password', '').strip()
        # Treat Top Level Admin like admin/supervisor for employee-creation defaults.
        is_top_admin = (get_user_role() or '').lower() == 'topleveladmin'
        is_privileged = bool(getattr(current_user, 'is_admin', False) or getattr(current_user, 'is_supervisor', False) or is_top_admin)
        team_lead_id = request.form.get('team_lead_id') or (current_user.id if not is_privileged else None)
        
        if not name or not email or not password:
            flash('Name, email, and password are required', 'error')
            return redirect(url_for('team_employees', team=team))
        
        cur = mysql.connection.cursor()
        cur.execute("""
            INSERT INTO employees (name, email, password, department, team_lead_id) 
            VALUES (%s, %s, %s, %s, %s)
        """, (name, email, password, team, team_lead_id if team_lead_id else None))
        
        mysql.connection.commit()
        cur.close()
        
        log_write('create_employee', f"Created employee {name} for {team} team")
        flash(f'Employee "{name}" created successfully!', 'success')
        
    except Exception as e:
        mysql.connection.rollback()
        cur.close()
        flash(f'Error creating employee: {str(e)}', 'error')
    
    return redirect(url_for('team_employees', team=team))

@app.route('/employee/<int:employee_id>/detail')
@login_required
def employee_detail(employee_id):
    """View employee details and tasks (for team leads/supervisors/admins)"""
    role_lower = (getattr(current_user, 'role', '') or '').lower()
    is_top_admin = (get_user_role() or '').lower() == 'topleveladmin'
    is_manager_user = role_lower == 'manager'
    is_team_lead_user = getattr(current_user, 'is_team_lead', False) or role_lower in [
        'business dev', 'business development', 'design', 'operations', 'site_engineer', 'site engineer', 'site manager', 'engineering', 'engineer'
    ]
    if not (current_user.is_admin or current_user.is_supervisor or is_top_admin or is_manager_user or is_team_lead_user):
        return "Access Denied - Team Lead or higher access required", 403
    
    cur = mysql.connection.cursor(DictCursor)
    
    # Get employee info
    cur.execute("""
        SELECT e.*, u.email as team_lead_email
        FROM employees e
        LEFT JOIN users u ON e.team_lead_id = u.id
        WHERE e.id = %s
    """, (employee_id,))
    employee = cur.fetchone()
    
    if not employee:
        cur.close()
        return "Employee not found", 404

    # Team leads can only view employees from their own team (unless admin/supervisor/top-admin/manager)
    if is_team_lead_user and not (current_user.is_admin or current_user.is_supervisor or is_top_admin or is_manager_user):
        team_for_role = {
            'business dev': 'business',
            'business development': 'business',
            'design': 'design',
            'operations': 'operations',
            'site_engineer': 'engineer',
            'site engineer': 'engineer',
            'site manager': 'engineer',
            'engineering': 'engineer',
            'engineer': 'engineer',
        }
        allowed_team = team_for_role.get(role_lower)
        emp_team = (employee.get('department') or '').strip().lower()
        if allowed_team and emp_team and allowed_team != emp_team:
            cur.close()
            return "Access Denied - team mismatch", 403
    
    # Get assigned tasks for this employee
    cur.execute("""
        SELECT bc.*, gb.b_name, gb.company, gb.due_date as bid_due_date
        FROM bid_checklists bc
        JOIN go_bids gb ON bc.g_id = gb.g_id
        WHERE bc.assigned_to = %s
        ORDER BY bc.due_date ASC, bc.priority DESC
    """, (employee_id,))
    tasks = cur.fetchall()
    
    # Calculate task statistics
    total_tasks = len(tasks)
    completed_tasks = len([t for t in tasks if (t.get('status') or '').lower() == 'completed'])
    pending_tasks = len([t for t in tasks if (t.get('status') or '').lower() in ('pending', 'rejected')])
    in_progress_tasks = len([t for t in tasks if (t.get('status') or '').lower() in ('in_progress', 'submitted')])
    
    cur.close()
    
    return render_template('employee_detail.html',
                         employee=employee,
                         tasks=tasks,
                         total_tasks=total_tasks,
                         completed_tasks=completed_tasks,
                         pending_tasks=pending_tasks,
                         in_progress_tasks=in_progress_tasks,
                         user=current_user)

@app.route('/employee/<int:employee_id>/dashboard')
def employee_dashboard(employee_id):
    """Employee-specific dashboard showing assigned tasks"""
    is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
    session_emp_id = session.get('employee_id')
    if not is_flask_user and not session_emp_id:
        return redirect(url_for('login'))
    if session_emp_id and int(session_emp_id) != int(employee_id):
        return render_template('access_denied.html', message="You don't have access to Employee Dashboard."), 403
    if is_flask_user and not getattr(current_user, 'is_admin', False) and not check_module_access_db('employee_dashboard'):
        return render_template('access_denied.html', message="You don't have access to Employee Dashboard."), 403
    def _normalize_task_status(v):
        """
        Normalize task status to canonical values used across the app:
        - pending
        - in_progress
        - rejected
        - completed
        """
        s = (v or '').strip().lower()
        s = s.replace('-', ' ').replace('_', ' ')
        s = ' '.join(s.split())
        if s in ('completed', 'complete', 'done', 'finished', 'closed'):
            return 'completed'
        if s in ('rejected', 'reject'):
            return 'rejected'
        if s in ('in progress', 'inprogress', 'working', 'wip', 'started'):
            return 'in_progress'
        if s in ('pending', 'not started', 'notstarted', 'new', ''):
            return 'pending'
        # Fallback: treat unknowns as pending so they don't disappear
        return 'pending'
    # Dual-mode access:
    # - Employees: via session['employee_id']
    # - Managers/Admin/Supervisor/Team Leads: via Flask-Login
    is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
    if is_flask_user:
        role_lower = (getattr(current_user, 'role', '') or '').lower()
        is_top_admin = (get_user_role() or '').lower() == 'topleveladmin'
        read_only = (request.args.get('readonly') or '').strip().lower() in ('1', 'true', 'yes', 'y')
        is_manager_user = role_lower == 'manager'
        is_team_lead_user = getattr(current_user, 'is_team_lead', False) or role_lower in [
            'business dev', 'business development', 'design', 'operations', 'site_engineer', 'site engineer', 'site manager', 'engineering', 'engineer'
        ]
        if not (current_user.is_admin or current_user.is_supervisor or is_top_admin or is_manager_user or is_team_lead_user):
            return "Access denied.", 403
        # If Top Admin is viewing in read-only mode, remember it in session so task mutation endpoints can enforce read-only.
        if is_top_admin and read_only:
            try:
                ro = session.get('readonly_employee_views') or []
                if not isinstance(ro, list):
                    ro = []
                emp_id_int = int(employee_id)
                if emp_id_int not in ro:
                    ro.append(emp_id_int)
                # Keep it small
                session['readonly_employee_views'] = ro[-25:]
            except Exception:
                pass
    else:
        # Check if employee is logged in and matches the requested employee
        if 'employee_id' not in session or session['employee_id'] != employee_id:
            return "Access denied. Please login first.", 403
        read_only = False
    
    cur = mysql.connection.cursor(DictCursor)
    
    # Get employee info
    cur.execute("SELECT * FROM employees WHERE id = %s", (employee_id,))
    employee = cur.fetchone()
    
    if not employee:
        cur.close()
        return "Employee not found", 404

    # If team lead is viewing, restrict to their own team (unless admin/supervisor/top-admin/manager)
    if is_flask_user:
        role_lower = (getattr(current_user, 'role', '') or '').lower()
        is_top_admin = (get_user_role() or '').lower() == 'topleveladmin'
        is_manager_user = role_lower == 'manager'
        is_team_lead_user = getattr(current_user, 'is_team_lead', False) or role_lower in [
            'business dev', 'business development', 'design', 'operations', 'site_engineer', 'site engineer', 'site manager', 'engineering', 'engineer'
        ]
        if is_team_lead_user and not (current_user.is_admin or current_user.is_supervisor or is_top_admin or is_manager_user):
            team_for_role = {
                'business dev': 'business',
                'business development': 'business',
                'design': 'design',
                'operations': 'operations',
                'site_engineer': 'engineer',
                'site engineer': 'engineer',
                'site manager': 'engineer',
                'engineering': 'engineer',
                'engineer': 'engineer',
            }
            allowed_team = team_for_role.get(role_lower)
            emp_team = (employee.get('department') or '').strip().lower()
            if allowed_team and emp_team and allowed_team != emp_team:
                cur.close()
                return "Access Denied - team mismatch", 403

    try:
        dept_key = _normalize_department_key(employee.get('department') or '') or 'business'
    except Exception:
        dept_key = 'business'
    cur.close()
    return _render_employee_assigned_tasks(dept_key, employee_id, 'Assigned Tasks')
    
    def _fmt_dt(v):
        try:
            if not v:
                return 'Not set'
            if hasattr(v, 'hour') and hasattr(v, 'minute'):
                return v.strftime('%Y-%m-%d %H:%M')
            return v.strftime('%Y-%m-%d')
        except Exception:
            return str(v) if v else 'Not set'

    def _fmt_date_short(v):
        try:
            if not v:
                return 'Not set'
            return v.strftime('%b-%d-%Y')
        except Exception:
            return str(v) if v else 'Not set'

    # Get assigned tasks for this employee (date-wise: earliest due first; empty dates last)
    try:
        cur.execute("""
            SELECT
                bc.*,
                COALESCE(gb.b_name, gb.title, '') AS bid_name,
                gb.company,
                COALESCE(gb.due_date, ba.due_date) AS bid_due_date,
                COALESCE(gb.state, ba.state, ba.depart) AS bid_state
            FROM bid_checklists bc
            JOIN go_bids gb ON bc.g_id = gb.g_id
            LEFT JOIN bid_assign ba ON ba.g_id = bc.g_id
            WHERE bc.assigned_to = %s
            ORDER BY
                (bc.due_date IS NULL) ASC,
                bc.due_date ASC,
                CASE LOWER(COALESCE(bc.priority,''))
                    WHEN 'urgent' THEN 4
                    WHEN 'high' THEN 3
                    WHEN 'medium' THEN 2
                    WHEN 'low' THEN 1
                    ELSE 0
                END DESC,
                bc.id ASC
        """, (employee_id,))
        tasks = cur.fetchall()
    except Exception as e:
        if "Unknown column 'gb.title'" in str(e):
            cur.execute("""
                SELECT
                    bc.*,
                    COALESCE(gb.b_name, '') AS bid_name,
                    gb.company,
                    COALESCE(gb.due_date, ba.due_date) AS bid_due_date,
                    COALESCE(gb.state, ba.state, ba.depart) AS bid_state
                FROM bid_checklists bc
                JOIN go_bids gb ON bc.g_id = gb.g_id
                LEFT JOIN bid_assign ba ON ba.g_id = bc.g_id
                WHERE bc.assigned_to = %s
                ORDER BY
                    (bc.due_date IS NULL) ASC,
                    bc.due_date ASC,
                    CASE LOWER(COALESCE(bc.priority,''))
                        WHEN 'urgent' THEN 4
                        WHEN 'high' THEN 3
                        WHEN 'medium' THEN 2
                        WHEN 'low' THEN 1
                        ELSE 0
                    END DESC,
                    bc.id ASC
            """, (employee_id,))
            tasks = cur.fetchall()
        else:
            raise

    # Decorate tasks for template display
    for t in (tasks or []):
        try:
            t['status'] = _normalize_task_status(t.get('status'))
        except Exception:
            t['status'] = 'pending'
        try:
            raw_due = t.get('due_date') or t.get('bid_due_date')
            t['due_date_str'] = _fmt_dt(raw_due)
        except Exception:
            t['due_date_str'] = 'Not set'
        try:
            raw_due = t.get('due_date') or t.get('bid_due_date')
            t['due_date_display'] = _fmt_date_short(raw_due)
        except Exception:
            t['due_date_display'] = 'Not set'
        try:
            t['bid_due_date_str'] = _fmt_dt(t.get('bid_due_date'))
        except Exception:
            t['bid_due_date_str'] = 'Not set'
        try:
            t['priority'] = (t.get('priority') or 'medium').strip().lower()
        except Exception:
            t['priority'] = 'medium'
        try:
            t['bid_name'] = (t.get('bid_name') or '').strip() or 'N/A'
        except Exception:
            t['bid_name'] = 'N/A'
        try:
            t['company'] = (t.get('company') or '').strip()
        except Exception:
            t['company'] = ''
        try:
            t['bid_state'] = (t.get('bid_state') or '').strip() or 'N/A'
        except Exception:
            t['bid_state'] = 'N/A'
    # Assigned Bids (ONLY bids explicitly assigned to this employee via bid_assignment_members)
    assigned_bids = []
    is_business_team = ((employee.get('department') or '').strip().lower() == 'business')
    try:
        # Ensure mapping table exists (safe for first run)
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS bid_assignment_members (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                employee_id INT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_g_emp (g_id, employee_id)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
            """
        )
        cur.execute(
            """
            SELECT
                gb.g_id AS g_id,
                COALESCE(gb.b_name, '') AS bid_name,
                gb.company AS company,
                COALESCE(bam.task_completion_date, gb.due_date) AS bid_due_date,
                COALESCE(gb.state, ba.state, ba.depart) AS state,
                COALESCE(gb.summary, '') AS summary,
                COUNT(bc.id) AS task_count,
                SUM(CASE
                        WHEN LOWER(TRIM(COALESCE(bc.status,''))) IN ('completed','complete','done','finished','closed')
                        THEN 1 ELSE 0
                    END) AS completed_count,
                SUM(CASE
                        WHEN LOWER(TRIM(COALESCE(bc.status,''))) IN ('in_progress','in progress','in-progress','inprogress','working','wip','started','submitted')
                        THEN 1 ELSE 0
                    END) AS in_progress_count,
                MAX(
                    CASE LOWER(COALESCE(bc.priority,''))
                        WHEN 'urgent' THEN 4
                        WHEN 'high' THEN 3
                        WHEN 'medium' THEN 2
                        WHEN 'low' THEN 1
                        ELSE 0
                    END
                ) AS prio_rank
            FROM bid_assignment_members bam
            JOIN go_bids gb ON gb.g_id = bam.g_id
            LEFT JOIN bid_assign ba ON ba.g_id = gb.g_id
            LEFT JOIN bid_checklists bc ON bc.g_id = gb.g_id AND bc.assigned_to = bam.employee_id
            WHERE bam.employee_id = %s
            GROUP BY gb.g_id, bid_name, gb.company, gb.due_date, state, summary
            ORDER BY
                (COALESCE(bam.task_completion_date, gb.due_date) IS NULL) ASC,
                COALESCE(bam.task_completion_date, gb.due_date) ASC,
                gb.g_id ASC
            """,
            (employee_id,),
        )
        rows = cur.fetchall() or []
    except Exception as e:
        msg = str(e)
        if ("Unknown column 'bam.task_completion_date'" in msg) or ("Unknown column 'gb.state'" in msg) or ("Unknown column 'gb.summary'" in msg):
            try:
                cur.execute(
                    """
                    SELECT
                        gb.g_id AS g_id,
                        COALESCE(gb.b_name, '') AS bid_name,
                        gb.company AS company,
                        gb.due_date AS bid_due_date,
                        COALESCE(ba.state, ba.depart) AS state,
                        '' AS summary,
                        COUNT(bc.id) AS task_count,
                        SUM(CASE
                                WHEN LOWER(TRIM(COALESCE(bc.status,''))) IN ('completed','complete','done','finished','closed')
                                THEN 1 ELSE 0
                            END) AS completed_count,
                        SUM(CASE
                                WHEN LOWER(TRIM(COALESCE(bc.status,''))) IN ('in_progress','in progress','in-progress','inprogress','working','wip','started')
                                THEN 1 ELSE 0
                            END) AS in_progress_count,
                        MAX(
                            CASE LOWER(COALESCE(bc.priority,''))
                                WHEN 'urgent' THEN 4
                                WHEN 'high' THEN 3
                                WHEN 'medium' THEN 2
                                WHEN 'low' THEN 1
                                ELSE 0
                            END
                        ) AS prio_rank
                    FROM bid_assignment_members bam
                    JOIN go_bids gb ON gb.g_id = bam.g_id
                    LEFT JOIN bid_assign ba ON ba.g_id = gb.g_id
                    LEFT JOIN bid_checklists bc ON bc.g_id = gb.g_id AND bc.assigned_to = bam.employee_id
                    WHERE bam.employee_id = %s
                    GROUP BY gb.g_id, bid_name, gb.company, gb.due_date, state
                    ORDER BY
                        (gb.due_date IS NULL) ASC,
                        gb.due_date ASC,
                        gb.g_id ASC
                    """,
                    (employee_id,),
                )
                rows = cur.fetchall() or []
            except Exception:
                rows = []
        else:
            rows = []

    def _prio_label(rank: int) -> str:
        if rank >= 4:
            return 'Urgent'
        if rank == 3:
            return 'High'
        if rank == 2:
            return 'Medium'
        if rank == 1:
            return 'Low'
        return 'Medium'

    for r in (rows or []):
        tc = int(r.get('task_count') or 0)
        cc = int(r.get('completed_count') or 0)
        ip = int(r.get('in_progress_count') or 0)
        if tc > 0 and cc >= tc:
            st = 'completed'
        elif ip > 0:
            st = 'in_progress'
        else:
            st = 'pending'
        pct = int(round((cc / tc) * 100)) if tc > 0 else 0
        due_dt = r.get('bid_due_date')
        try:
            if not due_dt:
                due_str = 'Not set'
            else:
                if hasattr(due_dt, 'hour') and hasattr(due_dt, 'minute'):
                    due_str = due_dt.strftime('%Y-%m-%d %H:%M')
                else:
                    due_str = due_dt.strftime('%Y-%m-%d')
        except Exception:
            due_str = str(due_dt) if due_dt else 'N/A'
        assigned_bids.append({
            'g_id': r.get('g_id'),
            'bid_name': r.get('bid_name') or 'N/A',
            'company': r.get('company') or '',
            'due_date': due_str,
            'status': st,
            'state': (r.get('state') or '').strip() or 'N/A',
            'progress_pct': pct,
            'priority': _prio_label(int(r.get('prio_rank') or 0)),
            'summary': (r.get('summary') or '').strip(),
        })
    
    # Calculate task statistics (normalize statuses to avoid UI/DB variant mismatches)
    total_tasks = len(tasks)
    completed_tasks = len([t for t in tasks if _normalize_task_status(t.get('status')) == 'completed'])
    pending_tasks = len([t for t in tasks if _normalize_task_status(t.get('status')) in ('pending', 'rejected')])
    in_progress_tasks = len([t for t in tasks if _normalize_task_status(t.get('status')) in ('in_progress', 'submitted')])
    
    cur.close()
    
    notif_mode = 'employee'
    if is_flask_user:
        try:
            emp_email = (employee.get('email') or '').strip().lower()
            user_email = (getattr(current_user, 'email', '') or '').strip().lower()
            notif_mode = 'employee' if (emp_email and user_email and emp_email == user_email) else 'user'
        except Exception:
            notif_mode = 'user'
    return render_template('employee_dashboard.html',
                           employee=employee,
                           tasks=tasks,
                           assigned_bids=assigned_bids,
                           is_business_team=is_business_team,
                           total_tasks=total_tasks,
                           completed_tasks=completed_tasks,
                           pending_tasks=pending_tasks,
                           in_progress_tasks=in_progress_tasks,
                           read_only=read_only,
                           viewer_is_top_admin=(hasattr(current_user, 'is_authenticated') and current_user.is_authenticated and ((get_user_role() or '').lower() == 'topleveladmin')),
                           user=current_user,
                           notif_mode=notif_mode)

@app.route('/task/<int:task_id>/update_status', methods=['POST'])
def update_task_status(task_id):
    """Update task status and progress"""
    try:
        new_status = request.form.get('status', '').strip()
        progress_notes = request.form.get('progress_notes', '').strip()
        
        if not new_status:
            return jsonify({'error': 'Status is required'}), 400
        
        cur = mysql.connection.cursor(DictCursor)
        
        # Get task info
        cur.execute("""
            SELECT bc.*, gb.b_name, gb.company, e.name as employee_name
            FROM bid_checklists bc
            JOIN go_bids gb ON bc.g_id = gb.g_id
            JOIN employees e ON bc.assigned_to = e.id
            WHERE bc.id = %s
        """, (task_id,))
        task = cur.fetchone()
        
        if not task:
            cur.close()
            return jsonify({'error': 'Task not found'}), 404
        
        # Authorization: allow admins/managers (flask-login) OR the assigned employee via session
        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        employee_id = session.get('employee_id')
        # If logged in as a Flask user, treat uploads as manager/team-lead uploads,
        # even if an employee_id is present in the session.
        effective_employee_id = None if is_flask_user else employee_id
        if not is_flask_user:
            # When not logged in via Flask-Login, require employee session and ownership of the task
            if not employee_id or task.get('assigned_to') != employee_id:
                cur.close()
                return jsonify({'error': 'Forbidden'}), 403
        else:
            # Enforce Top Admin read-only views (set by employee_dashboard?readonly=1)
            try:
                if (get_user_role() or '').lower() == 'topleveladmin':
                    ro = session.get('readonly_employee_views') or []
                    if isinstance(ro, list):
                        assigned_to = int(task.get('assigned_to') or 0)
                        ro_int = [int(x) for x in ro if str(x).isdigit()]
                        if assigned_to and assigned_to in ro_int:
                            cur.close()
                            return jsonify({'error': 'Read-only view'}), 403
            except Exception:
                pass

        # Normalize + persist canonical status values across the app
        def _normalize_task_status(v):
            s = (v or '').strip().lower()
            s = s.replace('-', ' ').replace('_', ' ')
            s = ' '.join(s.split())
            if s in ('completed', 'complete', 'done', 'finished', 'closed'):
                return 'completed'
            if s in ('submitted', 'submit', 'submission'):
                return 'submitted'
            if s in ('rejected', 'reject'):
                return 'rejected'
            if s in ('in progress', 'inprogress', 'working', 'wip', 'started'):
                return 'in_progress'
            if s in ('pending', 'not started', 'notstarted', 'new', ''):
                return 'pending'
            return 'pending'

        canonical_status = _normalize_task_status(new_status)

        # Update task status (and map to a percentage for persistence)
        if canonical_status == 'completed':
            pct_val = 100
        elif canonical_status == 'submitted':
            pct_val = 75
        elif canonical_status == 'rejected':
            pct_val = 0
        elif canonical_status == 'in_progress':
            pct_val = 50
        else:
            pct_val = 0
        cur.execute("""
            UPDATE bid_checklists 
            SET status = %s, progress_pct = %s, updated_at = CURRENT_TIMESTAMP
            WHERE id = %s
        """, (canonical_status, pct_val, task_id))
        
        # Log the update
        log_write('task_update', 
                 f"Task '{task['task_name']}' for bid '{task['b_name']}' updated to {new_status} by {task['employee_name']}")
        
        mysql.connection.commit()
        cur.close()
        
        # Emit real-time update to team dashboard
        socketio.emit('task_update', {
            'task_id': task_id,
            'status': canonical_status,
            'bid_name': task['b_name'],
            'employee_name': task['employee_name'],
            'company': task['company'],
            'g_id': task.get('g_id'),
            'stage': task.get('stage'),
        })

        # Also emit master_update with per-stage progress for this bid
        try:
            bid_id = task['g_id']
            cur2 = mysql.connection.cursor(DictCursor)
            # Compute per-team completion rates by tasks
            def pct_for(role_expr):
                cur2.execute(f"SELECT status FROM bid_checklists bc JOIN users u ON bc.created_by=u.id WHERE bc.g_id=%s AND u.role {role_expr}", (bid_id,))
                rows = cur2.fetchall()
                if not rows:
                    return 0
                done = len([r for r in rows if (r.get('status') or '').lower()=='completed'])
                return int(round((done/max(1,len(rows)))*100))
            stage_progress_map = {
                'business': pct_for("='business dev'"),
                'design': pct_for("='design'"),
                'operations': pct_for("='operations'"),
                'engineer': pct_for("IN ('site manager','engineer')"),
            }
            cur2.close()
            socketio.emit('master_update', {
                'summary': {
                    'bid_id': bid_id,
                    'work_progress_pct': stage_progress_map.get('design',0),
                    'project_status': 'ongoing',
                    'work_status': f"Task '{task['task_name']}' -> {canonical_status}",
                    'stage_progress_map': stage_progress_map
                }
            })
        except Exception:
            pass
        
        return jsonify({'success': 'Task status updated successfully'})
        
    except Exception as e:
        mysql.connection.rollback()
        if 'cur' in locals():
            cur.close()
        return jsonify({'error': f'Error updating task: {str(e)}'}), 500


@app.route('/task/<int:task_id>/log_time', methods=['POST'])
def log_task_time(task_id):
    """Record a timer entry for a task and notify the assigned team lead."""
    def _parse_duration(val):
        try:
            return max(0, int(float(val)))
        except Exception:
            return 0

    def _ms_to_datetime(ms_value):
        try:
            if ms_value is None or str(ms_value).strip() == '':
                return None
            ts = int(float(ms_value)) / 1000.0
            dt = datetime.fromtimestamp(ts, tz=timezone.utc)
            return dt.replace(tzinfo=None)
        except Exception:
            return None

    def _format_duration(seconds):
        try:
            seconds = int(seconds)
        except Exception:
            return '0s'
        seconds = max(0, seconds)
        hours, rem = divmod(seconds, 3600)
        minutes, secs = divmod(rem, 60)
        parts = []
        if hours:
            parts.append(f"{hours}h")
        if minutes:
            parts.append(f"{minutes}m")
        if secs or not parts:
            parts.append(f"{secs}s")
        return ' '.join(parts)

    try:
        payload = request.get_json(silent=True)
        if not payload:
            payload = request.form
        duration_seconds = _parse_duration(payload.get('duration_seconds') or payload.get('duration'))
        if duration_seconds <= 0:
            return jsonify({'error': 'Duration is required'}), 400
        started_at = _ms_to_datetime(payload.get('start_time_ms'))
        ended_at = _ms_to_datetime(payload.get('end_time_ms'))
        if not ended_at:
            ended_at = datetime.utcnow()
        if not started_at:
            started_at = ended_at - timedelta(seconds=duration_seconds)

        cur = mysql.connection.cursor(DictCursor)
        cur.execute("""
            SELECT bc.*, e.team_lead_id, e.name as employee_name
            FROM bid_checklists bc
            LEFT JOIN employees e ON bc.assigned_to = e.id
            WHERE bc.id = %s
        """, (task_id,))
        task = cur.fetchone()
        if not task:
            cur.close()
            return jsonify({'error': 'Task not found'}), 404

        assigned_to = task.get('assigned_to')
        if not assigned_to:
            cur.close()
            return jsonify({'error': 'Task has no assignee'}), 400

        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        employee_id = session.get('employee_id')
        if not is_flask_user:
            if not employee_id or employee_id != assigned_to:
                cur.close()
                return jsonify({'error': 'Forbidden'}), 403
        else:
            try:
                if (get_user_role() or '').lower() == 'topleveladmin':
                    ro = session.get('readonly_employee_views') or []
                    if isinstance(ro, list):
                        assigned = int(assigned_to or 0)
                        ro_int = [int(x) for x in ro if str(x).isdigit()]
                        if assigned and assigned in ro_int:
                            cur.close()
                            return jsonify({'error': 'Read-only view'}), 403
            except Exception:
                pass

        cur.execute("""
            INSERT INTO task_time_logs (task_id, employee_id, start_time, end_time, duration_seconds, created_by)
            VALUES (%s, %s, %s, %s, %s, %s)
        """, (
            task_id,
            assigned_to,
            started_at,
            ended_at,
            duration_seconds,
            current_user.id if is_flask_user else None
        ))
        mysql.connection.commit()

        emp_name = (task.get('employee_name') or '').strip() or 'Employee'
        task_name = (task.get('task_name') or '').strip() or 'Task'
        duration_label = _format_duration(duration_seconds)
        log_write('task_time_log',
                  f"{emp_name} logged {duration_label} on task '{task_name}' (id={task_id})")

        team_lead_id = 0
        try:
            team_lead_id = int(task.get('team_lead_id') or 0)
        except Exception:
            team_lead_id = 0
        if team_lead_id:
            _create_notification(
                recipient_kind='user',
                recipient_id=team_lead_id,
                category='info',
                title='Task timer entry',
                message=f"{emp_name} logged {duration_label} for '{task_name}'",
                link_url=url_for('employee_dashboard', employee_id=assigned_to)
            )

        cur.close()
        return jsonify({
            'success': 'Time entry saved',
            'duration_display': duration_label,
            'duration_seconds': duration_seconds
        })
    except Exception as e:
        mysql.connection.rollback()
        if 'cur' in locals():
            cur.close()
        return jsonify({'error': f'Error logging time: {str(e)}'}), 500



@app.route('/task/<int:task_id>/assign-self', methods=['POST'])
@login_required
def assign_task_self(task_id):
    """Allow managers/team leads to self-assign a task based on their user email."""
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SELECT * FROM bid_checklists WHERE id=%s", (task_id,))
        task = cur.fetchone()
        if not task:
            return jsonify({'error': 'Task not found'}), 404

        role_norm = ((get_user_role() or '') or '').strip().lower().replace('_', ' ')
        allowed_roles = {
            'itadmin', 'supervisor', 'top level admin', 'topleveladmin',
            'manager', 'business manager', 'design manager', 'operation manager', 'operations manager', 'site manager', 'team lead', 'teamlead'
        }
        if role_norm not in allowed_roles and not getattr(current_user, 'is_admin', False):
            return jsonify({'error': 'Forbidden'}), 403

        email = (getattr(current_user, 'email', '') or '').strip().lower()
        if not email:
            return jsonify({'error': 'Missing user email'}), 400

        cur.execute("SELECT id, department, is_active FROM employees WHERE LOWER(email)=LOWER(%s) LIMIT 1", (email,))
        emp = cur.fetchone()
        task_stage = _normalize_department_key(task.get('stage') or '')
        if emp:
            if not bool(emp.get('is_active', True)):
                return jsonify({'error': 'Employee profile inactive'}), 400
            emp_dept = _normalize_department_key(emp.get('department') or '')
            if task_stage and emp_dept and emp_dept != task_stage:
                return jsonify({'error': 'Employee department does not match task stage'}), 400
            emp_id = emp.get('id')
        else:
            dept_key = task_stage
            if not dept_key:
                dept_key = _normalize_department_key(session.get('active_department_key') or role_norm)
            if not dept_key:
                return jsonify({'error': 'Missing department for self-assign'}), 400
            display_name = (getattr(current_user, 'name', None) or '').strip()
            if not display_name:
                display_name = email.split('@')[0]
            raw_password = secrets.token_urlsafe(16)
            hashed_password = hash_password(raw_password)
            cur.execute(
                "INSERT INTO employees (name, email, password, department, is_active) VALUES (%s, %s, %s, %s, TRUE)",
                (display_name, email, hashed_password, dept_key),
            )
            emp_id = cur.lastrowid

        cur.execute(
            "UPDATE bid_checklists SET assigned_to=%s, updated_at=CURRENT_TIMESTAMP WHERE id=%s",
            (int(emp_id), int(task_id)),
        )
        mysql.connection.commit()
        log_write('task_assign_self', f"task_id={task_id}, user={email}")
        return jsonify({'success': True})
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        return jsonify({'error': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/task/<int:task_id>/update', methods=['POST'])
def update_task(task_id):
    """Update task fields (name, description, status, due_date, priority, assigned_to)."""
    try:
        cur = mysql.connection.cursor(DictCursor)
        # Fetch existing task
        cur.execute("SELECT * FROM bid_checklists WHERE id=%s", (task_id,))
        task = cur.fetchone()
        if not task:
            cur.close()
            return jsonify({'error': 'Task not found'}), 404

        # Authorization:
        # - Flask-Login users: allowed, but only managers/admins can change assignment
        # - Session employees: only allowed to update their own assigned task
        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        employee_id = session.get('employee_id')
        if not is_flask_user and (not employee_id or task.get('assigned_to') != employee_id):
            cur.close()
            return jsonify({'error': 'Forbidden'}), 403

        # Collect fields (optional updates)
        fields = []
        values = []
        m = request.form
        if 'task_name' in m:
            fields.append('task_name=%s'); values.append(m.get('task_name').strip())
        if 'description' in m:
            fields.append('description=%s'); values.append(m.get('description').strip())
        if 'status' in m:
            # Normalize to canonical values so dashboards/counts stay correct
            sv = (m.get('status') or '').strip()
            s = sv.lower().replace('-', ' ').replace('_', ' ')
            s = ' '.join(s.split())
            if s in ('completed', 'complete', 'done', 'finished', 'closed'):
                sv = 'completed'
            elif s in ('in progress', 'inprogress', 'working', 'wip', 'started'):
                sv = 'in_progress'
            elif s in ('pending', 'not started', 'notstarted', 'new', ''):
                sv = 'pending'
            else:
                sv = 'pending'
            fields.append('status=%s'); values.append(sv)
        if 'due_date' in m:
            fields.append('due_date=%s'); values.append(m.get('due_date'))
        if 'priority' in m:
            fields.append('priority=%s'); values.append(m.get('priority').strip())
        if 'assigned_to' in m:
            # Only managers/admins/supervisors can reassign tasks
            role_norm = ((get_user_role() or '') or '').strip().lower().replace('_', ' ')
            manager_roles = {
                'itadmin', 'supervisor', 'top level admin', 'topleveladmin',
                'manager', 'project manager', 'project_manager',
                'business manager', 'design manager', 'operation manager', 'operations manager', 'site manager',
                'engineering manager', 'procurement manager', 'accounts manager', 'finance manager',
                'team lead', 'teamlead', 'team leader'
            }
            if not is_flask_user or (role_norm not in manager_roles and not getattr(current_user, 'is_admin', False)):
                cur.close()
                return jsonify({'error': 'Forbidden'}), 403

            raw = (m.get('assigned_to') or '').strip()
            if not raw:
                at = None
            else:
                try:
                    at = int(raw)
                except Exception:
                    cur.close()
                    return jsonify({'error': 'Invalid assignee'}), 400

        # Validate employee exists + active and (if task.stage is a known team) matches the department
        if at is not None:
            cur.execute("SELECT id, department, is_active FROM employees WHERE id=%s LIMIT 1", (at,))
            emp = cur.fetchone() or {}
            if not emp or not bool(emp.get('is_active', True)):
                cur.close()
                return jsonify({'error': 'Assignee not found or inactive'}), 400
            task_stage = _normalize_department_key(task.get('stage') or '')
            emp_dept = _normalize_department_key(emp.get('department') or '')
            if task_stage in ('business', 'design', 'operations', 'engineer', 'engineering_team', 'procurement_team', 'accounts_finance') and emp_dept and emp_dept != task_stage:
                cur.close()
                return jsonify({'error': 'Assignee must be in the same department as the task'}), 400

            fields.append('assigned_to=%s'); values.append(at)
        if 'progress_pct' in m:
            try:
                pp = int(m.get('progress_pct'))
                pp = max(0, min(100, pp))
            except Exception:
                pp = 0
            fields.append('progress_pct=%s'); values.append(pp)
        if not fields:
            cur.close()
            return jsonify({'error': 'No fields to update'}), 400
        set_clause = ', '.join(fields) + ', updated_at = CURRENT_TIMESTAMP'
        values.append(task_id)
        cur.execute(f"UPDATE bid_checklists SET {set_clause} WHERE id=%s", tuple(values))
        try:
            _recalc_bid_team_progress(cur, int(task.get('g_id') or 0))
        except Exception:
            pass
        mysql.connection.commit()
        cur.close()
        log_write('task_update_fields', f"task_id={task_id}")
        return jsonify({'success': True})
    except Exception as e:
        mysql.connection.rollback()
        if 'cur' in locals():
            cur.close()
        return jsonify({'error': f'Error updating task: {str(e)}'}), 500


@app.route('/api/task/<int:task_id>/assign-team-lead', methods=['POST'])
@login_required
def assign_task_team_lead_api(task_id):
    """Assign a task to a team lead without creating an employee row."""
    try:
        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        if not is_flask_user:
            return jsonify({'success': False, 'error': 'Forbidden'}), 403

        role_norm = ((get_user_role() or '') or '').strip().lower().replace('_', ' ')
        manager_roles = {
            'itadmin', 'supervisor', 'top level admin', 'topleveladmin',
            'manager', 'project manager', 'project_manager',
            'business manager', 'design manager', 'operation manager', 'operations manager', 'site manager',
            'engineering manager', 'procurement manager', 'accounts manager', 'finance manager',
        }
        if role_norm not in manager_roles and not getattr(current_user, 'is_admin', False):
            return jsonify({'success': False, 'error': 'Forbidden'}), 403

        data = request.get_json(silent=True) or {}
        team_lead_user_id = data.get('team_lead_user_id')
        team_lead_email = (data.get('team_lead_email') or '').strip()
        dept_key = _normalize_department_key(data.get('department_key') or '')

        cur = mysql.connection.cursor(DictCursor)
        has_dept_col = False
        try:
            cur.execute("SHOW COLUMNS FROM bid_checklists LIKE 'department'")
            has_dept_col = cur.fetchone() is not None
        except Exception:
            has_dept_col = False
        if has_dept_col:
            cur.execute("SELECT id, stage, department FROM bid_checklists WHERE id=%s", (task_id,))
        else:
            cur.execute("SELECT id, stage FROM bid_checklists WHERE id=%s", (task_id,))
        task = cur.fetchone()
        if not task:
            cur.close()
            return jsonify({'success': False, 'error': 'Task not found'}), 404

        task_stage = _normalize_department_key(task.get('stage') or task.get('department') or '')

        # Resolve team lead user
        user_row = None
        if team_lead_user_id:
            try:
                cur.execute("SELECT id, email, full_name, role FROM users WHERE id=%s", (int(team_lead_user_id),))
                user_row = cur.fetchone()
            except Exception:
                user_row = None
        if not user_row and team_lead_email:
            cur.execute("SELECT id, email, full_name, role FROM users WHERE LOWER(email)=LOWER(%s) LIMIT 1", (team_lead_email,))
            user_row = cur.fetchone()
        if not user_row:
            cur.close()
            return jsonify({'success': False, 'error': 'Team lead not found'}), 404

        # Validate team lead role + department
        lead_id = int(user_row.get('id'))
        lead_role = (user_row.get('role') or '').strip().lower().replace('_', ' ')
        lead_dept = None
        try:
            active_cid = session.get('active_company_id')
        except Exception:
            active_cid = None
        try:
            cur.execute(
                """
                SELECT department_key, role
                FROM user_company_access
                WHERE user_id=%s AND COALESCE(is_active, TRUE)=TRUE
                """ + (" AND company_id=%s" if active_cid else "") + """
                ORDER BY id DESC
                LIMIT 1
                """,
                tuple([lead_id] + ([int(active_cid)] if active_cid else [])),
            )
            uca = cur.fetchone() or {}
            if uca:
                lead_dept = _normalize_department_key(uca.get('department_key') or '')
                # Prefer scoped role from user_company_access when available
                uca_role = (uca.get('role') or '').strip()
                if uca_role:
                    lead_role = uca_role
                elif lead_dept:
                    # If scoped dept exists but role is missing, assume team lead.
                    lead_role = 'teamlead'
        except Exception:
            lead_dept = None

        # Fallback: check team_leads roster for role/department
        if not lead_dept or _normalize_role_key(lead_role) != 'teamlead':
            try:
                cur.execute(
                    "SELECT department, role FROM team_leads WHERE (user_id=%s OR LOWER(email)=LOWER(%s)) LIMIT 1",
                    (int(lead_id), (user_row.get('email') or '').strip()),
                )
                tl = cur.fetchone() or {}
                if tl:
                    lead_dept = _normalize_department_key(tl.get('department') or '') or lead_dept
                    tl_role = (tl.get('role') or '').strip()
                    if tl_role:
                        lead_role = tl_role
            except Exception:
                pass

        acceptable_roles = {
            'teamlead', 'team lead', 'team_lead',
            'business', 'design', 'operations', 'site engineer', 'site_engineer', 'engineering', 'engineer',
            'engineering team', 'procurement team', 'accounts finance', 'accounts', 'finance'
        }
        lead_role_norm = _normalize_role_key(lead_role)
        if lead_role_norm != 'teamlead' and lead_role not in acceptable_roles:
            cur.close()
            return jsonify({'success': False, 'error': 'Selected user is not a team lead'}), 400

        if not lead_dept and dept_key:
            lead_dept = dept_key

        if task_stage and lead_dept and lead_dept != task_stage:
            cur.close()
            return jsonify({'success': False, 'error': 'Team lead must be in the same department as the task'}), 400

        _ensure_task_team_lead_assignments_table(cur)
        cur.execute(
            """
            INSERT INTO task_team_lead_assignments (task_id, team_lead_user_id, assigned_by_user_id, department_key)
            VALUES (%s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE
                team_lead_user_id = VALUES(team_lead_user_id),
                assigned_by_user_id = VALUES(assigned_by_user_id),
                department_key = VALUES(department_key),
                assigned_at = CURRENT_TIMESTAMP
            """,
            (int(task_id), lead_id, getattr(current_user, 'id', None), task_stage or dept_key),
        )
        mysql.connection.commit()
        cur.close()
        return jsonify({'success': True})
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        if 'cur' in locals():
            cur.close()
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/task/<int:task_id>/delete', methods=['POST'])
def delete_task(task_id):
    """Delete a task if authorized."""
    try:
        cur = mysql.connection.cursor(DictCursor)
        cur.execute("SELECT assigned_to, g_id FROM bid_checklists WHERE id=%s", (task_id,))
        row = cur.fetchone()
        if not row:
            cur.close()
            return jsonify({'error': 'Task not found'}), 404
        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        employee_id = session.get('employee_id')
        if not is_flask_user and (not employee_id or row.get('assigned_to') != employee_id):
            cur.close()
            return jsonify({'error': 'Forbidden'}), 403
        # Clean up related task records to avoid orphaned rows in dashboards/approvals.
        try:
            cur.execute("SELECT id FROM task_work_files WHERE task_id=%s", (task_id,))
            twf_ids = [r.get('id') for r in (cur.fetchall() or []) if r.get('id')]
        except Exception:
            twf_ids = []
        try:
            cur.execute("SELECT id FROM task_manager_attachments WHERE task_id=%s", (task_id,))
            tma_ids = [r.get('id') for r in (cur.fetchall() or []) if r.get('id')]
        except Exception:
            tma_ids = []
        try:
            cur.execute("SELECT id FROM task_comments WHERE task_id=%s", (task_id,))
            tc_ids = [r.get('id') for r in (cur.fetchall() or []) if r.get('id')]
        except Exception:
            tc_ids = []

        if twf_ids:
            try:
                placeholders = ",".join(["%s"] * len(twf_ids))
                cur.execute(
                    f"DELETE FROM document_approvals WHERE source_table='task_work_files' AND source_id IN ({placeholders})",
                    tuple(twf_ids),
                )
            except Exception:
                pass
        if tma_ids:
            try:
                placeholders = ",".join(["%s"] * len(tma_ids))
                cur.execute(
                    f"DELETE FROM document_approvals WHERE source_table='task_manager_attachments' AND source_id IN ({placeholders})",
                    tuple(tma_ids),
                )
            except Exception:
                pass
        if tc_ids:
            try:
                placeholders = ",".join(["%s"] * len(tc_ids))
                cur.execute(
                    f"DELETE FROM document_approvals WHERE source_table='task_comments' AND source_id IN ({placeholders})",
                    tuple(tc_ids),
                )
            except Exception:
                pass

        try:
            cur.execute("DELETE FROM task_time_logs WHERE task_id=%s", (task_id,))
        except Exception:
            pass
        try:
            cur.execute("DELETE FROM task_comments WHERE task_id=%s", (task_id,))
        except Exception:
            pass
        try:
            cur.execute("DELETE FROM task_work_files WHERE task_id=%s", (task_id,))
        except Exception:
            pass
        try:
            cur.execute("DELETE FROM task_manager_attachments WHERE task_id=%s", (task_id,))
        except Exception:
            pass
        try:
            cur.execute("DELETE FROM task_team_lead_assignments WHERE task_id=%s", (task_id,))
        except Exception:
            pass

        cur.execute("DELETE FROM bid_checklists WHERE id=%s", (task_id,))
        try:
            _recalc_bid_team_progress(cur, int(row.get('g_id') or 0))
        except Exception:
            pass
        try:
            _recalc_bid_team_progress(cur, int(g_id))
        except Exception:
            pass
        mysql.connection.commit()
        cur.close()
        log_write('task_delete', f"task_id={task_id}")
        return jsonify({'success': 'Task deleted'})
    except Exception as e:
        mysql.connection.rollback()
        if 'cur' in locals():
            cur.close()
        return jsonify({'error': f'Error deleting task: {str(e)}'}), 500

# --- Employee Task Work Upload and Comments ---
@app.route('/task/<int:task_id>/upload', methods=['POST'])
def task_upload_work(task_id):
    """Allow employees to upload work files for a task"""
    try:
        cur = mysql.connection.cursor(DictCursor)
        
        # Get task info
        cur.execute("SELECT * FROM bid_checklists WHERE id = %s", (task_id,))
        task = cur.fetchone()
        
        if not task:
            cur.close()
            return jsonify({'error': 'Task not found'}), 404
        
        # Authorization: admin/manager or assigned employee
        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        employee_id = session.get('employee_id')
        if not is_flask_user and (not employee_id or task.get('assigned_to') != employee_id):
            cur.close()
            return jsonify({'error': 'Forbidden'}), 403
        if is_flask_user:
            # Enforce Top Admin read-only views
            try:
                if (get_user_role() or '').lower() == 'topleveladmin':
                    ro = session.get('readonly_employee_views') or []
                    if isinstance(ro, list):
                        assigned_to = int(task.get('assigned_to') or 0)
                        ro_int = [int(x) for x in ro if str(x).isdigit()]
                        if assigned_to and assigned_to in ro_int:
                            cur.close()
                            return jsonify({'error': 'Read-only view'}), 403
            except Exception:
                pass
        
        try:
            _ensure_task_work_files_table(cur)
            _ensure_task_manager_attachments_table(cur)
        except Exception:
            pass
        
        if 'file' not in request.files:
            cur.close()
            return jsonify({'error': 'No file provided'}), 400
        
        file = request.files['file']
        if file.filename == '':
            cur.close()
            return jsonify({'error': 'No file selected'}), 400
        
        # Save file
        upload_folder = os.path.join(app.root_path, 'static', 'uploads', 'task_work')
        os.makedirs(upload_folder, exist_ok=True)
        
        original_filename = secure_filename(file.filename)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"task_{task_id}_{timestamp}_{original_filename}"
        file_path = os.path.join(upload_folder, filename)
        file.save(file_path)
        
        file_size = os.path.getsize(file_path)
        description = request.form.get('description', '')
        raw_target = (request.form.get('approval_target') or '').strip().lower()
        needs_flag = (request.form.get('needs_approval') or '').strip().lower()
        needs_approval = needs_flag in ('1', 'true', 'yes', 'on', 'approval')
        mode = (request.form.get('mode') or 'review').strip().lower()
        recipients = _normalize_recipient_list(request.form.get('recipients'))
        if raw_target in ('none', 'review'):
            needs_approval = False
        if needs_approval:
            if raw_target in ('', 'auto'):
                approval_target = _approval_target_from_creator(cur, task)
            else:
                approval_target = _normalize_approval_target(raw_target) or 'admin'
            role_raw = (get_user_role() or getattr(current_user, 'role', '') or '')
            allowed_targets = _allowed_approval_targets_for_request(is_flask_user=is_flask_user, role=role_raw)
            if approval_target not in allowed_targets:
                approval_target = 'admin' if 'admin' in allowed_targets else next(iter(allowed_targets))
        else:
            approval_target = _normalize_approval_target(raw_target) or 'admin'
        department_key = None
        try:
            if employee_id:
                cur.execute("SELECT department FROM employees WHERE id=%s", (int(employee_id),))
                er = cur.fetchone() or {}
                department_key = er.get('department')
            elif task.get('assigned_to'):
                cur.execute("SELECT department FROM employees WHERE id=%s", (int(task.get('assigned_to')),))
                er = cur.fetchone() or {}
                department_key = er.get('department')
        except Exception:
            department_key = None
        if not department_key:
            department_key = task.get('stage') or None
        department_key = _normalize_department_key(department_key)
        
        # Save to database
        source_table = 'task_work_files'
        if is_flask_user:
            cur.execute("""
                INSERT INTO task_manager_attachments (task_id, user_id, filename, original_filename, file_path, file_size, description, approval_target)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """, (task_id, getattr(current_user, 'id', None), filename, original_filename, file_path, file_size, description, approval_target))
            source_table = 'task_manager_attachments'
        else:
            cur.execute("""
                INSERT INTO task_work_files (task_id, employee_id, filename, original_filename, file_path, file_size, description, approval_target)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """, (task_id, employee_id, filename, original_filename, file_path, file_size, description, approval_target))

        file_id = cur.lastrowid
        if needs_approval:
            try:
                _ensure_document_approvals_table(cur)
                cur.execute("""
                    INSERT INTO document_approvals (source_table, source_id, status, department_key)
                    VALUES (%s, %s, 'pending', %s)
                    ON DUPLICATE KEY UPDATE status='pending', department_key=VALUES(department_key)
                """, (source_table, file_id, department_key))
                _mark_task_submitted(cur, task_id)
            except Exception:
                pass
        else:
            # Track document exchange as a review item (no approval required).
            try:
                _ensure_document_approvals_table(cur)
                cur.execute(
                    """
                    INSERT INTO document_approvals (source_table, source_id, status, department_key)
                    VALUES (%s, %s, 'review', %s)
                    ON DUPLICATE KEY UPDATE status='review', department_key=VALUES(department_key)
                    """,
                    (source_table, file_id, department_key),
                )
            except Exception:
                pass
        mysql.connection.commit()
        cur.close()

        if recipients:
            try:
                share_title = "Approval request" if needs_approval else "Document exchange"
                share_category = "approval" if needs_approval else "task_share"
                share_message = f"Task #{int(task_id)} has a new document for you."
                _notify_custom_recipients(
                    recipients,
                    task_id=task_id,
                    title=share_title,
                    message=share_message,
                    category=share_category,
                )
            except Exception:
                pass
        else:
            if needs_approval:
                try:
                    _notify_approval_request(
                        employee_id=effective_employee_id,
                        department_key=department_key,
                        approval_target=approval_target,
                        task_id=int(task_id),
                        title="Approval request",
                        message=f"New upload for task #{int(task_id)} requires approval.",
                    )
                except Exception:
                    pass
            else:
                try:
                    review_title = "Document exchange"
                    review_msg = f"New document shared for review on task #{int(task_id)}."
                    _notify_approval_request(
                        employee_id=effective_employee_id,
                        department_key=department_key,
                        approval_target=approval_target,
                        task_id=int(task_id),
                        title=review_title,
                        message=review_msg,
                    )
                except Exception:
                    pass

        try:
            # Append project activity for managers/team leads.
            g_id = task.get('g_id')
            if g_id:
                actor = getattr(current_user, 'email', None) or ''
                if not actor and employee_id:
                    try:
                        cur2 = mysql.connection.cursor(DictCursor)
                        cur2.execute("SELECT email FROM employees WHERE id=%s", (int(employee_id),))
                        er = cur2.fetchone() or {}
                        actor = er.get('email') or ''
                    except Exception:
                        actor = ''
                    finally:
                        try:
                            cur2.close()
                        except Exception:
                            pass
                entry = {
                    'author': actor,
                    'message': '',
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M'),
                }
                action_label = 'Approval request' if needs_approval else 'Document exchange'
                entry['message'] = f"{action_label}: {original_filename} for task \"{task.get('task_name') or 'Task'}\"."
                _append_project_activity(int(g_id), entry)
        except Exception:
            pass

        try:
            socketio.emit('task_activity', {
                'task_id': task_id,
                'event': 'upload',
                'g_id': task.get('g_id'),
                'stage': task.get('stage'),
            })
        except Exception:
            pass
        
        return jsonify({
            'success': True,
            'file_id': file_id,
            'filename': original_filename,
            'approval_target': approval_target if needs_approval else None,
            'message': 'File uploaded successfully'
        })
        
    except Exception as e:
        mysql.connection.rollback()
        if 'cur' in locals():
            cur.close()
        return jsonify({'error': f'Error uploading file: {str(e)}'}), 500

@app.route('/task/<int:task_id>/comment', methods=['POST'])
def task_add_comment(task_id):
    """Allow employees to add comments/notes to a task"""
    try:
        cur = mysql.connection.cursor(DictCursor)
        
        # Get task info
        cur.execute("SELECT * FROM bid_checklists WHERE id = %s", (task_id,))
        task = cur.fetchone()
        
        if not task:
            cur.close()
            return jsonify({'error': 'Task not found'}), 404
        
        # Authorization: admin/manager or assigned employee
        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        employee_id = session.get('employee_id')
        if not is_flask_user and (not employee_id or task.get('assigned_to') != employee_id):
            cur.close()
            return jsonify({'error': 'Forbidden'}), 403
        if is_flask_user:
            # Enforce Top Admin read-only views
            try:
                if (get_user_role() or '').lower() == 'topleveladmin':
                    ro = session.get('readonly_employee_views') or []
                    if isinstance(ro, list):
                        assigned_to = int(task.get('assigned_to') or 0)
                        ro_int = [int(x) for x in ro if str(x).isdigit()]
                        if assigned_to and assigned_to in ro_int:
                            cur.close()
                            return jsonify({'error': 'Read-only view'}), 403
            except Exception:
                pass
        
        # Ensure comments table exists (with approval-request flag)
        try:
            _ensure_task_comments_table(cur)
        except Exception:
            # Fallback: legacy create (should rarely be needed)
            cur.execute("""
                CREATE TABLE IF NOT EXISTS task_comments (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    task_id INT NOT NULL,
                    employee_id INT,
                    user_id INT,
                    comment TEXT NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    INDEX idx_task_id (task_id)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
            """)
        
        data = request.get_json(silent=True) or {}
        comment = data.get('comment', '').strip()
        mode = (data.get('mode') or 'review').strip().lower()
        recipients = _normalize_recipient_list(data.get('recipients'))
        needs_approval = 1 if bool(data.get('needs_approval')) else 0
        raw_target = (data.get('approval_target') or '').strip().lower()
        if raw_target in ('none', 'review'):
            needs_approval = 0
        role_raw = (get_user_role() or getattr(current_user, 'role', '') or '')
        if needs_approval:
            if raw_target in ('', 'auto'):
                approval_target = _approval_target_from_creator(cur, task)
            else:
                approval_target = _normalize_approval_target(raw_target) or 'admin'
            allowed_targets = _allowed_approval_targets_for_request(is_flask_user=is_flask_user, role=role_raw)
            if approval_target not in allowed_targets:
                approval_target = 'admin' if 'admin' in allowed_targets else next(iter(allowed_targets))
        else:
            approval_target = 'admin'
        
        if not comment:
            cur.close()
            return jsonify({'error': 'Comment is required'}), 400
        
        # Get employee name for response
        employee_name = 'User'
        if employee_id:
            cur.execute("SELECT name FROM employees WHERE id = %s", (employee_id,))
            emp = cur.fetchone()
            if emp:
                employee_name = emp['name']
        
        # Insert comment
        user_id = current_user.id if is_flask_user else None
        cur.execute("""
            INSERT INTO task_comments (task_id, employee_id, user_id, comment, needs_approval, approval_target)
            VALUES (%s, %s, %s, %s, %s, %s)
        """, (task_id, employee_id, user_id, comment, needs_approval, approval_target))
        
        comment_id = cur.lastrowid

        # Notify mentioned users/employees by email (e.g., @user@example.com)
        try:
            mention_emails = set(re.findall(r'@([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,})', comment))
        except Exception:
            mention_emails = set()
        if mention_emails:
            sender_email = ''
            try:
                if is_flask_user:
                    sender_email = (getattr(current_user, 'email', '') or '').strip().lower()
                elif employee_id:
                    cur.execute("SELECT email FROM employees WHERE id=%s", (employee_id,))
                    er = cur.fetchone() or {}
                    sender_email = (er.get('email') or '').strip().lower()
            except Exception:
                sender_email = ''
            for email in mention_emails:
                email_norm = (email or '').strip().lower()
                if not email_norm or email_norm == sender_email:
                    continue
                try:
                    cur.execute("SELECT id FROM users WHERE LOWER(email)=%s LIMIT 1", (email_norm,))
                    urow = cur.fetchone()
                except Exception:
                    urow = None
                try:
                    cur.execute("SELECT id FROM employees WHERE LOWER(email)=%s LIMIT 1", (email_norm,))
                    erow = cur.fetchone()
                except Exception:
                    erow = None
                link_url = f"/task/{int(task_id)}/details"
                if urow and urow.get('id'):
                    _create_notification(
                        recipient_kind="user",
                        recipient_id=int(urow.get('id')),
                        title="You were mentioned in a task note",
                        message=f"Task #{int(task_id)} has a new note mentioning you.",
                        category="mention",
                        link_url=link_url,
                    )
                if erow and erow.get('id'):
                    _create_notification(
                        recipient_kind="employee",
                        recipient_id=int(erow.get('id')),
                        title="You were mentioned in a task note",
                        message=f"Task #{int(task_id)} has a new note mentioning you.",
                        category="mention",
                        link_url=link_url,
                    )

        # If approval requested, create a pending approval entry
        dept = None
        if needs_approval:
            try:
                _ensure_document_approvals_table(cur)
                # Best-effort department key
                if employee_id:
                    cur.execute("SELECT department FROM employees WHERE id = %s", (employee_id,))
                    er = cur.fetchone()
                    dept = (er.get('department') if er else None)
                elif task.get('assigned_to'):
                    cur.execute("SELECT department FROM employees WHERE id = %s", (int(task.get('assigned_to')),))
                    er = cur.fetchone()
                    dept = (er.get('department') if er else None)
                cur.execute("""
                    INSERT INTO document_approvals (source_table, source_id, status, department_key)
                    VALUES (%s, %s, 'pending', %s)
                    ON DUPLICATE KEY UPDATE status='pending', department_key=VALUES(department_key)
                """, ('task_comments', comment_id, dept))
                _mark_task_submitted(cur, task_id)
            except Exception:
                pass

        mysql.connection.commit()
        cur.close()
        
        if needs_approval:
            try:
                _notify_approval_request(
                    employee_id=employee_id,
                    department_key=dept,
                    approval_target=approval_target,
                    task_id=int(task_id),
                    title="Approval request",
                    message=f"New note for task #{int(task_id)} requires approval.",
                )
            except Exception:
                pass

        if recipients:
            try:
                share_title = "Approval request" if mode == 'approval' else "Task update"
                share_category = 'approval' if mode == 'approval' else 'task_share'
                share_message = f"Task #{int(task_id)} has a new note for you."
                if comment:
                    snippet = comment if len(comment) <= 120 else f"{comment[:117]}..."
                    share_message = f"{share_message} {snippet}"
                _notify_custom_recipients(
                    recipients,
                    task_id=task_id,
                    title=share_title,
                    message=share_message,
                    category=share_category,
                )
            except Exception:
                pass

        try:
            socketio.emit('task_activity', {
                'task_id': task_id,
                'event': 'comment',
                'g_id': task.get('g_id'),
                'stage': task.get('stage'),
            })
        except Exception:
            pass

        return jsonify({
            'success': True,
            'comment_id': comment_id,
            'employee_name': employee_name,
            'comment': comment,
            'needs_approval': bool(needs_approval),
            'approval_target': approval_target,
            'created_at': datetime.now().strftime('%Y-%m-%d %H:%M')
        })
        
    except Exception as e:
        mysql.connection.rollback()
        if 'cur' in locals():
            cur.close()
        return jsonify({'error': f'Error adding comment: {str(e)}'}), 500

@app.route('/task/<int:task_id>/details')
def task_get_details(task_id):
    """Get task details including comments and uploaded files"""
    try:
        cur = mysql.connection.cursor(DictCursor)
        
        # Get task info
        cur.execute("""
            SELECT bc.*, gb.b_name, gb.company, e.name as employee_name
            FROM bid_checklists bc
            JOIN go_bids gb ON bc.g_id = gb.g_id
            LEFT JOIN employees e ON bc.assigned_to = e.id
            WHERE bc.id = %s
        """, (task_id,))
        task = cur.fetchone()
        
        if not task:
            cur.close()
            return jsonify({'error': 'Task not found'}), 404
        
        # Authorization: admin/manager or assigned employee
        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        employee_id = session.get('employee_id')
        if not is_flask_user and (not employee_id or task.get('assigned_to') != employee_id):
            cur.close()
            return jsonify({'error': 'Forbidden'}), 403
        
        # Get comments
        comments = []
        try:
            try:
                _ensure_document_approvals_table(cur)
                _ensure_task_comments_table(cur)
            except Exception:
                pass
            cur.execute("""
                SELECT
                  tc.*,
                  e.name as employee_name,
                  da.status AS approval_status,
                  da.decided_at AS decided_at
                FROM task_comments tc
                LEFT JOIN employees e ON tc.employee_id = e.id
                LEFT JOIN document_approvals da ON da.source_table='task_comments' AND da.source_id=tc.id
                WHERE tc.task_id = %s
                ORDER BY tc.created_at DESC
            """, (task_id,))
            comments = cur.fetchall()
            # Convert datetime to string
            for c in comments:
                if c.get('created_at'):
                    c['created_at'] = c['created_at'].strftime('%Y-%m-%d %H:%M')
                if c.get('decided_at'):
                    c['decided_at'] = c['decided_at'].strftime('%Y-%m-%d %H:%M')
                try:
                    c['approval_status'] = ((c.get('approval_status') or '').strip().lower() or None)
                except Exception:
                    c['approval_status'] = None
                c['approval_target'] = (c.get('approval_target') or 'admin')
        except Exception:
            pass
        
        # Get uploaded files (employee uploads)
        files = []
        try:
            try:
                _ensure_document_approvals_table(cur)
            except Exception:
                pass
            cur.execute("""
                SELECT
                  twf.*,
                  e.name as employee_name,
                  da.status AS approval_status,
                  da.decided_at AS decided_at
                FROM task_work_files twf
                LEFT JOIN employees e ON twf.employee_id = e.id
                LEFT JOIN document_approvals da ON da.source_table='task_work_files' AND da.source_id=twf.id
                WHERE twf.task_id = %s
                ORDER BY twf.uploaded_at DESC
            """, (task_id,))
            files = cur.fetchall()
            # Convert datetime to string and add download URL
            for f in files:
                if f.get('uploaded_at'):
                    f['uploaded_at'] = f['uploaded_at'].strftime('%Y-%m-%d %H:%M')
                if f.get('decided_at'):
                    f['decided_at'] = f['decided_at'].strftime('%Y-%m-%d %H:%M')
                f['download_url'] = f"/task/file/{f['id']}/download"
                f['uploaded_by'] = 'employee'
                try:
                    f['approval_status'] = ((f.get('approval_status') or '').strip().lower() or None)
                except Exception:
                    f['approval_status'] = None
                f['approval_target'] = (f.get('approval_target') or 'admin')
        except Exception:
            pass
        
        # Get manager attachments
        manager_files = []
        try:
            try:
                _ensure_document_approvals_table(cur)
            except Exception:
                pass
            cur.execute("""
                SELECT
                  tma.*,
                  u.email as manager_email,
                  da.status AS approval_status,
                  da.decided_at AS decided_at
                FROM task_manager_attachments tma
                LEFT JOIN users u ON tma.user_id = u.id
                LEFT JOIN document_approvals da ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
                WHERE tma.task_id = %s
                ORDER BY tma.uploaded_at DESC
            """, (task_id,))
            manager_files = cur.fetchall()
            for f in manager_files:
                if f.get('uploaded_at'):
                    f['uploaded_at'] = f['uploaded_at'].strftime('%Y-%m-%d %H:%M')
                if f.get('decided_at'):
                    f['decided_at'] = f['decided_at'].strftime('%Y-%m-%d %H:%M')
                f['download_url'] = f"/task/manager-file/{f['id']}/download"
                f['uploaded_by'] = 'manager'
                f['filename'] = f.get('original_filename', f.get('filename', 'File'))
                try:
                    f['approval_status'] = ((f.get('approval_status') or '').strip().lower() or None)
                except Exception:
                    f['approval_status'] = None
                f['approval_target'] = (f.get('approval_target') or 'admin')
        except Exception:
            pass
        
        cur.close()
        
        return jsonify({
            'success': True,
            'task': {
                'id': task['id'],
                'task_name': task['task_name'],
                'description': task.get('description', ''),
                'status': task['status'],
                'priority': task.get('priority', 'medium'),
                'due_date': task['due_date'].strftime('%Y-%m-%d %H:%M') if task.get('due_date') else None,
                'bid_name': task['b_name'],
                'company': task.get('company', 'N/A'),
                'employee_name': task.get('employee_name', 'Unassigned')
            },
            'comments': comments,
            'files': files,
            'manager_files': manager_files
        })
        
    except Exception as e:
        if 'cur' in locals():
            cur.close()
        return jsonify({'error': f'Error fetching task details: {str(e)}'}), 500

@app.route('/task/file/<int:file_id>/download')
def task_file_download(file_id):
    """Download a task work file"""
    try:
        cur = mysql.connection.cursor(DictCursor)
        cur.execute("SELECT * FROM task_work_files WHERE id = %s", (file_id,))
        file_record = cur.fetchone()
        
        if not file_record:
            cur.close()
            return "File not found", 404
        
        # Get task to check authorization
        cur.execute("SELECT * FROM bid_checklists WHERE id = %s", (file_record['task_id'],))
        task = cur.fetchone()
        cur.close()
        
        # Authorization: admin/manager or assigned employee
        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        employee_id = session.get('employee_id')
        if not is_flask_user and (not employee_id or (task and task.get('assigned_to') != employee_id)):
            return "Forbidden", 403
        
        file_path = file_record['file_path']
        if os.path.exists(file_path):
            return send_file(file_path, download_name=file_record['original_filename'], as_attachment=True)
        else:
            return "File not found on server", 404
            
    except Exception as e:
        return f"Error downloading file: {str(e)}", 500

@app.route('/task/manager-file/<int:file_id>/download')
def task_manager_file_download(file_id):
    """Download a manager attachment file"""
    try:
        cur = mysql.connection.cursor(DictCursor)
        cur.execute("SELECT * FROM task_manager_attachments WHERE id = %s", (file_id,))
        file_record = cur.fetchone()
        
        if not file_record:
            cur.close()
            return "File not found", 404
        
        # Get task to check authorization
        cur.execute("SELECT * FROM bid_checklists WHERE id = %s", (file_record['task_id'],))
        task = cur.fetchone()
        cur.close()
        
        # Authorization: admin/manager or assigned employee
        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        employee_id = session.get('employee_id')
        # Allow access for flask users (managers) and assigned employees
        if not is_flask_user and (not employee_id or (task and task.get('assigned_to') != employee_id)):
            return "Forbidden", 403
        
        file_path = os.path.join(os.getcwd(), file_record['file_path'])
        if os.path.exists(file_path):
            return send_file(file_path, download_name=file_record['original_filename'], as_attachment=True)
        else:
            return "File not found on server", 404
            
    except Exception as e:
        return f"Error downloading file: {str(e)}", 500

@app.route('/task/file/<int:file_id>/delete', methods=['POST'])
def task_file_delete(file_id):
    """Delete a task work file"""
    try:
        cur = mysql.connection.cursor(DictCursor)
        cur.execute("SELECT * FROM task_work_files WHERE id = %s", (file_id,))
        file_record = cur.fetchone()
        
        if not file_record:
            cur.close()
            return jsonify({'error': 'File not found'}), 404
        
        # Get task to check authorization
        cur.execute("SELECT * FROM bid_checklists WHERE id = %s", (file_record['task_id'],))
        task = cur.fetchone()
        
        # Authorization: admin/manager or assigned employee (owner of file)
        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        employee_id = session.get('employee_id')
        if not is_flask_user and (not employee_id or file_record.get('employee_id') != employee_id):
            cur.close()
            return jsonify({'error': 'Forbidden'}), 403
        
        # Delete file from disk
        try:
            if os.path.exists(file_record['file_path']):
                os.remove(file_record['file_path'])
        except Exception:
            pass
        
        # Delete from database
        cur.execute("DELETE FROM task_work_files WHERE id = %s", (file_id,))
        mysql.connection.commit()
        cur.close()
        
        return jsonify({'success': True, 'message': 'File deleted successfully'})
        
    except Exception as e:
        mysql.connection.rollback()
        if 'cur' in locals():
            cur.close()
        return jsonify({'error': f'Error deleting file: {str(e)}'}), 500

@app.route('/team/<team>/bids/<int:g_id>/checklist')
@login_required
def bid_checklist(team, g_id):
    """Manage checklist/tasks for a specific bid"""
    force_team_lead_sidebar = (request.args.get('view') or '').strip().lower() == 'team_lead'
    cur = mysql.connection.cursor(DictCursor)
    
    # Get bid info
    cur.execute("SELECT * FROM go_bids WHERE g_id = %s", (g_id,))
    bid = cur.fetchone()
    
    if not bid:
        cur.close()
        return "Bid not found", 404
    
    # Get checklist items for this bid (team-specific)
    # We filter by bc.stage so each team sees only their own tasks for the bid.
    # Keep a small legacy fallback for old rows with empty stage.
    cur.execute("""
        SELECT bc.*, e.name as assigned_employee_name
        FROM bid_checklists bc
        LEFT JOIN employees e ON bc.assigned_to = e.id
        WHERE bc.g_id = %s
          AND (
                LOWER(COALESCE(bc.stage,'')) = %s
                OR COALESCE(bc.stage,'') = ''
              )
        ORDER BY bc.priority DESC, bc.created_at ASC
    """, (g_id, (team or '').strip().lower()))
    checklist_items = cur.fetchall()
    
    # Get team employees for assignment
    cur.execute("""
        SELECT * FROM employees 
        WHERE department = %s AND is_active = TRUE
        ORDER BY name
    """, (team,))
    team_employees = cur.fetchall()

    team_leads = []
    try:
        company_id = session.get('active_company_id')
        if company_id:
            cur.execute("""
            SELECT e.id, u.email, u.name
            FROM users u
            JOIN user_company_access uca ON uca.user_id = u.id
            JOIN employees e ON LOWER(e.email) = LOWER(u.email)
            WHERE LOWER(COALESCE(uca.role,'')) = 'teamlead'
              AND uca.company_id = %s
              AND (uca.department_key IS NULL OR LOWER(COALESCE(uca.department_key,'')) = %s)
              AND COALESCE(uca.is_active, TRUE) = TRUE
            ORDER BY u.name
            """, (int(company_id), team))
        team_leads = cur.fetchall() or []
    except Exception:
        team_leads = []
    assigned_team_leads = []
    try:
        cur.execute("""
            SELECT tab.team_lead, u.name, tab.assigned_at
            FROM teamlead_assign_bids tab
            LEFT JOIN users u ON LOWER(u.email) = LOWER(tab.team_lead)
            WHERE tab.g_id = %s
            ORDER BY tab.assigned_at DESC
        """, (g_id,))
        assigned_team_leads = cur.fetchall() or []
    except Exception:
        assigned_team_leads = []

    cur.close()

    return render_template('bid_checklist.html',
                         team=team,
                         bid=bid,
                         checklist_items=checklist_items,
                         team_employees=team_employees,
                         team_leads=team_leads,
                         assigned_team_leads=assigned_team_leads,
                         user=current_user,
                         user_role=getattr(current_user, 'role', 'member'),
                         force_team_lead_sidebar=force_team_lead_sidebar)

@app.route('/team/<team>/bids/<int:g_id>/checklist/create', methods=['POST'])
@login_required
def create_checklist_item(team, g_id):
    """Create a new checklist item for a bid"""
    try:
        task_name = request.form.get('task_name', '').strip()
        description = request.form.get('description', '').strip()
        assigned_to = request.form.get('assigned_to')
        priority = request.form.get('priority', 'medium')
        due_date = request.form.get('due_date')
        file_obj = request.files.get('attachment')
        saved_path = None
        
        if not task_name:
            flash('Task name is required', 'error')
            return redirect(url_for('bid_checklist', team=team, g_id=g_id))
        
        cur = mysql.connection.cursor()
        # Explicit stage name for parallel tracking
        stage_name = team.strip().lower()
        prefix, next_num = _next_task_code_number(cur, stage_name)

        # If "Assign To" is left blank, treat it as "assign to all employees assigned to this bid"
        # so the task actually appears in each employee's dashboard (otherwise assigned_to=NULL
        # and employees won't see it).
        assignee_ids = []
        try:
            if assigned_to:
                assignee_ids = [int(assigned_to)]
            else:
                # Ensure mapping table exists (safe for first run)
                cur.execute(
                    """
                    CREATE TABLE IF NOT EXISTS bid_assignment_members (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        g_id INT NOT NULL,
                        employee_id INT NOT NULL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        UNIQUE KEY uniq_g_emp (g_id, employee_id)
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
                    """
                )
                cur.execute("SELECT employee_id FROM bid_assignment_members WHERE g_id=%s", (g_id,))
                assignee_ids = [int(r[0]) for r in (cur.fetchall() or []) if r and r[0] is not None]
        except Exception:
            assignee_ids = [int(assigned_to)] if assigned_to else []

        # If we still have no assignees (bid has no assigned members), allow creating an unassigned task
        if not assignee_ids:
            assignee_ids = [None]

        # Handle optional attachment upload
        if file_obj and getattr(file_obj, 'filename', None):
            try:
                os.makedirs(os.path.join(os.getcwd(), 'uploads', 'checklists', str(g_id)), exist_ok=True)
                safe_name = secure_filename(file_obj.filename)
                saved_path = os.path.join('uploads', 'checklists', str(g_id), safe_name)
                file_obj.save(os.path.join(os.getcwd(), saved_path))
            except Exception:
                saved_path = None
        for aid in assignee_ids:
            task_code = f"{prefix}-{next_num:03d}" if prefix and next_num else None
            cur.execute(
                """
                INSERT INTO bid_checklists (g_id, task_code, task_name, description, assigned_to, priority, due_date, progress_pct, stage, created_by, attachment_path)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """,
                (
                    g_id,
                    task_code,
                    task_name,
                    description,
                    aid,
                    priority,
                    due_date if due_date else None,
                    0,
                    stage_name,
                    current_user.id,
                    saved_path,
                ),
            )
            if prefix and next_num:
                next_num += 1
        
        mysql.connection.commit()
        cur.close()
        
        log_write('create_checklist_item', f"Created task '{task_name}' for bid {g_id}")
        if assigned_to:
            flash(f'Task "{task_name}" created successfully!', 'success')
        else:
            # If we fanned out to multiple assignees, make that clear
            created_for = len([x for x in assignee_ids if x is not None])
            if created_for > 0:
                flash(f'Task "{task_name}" created for {created_for} assigned employee(s).', 'success')
            else:
                flash(f'Task "{task_name}" created (unassigned).', 'success')
        
    except Exception as e:
        mysql.connection.rollback()
        cur.close()
        flash(f'Error creating task: {str(e)}', 'error')
    
    return redirect(url_for('bid_checklist', team=team, g_id=g_id))


@app.route('/api/project/<int:g_id>/tasks/create', methods=['POST'])
@login_required
def create_project_stage_task(g_id):
    """Create a new task for a project stage (Project Manager flow)."""
    try:
        task_name = request.form.get('task_name', '').strip()
        description = request.form.get('description', '').strip()
        priority = request.form.get('priority', 'normal')
        due_date = request.form.get('due_date')
        stage_name = request.form.get('stage', '').strip()
        stage_name = _normalize_department_key(stage_name) or 'engineering_team'
        if stage_name not in ('engineering_team', 'procurement_team', 'accounts_finance'):
            stage_name = 'engineering_team'
        file_obj = request.files.get('attachment')
        saved_path = None

        if not task_name:
            return jsonify({'error': 'Task name is required'}), 400

        cur = mysql.connection.cursor(DictCursor)

        # Verify project assignment for non-admin users.
        cur.execute("SELECT w_id FROM win_lost_results WHERE g_id=%s LIMIT 1", (int(g_id),))
        row = cur.fetchone() or {}
        project_id = row.get('w_id')
        if project_id and not getattr(current_user, 'is_admin', False):
            if not _is_project_manager_for_project(int(current_user.id), int(project_id)):
                cur.close()
                return jsonify({'error': 'Not authorized'}), 403

        # Assign to all bid members if any, otherwise leave unassigned.
        assignee_ids = []
        try:
            cur.execute(
                """
                CREATE TABLE IF NOT EXISTS bid_assignment_members (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    g_id INT NOT NULL,
                    employee_id INT NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE KEY uniq_g_emp (g_id, employee_id)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
                """
            )
            cur.execute("SELECT employee_id FROM bid_assignment_members WHERE g_id=%s", (int(g_id),))
            assignee_ids = [int(r[0]) for r in (cur.fetchall() or []) if r and r[0] is not None]
        except Exception:
            assignee_ids = []

        if not assignee_ids:
            assignee_ids = [None]

        # Optional attachment
        if file_obj and getattr(file_obj, 'filename', None):
            try:
                os.makedirs(os.path.join(os.getcwd(), 'uploads', 'checklists', str(g_id)), exist_ok=True)
                safe_name = secure_filename(file_obj.filename)
                saved_path = os.path.join('uploads', 'checklists', str(g_id), safe_name)
                file_obj.save(os.path.join(os.getcwd(), saved_path))
            except Exception:
                saved_path = None

        prefix, next_num = _next_task_code_number(cur, stage_name)
        for aid in assignee_ids:
            task_code = f"{prefix}-{next_num:03d}" if prefix and next_num else None
            cur.execute(
                """
                INSERT INTO bid_checklists (
                    g_id, task_code, task_name, description, assigned_to,
                    priority, due_date, progress_pct, stage, created_by, attachment_path
                )
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """,
                (
                    int(g_id),
                    task_code,
                    task_name,
                    description,
                    aid,
                    priority,
                    due_date if due_date else None,
                    0,
                    stage_name,
                    int(current_user.id),
                    saved_path,
                ),
            )
            if prefix and next_num:
                next_num += 1

        mysql.connection.commit()
        cur.close()
        log_write('create_project_stage_task', f"Created stage task '{task_name}' for project {g_id}")
        return jsonify({'ok': True})
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        try:
            cur.close()
        except Exception:
            pass
        return jsonify({'error': str(e)}), 500


@app.route('/api/project/<int:g_id>/tasks', methods=['GET'])
@login_required
def api_project_tasks(g_id):
    """Return all tasks for a project (grouped by stage on the client)."""
    cur = mysql.connection.cursor(DictCursor)
    try:
        try:
            _ensure_document_approvals_table(cur)
            _ensure_task_comments_table(cur)
            _ensure_task_work_files_table(cur)
            _ensure_task_manager_attachments_table(cur)
        except Exception:
            pass
        cur.execute(
            """
            SELECT bc.id, bc.g_id, bc.task_code, bc.task_name, bc.description, bc.stage, bc.status, bc.priority,
                   bc.due_date, bc.progress_pct, bc.assigned_to, bc.created_at,
                   e.name AS assigned_employee_name, e.email AS employee_email, e.department,
                   (
                       SELECT COUNT(*)
                       FROM document_approvals da
                       JOIN task_work_files twf
                         ON da.source_table='task_work_files' AND da.source_id=twf.id
                       WHERE twf.task_id = bc.id AND da.status='pending'
                   ) +
                   (
                       SELECT COUNT(*)
                       FROM document_approvals da
                       JOIN task_comments tc
                         ON da.source_table='task_comments' AND da.source_id=tc.id
                       WHERE tc.task_id = bc.id AND da.status='pending'
                   ) +
                   (
                       SELECT COUNT(*)
                       FROM task_comments tc
                       LEFT JOIN document_approvals da
                         ON da.source_table='task_comments' AND da.source_id=tc.id
                       WHERE tc.task_id = bc.id AND tc.needs_approval=1 AND da.id IS NULL
                   ) +
                   (
                       SELECT COUNT(*)
                       FROM document_approvals da
                       JOIN task_manager_attachments tma
                         ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
                       WHERE tma.task_id = bc.id AND da.status='pending'
                   ) AS pending_approvals,
                   (
                       SELECT COUNT(*)
                       FROM document_approvals da
                       JOIN task_work_files twf
                         ON da.source_table='task_work_files' AND da.source_id=twf.id
                       WHERE twf.task_id = bc.id AND da.status='review'
                   ) +
                   (
                       SELECT COUNT(*)
                       FROM document_approvals da
                       JOIN task_comments tc
                         ON da.source_table='task_comments' AND da.source_id=tc.id
                       WHERE tc.task_id = bc.id AND da.status='review'
                   ) +
                   (
                       SELECT COUNT(*)
                       FROM document_approvals da
                       JOIN task_manager_attachments tma
                         ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
                       WHERE tma.task_id = bc.id AND da.status='review'
                   ) AS review_items,
                   (
                       SELECT COUNT(*)
                       FROM document_approvals da
                       JOIN task_work_files twf
                         ON da.source_table='task_work_files' AND da.source_id=twf.id
                       WHERE twf.task_id = bc.id AND da.status='approved'
                   ) +
                   (
                       SELECT COUNT(*)
                       FROM document_approvals da
                       JOIN task_comments tc
                         ON da.source_table='task_comments' AND da.source_id=tc.id
                       WHERE tc.task_id = bc.id AND da.status='approved'
                   ) +
                   (
                       SELECT COUNT(*)
                       FROM document_approvals da
                       JOIN task_manager_attachments tma
                         ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
                       WHERE tma.task_id = bc.id AND da.status='approved'
                   ) AS approved_items
            FROM bid_checklists bc
            LEFT JOIN employees e ON bc.assigned_to = e.id
            WHERE g_id=%s AND team_archive IS NULL
            ORDER BY created_at DESC, id DESC
            """,
            (int(g_id),),
        )
        tasks = cur.fetchall() or []
        task_ids = [t.get('id') for t in tasks if t.get('id')]
        comments_map = {}
        employee_files_map = {}
        manager_files_map = {}
        if task_ids:
            placeholders = ",".join(["%s"] * len(task_ids))
            try:
                cur.execute(f"""
                    SELECT tc.*, e.name as employee_name, u.email as user_email, da.status as approval_status, da.decision_note as decision_note
                    FROM task_comments tc
                    LEFT JOIN employees e ON tc.employee_id = e.id
                    LEFT JOIN users u ON tc.user_id = u.id
                    LEFT JOIN document_approvals da ON da.source_table='task_comments' AND da.source_id=tc.id
                    WHERE tc.task_id IN ({placeholders})
                    ORDER BY tc.created_at DESC
                """, tuple(task_ids))
                all_comments = cur.fetchall() or []
                for c in all_comments:
                    tid = c.get('task_id')
                    if not tid:
                        continue
                    created_at = c.get('created_at')
                    try:
                        created_str = created_at.strftime('%Y-%m-%d %H:%M') if created_at else ''
                    except Exception:
                        created_str = str(created_at) if created_at else ''
                    comments_map.setdefault(tid, []).append({
                        'id': c.get('id'),
                        'comment': c.get('comment'),
                        'employee_name': c.get('employee_name') or c.get('user_email') or 'User',
                        'employee_email': c.get('employee_email') or '',
                        'created_at': created_str,
                        'approval_status': ((c.get('approval_status') or '').strip().lower() or None),
                        'approval_target': (c.get('approval_target') or 'admin'),
                        'needs_approval': bool(c.get('needs_approval')),
                        'decision_note': c.get('decision_note') or ''
                    })
            except Exception:
                comments_map = {}
            try:
                cur.execute(f"""
                    SELECT twf.*, e.name as employee_name, e.email as employee_email, da.status as approval_status, da.decision_note as decision_note
                    FROM task_work_files twf
                    LEFT JOIN employees e ON twf.employee_id = e.id
                    LEFT JOIN document_approvals da ON da.source_table='task_work_files' AND da.source_id=twf.id
                    WHERE twf.task_id IN ({placeholders})
                    ORDER BY twf.uploaded_at DESC
                """, tuple(task_ids))
                all_files = cur.fetchall() or []
                for f in all_files:
                    tid = f.get('task_id')
                    if not tid:
                        continue
                    uploaded_at = f.get('uploaded_at')
                    try:
                        uploaded_str = uploaded_at.strftime('%Y-%m-%d %H:%M') if uploaded_at else ''
                    except Exception:
                        uploaded_str = str(uploaded_at) if uploaded_at else ''
                    employee_files_map.setdefault(tid, []).append({
                        'id': f.get('id'),
                        'filename': f.get('original_filename') or f.get('filename'),
                        'description': f.get('description', ''),
                        'employee_name': f.get('employee_name', ''),
                        'employee_email': f.get('employee_email', ''),
                        'uploaded_at': uploaded_str,
                        'download_url': f"/task/file/{f.get('id')}/download",
                        'approval_status': ((f.get('approval_status') or '').strip().lower() or None),
                        'approval_target': f.get('approval_target') or 'admin',
                        'decision_note': f.get('decision_note') or ''
                    })
            except Exception:
                employee_files_map = {}
            try:
                cur.execute(f"""
                    SELECT tma.*, u.email as manager_email, da.status as approval_status, da.decision_note as decision_note
                    FROM task_manager_attachments tma
                    LEFT JOIN users u ON tma.user_id = u.id
                    LEFT JOIN document_approvals da ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
                    WHERE tma.task_id IN ({placeholders})
                    ORDER BY tma.uploaded_at DESC
                """, tuple(task_ids))
                all_manager_files = cur.fetchall() or []
                for f in all_manager_files:
                    tid = f.get('task_id')
                    if not tid:
                        continue
                    uploaded_at = f.get('uploaded_at')
                    try:
                        uploaded_str = uploaded_at.strftime('%Y-%m-%d %H:%M') if uploaded_at else ''
                    except Exception:
                        uploaded_str = str(uploaded_at) if uploaded_at else ''
                    manager_files_map.setdefault(tid, []).append({
                        'id': f.get('id'),
                        'filename': f.get('original_filename') or f.get('filename'),
                        'manager_email': f.get('manager_email') or 'Manager',
                        'uploaded_at': uploaded_str,
                        'download_url': f"/task/manager-file/{f.get('id')}/download",
                        'approval_status': ((f.get('approval_status') or '').strip().lower() or None),
                        'approval_target': f.get('approval_target') or 'admin',
                        'decision_note': f.get('decision_note') or ''
                    })
            except Exception:
                manager_files_map = {}
        try:
            _assign_missing_task_codes(cur, tasks, fallback_stage='engineering_team')
            mysql.connection.commit()
        except Exception:
            mysql.connection.rollback()
        for t in tasks:
            tid = t.get('id')
            t['pending_approvals'] = int(t.get('pending_approvals') or 0)
            t['review_items'] = int(t.get('review_items') or 0)
            t['approved_items'] = int(t.get('approved_items') or 0)
            t['employee_comments'] = comments_map.get(tid, [])
            t['employee_files'] = employee_files_map.get(tid, [])
            t['manager_files'] = manager_files_map.get(tid, [])
        return jsonify({'tasks': tasks})
    except Exception as e:
        return jsonify({'error': str(e), 'tasks': []}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass

@app.route('/task/<int:task_id>/attach', methods=['POST'])
@login_required
def attach_file_to_task(task_id):
    """Attach or replace a file for a checklist task - saves to manager_attachments table for employees to see."""
    try:
        file_obj = request.files.get('attachment')
        if not file_obj or not getattr(file_obj, 'filename', None):
            return jsonify({'error': 'No file provided'}), 400
        cur = mysql.connection.cursor(DictCursor)
        
        # Create manager attachments table if not exists
        cur.execute("""
            CREATE TABLE IF NOT EXISTS task_manager_attachments (
                id INT AUTO_INCREMENT PRIMARY KEY,
                task_id INT NOT NULL,
                user_id INT,
                filename VARCHAR(255) NOT NULL,
                original_filename VARCHAR(255) NOT NULL,
                file_path VARCHAR(512) NOT NULL,
                file_size INT DEFAULT 0,
                uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                description TEXT,
                approval_target VARCHAR(32) NOT NULL DEFAULT 'admin',
                INDEX idx_task_id (task_id)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """)
        try:
            cur.execute("ALTER TABLE task_manager_attachments ADD COLUMN approval_target VARCHAR(32) NOT NULL DEFAULT 'admin'")
        except Exception:
            pass
        
        cur.execute("SELECT id, g_id, assigned_to FROM bid_checklists WHERE id=%s", (task_id,))
        task = cur.fetchone()
        if not task:
            cur.close()
            return jsonify({'error': 'Task not found'}), 404
        # Authorization: admin/manager or assigned employee via session
        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        employee_id = session.get('employee_id')
        if not is_flask_user and (not employee_id or task.get('assigned_to') != employee_id):
            cur.close()
            return jsonify({'error': 'Forbidden'}), 403
        g_id = task['g_id']
        os.makedirs(os.path.join(os.getcwd(), 'uploads', 'checklists', str(g_id)), exist_ok=True)
        safe_name = secure_filename(file_obj.filename)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        unique_name = f"{timestamp}_{safe_name}"
        saved_rel = os.path.join('uploads', 'checklists', str(g_id), unique_name)
        abs_path = os.path.join(os.getcwd(), saved_rel)
        file_obj.save(abs_path)
        file_size = os.path.getsize(abs_path)

        # Update legacy attachment_path field
        cur.execute("UPDATE bid_checklists SET attachment_path=%s, updated_at=CURRENT_TIMESTAMP WHERE id=%s", (saved_rel, task_id))

        # Also save to manager_attachments table so employees can see it
        user_id = current_user.id if is_flask_user else None
        raw_target = (request.form.get('approval_target') or 'admin')
        approval_target = _normalize_approval_target(raw_target) or 'admin'
        role_raw = (get_user_role() or getattr(current_user, 'role', '') or '')
        allowed_targets = _allowed_approval_targets_for_request(is_flask_user=is_flask_user, role=role_raw)
        if approval_target not in allowed_targets:
            approval_target = 'admin' if 'admin' in allowed_targets else next(iter(allowed_targets))
        cur.execute("""
            INSERT INTO task_manager_attachments (task_id, user_id, filename, original_filename, file_path, file_size, approval_target)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
        """, (task_id, user_id, unique_name, safe_name, saved_rel, file_size, approval_target))
        
        mysql.connection.commit()
        cur.close()
        try:
            socketio.emit('task_activity', {
                'task_id': task_id,
                'event': 'manager_attachment',
                'g_id': task.get('g_id'),
                'stage': task.get('stage'),
            })
        except Exception:
            pass
        return jsonify({'success': True, 'attachment_path': saved_rel, 'filename': safe_name})
    except Exception as e:
        mysql.connection.rollback()
        if 'cur' in locals():
            cur.close()
        return jsonify({'error': str(e)}), 500

@app.route('/task/<int:task_id>/attachment')
@login_required
def get_task_attachment(task_id):
    """Serve the attachment file for a task if present."""
    try:
        cur = mysql.connection.cursor(DictCursor)
        cur.execute("SELECT attachment_path FROM bid_checklists WHERE id=%s", (task_id,))
        row = cur.fetchone()
        cur.close()
        path = (row or {}).get('attachment_path') if row else None
        if not path:
            return "No attachment", 404
        abs_path = os.path.join(os.getcwd(), path)
        directory = os.path.dirname(abs_path)
        filename = os.path.basename(abs_path)
        if not os.path.exists(abs_path):
            return "Attachment missing on server", 404
        return send_from_directory(directory, filename, as_attachment=True)
    except Exception as e:
        return f"Error: {e}", 500

# --- RFP File Routes ---

def _ensure_uploaded_rfp_table_exists(cur):
    """Ensure the uploaded_rfp_files table exists before querying."""
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS uploaded_rfp_files (
            id INT AUTO_INCREMENT PRIMARY KEY,
            bid_id INT,
            g_id INT,
            filename VARCHAR(500) NOT NULL,
            file_path VARCHAR(1000) NOT NULL,
            file_size BIGINT,
            uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            uploaded_by INT,
            INDEX idx_bid_id (bid_id),
            INDEX idx_g_id (g_id)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """
    )
    mysql.connection.commit()

    def _column_exists(column_name: str) -> bool:
        cur.execute("SHOW COLUMNS FROM uploaded_rfp_files LIKE %s", (column_name,))
        return cur.fetchone() is not None

    def _index_exists(index_name: str) -> bool:
        cur.execute("SHOW INDEX FROM uploaded_rfp_files WHERE Key_name = %s", (index_name,))
        return cur.fetchone() is not None

    def _ensure_column(column_name: str, ddl: str):
        if _column_exists(column_name):
            return
        try:
            cur.execute(f"ALTER TABLE uploaded_rfp_files ADD COLUMN {ddl}")
            mysql.connection.commit()
        except Exception:
            mysql.connection.rollback()

    def _ensure_index(index_name: str, ddl: str):
        if _index_exists(index_name):
            return
        try:
            cur.execute(f"ALTER TABLE uploaded_rfp_files ADD INDEX {ddl}")
            mysql.connection.commit()
        except Exception:
            mysql.connection.rollback()

    # Ensure legacy tables have required columns and indexes, ignoring duplicate errors safely
    _ensure_column('bid_id', "bid_id INT AFTER id")
    _ensure_index('idx_bid_id', "idx_bid_id (bid_id)")

    _ensure_column('g_id', "g_id INT AFTER bid_id")
    _ensure_index('idx_g_id', "idx_g_id (g_id)")

    _ensure_column('filename', "filename VARCHAR(500) DEFAULT NULL")
    _ensure_column('original_filename', "original_filename VARCHAR(500) DEFAULT NULL")
    _ensure_column('saved_filename', "saved_filename VARCHAR(500) DEFAULT NULL")
    _ensure_column('file_type', "file_type VARCHAR(50) DEFAULT 'pdf'")
    _ensure_column('file_hash', "file_hash VARCHAR(128) DEFAULT NULL")
    _ensure_column('file_size', "file_size BIGINT DEFAULT NULL")
    _ensure_column('uploaded_at', "uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP")
    _ensure_column('uploaded_by', "uploaded_by INT DEFAULT NULL")
    _ensure_column('file_path', "file_path VARCHAR(1000) DEFAULT NULL")
    _ensure_column('section_id', "section_id VARCHAR(100) DEFAULT NULL")
    _ensure_column('description', "description TEXT DEFAULT NULL")


def _get_latest_rfp_file_for_bid(g_id):
    """Fetch the most recent RFP file record for a bid using g_id."""
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_uploaded_rfp_table_exists(cur)

        # Inspect available columns to support legacy schemas
        cur.execute("SHOW COLUMNS FROM uploaded_rfp_files")
        column_rows = cur.fetchall() or []
        columns = {row['Field'] for row in column_rows if 'Field' in row}

        has_g_id = 'g_id' in columns
        has_bid_id = 'bid_id' in columns
        has_filename = 'filename' in columns
        has_original_filename = 'original_filename' in columns
        has_saved_filename = 'saved_filename' in columns
        has_file_path = 'file_path' in columns
        has_file_size = 'file_size' in columns
        has_uploaded_at = 'uploaded_at' in columns

        select_fields = ['id']
        if has_g_id:
            select_fields.append('g_id')
        else:
            select_fields.append('NULL AS g_id')
        if has_bid_id:
            select_fields.append('bid_id')
        else:
            select_fields.append('NULL AS bid_id')

        if has_filename:
            select_fields.append('filename')
        else:
            # Fall back to original/saved filename columns if present
            coalesce_parts = []
            if has_original_filename:
                coalesce_parts.append('original_filename')
            if has_saved_filename:
                coalesce_parts.append('saved_filename')
            if coalesce_parts:
                select_fields.append(f"COALESCE({', '.join(coalesce_parts)}) AS filename")
            else:
                select_fields.append("NULL AS filename")

        if has_file_path:
            select_fields.append('file_path')
        else:
            select_fields.append('NULL AS file_path')

        if has_file_size:
            select_fields.append('file_size')
        else:
            select_fields.append('NULL AS file_size')

        if has_uploaded_at:
            select_fields.append('uploaded_at')
            order_clause = "uploaded_at DESC, id DESC"
        else:
            # Legacy tables might use created_at/updated_at; prefer whichever exists
            timestamp_col = None
            for legacy_col in ('created_at', 'updated_at', 'saved_at'):
                if legacy_col in columns:
                    timestamp_col = legacy_col
                    break
            if timestamp_col:
                select_fields.append(f"{timestamp_col} AS uploaded_at")
                order_clause = f"{timestamp_col} DESC, id DESC"
            else:
                select_fields.append('NULL AS uploaded_at')
                order_clause = "id DESC"

        where_clauses = []
        params = []
        if has_g_id:
            where_clauses.append("g_id = %s")
            params.append(g_id)
        if has_bid_id:
            where_clauses.append("bid_id = %s")
            params.append(g_id)

        if not where_clauses:
            # As a last resort, attempt to match against legacy columns such as bid or project id
            for legacy_col in ('b_id', 'project_id'):
                if legacy_col in columns:
                    where_clauses.append(f"{legacy_col} = %s")
                    params.append(g_id)
                    break

        if not where_clauses:
            return None

        select_clause = ", ".join(select_fields)
        base_where = " OR ".join(f"({clause})" for clause in where_clauses)
        # Only consider true RFP source PDFs (exclude per-section attachments)
        extra_filters = []
        # Exclude rows tied to a section if the column exists
        extra_filters.append("(section_id IS NULL OR section_id = '')")
        # Ensure the file is a PDF based on file_type or filename columns if present
        pdf_checks = ["LOWER(file_path) LIKE '%%.pdf'"]
        if 'file_type' in columns:
            pdf_checks.append("LOWER(file_type) = 'pdf'")
        if 'filename' in columns:
            pdf_checks.append("LOWER(filename) LIKE '%%.pdf'")
        if 'saved_filename' in columns:
            pdf_checks.append("LOWER(saved_filename) LIKE '%%.pdf'")
        extra_filters.append("(" + " OR ".join(pdf_checks) + ")")
        where_clause_sql = f"({base_where}) AND " + " AND ".join(extra_filters)

        try:
            cur.execute(
                f"""
                SELECT {select_clause}
                FROM uploaded_rfp_files
                WHERE {where_clause_sql}
                ORDER BY {order_clause}
                LIMIT 1
                """,
                tuple(params),
            )
        except Exception:
            # The table may not exist yet???create it and retry once.
            mysql.connection.rollback()
            _ensure_uploaded_rfp_table_exists(cur)
            cur.execute(
                f"""
                SELECT {select_clause}
                FROM uploaded_rfp_files
                WHERE {where_clause_sql}
                ORDER BY {order_clause}
                LIMIT 1
                """,
                tuple(params),
            )
        row = cur.fetchone()

        # Fallback: if nothing matched strict filters (e.g., legacy rows with section_id populated),
        # relax the section_id constraint and try again for a PDF.
        if not row:
            relaxed_filters = []
            relaxed_filters.append(base_where)
            relaxed_pdf_checks = []
            relaxed_pdf_checks.append("LOWER(file_path) LIKE '%%.pdf'")
            if 'file_type' in columns:
                relaxed_pdf_checks.append("LOWER(file_type) = 'pdf'")
            if 'filename' in columns:
                relaxed_pdf_checks.append("LOWER(filename) LIKE '%%.pdf'")
            if 'saved_filename' in columns:
                relaxed_pdf_checks.append("LOWER(saved_filename) LIKE '%%.pdf'")
            relaxed_where_sql = f"({base_where}) AND (" + " OR ".join(relaxed_pdf_checks) + ")"
            try:
                cur.execute(
                    f"""
                    SELECT {select_clause}
                    FROM uploaded_rfp_files
                    WHERE {relaxed_where_sql}
                    ORDER BY {order_clause}
                    LIMIT 1
                    """,
                    tuple(params),
                )
                row = cur.fetchone()
            except Exception:
                pass

        if row and 'id' in row:
            update_clauses = []
            update_params = []
            # Backfill missing identifiers for legacy rows
            if has_g_id and (not row.get('g_id')):
                update_clauses.append("g_id = %s")
                update_params.append(g_id)
                row['g_id'] = g_id
            if has_bid_id and (not row.get('bid_id')):
                update_clauses.append("bid_id = %s")
                update_params.append(g_id)
                row['bid_id'] = g_id

            if update_clauses:
                update_params.append(row['id'])
                try:
                    cur.execute(
                        f"UPDATE uploaded_rfp_files SET {', '.join(update_clauses)} WHERE id = %s",
                        tuple(update_params),
                    )
                    mysql.connection.commit()
                except Exception:
                    mysql.connection.rollback()

        return row
    finally:
        cur.close()


def _extract_pdf_pages(file_path, start_page=1, limit=None):
    """Extract text from a PDF file path using PyMuPDF or fall back to PyPDF2."""
    pages = []
    total_pages = 0
    start_index = max(start_page - 1, 0)
    use_limit = None if (limit is None or limit <= 0) else limit

    if _FITZ_AVAILABLE:
        with _pymupdf.open(file_path) as doc:
            total_pages = doc.page_count
            if start_index >= total_pages:
                return pages, total_pages
            end_index = total_pages if use_limit is None else min(total_pages, start_index + use_limit)
            for index in range(start_index, end_index):
                page = doc.load_page(index)
                text = page.get_text("text") or ""
                pages.append(
                    {
                        "number": index + 1,
                        "text": text,
                        "characters": len(text),
                    }
                )
        return pages, total_pages

    if _PdfReader is not None:
        with open(file_path, "rb") as fh:
            reader = _PdfReader(fh)
            total_pages = len(reader.pages)
            if start_index >= total_pages:
                return pages, total_pages
            end_index = total_pages if use_limit is None else min(total_pages, start_index + use_limit)
            for index in range(start_index, end_index):
                page = reader.pages[index]
                text = page.extract_text() or ""
                pages.append(
                    {
                        "number": index + 1,
                        "text": text,
                        "characters": len(text),
                    }
                )
        return pages, total_pages

    raise RuntimeError(
        "PDF text extraction requires PyMuPDF (`pip install PyMuPDF`) or PyPDF2 (`pip install PyPDF2`)."
    )


@app.route('/api/rfp-file/<int:g_id>/upload', methods=['POST'])
@login_required
def api_upload_rfp_file(g_id):
    """Upload a PDF for the specified g_id and store metadata in uploaded_rfp_files."""
    upload_files = request.files.getlist('file')
    if not upload_files:
        upload_files = request.files.getlist('files')
    upload_files = [f for f in (upload_files or []) if f and f.filename]
    if not upload_files:
        return jsonify({'error': 'missing_file', 'message': 'Please choose a PDF to upload.'}), 400

    for f in upload_files:
        filename_lower = f.filename.lower()
        if not filename_lower.endswith('.pdf'):
            return jsonify({'error': 'invalid_type', 'message': 'Only PDF files are supported.'}), 400

    from werkzeug.utils import secure_filename
    import uuid
    import hashlib

    first_original = secure_filename(upload_files[0].filename) or f"rfp_{uuid.uuid4().hex}.pdf"
    if len(upload_files) > 1:
        safe_original = f"merged_{len(upload_files)}_{first_original}"
    else:
        safe_original = first_original
    unique_token = uuid.uuid4().hex
    saved_filename = f"{unique_token}_{safe_original}"

    uploads_dir = os.path.join(os.getcwd(), 'uploads', 'rfp')
    os.makedirs(uploads_dir, exist_ok=True)
    absolute_path = os.path.join(uploads_dir, saved_filename)

    try:
        if len(upload_files) == 1:
            upload_files[0].save(absolute_path)
        else:
            try:
                from PyPDF2 import PdfMerger
            except Exception:
                return jsonify({'error': 'dependency_missing', 'message': 'PyPDF2 is required to merge PDF files.'}), 500
            merger = PdfMerger()
            for f in upload_files:
                try:
                    f.stream.seek(0)
                    merger.append(f.stream)
                except Exception as err:
                    merger.close()
                    return jsonify({'error': 'merge_failed', 'message': f'Failed to merge PDF: {err}'}), 500
            with open(absolute_path, 'wb') as out:
                merger.write(out)
            merger.close()
    except Exception as err:
        return jsonify({'error': 'save_failed', 'message': f'Could not save file: {err}'}), 500

    file_size = 0
    file_hash = ''
    try:
        file_size = os.path.getsize(absolute_path)
        with open(absolute_path, 'rb') as handler:
            file_hash = hashlib.sha256(handler.read()).hexdigest()
    except Exception:
        pass

    # Lookup bid_id (legacy) from go_bids table if available
    bid_id = None
    cur_lookup = mysql.connection.cursor(DictCursor)
    try:
        cur_lookup.execute("SELECT id FROM go_bids WHERE g_id = %s", (g_id,))
        go_bid_row = cur_lookup.fetchone()
        if go_bid_row and go_bid_row.get('id'):
            bid_id = go_bid_row['id']
    finally:
        cur_lookup.close()

    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_uploaded_rfp_table_exists(cur)
        cur.execute("SHOW COLUMNS FROM uploaded_rfp_files")
        column_rows = cur.fetchall() or []
        available_columns = {row['Field'] for row in column_rows if 'Field' in row}

        columns = []
        values = []

        def add_column(col_name, value):
            if col_name in available_columns:
                columns.append(col_name)
                values.append(value)

        add_column('bid_id', bid_id)
        add_column('g_id', g_id)
        add_column('filename', safe_original)
        if len(upload_files) == 1:
            add_column('original_filename', upload_files[0].filename)
        else:
            add_column('original_filename', ', '.join([f.filename for f in upload_files]))
        add_column('saved_filename', saved_filename)
        add_column('file_path', absolute_path)
        add_column('file_type', 'pdf')
        add_column('file_size', file_size)
        add_column('file_hash', file_hash)
        add_column('uploaded_by', getattr(current_user, 'id', None))

        if not columns:
            return jsonify({'error': 'schema_error', 'message': 'Unable to persist the uploaded file.'}), 500

        placeholders = ','.join(['%s'] * len(columns))
        column_sql = ','.join(columns)
        cur.execute(
            f"INSERT INTO uploaded_rfp_files ({column_sql}) VALUES ({placeholders})",
            tuple(values),
        )
        mysql.connection.commit()

        # Fetch parsed preview for immediate display
        parsed_pages = []
        total_pages = 0
        next_start = None
        try:
            parsed_pages, total_pages = _extract_pdf_pages(absolute_path, start_page=1, limit=3)
            if parsed_pages:
                last_number = parsed_pages[-1].get('number')
                if last_number and total_pages and last_number < total_pages:
                    next_start = last_number + 1
        except Exception:
            parsed_pages = []
            total_pages = 0
            next_start = None

        return jsonify(
            {
                'success': True,
                'file_id': cur.lastrowid,
                'filename': safe_original,
                'total_pages': total_pages,
                'next_start': next_start,
                'pages': parsed_pages,
            }
        )
    except Exception as err:
        mysql.connection.rollback()
        if os.path.exists(absolute_path):
            try:
                os.remove(absolute_path)
            except Exception:
                pass
        return jsonify({'error': 'upload_failed', 'message': str(err)}), 500
    finally:
        cur.close()


@app.route('/api/bid-analyzer/final-docs/upload', methods=['POST'])
@login_required
def api_upload_final_submission_docs():
    """Upload final submission documents for a bid and store in uploaded_rfp_files."""
    from werkzeug.utils import secure_filename
    import uuid
    import hashlib

    g_id = (request.form.get('g_id') or '').strip()
    bid_id = (request.form.get('bid_id') or '').strip()
    bid_name = (request.form.get('bid_name') or '').strip()
    description = (request.form.get('description') or '').strip()

    if g_id and not g_id.isdigit():
        g_id = ''

    if not g_id and bid_id:
        try:
            cur_lookup = mysql.connection.cursor(DictCursor)
            cur_lookup.execute("SELECT g_id FROM go_bids WHERE id=%s", (int(bid_id),))
            row = cur_lookup.fetchone() or {}
            g_id = str(row.get('g_id') or '').strip()
        finally:
            try:
                cur_lookup.close()
            except Exception:
                pass

    if not g_id:
        return jsonify({'success': False, 'error': 'missing_g_id', 'message': 'Project code is required.'}), 400

    upload_files = request.files.getlist('files')
    if not upload_files:
        upload_files = request.files.getlist('file')
    upload_files = [f for f in (upload_files or []) if f and f.filename]
    if not upload_files:
        return jsonify({'success': False, 'error': 'missing_file', 'message': 'Please attach one or more files.'}), 400

    uploads_dir = os.path.join(os.getcwd(), 'uploads', 'final_submissions', str(g_id))
    os.makedirs(uploads_dir, exist_ok=True)

    saved_ids = []
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_uploaded_rfp_table_exists(cur)
        cur.execute("SHOW COLUMNS FROM uploaded_rfp_files")
        column_rows = cur.fetchall() or []
        available_columns = {row['Field'] for row in column_rows if 'Field' in row}

        for f in upload_files:
            safe_original = secure_filename(f.filename) or f"final_{uuid.uuid4().hex}"
            prefix = secure_filename(bid_name) or f"bid_{g_id}"
            display_name = f"{prefix}_{safe_original}" if prefix else safe_original
            unique_token = uuid.uuid4().hex
            saved_filename = f"{unique_token}_{display_name}"
            absolute_path = os.path.join(uploads_dir, saved_filename)

            try:
                f.save(absolute_path)
            except Exception as err:
                return jsonify({'success': False, 'error': 'save_failed', 'message': f'Could not save file: {err}'}), 500

            file_size = 0
            file_hash = ''
            try:
                file_size = os.path.getsize(absolute_path)
                with open(absolute_path, 'rb') as handler:
                    file_hash = hashlib.sha256(handler.read()).hexdigest()
            except Exception:
                pass

            filename_lower = (safe_original or '').lower()
            if filename_lower.endswith('.pdf'):
                file_type = 'pdf'
            elif filename_lower.endswith(('.png', '.jpg', '.jpeg', '.webp')):
                file_type = 'image'
            else:
                file_type = 'file'

            columns = []
            values = []

            def add_column(col_name, value):
                if col_name in available_columns:
                    columns.append(col_name)
                    values.append(value)

            add_column('bid_id', int(bid_id) if bid_id.isdigit() else None)
            add_column('g_id', int(g_id) if g_id.isdigit() else None)
            add_column('filename', display_name)
            add_column('original_filename', f.filename)
            add_column('saved_filename', saved_filename)
            add_column('file_path', absolute_path)
            add_column('file_type', file_type)
            add_column('file_size', file_size)
            add_column('file_hash', file_hash)
            add_column('uploaded_by', getattr(current_user, 'id', None))
            add_column('section_id', 'final_submission')
            add_column('description', description or None)

            if not columns:
                return jsonify({'success': False, 'error': 'schema_error', 'message': 'Unable to persist the uploaded file.'}), 500

            placeholders = ','.join(['%s'] * len(columns))
            column_sql = ','.join(columns)
            cur.execute(
                f"INSERT INTO uploaded_rfp_files ({column_sql}) VALUES ({placeholders})",
                tuple(values),
            )
            saved_ids.append(cur.lastrowid)

        mysql.connection.commit()
        return jsonify({'success': True, 'file_ids': saved_ids})
    except Exception as err:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': 'upload_failed', 'message': str(err)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/api/section-attachment/<int:g_id>/upload', methods=['POST'])
@login_required
def api_upload_section_attachment(g_id):
    """Upload attachments for a specific section (images or PDFs)."""
    section_id = request.args.get('section_id') or request.form.get('section_id') or ''
    section_id = section_id.strip()
    if not section_id:
        return jsonify({'error': 'missing_section', 'message': 'Section ID is required.'}), 400
    upload_file = request.files.get('file')
    if not upload_file or not upload_file.filename:
        return jsonify({'error': 'missing_file', 'message': 'Please choose a file to upload.'}), 400
    filename_lower = upload_file.filename.lower()
    # Allow images and PDF files
    allowed_ext = ('.png', '.jpg', '.jpeg', '.webp', '.pdf')
    if not filename_lower.endswith(allowed_ext):
        return jsonify({'error': 'invalid_type', 'message': 'Only images (.png, .jpg, .jpeg, .webp) or PDF files are allowed.'}), 400
    from werkzeug.utils import secure_filename
    import uuid
    import hashlib
    safe_original = secure_filename(upload_file.filename) or f"img_{uuid.uuid4().hex}.png"
    unique_token = uuid.uuid4().hex
    saved_filename = f"{unique_token}_{safe_original}"
    uploads_dir = os.path.join(os.getcwd(), 'uploads', 'sections', section_id)
    os.makedirs(uploads_dir, exist_ok=True)
    absolute_path = os.path.join(uploads_dir, saved_filename)
    try:
        upload_file.save(absolute_path)
    except Exception as err:
        return jsonify({'error': 'save_failed', 'message': f'Could not save file: {err}'}), 500
    file_size = 0
    file_hash = ''
    try:
        file_size = os.path.getsize(absolute_path)
        with open(absolute_path, 'rb') as handler:
            file_hash = hashlib.sha256(handler.read()).hexdigest()
    except Exception:
        pass
    bid_id = None
    cur_lookup = mysql.connection.cursor(DictCursor)
    try:
        cur_lookup.execute("SELECT id FROM go_bids WHERE g_id = %s", (g_id,))
        go_bid_row = cur_lookup.fetchone()
        if go_bid_row and go_bid_row.get('id'):
            bid_id = go_bid_row['id']
    finally:
        cur_lookup.close()
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_uploaded_rfp_table_exists(cur)
        cur.execute("SHOW COLUMNS FROM uploaded_rfp_files")
        column_rows = cur.fetchall() or []
        available_columns = {row['Field'] for row in column_rows if 'Field' in row}
        columns = []
        values = []
        def add_column(col_name, value):
            if col_name in available_columns:
                columns.append(col_name)
                values.append(value)
        add_column('bid_id', bid_id)
        add_column('g_id', g_id)
        add_column('filename', safe_original)
        add_column('original_filename', upload_file.filename)
        add_column('saved_filename', saved_filename)
        add_column('file_path', absolute_path)
        add_column('file_type', 'pdf' if filename_lower.endswith('.pdf') else 'image')
        add_column('file_size', file_size)
        add_column('file_hash', file_hash)
        add_column('uploaded_by', getattr(current_user, 'id', None))
        add_column('section_id', section_id)
        if not columns:
            return jsonify({'error': 'schema_error', 'message': 'Unable to persist the uploaded image.'}), 500
        placeholders = ','.join(['%s'] * len(columns))
        column_sql = ','.join(columns)
        cur.execute(
            f"INSERT INTO uploaded_rfp_files ({column_sql}) VALUES ({placeholders})",
            tuple(values),
        )
        mysql.connection.commit()
        return jsonify(
            {
                'success': True,
                'file_id': cur.lastrowid,
                'filename': safe_original,
                'section_id': section_id,
                'file_type': 'pdf' if filename_lower.endswith('.pdf') else 'image',
            }
        )
    except Exception as err:
        mysql.connection.rollback()
        if os.path.exists(absolute_path):
            try:
                os.remove(absolute_path)
            except Exception:
                pass
        return jsonify({'error': 'upload_failed', 'message': str(err)}), 500
    finally:
        cur.close()


@app.route('/rfp-file/view/by-g/<int:g_id>')
@login_required
def view_rfp_file_by_g(g_id):
    """View the latest RFP file for a bid using its g_id."""
    try:
        file_data = _get_latest_rfp_file_for_bid(g_id)
    except Exception as err:
        app.logger.exception("Error locating RFP file for g_id %s: %s", g_id, err)
        abort(500, description="Failed to locate RFP file.")

    if not file_data:
        abort(404, description="No RFP file associated with this project.")

    file_path = file_data.get('file_path')
    filename = file_data.get('filename') or os.path.basename(file_path or '')

    if not file_path or not os.path.exists(file_path):
        abort(404, description="RFP file not found on server.")

    if file_path.lower().endswith('.pdf'):
        return send_file(file_path, mimetype='application/pdf', as_attachment=False, download_name=filename)

    return send_file(file_path, as_attachment=True, download_name=filename)


@app.route('/api/rfp-file/<int:g_id>/parsed', methods=['GET'])
@login_required
def api_rfp_file_parsed(g_id):
    """Return parsed PDF text for the latest RFP file associated with g_id."""
    start = request.args.get('start', default=1, type=int)
    limit = request.args.get('limit', default=3, type=int)
    page_limit = None if limit is None or limit <= 0 else limit
    start = start if start and start > 0 else 1

    try:
        file_data = _get_latest_rfp_file_for_bid(g_id)
    except Exception as err:
        app.logger.exception("Error locating RFP file for g_id %s: %s", g_id, err)
        return jsonify({'error': 'internal_error'}), 500

    if not file_data:
        return jsonify({'error': 'not_found', 'message': 'No RFP file associated with this project.'}), 404

    file_path = file_data.get('file_path')
    if not file_path or not os.path.exists(file_path):
        return jsonify({'error': 'file_missing', 'message': 'RFP file not found on server.'}), 404

    if not file_path.lower().endswith('.pdf'):
        return jsonify({'error': 'unsupported_type', 'message': 'Only PDF files can be parsed.'}), 400

    try:
        pages, total_pages = _extract_pdf_pages(file_path, start_page=start, limit=page_limit)
    except Exception as err:
        app.logger.exception("Error parsing PDF for g_id %s: %s", g_id, err)
        return jsonify({'error': 'parse_failed', 'message': 'Unable to parse the PDF file.'}), 500

    next_start = None
    if pages:
        last_page_number = pages[-1]['number']
        if last_page_number < total_pages:
            next_start = last_page_number + 1

    return jsonify(
        {
            'g_id': g_id,
            'file_id': file_data.get('id'),
            'filename': file_data.get('filename'),
            'total_pages': total_pages,
            'start': start,
            'limit': page_limit,
            'next_start': next_start,
            'pages': pages,
        }
    )


@app.route('/rfp-file/view/<int:file_id>')
@login_required
def view_rfp_file(file_id):
    """View RFP file in browser"""
    try:
        cur = mysql.connection.cursor(DictCursor)
        cur.execute("""
            SELECT file_path, filename
            FROM uploaded_rfp_files
            WHERE id = %s
        """, (file_id,))
        file_data = cur.fetchone()
        cur.close()
        
        if not file_data:
            flash('RFP file not found', 'error')
            return redirect(request.referrer or url_for('top_admin_overview'))
        
        file_path = file_data['file_path']
        if not os.path.exists(file_path):
            flash('RFP file not found on server', 'error')
            return redirect(request.referrer or url_for('top_admin_overview'))
        
        # For PDF files, send as inline to view in browser
        if file_path.lower().endswith('.pdf'):
            return send_file(file_path, mimetype='application/pdf', as_attachment=False)
        else:
            # For other file types, download
            return send_file(file_path, as_attachment=True)
    except Exception as e:
        flash(f'Error viewing file: {str(e)}', 'error')
        return redirect(request.referrer or url_for('top_admin_overview'))

@app.route('/rfp-file/download/<int:file_id>')
@login_required
def download_rfp_file(file_id):
    """Download RFP file"""
    try:
        cur = mysql.connection.cursor(DictCursor)
        cur.execute("""
            SELECT file_path, filename
            FROM uploaded_rfp_files
            WHERE id = %s
        """, (file_id,))
        file_data = cur.fetchone()
        cur.close()
        
        if not file_data:
            flash('RFP file not found', 'error')
            return redirect(request.referrer or url_for('top_admin_overview'))
        
        file_path = file_data['file_path']
        filename = file_data['filename']
        
        if not os.path.exists(file_path):
            flash('RFP file not found on server', 'error')
            return redirect(request.referrer or url_for('top_admin_overview'))
        
        return send_file(file_path, as_attachment=True, download_name=filename)
    except Exception as e:
        flash(f'Error downloading file: {str(e)}', 'error')
        return redirect(request.referrer or url_for('top_admin_overview'))


@app.route('/api/rfp-file/decrypt', methods=['POST'])
@login_required
def decrypt_rfp_file():
    """Decrypt an encrypted PDF file and return the decrypted version."""
    try:
        pdf_url = request.args.get('url')
        if not pdf_url:
            return jsonify({'error': 'URL parameter is required'}), 400

        # Extract file path from URL or fetch the file
        from urllib.parse import urlparse, unquote
        import tempfile
        
        # If it's a local file URL, extract the path
        if pdf_url.startswith('/'):
            # It's a relative URL, construct full path
            parsed = urlparse(pdf_url)
            # Try to find the file in the uploads directory
            if 'rfp-file/view' in pdf_url:
                # Extract file_id or g_id from URL
                import re
                match = re.search(r'/rfp-file/view/(\d+)', pdf_url)
                if match:
                    file_id = int(match.group(1))
                    cur = mysql.connection.cursor(DictCursor)
                    cur.execute("SELECT file_path FROM uploaded_rfp_files WHERE id = %s", (file_id,))
                    file_data = cur.fetchone()
                    cur.close()
                    if file_data and os.path.exists(file_data['file_path']):
                        file_path = file_data['file_path']
                    else:
                        return jsonify({'error': 'File not found'}), 404
                else:
                    # Try g_id
                    match = re.search(r'/rfp-file/view/by-g/(\d+)', pdf_url)
                    if match:
                        g_id = int(match.group(1))
                        file_data = _get_latest_rfp_file_for_bid(g_id)
                        if file_data and os.path.exists(file_data.get('file_path')):
                            file_path = file_data['file_path']
                        else:
                            return jsonify({'error': 'File not found'}), 404
                    else:
                        return jsonify({'error': 'Invalid URL format'}), 400
            else:
                return jsonify({'error': 'Invalid URL format'}), 400
        else:
            return jsonify({'error': 'Only local file URLs are supported'}), 400

        if not _FITZ_AVAILABLE:
            return jsonify({'error': 'PyMuPDF is not available for PDF decryption'}), 500

        # Attempt to decrypt the PDF
        try:
            # Try opening with empty password first (some PDFs have empty password)
            doc = _pymupdf.open(file_path)
            
            # If PDF is encrypted, try common passwords or empty password
            if doc.is_encrypted:
                # Try empty password
                if not doc.authenticate(""):
                    # Try some common passwords
                    common_passwords = ["", "password", "admin", "1234", "12345"]
                    authenticated = False
                    for pwd in common_passwords:
                        if doc.authenticate(pwd):
                            authenticated = True
                            break
                    
                    if not authenticated:
                        # Try to decrypt without password (some PDFs can be decrypted this way)
                        try:
                            doc.close()
                            # Create a new document by copying pages (this sometimes works for encrypted PDFs)
                            doc = _pymupdf.open(file_path)
                            if doc.is_encrypted and not doc.authenticate(""):
                                return jsonify({'error': 'PDF is password protected and cannot be decrypted automatically'}), 400
                        except:
                            return jsonify({'error': 'PDF is password protected and cannot be decrypted automatically'}), 400

            # Create a new decrypted PDF in memory
            decrypted_doc = _pymupdf.open()  # Create new empty PDF
            decrypted_doc.insert_pdf(doc)  # Copy all pages from encrypted to decrypted
            
            # Save to temporary file
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.pdf')
            temp_path = temp_file.name
            temp_file.close()
            
            decrypted_doc.save(temp_path)
            decrypted_doc.close()
            doc.close()
            
            # Return the decrypted PDF
            return send_file(temp_path, mimetype='application/pdf', as_attachment=False, download_name='decrypted_rfp.pdf')
            
        except Exception as decrypt_error:
            app.logger.exception("Error decrypting PDF: %s", decrypt_error)
            return jsonify({'error': f'Failed to decrypt PDF: {str(decrypt_error)}'}), 500

    except Exception as e:
        app.logger.exception("Error in decrypt_rfp_file: %s", e)
        return jsonify({'error': str(e)}), 500


@app.route('/api/rfp-file/<int:g_id>/save-edited', methods=['POST'])
@login_required
def save_edited_rfp_file(g_id):
    """Save an edited PDF file."""
    try:
        upload_file = request.files.get('file')
        if not upload_file or not upload_file.filename:
            return jsonify({'error': 'missing_file', 'message': 'Please provide a PDF file to save.'}), 400

        filename_lower = upload_file.filename.lower()
        if not filename_lower.endswith('.pdf'):
            return jsonify({'error': 'invalid_type', 'message': 'Only PDF files are supported.'}), 400

        from werkzeug.utils import secure_filename
        import uuid
        import hashlib

        safe_original = secure_filename(upload_file.filename) or f"edited_rfp_{uuid.uuid4().hex}.pdf"
        unique_token = uuid.uuid4().hex
        saved_filename = f"{unique_token}_{safe_original}"

        uploads_dir = os.path.join(os.getcwd(), 'uploads', 'rfp')
        os.makedirs(uploads_dir, exist_ok=True)
        absolute_path = os.path.join(uploads_dir, saved_filename)

        try:
            upload_file.save(absolute_path)
        except Exception as err:
            return jsonify({'error': 'save_failed', 'message': f'Could not save file: {err}'}), 500

        file_size = 0
        file_hash = ''
        try:
            file_size = os.path.getsize(absolute_path)
            with open(absolute_path, 'rb') as handler:
                file_hash = hashlib.sha256(handler.read()).hexdigest()
        except Exception:
            pass

        # Lookup bid_id (legacy) from go_bids table if available
        bid_id = None
        cur_lookup = mysql.connection.cursor(DictCursor)
        try:
            cur_lookup.execute("SELECT id FROM go_bids WHERE g_id = %s", (g_id,))
            go_bid_row = cur_lookup.fetchone()
            if go_bid_row and go_bid_row.get('id'):
                bid_id = go_bid_row['id']
        finally:
            cur_lookup.close()

        cur = mysql.connection.cursor(DictCursor)
        try:
            _ensure_uploaded_rfp_table_exists(cur)
            cur.execute("SHOW COLUMNS FROM uploaded_rfp_files")
            column_rows = cur.fetchall() or []
            available_columns = {row['Field'] for row in column_rows if 'Field' in row}

            columns = []
            values = []

            def add_column(col_name, value):
                if col_name in available_columns:
                    columns.append(col_name)
                    values.append(value)

            add_column('bid_id', bid_id)
            add_column('g_id', g_id)
            add_column('filename', safe_original)
            add_column('original_filename', upload_file.filename)
            add_column('saved_filename', saved_filename)
            add_column('file_path', absolute_path)
            add_column('file_type', 'pdf')
            add_column('file_size', file_size)
            add_column('file_hash', file_hash)
            add_column('uploaded_by', getattr(current_user, 'id', None))

            if not columns:
                return jsonify({'error': 'schema_error', 'message': 'Unable to persist the uploaded file.'}), 500

            placeholders = ','.join(['%s'] * len(columns))
            column_sql = ','.join(columns)
            cur.execute(
                f"INSERT INTO uploaded_rfp_files ({column_sql}) VALUES ({placeholders})",
                tuple(values),
            )
            mysql.connection.commit()

            return jsonify({
                'success': True,
                'message': 'Edited PDF saved successfully',
                'file_id': cur.lastrowid,
                'filename': safe_original
            })

        except Exception as db_error:
            mysql.connection.rollback()
            app.logger.exception("Database error saving edited PDF: %s", db_error)
            return jsonify({'error': 'database_error', 'message': f'Failed to save file metadata: {db_error}'}), 500
        finally:
            cur.close()

    except Exception as e:
        app.logger.exception("Error in save_edited_rfp_file: %s", e)
        return jsonify({'error': 'server_error', 'message': str(e)}), 500

# --- API Endpoints for Team Dashboard ---
@app.route('/api/bid/<int:g_id>/assignees')
@login_required
def api_bid_assignees(g_id):
    """API endpoint to get assigned members for a specific bid"""
    cur = mysql.connection.cursor(DictCursor)
    
    try:
        cur.execute(
            """
            SELECT bam.g_id, e.id AS employee_id, e.name, e.email, e.department
            FROM bid_assignment_members bam
            JOIN employees e ON e.id = bam.employee_id
            WHERE bam.g_id = %s AND e.is_active = TRUE
            ORDER BY e.name
            """,
            (g_id,)
        )
        members = cur.fetchall()
        result = [{'id': m['employee_id'], 'name': m['name'], 'email': m['email'], 'department': m['department']} for m in members]
        cur.close()
        return jsonify({'ok': True, 'members': result})
    except Exception as e:
        cur.close()
        return jsonify({'ok': False, 'members': [], 'error': str(e)})


@app.route('/api/bid/<int:g_id>/team-lead')
@login_required
def api_bid_team_lead(g_id):
    """API endpoint to get the assigned Team Lead(s) for a bid (Manager -> Team Lead assignment)."""
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute(
            """
            SELECT tab.team_lead, tab.task_completion_date, tab.assigned_at, tab.assigned_by_email, u.role
            FROM teamlead_assign_bids tab
            LEFT JOIN users u ON LOWER(u.email)=LOWER(tab.team_lead)
            WHERE tab.g_id=%s
            ORDER BY tab.assigned_at DESC, tab.updated_at DESC
            """,
            (g_id,),
        )
        rows = cur.fetchall() or []
        results = []
        for r in rows:
            email = (r.get('team_lead') or '').strip()
            if not email:
                continue
            try:
                name = email.split('@')[0].replace('.', ' ').title()
            except Exception:
                name = email
            results.append({
                'email': email,
                'name': name,
                'role': (r.get('role') or '').strip(),
                'task_completion_date': r.get('task_completion_date'),
                'assigned_at': r.get('assigned_at'),
                'assigned_by_email': r.get('assigned_by_email'),
            })
        primary = results[0] if results else None
        return jsonify({'ok': True, 'team_leads': results, 'team_lead': primary})
    except Exception as e:
        return jsonify({'ok': False, 'team_leads': [], 'team_lead': None, 'error': str(e)})
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/task/<int:task_id>/assign-team-lead', methods=['POST'])
@login_required
def assign_task_team_lead(task_id):
    data = request.get_json(silent=True) or {}
    email = (data.get('email') or '').strip()
    stage = (data.get('stage') or '').strip().lower()
    if not email or not stage:
        return jsonify({'success': False, 'error': 'missing_fields'}), 400

    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SELECT id, role FROM users WHERE LOWER(email)=LOWER(%s) LIMIT 1", (email,))
        user_row = cur.fetchone() or {}
        if not user_row.get('id'):
            return jsonify({'success': False, 'error': 'team_lead_not_found'}), 404
        lead_id = int(user_row.get('id'))
        lead_role = (user_row.get('role') or '').strip().lower().replace('_', ' ')
        acceptable_roles = {'teamlead', 'team lead', 'team_lead', 'business', 'design', 'operations', 'site engineer', 'site_engineer', 'engineering', 'engineer'}
        if lead_role not in acceptable_roles and _normalize_role_key(lead_role) != 'teamlead':
            return jsonify({'success': False, 'error': 'not_team_lead'}), 400

        task_stage = _normalize_department_key(stage)
        lead_dept = None
        try:
            cur.execute(
                """
                SELECT department_key
                FROM user_company_access
                WHERE user_id=%s AND COALESCE(is_active, TRUE)=TRUE
                ORDER BY updated_at DESC
                LIMIT 1
                """,
                (lead_id,),
            )
            uca = cur.fetchone() or {}
            lead_dept = _normalize_department_key(uca.get('department_key') or '')
        except Exception:
            lead_dept = None

        if task_stage and lead_dept and lead_dept != task_stage:
            return jsonify({'success': False, 'error': 'team_lead_department_mismatch'}), 400

        _ensure_task_team_lead_assignments_table(cur)
        cur.execute(
            """
            INSERT INTO task_team_lead_assignments (task_id, team_lead_user_id, assigned_by_user_id, department_key)
            VALUES (%s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE
                team_lead_user_id = VALUES(team_lead_user_id),
                assigned_by_user_id = VALUES(assigned_by_user_id),
                department_key = VALUES(department_key),
                assigned_at = CURRENT_TIMESTAMP
            """,
            (int(task_id), lead_id, getattr(current_user, 'id', None), task_stage),
        )
        mysql.connection.commit()
        return jsonify({'success': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'success': False, 'error': 'db', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/api/employee/bids/<int:g_id>/tasks')
def api_employee_bid_tasks(g_id):
    """Return tasks for the current employee for a specific bid.
    Used by employee_dashboard.html task modal."""
    cur = mysql.connection.cursor(DictCursor)
    try:
        # Support both:
        # - Flask-Login users (current_user.email)
        # - Employee session users (session['employee_id'])
        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        employee_id = session.get('employee_id')

        emp = None
        if is_flask_user:
            try:
                cur.execute(
                    "SELECT id, name, email FROM employees WHERE LOWER(email)=LOWER(%s) AND is_active=TRUE LIMIT 1",
                    (current_user.email,),
                )
                emp = cur.fetchone()
            except Exception:
                emp = None
        else:
            if employee_id:
                try:
                    cur.execute("SELECT id, name, email FROM employees WHERE id=%s AND is_active=TRUE LIMIT 1", (employee_id,))
                    emp = cur.fetchone()
                except Exception:
                    emp = None

        if not emp:
            return jsonify({'ok': False, 'error': 'employee_not_found', 'tasks': []}), 403

        cur.execute(
            """
            SELECT
                bc.id,
                bc.task_code,
                bc.task_name,
                COALESCE(bc.description,'') AS description,
                COALESCE(bc.status,'pending') AS status,
                bc.due_date,
                bc.created_at,
                COALESCE(bc.priority,'medium') AS priority,
                (
                    SELECT COUNT(*)
                    FROM document_approvals da
                    JOIN task_work_files twf
                      ON da.source_table='task_work_files' AND da.source_id=twf.id
                    WHERE twf.task_id = bc.id AND da.status='pending'
                ) +
                (
                    SELECT COUNT(*)
                    FROM document_approvals da
                    JOIN task_comments tc
                      ON da.source_table='task_comments' AND da.source_id=tc.id
                    WHERE tc.task_id = bc.id AND da.status='pending'
                ) +
                (
                    SELECT COUNT(*)
                    FROM task_comments tc
                    LEFT JOIN document_approvals da
                      ON da.source_table='task_comments' AND da.source_id=tc.id
                    WHERE tc.task_id = bc.id AND tc.needs_approval=1 AND da.id IS NULL
                ) +
                (
                    SELECT COUNT(*)
                    FROM document_approvals da
                    JOIN task_manager_attachments tma
                      ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
                    WHERE tma.task_id = bc.id AND da.status='pending'
                ) AS pending_approvals,
                (
                    SELECT COUNT(*)
                    FROM document_approvals da
                    JOIN task_work_files twf
                      ON da.source_table='task_work_files' AND da.source_id=twf.id
                    WHERE twf.task_id = bc.id AND da.status='review'
                ) +
                (
                    SELECT COUNT(*)
                    FROM document_approvals da
                    JOIN task_comments tc
                      ON da.source_table='task_comments' AND da.source_id=tc.id
                    WHERE tc.task_id = bc.id AND da.status='review'
                ) +
                (
                    SELECT COUNT(*)
                    FROM document_approvals da
                    JOIN task_manager_attachments tma
                      ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
                    WHERE tma.task_id = bc.id AND da.status='review'
                ) AS review_items,
                (
                    SELECT COUNT(*)
                    FROM document_approvals da
                    JOIN task_work_files twf
                      ON da.source_table='task_work_files' AND da.source_id=twf.id
                    WHERE twf.task_id = bc.id AND da.status='approved'
                ) +
                (
                    SELECT COUNT(*)
                    FROM document_approvals da
                    JOIN task_comments tc
                      ON da.source_table='task_comments' AND da.source_id=tc.id
                    WHERE tc.task_id = bc.id AND da.status='approved'
                ) +
                (
                    SELECT COUNT(*)
                    FROM document_approvals da
                    JOIN task_manager_attachments tma
                      ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
                    WHERE tma.task_id = bc.id AND da.status='approved'
                ) AS approved_items
            FROM bid_checklists bc
            WHERE bc.g_id = %s AND bc.assigned_to = %s
            ORDER BY COALESCE(bc.due_date, bc.created_at) ASC, bc.id ASC
            """,
            (g_id, emp.get('id')),
        )
        rows = cur.fetchall() or []
        task_ids = [r.get('id') for r in rows if r.get('id')]
        comments_map = {}
        employee_files_map = {}
        manager_files_map = {}
        if task_ids:
            try:
                placeholders = ",".join(["%s"] * len(task_ids))
            except Exception:
                placeholders = ""
            try:
                cur.execute(f"""
                    SELECT tc.*, e.name as employee_name, u.email as user_email, da.status as approval_status, da.decision_note as decision_note
                    FROM task_comments tc
                    LEFT JOIN employees e ON tc.employee_id = e.id
                    LEFT JOIN users u ON tc.user_id = u.id
                    LEFT JOIN document_approvals da ON da.source_table='task_comments' AND da.source_id=tc.id
                    WHERE tc.task_id IN ({placeholders})
                    ORDER BY tc.created_at DESC
                """, tuple(task_ids))
                all_comments = cur.fetchall() or []
                for c in all_comments:
                    tid = c.get('task_id')
                    if not tid:
                        continue
                    comments_map.setdefault(tid, []).append({
                        'id': c.get('id'),
                        'comment': c.get('comment'),
                        'employee_name': c.get('employee_name') or c.get('user_email') or 'User',
                        'employee_email': c.get('employee_email') or '',
                        'created_at': c.get('created_at').strftime('%Y-%m-%d %H:%M') if c.get('created_at') else '',
                        'approval_status': ((c.get('approval_status') or '').strip().lower() or None),
                        'approval_target': (c.get('approval_target') or 'admin'),
                        'needs_approval': bool(c.get('needs_approval')),
                        'decision_note': c.get('decision_note') or ''
                    })
            except Exception:
                comments_map = {}
            try:
                _ensure_task_work_files_table(cur)
                _ensure_task_manager_attachments_table(cur)
            except Exception:
                pass
            try:
                cur.execute(f"""
                    SELECT twf.*, e.name as employee_name, e.email as employee_email, da.status as approval_status, da.decision_note as decision_note
                    FROM task_work_files twf
                    LEFT JOIN employees e ON twf.employee_id = e.id
                    LEFT JOIN document_approvals da ON da.source_table='task_work_files' AND da.source_id=twf.id
                    WHERE twf.task_id IN ({placeholders})
                    ORDER BY twf.uploaded_at DESC
                """, tuple(task_ids))
                all_files = cur.fetchall() or []
                for f in all_files:
                    tid = f.get('task_id')
                    if not tid:
                        continue
                    employee_files_map.setdefault(tid, []).append({
                        'id': f.get('id'),
                        'filename': f.get('original_filename') or f.get('filename'),
                        'description': f.get('description', ''),
                        'employee_name': f.get('employee_name', ''),
                        'employee_email': f.get('employee_email', ''),
                        'uploaded_at': f.get('uploaded_at').strftime('%Y-%m-%d %H:%M') if f.get('uploaded_at') else '',
                        'download_url': f"/task/file/{f.get('id')}/download",
                        'approval_status': ((f.get('approval_status') or '').strip().lower() or None),
                        'approval_target': f.get('approval_target') or 'admin',
                        'decision_note': f.get('decision_note') or ''
                    })
            except Exception:
                employee_files_map = {}
            try:
                cur.execute(f"""
                    SELECT tma.*, u.email as manager_email, da.status as approval_status, da.decision_note as decision_note
                    FROM task_manager_attachments tma
                    LEFT JOIN users u ON tma.user_id = u.id
                    LEFT JOIN document_approvals da ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
                    WHERE tma.task_id IN ({placeholders})
                    ORDER BY tma.uploaded_at DESC
                """, tuple(task_ids))
                all_manager_files = cur.fetchall() or []
                for f in all_manager_files:
                    tid = f.get('task_id')
                    if not tid:
                        continue
                    manager_files_map.setdefault(tid, []).append({
                        'id': f.get('id'),
                        'filename': f.get('original_filename') or f.get('filename'),
                        'manager_email': f.get('manager_email') or 'Manager',
                        'uploaded_at': f.get('uploaded_at').strftime('%Y-%m-%d %H:%M') if f.get('uploaded_at') else '',
                        'download_url': f"/task/manager-file/{f.get('id')}/download",
                        'approval_status': ((f.get('approval_status') or '').strip().lower() or None),
                        'approval_target': f.get('approval_target') or 'admin',
                        'decision_note': f.get('decision_note') or ''
                    })
            except Exception:
                manager_files_map = {}

        tasks = []
        for r in rows:
            dd = r.get('due_date')
            try:
                due_str = dd.strftime('%Y-%m-%d %H:%M') if dd else ''
            except Exception:
                due_str = str(dd) if dd else ''
            ca = r.get('created_at')
            try:
                created_str = ca.strftime('%Y-%m-%d %H:%M') if ca else ''
            except Exception:
                created_str = str(ca) if ca else ''
            tasks.append({
                'id': r.get('id'),
                'task_code': r.get('task_code') or '',
                'task_name': r.get('task_name') or 'Task',
                'description': r.get('description') or '',
                'status': (r.get('status') or 'pending').lower(),
                'due_date': due_str,
                'assigned_at': created_str,
                'pending_approvals': int(r.get('pending_approvals') or 0),
                'review_items': int(r.get('review_items') or 0),
                'approved_items': int(r.get('approved_items') or 0),
                'priority': (r.get('priority') or 'medium').lower(),
                'employee_comments': comments_map.get(r.get('id'), []),
                'employee_files': employee_files_map.get(r.get('id'), []),
                'manager_files': manager_files_map.get(r.get('id'), []),
            })
        return jsonify({'ok': True, 'tasks': tasks})
    except Exception as e:
        return jsonify({'ok': False, 'error': str(e), 'tasks': []}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/task/<int:task_id>/escalate', methods=['POST'])
def task_escalate(task_id):
    """Reassign a task to another employee in the same department (escalation within team)."""
    try:
        payload = request.get_json(silent=True) or {}
    except Exception:
        payload = {}
    new_assigned_to = payload.get('assigned_to')
    note = (payload.get('note') or '').strip()
    try:
        new_assigned_to = int(new_assigned_to)
    except Exception:
        return jsonify({'success': False, 'error': 'invalid_assignee'}), 400

    cur = mysql.connection.cursor(DictCursor)
    try:
        # Load task + current assignee department
        cur.execute(
            """
            SELECT bc.id, bc.g_id, bc.task_name, bc.assigned_to,
                   e.department AS current_department,
                   gb.b_name AS bid_name, gb.company
            FROM bid_checklists bc
            LEFT JOIN employees e ON e.id = bc.assigned_to
            LEFT JOIN go_bids gb ON gb.g_id = bc.g_id
            WHERE bc.id=%s
            """,
            (task_id,),
        )
        task = cur.fetchone()
        if not task:
            return jsonify({'success': False, 'error': 'task_not_found'}), 404

        # Resolve requester (dual-mode):
        # - Flask-Login user: by current_user.email
        # - Employee session user: by session['employee_id']
        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        req_emp = None
        if is_flask_user:
            try:
                cur.execute(
                    "SELECT id, name, email, department FROM employees WHERE LOWER(email)=LOWER(%s) AND is_active=TRUE LIMIT 1",
                    (getattr(current_user, 'email', None),),
                )
                req_emp = cur.fetchone()
            except Exception:
                req_emp = None
        else:
            try:
                employee_id = session.get('employee_id')
                if employee_id:
                    cur.execute(
                        "SELECT id, name, email, department FROM employees WHERE id=%s AND is_active=TRUE LIMIT 1",
                        (employee_id,),
                    )
                    req_emp = cur.fetchone()
            except Exception:
                req_emp = None

        # Authorization:
        # - Flask-Login Admin/Supervisor/Manager/Top-Admin can reassign
        # - Otherwise only the currently assigned employee can reassign within team
        if is_flask_user:
            role_lower = (getattr(current_user, 'role', '') or '').strip().lower().replace('_', ' ')
            is_manager_user = role_lower == 'manager'
            is_top_admin = role_lower in ['top level admin', 'top_level_admin', 'top_level_admin'.replace('_',' ')]
            is_priv = (getattr(current_user, 'is_admin', False) or getattr(current_user, 'is_supervisor', False) or is_manager_user or is_top_admin)
            # Enforce Top Admin read-only views
            try:
                if (get_user_role() or '').lower() == 'topleveladmin':
                    ro = session.get('readonly_employee_views') or []
                    if isinstance(ro, list):
                        assigned_to = int(task.get('assigned_to') or 0)
                        ro_int = [int(x) for x in ro if str(x).isdigit()]
                        if assigned_to and assigned_to in ro_int:
                            return jsonify({'success': False, 'error': 'read_only'}), 403
            except Exception:
                pass
            if not is_priv:
                if not req_emp or int(req_emp.get('id') or 0) != int(task.get('assigned_to') or 0):
                    return jsonify({'success': False, 'error': 'forbidden'}), 403
        else:
            # Session employee must be the assignee
            if not req_emp or int(req_emp.get('id') or 0) != int(task.get('assigned_to') or 0):
                return jsonify({'success': False, 'error': 'forbidden'}), 403

        # Validate target employee + same department constraint
        cur.execute("SELECT id, name, email, department FROM employees WHERE id=%s AND is_active=TRUE", (new_assigned_to,))
        target = cur.fetchone()
        if not target:
            return jsonify({'success': False, 'error': 'assignee_not_found'}), 404

        current_dept = (task.get('current_department') or (req_emp or {}).get('department') or '').strip().lower()
        target_dept = (target.get('department') or '').strip().lower()
        if not current_dept or current_dept != target_dept:
            return jsonify({'success': False, 'error': 'assignee_not_in_same_team'}), 400

        # Update assignment
        cur.execute(
            "UPDATE bid_checklists SET assigned_to=%s, updated_at=CURRENT_TIMESTAMP WHERE id=%s",
            (new_assigned_to, task_id),
        )

        # Optionally record escalation note as a comment (reuse task comments table if present)
        if note:
            try:
                try:
                    _ensure_task_comments_table(cur)
                except Exception:
                    pass
                cur.execute(
                    "INSERT INTO task_comments (task_id, employee_id, user_id, comment, needs_approval, approval_target) VALUES (%s, %s, %s, %s, %s, %s)",
                    (task_id, (req_emp or {}).get('id'), None, f"[Escalated] {note}", 0, 'admin'),
                )
            except Exception:
                pass

        mysql.connection.commit()

        try:
            log_write(
                'task_escalate',
                f"Task '{task.get('task_name')}' for bid '{task.get('bid_name')}' escalated to {target.get('email')} by {(req_emp or {}).get('email') or getattr(current_user, 'email', '')}",
            )
        except Exception:
            pass

        # Realtime update for dashboards
        try:
            socketio.emit('task_update', {
                'task_id': task_id,
                'status': None,
                'bid_name': task.get('bid_name'),
                'employee_name': target.get('name') or target.get('email'),
                'company': task.get('company'),
                'event': 'escalated'
            })
        except Exception:
            pass

        return jsonify({'success': True})
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass

@app.route('/api/team/<team>/employees')
def api_team_employees(team):
    """API endpoint to get team employees.
    Used by employee dashboard (escalation dropdown) and manager/team UIs.
    Supports both Flask-Login users and session-based employees.
    """
    team = (team or '').strip()
    if not team:
        return jsonify({'employees': []})

    cur = mysql.connection.cursor(DictCursor)
    try:
        # Dual-mode auth:
        # - Flask-Login users: allowed
        # - Session employees: only allowed to fetch their own department roster
        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        if not is_flask_user:
            employee_id = session.get('employee_id')
            if not employee_id:
                return jsonify({'employees': []}), 403
            cur.execute(
                "SELECT id, department FROM employees WHERE id=%s AND is_active=TRUE LIMIT 1",
                (employee_id,),
            )
            emp = cur.fetchone()
            if not emp:
                return jsonify({'employees': []}), 403
            emp_dept = (emp.get('department') or '').strip().lower()
            if emp_dept and emp_dept != team.lower():
                return jsonify({'employees': []}), 403

        # Return minimal fields (safe to expose to employees)
        #
        # IMPORTANT: For Flask-Login users, scope the roster by ACTIVE company context
        # (prevents cross-company assignments like Sunsprint employees showing under IKIO context).
        extra_clause = ""
        params = [team]
        if is_flask_user:
            try:
                active_cid = session.get('active_company_id')
            except Exception:
                active_cid = None
            if active_cid:
                cname = ''
                try:
                    cur.execute("SELECT name FROM companies WHERE id=%s", (int(active_cid),))
                    row = cur.fetchone() or {}
                    cname = (row.get('name') or '').strip().lower()
                except Exception:
                    cname = ''
                pattern = None
                if 'metco' in cname:
                    pattern = '%metco%'
                elif 'ikio' in cname:
                    pattern = '%ikio%'
                elif 'sunsprint' in cname:
                    pattern = '%sunsprint%'
                if pattern:
                    extra_clause = " AND LOWER(COALESCE(email,'')) LIKE %s"
                    params.append(pattern)

        cur.execute(
            f"""
            SELECT id, name, email, department
            FROM employees
            WHERE is_active = TRUE
              AND LOWER(COALESCE(department,'')) = LOWER(%s)
              AND LOWER(COALESCE(email,'')) NOT IN (SELECT LOWER(email) FROM users)
              {extra_clause}
            ORDER BY name
            """,
            tuple(params),
        )
        employees = cur.fetchall() or []
        return jsonify({'employees': employees})
    finally:
        try:
            cur.close()
        except Exception:
            pass


def _ensure_team_lead_employee(cur, email: str, dept: str | None = None, name: str | None = None) -> int | None:
    """Ensure a team lead has a matching employees row and return the employee_id."""
    if not email:
        return None
    try:
        cur.execute(
            "SELECT id FROM employees WHERE LOWER(email)=LOWER(%s) AND COALESCE(is_active, TRUE)=TRUE LIMIT 1",
            (email,),
        )
        row = cur.fetchone() or {}
        if row.get('id'):
            return int(row.get('id'))
    except Exception:
        pass

    def _create_employee_record(emp_name: str, emp_dept: str) -> int | None:
        try:
            raw_password = secrets.token_urlsafe(16)
            hashed_password = hash_password(raw_password)
            cur.execute(
                "INSERT INTO employees (name, email, password, department, is_active) VALUES (%s, %s, %s, %s, TRUE)",
                (emp_name, email, hashed_password, emp_dept),
            )
            return int(cur.lastrowid or 0) or None
        except Exception:
            return None

    # Only attempt to sync from team_leads if the table exists.
    team_leads_exists = False
    try:
        cur.execute("SHOW TABLES LIKE 'team_leads'")
        team_leads_exists = bool(cur.fetchone())
    except Exception:
        team_leads_exists = False

    try:
        lead = {}
        col_names = set()
        if team_leads_exists:
            cur.execute("SHOW COLUMNS FROM team_leads")
            cols = cur.fetchall() or []
            for c in cols:
                if isinstance(c, dict) and c.get('Field'):
                    col_names.add(c.get('Field'))
                elif isinstance(c, (list, tuple)) and c:
                    col_names.add(c[0])
            name_col = 'name' if 'name' in col_names else ('full_name' if 'full_name' in col_names else None)
            dept_col = 'department' if 'department' in col_names else None
            active_col = 'is_active' if 'is_active' in col_names else None
            select_cols = ["id"]
            if name_col:
                select_cols.append(f"{name_col} AS name")
            if dept_col:
                select_cols.append(f"{dept_col} AS department")
            if active_col:
                select_cols.append(f"{active_col} AS is_active")
            select_sql = ", ".join(select_cols)
            cur.execute(
                f"SELECT {select_sql} FROM team_leads WHERE LOWER(email)=LOWER(%s) LIMIT 1",
                (email,),
            )
            lead = cur.fetchone() or {}
        if lead and 'is_active' in lead and not bool(lead.get('is_active', True)):
            return None
        lead_name = (lead.get('name') or name or '').strip()
        if not lead_name:
            try:
                lead_name = email.split('@')[0]
            except Exception:
                lead_name = email
        lead_dept = (lead.get('department') or dept or '').strip()
        if not lead_dept:
            lead_dept = dept or ''

        if team_leads_exists and not lead:
            try:
                insert_cols = []
                insert_vals = []
                if 'name' in col_names:
                    insert_cols.append('name'); insert_vals.append(lead_name)
                elif 'full_name' in col_names:
                    insert_cols.append('full_name'); insert_vals.append(lead_name)
                if 'email' in col_names:
                    insert_cols.append('email'); insert_vals.append(email)
                if 'password' in col_names or 'password_hash' in col_names:
                    raw_password = secrets.token_urlsafe(16)
                    hashed_password = hash_password(raw_password)
                    if 'password' in col_names:
                        insert_cols.append('password'); insert_vals.append(hashed_password)
                    else:
                        insert_cols.append('password_hash'); insert_vals.append(hashed_password)
                if 'department' in col_names:
                    insert_cols.append('department'); insert_vals.append(lead_dept)
                if 'role' in col_names:
                    insert_cols.append('role'); insert_vals.append('Team Lead')
                if 'is_active' in col_names:
                    insert_cols.append('is_active'); insert_vals.append(True)
                if insert_cols:
                    placeholders = ",".join(["%s"] * len(insert_cols))
                    cur.execute(
                        f"INSERT IGNORE INTO team_leads ({','.join(insert_cols)}) VALUES ({placeholders})",
                        tuple(insert_vals),
                    )
            except Exception:
                pass

        if not lead_dept:
            return None
        return _create_employee_record(lead_name, lead_dept)
    except Exception:
        if dept:
            fallback_name = (name or '').strip()
            if not fallback_name:
                try:
                    fallback_name = email.split('@')[0]
                except Exception:
                    fallback_name = email
            return _create_employee_record(fallback_name, dept)
        return None


@app.route('/api/team/<team>/team-leads')
def api_team_team_leads(team):
    """API endpoint to get team leads for a team (used by Manager -> Team Lead assignment UI)."""
    is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
    if not is_flask_user and not session.get('employee_id'):
        return jsonify({'ok': False, 'error': 'unauthorized', 'team_leads': []}), 401
    team = (team or '').strip().lower()
    team = _normalize_department_key(team) or team
    allow_all = team in ('all', '*', '')

    dept_keys_by_team = {
        'business': ('business',),
        'design': ('design', 'marketing'),
        'operations': ('operations',),
        'engineer': ('site_engineer', 'engineer', 'engineering'),
        'engineering_team': ('engineering_team',),
        'procurement_team': ('procurement_team',),
        'accounts_finance': ('accounts_finance',),
    }
    role_map = {
        'business': ('teamlead', 'team_lead', 'team lead', 'business', 'business dev', 'business development'),
        'design': ('teamlead', 'team_lead', 'team lead', 'design', 'marketing'),
        'operations': ('teamlead', 'team_lead', 'team lead', 'operations'),
        'engineer': ('teamlead', 'team_lead', 'team lead', 'site_engineer', 'site engineer', 'engineering', 'engineer'),
        'engineering_team': ('teamlead', 'team_lead', 'team lead', 'engineering team', 'engineering', 'engineering_team'),
        'procurement_team': ('teamlead', 'team_lead', 'team lead', 'procurement team', 'procurement', 'procurement_team'),
        'accounts_finance': ('teamlead', 'team_lead', 'team lead', 'accounts finance', 'accounts & finance', 'accounting', 'finance', 'accounts_finance'),
    }
    acceptable_depts = dept_keys_by_team.get(team, ())
    acceptable_roles = role_map.get(team, ('teamlead', 'team_lead', 'team lead'))
    if allow_all or not acceptable_depts:
        acceptable_depts = ()
        acceptable_roles = (
            'teamlead', 'team_lead', 'team lead',
            'business', 'business dev', 'business development',
            'design', 'marketing',
            'operations',
            'engineer', 'engineering', 'site engineer', 'site_engineer',
        )

    cur = mysql.connection.cursor(DictCursor)
    go_projects = []
    try:
        # Prefer scoped access (user_company_access) over users.role (users.role is global now)
        try:
            active_cid = session.get('active_company_id')
        except Exception:
            active_cid = None
        dept_ph = ','.join(['%s'] * len(acceptable_depts))
        role_ph = ','.join(['%s'] * len(acceptable_roles))
        params = [*acceptable_depts, *acceptable_roles]
        cid_clause = ""
        if active_cid:
            cid_clause = " AND uca.company_id = %s"
            params.append(int(active_cid))
        cur.execute(
            f"""
            SELECT DISTINCT u.id, u.email, COALESCE(u.full_name, u.email) AS name, e.id AS employee_id, 'teamlead' AS role, uca.department_key
            FROM user_company_access uca
            JOIN users u ON u.id = uca.user_id
            LEFT JOIN employees e ON LOWER(e.email) = LOWER(u.email) AND COALESCE(e.is_active, TRUE) = TRUE
            WHERE LOWER(COALESCE(uca.role,'')) IN ({role_ph})
              AND COALESCE(uca.is_active, TRUE) = TRUE
              {"" if not acceptable_depts else f"AND (uca.department_key IS NULL OR LOWER(COALESCE(uca.department_key,'')) IN ({dept_ph}))"}
              {cid_clause}
            ORDER BY u.email
            """,
            tuple(params),
        )
        team_leads = cur.fetchall() or []
        # Fallback: users.role-based team leads (when UCA is missing)
        params_roles = [*acceptable_roles]
        company_filter = ""
        cur.execute(
            f"""
            SELECT DISTINCT u.id, u.email, COALESCE(u.full_name, u.email) AS name, e.id AS employee_id, 'teamlead' AS role, %s AS department_key
            FROM users u
            LEFT JOIN employees e ON LOWER(e.email) = LOWER(u.email) AND COALESCE(e.is_active, TRUE) = TRUE
            WHERE LOWER(COALESCE(u.role,'')) IN ({role_ph})
            {company_filter}
            """,
            tuple([team or 'all'] + params_roles),
        )
        team_leads += cur.fetchall() or []
        # De-dupe by email
        seen = set()
        unique = []
        for lead in team_leads:
            key = (lead.get('email') or '').strip().lower()
            if not key or key in seen:
                continue
            seen.add(key)
            unique.append(lead)
        team_leads = unique
        return jsonify({'ok': True, 'team_leads': team_leads})
    except Exception as e:
        return jsonify({'ok': False, 'error': str(e), 'team_leads': []}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/api/team/<team>/managers')
def api_team_managers(team):
    """API endpoint to get department managers for a team."""
    is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
    if not is_flask_user and not session.get('employee_id'):
        return jsonify({'ok': False, 'error': 'unauthorized', 'managers': []}), 401
    team = (team or '').strip().lower()
    team = _normalize_department_key(team) or team
    allow_all = team in ('all', '*', '')
    role_raw = (get_user_role() or getattr(current_user, 'role', '') or '').strip().lower()
    is_team_lead_user = bool(
        getattr(current_user, 'is_team_lead', False)
        or role_raw in (
            'teamlead', 'team_lead', 'team lead',
            'business', 'business dev', 'business development',
            'design', 'operations',
            'site engineer', 'site_engineer', 'engineering', 'engineer',
            'engineering team', 'procurement team', 'accounts finance', 'accounts & finance'
        )
    )

    dept_keys_by_team = {
        'business': ('business', 'business_dev', 'business_development'),
        'design': ('design', 'marketing'),
        'operations': ('operations',),
        'engineer': ('site_engineer', 'engineer', 'engineering'),
        'engineering_team': ('engineering_team',),
        'procurement_team': ('procurement_team',),
        'accounts_finance': ('accounts_finance',),
    }
    employee_depts_by_team = {
        'business': ('business', 'business dev', 'business development', 'business manager', 'business_manager'),
        'design': ('design', 'marketing', 'design manager', 'design_manager'),
        'operations': ('operations', 'operation', 'operations manager', 'operation manager', 'operations_manager', 'operation_manager'),
        'engineer': ('site_engineer', 'site engineer', 'engineer', 'engineering', 'site manager', 'site_manager'),
        'engineering_team': ('engineering_team', 'engineering team'),
        'procurement_team': ('procurement_team', 'procurement team'),
        'accounts_finance': ('accounts_finance', 'accounts & finance', 'accounts finance', 'accounting', 'finance'),
    }
    acceptable_depts = dept_keys_by_team.get(team, ())
    acceptable_emp_depts = employee_depts_by_team.get(team, ())
    if allow_all or not acceptable_depts:
        acceptable_depts = ()
        acceptable_emp_depts = ()

    role_map = {
        'business': ('business manager', 'business_manager', 'businessmanager', 'manager'),
        'design': ('design manager', 'design_manager', 'designmanager', 'manager'),
        'operations': ('operation manager', 'operations manager', 'operation_manager', 'operations_manager', 'operationsmanager', 'manager'),
        'engineer': ('site manager', 'site_manager', 'sitemanager', 'manager'),
        'engineering_team': ('engineering manager', 'engineering_team', 'engineering team', 'manager'),
        'procurement_team': ('procurement manager', 'procurement_team', 'procurement team', 'manager'),
        'accounts_finance': ('accounts manager', 'finance manager', 'accounts_finance', 'accounts & finance', 'manager'),
    }
    acceptable_roles = role_map.get(team, ('manager',))
    if allow_all or not role_map.get(team):
        acceptable_roles = (
            'manager',
            'business manager', 'business_manager', 'businessmanager',
            'design manager', 'design_manager', 'designmanager',
            'operations manager', 'operation manager', 'operations_manager', 'operation_manager', 'operationsmanager',
            'site manager', 'site_manager', 'sitemanager',
            'project manager', 'projectmanager',
        )

    cur = mysql.connection.cursor(DictCursor)
    try:
        try:
            active_cid = session.get('active_company_id')
        except Exception:
            active_cid = None
        dept_ph = ','.join(['%s'] * len(acceptable_depts))
        emp_dept_ph = ','.join(['%s'] * len(acceptable_emp_depts))
        role_ph = ','.join(['%s'] * len(acceptable_roles))
        params = [*acceptable_emp_depts, *acceptable_roles]
        cid_clause = ""
        if active_cid:
            cid_clause = " AND uca.company_id = %s"
            params.append(int(active_cid))
        dept_clause = ""
        if not is_team_lead_user and acceptable_depts:
            dept_clause = f" AND (uca.department_key IS NULL OR LOWER(COALESCE(uca.department_key,'')) IN ({dept_ph}))"
            params.extend(list(acceptable_depts))
        cur.execute(
            f"""
            SELECT DISTINCT
                u.id,
                u.email,
                COALESCE(e.name, u.email) AS name,
                e.id AS employee_id,
                uca.department_key
            FROM user_company_access uca
            JOIN users u ON u.id = uca.user_id
            LEFT JOIN employees e
              ON LOWER(e.email) = LOWER(u.email)
             AND e.is_active = TRUE
             {"" if not acceptable_emp_depts else f"AND LOWER(COALESCE(e.department,'')) IN ({emp_dept_ph})"}
            WHERE LOWER(COALESCE(uca.role,'')) IN ({role_ph})
              AND COALESCE(uca.is_active, TRUE) = TRUE
              {dept_clause}
              {cid_clause}
            ORDER BY u.email
            """,
            tuple(params),
        )
        managers = cur.fetchall() or []

        # Fallback: users.role based managers (when UCA is missing)
        params_roles = [*acceptable_emp_depts, *acceptable_roles]
        company_filter = ""
        if active_cid and not is_team_lead_user:
            company_filter = "AND EXISTS (SELECT 1 FROM user_company_access uca2 WHERE uca2.user_id=u.id AND uca2.company_id=%s)"
            params_roles.append(int(active_cid))
        cur.execute(
            f"""
            SELECT DISTINCT
                u.id,
                u.email,
                COALESCE(e.name, u.email) AS name,
                e.id AS employee_id,
                NULL AS department_key
            FROM users u
            LEFT JOIN employees e
              ON LOWER(e.email) = LOWER(u.email)
             AND e.is_active = TRUE
             {"" if not acceptable_emp_depts else f"AND LOWER(COALESCE(e.department,'')) IN ({emp_dept_ph})"}
            WHERE LOWER(COALESCE(u.role,'')) IN ({role_ph})
            {company_filter}
            """,
            tuple(params_roles),
        )
        managers += cur.fetchall() or []

        seen = set()
        unique = []
        for m in managers:
            key = (m.get('email') or '').strip().lower()
            if not key or key in seen:
                continue
            seen.add(key)
            unique.append(m)

        return jsonify({'ok': True, 'managers': unique})
    except Exception as e:
        return jsonify({'ok': False, 'error': str(e), 'managers': []}), 500
    
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/api/top-admins')
def api_top_admins():
    """Return active users with the Top Level Admin role."""
    is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
    if not is_flask_user and not session.get('employee_id'):
        return jsonify({'admins': [], 'error': 'unauthorized'}), 401
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SHOW COLUMNS FROM users")
        cols = {row.get('Field') for row in (cur.fetchall() or []) if row.get('Field')}
        name_expr = "COALESCE(name, email)" if "name" in cols else "email"
        is_active_expr = "COALESCE(is_active, TRUE) = TRUE" if "is_active" in cols else "1=1"
        role_expr = ""
        if "role" in cols:
            role_expr = "LOWER(REPLACE(REPLACE(COALESCE(role,''),'_',' '),'-',' ')) IN ('top level admin', 'topleveladmin')"
        admin_exprs = []
        if role_expr:
            admin_exprs.append(role_expr)
        if "is_admin" in cols:
            admin_exprs.append("COALESCE(is_admin, 0)=1")
        if "is_supervisor" in cols:
            admin_exprs.append("COALESCE(is_supervisor, 0)=1")
        if not admin_exprs:
            admin_exprs.append("COALESCE(is_admin, 0)=1") if "is_admin" in cols else admin_exprs.append("1=0")
        where_admin = " OR ".join(admin_exprs)
        cur.execute(
            f"""
            SELECT id, email, {name_expr} AS name
            FROM users
            WHERE {is_active_expr}
              AND ({where_admin})
            ORDER BY email
            """
        )
        admins = cur.fetchall() or []
        return jsonify({'admins': admins})
    finally:
        try:
            cur.close()
        except Exception:
            pass


def _require_teamlead_assignment_access(team):
    team = (team or '').strip().lower()
    user_role = (get_user_role() or 'member').strip().lower()
    # Legacy fallback: honor users.role when scoped role resolves to member.
    if user_role == 'member':
        try:
            raw = (getattr(current_user, 'role', '') or '').strip().lower().replace('_', ' ')
            if raw:
                user_role = raw
        except Exception:
            pass
    allowed_roles = {
        'itadmin',
        'supervisor',
        'topleveladmin',
        'manager',
        'business manager',
        'design manager',
        'operation manager',
        'operations manager',
        'site manager',
    }
    if user_role not in allowed_roles:
        return jsonify({'ok': False, 'error': 'access_denied'}), 403

    if user_role == 'topleveladmin':
        try:
            ro = session.get('readonly_team_views') or []
            if isinstance(ro, list) and team in ro:
                return jsonify({'ok': False, 'error': 'read_only'}), 403
        except Exception:
            pass

    if user_role == 'manager' and not getattr(current_user, 'is_admin', False):
        all_teams = {'business', 'design', 'operations', 'engineer'}
        access_rows = _fetch_user_access_rows(int(current_user.id))
        try:
            active_cid = session.get('active_company_id')
        except Exception:
            active_cid = None
        mgr_rows = []
        for r in (access_rows or []):
            if (r.get('role') or '').strip().lower() != 'manager':
                continue
            if active_cid and int(r.get('company_id') or 0) != int(active_cid):
                continue
            mgr_rows.append(r)

        def _team_key_from_dept_key(dept_key: str | None) -> str | None:
            d = (dept_key or '').strip().lower().replace(' ', '_')
            if not d:
                return None
            if d in ['business', 'business_dev', 'business_development']:
                return 'business'
            if d in ['design', 'marketing']:
                return 'design'
            if d in ['operations', 'operation', 'ops']:
                return 'operations'
            if d in ['site_engineer', 'site_engineering', 'engineer', 'engineering']:
                return 'engineer'
            return None

        if any(r.get('department_key') in [None, '', 'null'] for r in mgr_rows):
            allowed_teams = set(all_teams)
        else:
            allowed_teams = {_team_key_from_dept_key(r.get('department_key')) for r in mgr_rows}
            allowed_teams = {t for t in allowed_teams if t}
        if allowed_teams and team not in allowed_teams:
            return jsonify({'ok': False, 'error': 'access_denied'}), 403

    return None


def _ensure_manager_employee(cur, email: str, dept: str | None = None, name: str | None = None) -> int | None:
    """Ensure a manager has a matching employees row and return the employee_id."""
    if not email:
        return None
    try:
        cur.execute(
            "SELECT id FROM employees WHERE LOWER(email)=LOWER(%s) AND COALESCE(is_active, TRUE)=TRUE LIMIT 1",
            (email,),
        )
        row = cur.fetchone() or {}
        if row.get('id'):
            return int(row.get('id'))
    except Exception:
        pass

    emp_name = (name or '').strip()
    if not emp_name:
        try:
            emp_name = email.split('@')[0]
        except Exception:
            emp_name = email
    emp_dept = (dept or '').strip()
    if emp_dept:
        try:
            emp_dept = _normalize_department_key(emp_dept) or emp_dept
        except Exception:
            pass
    try:
        raw_password = secrets.token_urlsafe(16)
        hashed_password = hash_password(raw_password)
        cur.execute(
            "INSERT INTO employees (name, email, password, department, is_active) VALUES (%s, %s, %s, %s, TRUE)",
            (emp_name, email, hashed_password, emp_dept),
        )
        return int(cur.lastrowid or 0) or None
    except Exception:
        return None


@app.route('/api/team/<team>/assign-team-lead', methods=['POST'])
@login_required
def api_team_assign_team_lead(team):
    """Assign a bid to a Team Lead (Manager -> Team Lead).
    Body: JSON { g_id: int, team_lead_email: str|list, team_lead_emails: list, task_completion_date: 'YYYY-MM-DD' }"""
    team = (team or '').strip().lower()

    deny = _require_teamlead_assignment_access(team)
    if deny:
        return deny

    data = request.get_json(silent=True) or {}
    try:
        g_id = int(data.get('g_id')) if data.get('g_id') is not None else None
    except Exception:
        g_id = None
    raw_team_leads = data.get('team_lead_emails') or data.get('team_lead_email') or []
    if isinstance(raw_team_leads, str):
        raw_team_leads = [raw_team_leads]
    team_lead_emails = []
    for tl in (raw_team_leads or []):
        email = (tl or '').strip()
        if email and email.lower() not in [e.lower() for e in team_lead_emails]:
            team_lead_emails.append(email)
    task_completion_date = (data.get('task_completion_date') or '').strip()

    if not g_id or not team_lead_emails or not task_completion_date:
        return jsonify({'ok': False, 'error': 'missing_fields'}), 400

    # Validate date format (store as DATE)
    try:
        _ = datetime.strptime(task_completion_date, '%Y-%m-%d').date()
    except Exception:
        return jsonify({'ok': False, 'error': 'invalid_task_completion_date'}), 400

    # Validate team-lead membership matches the team (scoped department_key)
    dept_keys_by_team = {
        'business': ('business',),
        'design': ('design', 'marketing'),
        'operations': ('operations',),
        'engineer': ('site_engineer', 'engineer', 'engineering'),
    }
    acceptable_depts = tuple([d.lower() for d in dept_keys_by_team.get(team, ())])
    if not acceptable_depts:
        return jsonify({'ok': False, 'error': 'invalid_team'}), 400

    cur = mysql.connection.cursor(DictCursor)
    try:
        try:
            _ensure_teamlead_assign_bids_table(cur)
        except Exception:
            pass
        # Ensure target team lead exists in scoped access (user_company_access)
        try:
            active_cid = session.get('active_company_id')
        except Exception:
            active_cid = None
        dept_ph = ','.join(['%s'] * len(acceptable_depts))
        cid_clause = " AND uca.company_id = %s" if active_cid else ""
        params = [*[e.lower() for e in team_lead_emails]]
        if active_cid:
            params.append(int(active_cid))
        params.extend(list(acceptable_depts))
        cur.execute(
            f"""
            SELECT u.id, u.email, uca.department_key
            FROM users u
            JOIN user_company_access uca ON uca.user_id = u.id
            WHERE LOWER(u.email) IN ({','.join(['%s'] * len(team_lead_emails))})
              {cid_clause}
              AND COALESCE(uca.is_active, TRUE) = TRUE
              AND LOWER(COALESCE(uca.role,'')) = 'teamlead'
              AND (uca.department_key IS NULL OR LOWER(COALESCE(uca.department_key,'')) IN ({dept_ph}))
            """,
            tuple(params),
        )
        found = cur.fetchall() or []
        found_emails = { (r.get('email') or '').lower() for r in found }
        missing = [e for e in team_lead_emails if e.lower() not in found_emails]
        # Legacy fallback: allow users.role-based team leads when user_company_access is not set.
        if missing:
            role_map = {
                'business': {'teamlead', 'team lead', 'business dev', 'business development', 'business'},
                'design': {'teamlead', 'team lead', 'design', 'marketing'},
                'operations': {'teamlead', 'team lead', 'operations', 'operation', 'ops'},
                'engineer': {'teamlead', 'team lead', 'site engineer', 'site_engineer', 'engineering', 'engineer', 'site manager'},
            }
            acceptable_roles = role_map.get(team, {'teamlead', 'team lead'})
            cur.execute(
                f"""
                SELECT id, email, role
                FROM users
                WHERE LOWER(email) IN ({','.join(['%s'] * len(missing))})
                  AND LOWER(REPLACE(REPLACE(COALESCE(role,''),'_',' '),'-',' ')) IN ({','.join(['%s'] * len(acceptable_roles))})
                """,
                tuple([e.lower() for e in missing] + [r.lower() for r in acceptable_roles]),
            )
            legacy_found = cur.fetchall() or []
            for r in legacy_found:
                em = (r.get('email') or '').lower()
                if em:
                    found_emails.add(em)
            missing = [e for e in team_lead_emails if e.lower() not in found_emails]
        if missing:
            return jsonify({'ok': False, 'error': 'team_lead_not_found', 'missing': missing}), 404

        # Load bid details
        cur.execute("SELECT g_id, b_name, due_date, state, scope, type, scoring, company, summary, submission_status, submission_reason FROM go_bids WHERE g_id=%s", (g_id,))
        gb = cur.fetchone()
        if not gb:
            return jsonify({'ok': False, 'error': 'bid_not_found'}), 404

        # Ensure due_date is never NULL (older rows can have NULL due_date)
        due_date_val = gb.get('due_date')
        if not due_date_val:
            try:
                due_date_val = datetime.now().date()
            except Exception:
                due_date_val = None

        # Upsert into teamlead_assign_bids (tolerant to older schemas)
        existing_emails = []
        try:
            cur.execute(
                "SELECT team_lead FROM teamlead_assign_bids WHERE g_id=%s",
                (g_id,)
            )
            existing_emails = [(r.get('team_lead') or '').lower() for r in (cur.fetchall() or []) if r.get('team_lead')]
        except Exception:
            existing_emails = []

        to_delete = [e for e in existing_emails if e not in [t.lower() for t in team_lead_emails]]
        if to_delete:
            cur.execute(
                f"DELETE FROM teamlead_assign_bids WHERE g_id=%s AND LOWER(team_lead) IN ({','.join(['%s'] * len(to_delete))})",
                (g_id, *to_delete),
            )

        q_full = """
            INSERT INTO teamlead_assign_bids (
                g_id, b_name, due_date, state, scope, type, scoring,
                comp_name, company, summary, submission_status, submission_reason,
                task_completion_date, team_lead, assigned_by_email
            )
            VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
            ON DUPLICATE KEY UPDATE
                b_name = VALUES(b_name),
                due_date = VALUES(due_date),
                state = VALUES(state),
                scope = VALUES(scope),
                type = VALUES(type),
                scoring = VALUES(scoring),
                comp_name = VALUES(comp_name),
                company = VALUES(company),
                summary = VALUES(summary),
                submission_status = VALUES(submission_status),
                submission_reason = VALUES(submission_reason),
                task_completion_date = VALUES(task_completion_date),
                assigned_by_email = VALUES(assigned_by_email),
                assigned_at = CURRENT_TIMESTAMP,
                updated_at = CURRENT_TIMESTAMP
        """

        params_base = (
            gb.get('g_id'),
            gb.get('b_name'),
            due_date_val,
            gb.get('state'),
            gb.get('scope'),
            gb.get('type'),
            gb.get('scoring'),
            gb.get('company'),
            gb.get('company'),
            gb.get('summary') or '',
            gb.get('submission_status') or 'Work Progress',
            gb.get('submission_reason') or '',
            task_completion_date,
        )
        for email in team_lead_emails:
            params_full = params_base + (email, current_user.email)
            try:
                cur.execute(q_full, params_full)
            except Exception as e_full:
                msg = str(e_full)
                if ("Unknown column 'assigned_by_email'" in msg) or ("Unknown column 'assigned_at'" in msg):
                    q_legacy = """
                        INSERT INTO teamlead_assign_bids (
                            g_id, b_name, due_date, state, scope, type, scoring,
                            comp_name, company, summary, submission_status, submission_reason,
                            task_completion_date, team_lead
                        )
                        VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
                        ON DUPLICATE KEY UPDATE
                            b_name = VALUES(b_name),
                            due_date = VALUES(due_date),
                            state = VALUES(state),
                            scope = VALUES(scope),
                            type = VALUES(type),
                            scoring = VALUES(scoring),
                            comp_name = VALUES(comp_name),
                            company = VALUES(company),
                            summary = VALUES(summary),
                            submission_status = VALUES(submission_status),
                            submission_reason = VALUES(submission_reason),
                            task_completion_date = VALUES(task_completion_date),
                            updated_at = CURRENT_TIMESTAMP
                    """
                    cur.execute(q_legacy, params_base + (email,))
                else:
                    raise

        # Tag checklist items so Team Lead Assigned Tasks view can see them.
        try:
            _ensure_bid_assign_meta_table()
            cur.execute("SELECT data FROM bid_assign_meta WHERE g_id=%s", (g_id,))
            meta_row = cur.fetchone() or {}
            meta_raw = meta_row.get('data') or ''
            meta = json.loads(meta_raw) if meta_raw else {}
            checklist = meta.get('checklist') or []
            lead_email = team_lead_emails[0] if team_lead_emails else ''
            updated = False
            for item in checklist:
                dept_key = (item.get('dept') or '').strip().lower()
                if dept_key and dept_key != team:
                    continue
                if lead_email:
                    item['team_lead'] = lead_email
                    updated = True
            if updated:
                cur.execute(
                    "UPDATE bid_assign_meta SET data=%s, updated_at=CURRENT_TIMESTAMP WHERE g_id=%s",
                    (json.dumps(meta), g_id),
                )
        except Exception:
            pass

        log_action = f"Assigned bid '{gb.get('b_name')}' (ID: {g_id}) to team_leads={','.join(team_lead_emails)} [{team}] due={task_completion_date}"
        try:
            cur.execute("INSERT INTO logs (action, user_id) VALUES (%s, %s)", (log_action, current_user.id))
        except Exception:
            pass

        mysql.connection.commit()
        try:
            socketio.emit('master_update', {
                'log': {'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'action': log_action, 'user_email': current_user.email, 'user_role': getattr(current_user, 'role', '')},
                'assignment': True
            })
        except Exception:
            pass

        return jsonify({'ok': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'ok': False, 'error': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass

@app.route('/api/team/<team>/unassign-team-lead', methods=['POST'])
@login_required
def api_team_unassign_team_lead(team):
    team = (team or '').strip().lower()
    deny = _require_teamlead_assignment_access(team)
    if deny:
        return deny

    data = request.get_json(silent=True) or {}
    try:
        g_id = int(data.get('g_id')) if data.get('g_id') is not None else None
    except Exception:
        g_id = None
    email = (data.get('team_lead_email') or '').strip()
    if not g_id or not email:
        return jsonify({'ok': False, 'error': 'missing_fields'}), 400

    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute(
            "DELETE FROM teamlead_assign_bids WHERE g_id=%s AND LOWER(team_lead)=LOWER(%s)",
            (g_id, email),
        )
        mysql.connection.commit()
        log_action = f"Removed team lead '{email}' from bid ID {g_id}"
        try:
            cur.execute("INSERT INTO logs (action, user_id) VALUES (%s, %s)", (log_action, current_user.id))
        except Exception:
            pass
        return jsonify({'ok': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'ok': False, 'error': 'db', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/api/team/<team>/assign', methods=['POST'])
@login_required
def api_team_assign(team):
    """Assign a bid to an employee from the current team.
    Body: JSON { g_id: int, employee_id: int }
    Note: Includes safe fallbacks when bid_assign.state or assignee_email
    columns are missing in older schemas."""
    try:
        data = request.get_json(silent=True) or {}
        g_id = int(data.get('g_id')) if data.get('g_id') is not None else None
        bid_name = (data.get('bid_name') or '').strip()
        # accept single or multiple
        employee_ids = data.get('employee_ids')
        if employee_ids is None and data.get('employee_id') is not None:
            employee_ids = [data.get('employee_id')]
        if isinstance(employee_ids, list):
            try:
                employee_ids = [int(x) for x in employee_ids if x is not None]
            except Exception:
                employee_ids = []
        else:
            employee_ids = []

        # Optional: Team Lead sets a completion/due date for the employee assignment
        task_completion_date = (data.get('task_completion_date') or '').strip()
        if task_completion_date:
            try:
                task_completion_date = datetime.strptime(task_completion_date, '%Y-%m-%d').strftime('%Y-%m-%d')
            except Exception:
                task_completion_date = ''
    except Exception:
        return jsonify({'ok': False, 'error': 'Invalid payload'}), 400

    if not g_id:
        return jsonify({'ok': False, 'error': 'g_id is required'}), 400

    # Enforce Top Admin read-only team views (set by /team-lead/<team>/overview?readonly=1)
    try:
        if (get_user_role() or '').strip().lower() == 'topleveladmin':
            ro = session.get('readonly_team_views') or []
            if isinstance(ro, list) and (team or '').strip().lower() in [str(x).strip().lower() for x in ro]:
                return jsonify({'ok': False, 'error': 'read_only'}), 403
    except Exception:
        pass

    cur = mysql.connection.cursor(DictCursor)
    try:
        # Validate employee belongs to this team
        # Validate employees belong to this team
        valid_emps = []
        if employee_ids:
            placeholders = ','.join(['%s'] * len(employee_ids))
            cur.execute(
                f"SELECT id, name, email FROM employees WHERE id IN ({placeholders}) AND department=%s AND is_active=TRUE",
                (*employee_ids, team)
            )
            valid_emps = cur.fetchall()
        # For legacy single assignment
        first_emp = (valid_emps[0] if valid_emps else None)

        # Get bid basic details (fallback to bid_incoming if GO bid missing)
        cur.execute("SELECT * FROM go_bids WHERE g_id=%s", (g_id,))
        gb = cur.fetchone()
        if not gb:
            try:
                cur.execute("SELECT * FROM bid_incoming WHERE id=%s", (g_id,))
                inc = cur.fetchone()
            except Exception:
                inc = None

            if not inc and bid_name:
                try:
                    cur.execute("SELECT * FROM bid_incoming WHERE b_name=%s ORDER BY id DESC LIMIT 1", (bid_name,))
                    inc = cur.fetchone()
                except Exception:
                    inc = None

            # Try to match by name if GO record exists under different g_id
            if not gb and inc:
                try:
                    cur.execute("SELECT * FROM go_bids WHERE b_name=%s ORDER BY g_id DESC LIMIT 1", (inc.get('b_name'),))
                    gb = cur.fetchone()
                    if gb:
                        g_id = gb.get('g_id')
                except Exception:
                    gb = None

            # If still not found, create a GO record from bid_incoming
            if not gb and inc:
                try:
                    cur.execute(
                        """
                        INSERT INTO go_bids (b_name, state, scope, company, due_date, in_date, decision, scoring)
                        VALUES (%s,%s,%s,%s,%s,%s,%s,%s)
                        """,
                        (
                            inc.get('b_name'),
                            inc.get('state'),
                            inc.get('scope'),
                            inc.get('comp_name'),
                            inc.get('due_date'),
                            inc.get('in_date'),
                            inc.get('decision'),
                            inc.get('scoring', 0),
                        ),
                    )
                    mysql.connection.commit()
                    new_g_id = cur.lastrowid
                    cur.execute("SELECT * FROM go_bids WHERE g_id=%s", (new_g_id,))
                    gb = cur.fetchone()
                    g_id = new_g_id
                except Exception:
                    gb = None

            if not gb:
                cur.close()
                return jsonify({'ok': False, 'error': 'Bid not found'}), 404

        # Upsert into bid_assign
        cur.execute("SELECT a_id FROM bid_assign WHERE g_id=%s", (g_id,))
        row = cur.fetchone()
        new_stage = team  # team name aligns to stage keys in our system
        if not row:
            try:
                # Full insert (newer schema with in_date, due_date, assignee_email)
                cur.execute(
                    """
                    INSERT INTO bid_assign (g_id, b_name, in_date, due_date, state, scope, type, company, depart, person_name, assignee_email, status, value, revenue)
                    VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,'assigned',%s,%s)
                    """,
                    (
                        gb['g_id'], gb.get('b_name'), gb.get('in_date'), gb.get('due_date'), new_stage,
                        gb.get('scope'), gb.get('type'), gb.get('company'), team, (first_emp or {}).get('name'), (first_emp or {}).get('email'),
                        gb.get('scoring', 0), gb.get('revenue', gb.get('scoring', 0))
                    )
                )
            except Exception as e:
                msg = str(e)
                if "Unknown column 'revenue'" in msg:
                    # Retry without 'revenue' column; keep dates and assignee_email
                    try:
                        cur.execute(
                            """
                            INSERT INTO bid_assign (g_id, b_name, in_date, due_date, state, scope, type, company, depart, person_name, assignee_email, status, value)
                            VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,'assigned',%s)
                            """,
                            (
                                gb['g_id'], gb.get('b_name'), gb.get('in_date'), gb.get('due_date'), new_stage,
                                gb.get('scope'), gb.get('type'), gb.get('company'), team, (first_emp or {}).get('name'), (first_emp or {}).get('email'),
                                gb.get('scoring', 0)
                            )
                        )
                    except Exception as e_revenue_dates:
                        # If dates/assignee_email also missing, progressively fallback
                        msg2 = str(e_revenue_dates)
                        if "Unknown column 'in_date'" in msg2 or "Unknown column 'due_date'" in msg2:
                            try:
                                cur.execute(
                                    """
                                    INSERT INTO bid_assign (g_id, b_name, state, scope, type, company, depart, person_name, assignee_email, status, value)
                                    VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,'assigned',%s)
                                    """,
                                    (
                                        gb['g_id'], gb.get('b_name'), new_stage,
                                        gb.get('scope'), gb.get('type'), gb.get('company'), team, (first_emp or {}).get('name'), (first_emp or {}).get('email'),
                                        gb.get('scoring', 0)
                                    )
                                )
                            except Exception as e_revenue_dates_email:
                                if "Unknown column 'assignee_email'" in str(e_revenue_dates_email):
                                    cur.execute(
                                        """
                                        INSERT INTO bid_assign (g_id, b_name, state, scope, type, company, depart, person_name, status, value)
                                        VALUES (%s,%s,%s,%s,%s,%s,%s,%s,'assigned',%s)
                                        """,
                                        (
                                            gb['g_id'], gb.get('b_name'), new_stage,
                                            gb.get('scope'), gb.get('type'), gb.get('company'), team, (first_emp or {}).get('name'),
                                            gb.get('scoring', 0)
                                        )
                                    )
                                else:
                                    raise
                        elif "Unknown column 'assignee_email'" in msg2:
                            cur.execute(
                                """
                                INSERT INTO bid_assign (g_id, b_name, in_date, due_date, state, scope, type, company, depart, person_name, status, value)
                                VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,'assigned',%s)
                                """,
                                (
                                    gb['g_id'], gb.get('b_name'), gb.get('in_date'), gb.get('due_date'), new_stage,
                                    gb.get('scope'), gb.get('type'), gb.get('company'), team, (first_emp or {}).get('name'),
                                    gb.get('scoring', 0)
                                )
                            )
                        else:
                            raise
                elif "Unknown column 'in_date'" in msg or "Unknown column 'due_date'" in msg:
                    # Older schema without date columns
                    try:
                        cur.execute(
                            """
                            INSERT INTO bid_assign (g_id, b_name, state, scope, type, company, depart, person_name, assignee_email, status, value, revenue)
                            VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,'assigned',%s,%s)
                            """,
                            (
                                gb['g_id'], gb.get('b_name'), new_stage,
                                gb.get('scope'), gb.get('type'), gb.get('company'), team, (first_emp or {}).get('name'), (first_emp or {}).get('email'),
                                gb.get('scoring', 0), gb.get('revenue', gb.get('scoring', 0))
                            )
                        )
                    except Exception as e2:
                        msg2 = str(e2)
                        if "Unknown column 'revenue'" in msg2:
                            try:
                                cur.execute(
                                    """
                                    INSERT INTO bid_assign (g_id, b_name, state, scope, type, company, depart, person_name, assignee_email, status, value)
                                    VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,'assigned',%s)
                                    """,
                                    (
                                        gb['g_id'], gb.get('b_name'), new_stage,
                                        gb.get('scope'), gb.get('type'), gb.get('company'), team, (first_emp or {}).get('name'), (first_emp or {}).get('email'),
                                        gb.get('scoring', 0)
                                    )
                                )
                            except Exception as e2b:
                                if "Unknown column 'assignee_email'" in str(e2b):
                                    cur.execute(
                                        """
                                        INSERT INTO bid_assign (g_id, b_name, state, scope, type, company, depart, person_name, status, value)
                                        VALUES (%s,%s,%s,%s,%s,%s,%s,%s,'assigned',%s)
                                        """,
                                        (
                                            gb['g_id'], gb.get('b_name'), new_stage,
                                            gb.get('scope'), gb.get('type'), gb.get('company'), team, (first_emp or {}).get('name'),
                                            gb.get('scoring', 0)
                                        )
                                    )
                                else:
                                    raise
                        elif "Unknown column 'assignee_email'" in msg2:
                            # Oldest schema: no assignee_email either
                            cur.execute(
                                """
                                INSERT INTO bid_assign (g_id, b_name, state, scope, type, company, depart, person_name, status, value, revenue)
                                VALUES (%s,%s,%s,%s,%s,%s,%s,%s,'assigned',%s,%s)
                                """,
                                (
                                    gb['g_id'], gb.get('b_name'), new_stage,
                                    gb.get('scope'), gb.get('type'), gb.get('company'), team, (first_emp or {}).get('name'),
                                    gb.get('scoring', 0), gb.get('revenue', gb.get('scoring', 0))
                                )
                            )
                        else:
                            raise
                elif "Unknown column 'assignee_email'" in msg:
                    # No assignee_email but has in_date/due_date
                    try:
                        cur.execute(
                            """
                            INSERT INTO bid_assign (g_id, b_name, in_date, due_date, state, scope, type, company, depart, person_name, status, value, revenue)
                            VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,'assigned',%s,%s)
                            """,
                            (
                                gb['g_id'], gb.get('b_name'), gb.get('in_date'), gb.get('due_date'), new_stage,
                                gb.get('scope'), gb.get('type'), gb.get('company'), team, (first_emp or {}).get('name'),
                                gb.get('scoring', 0), gb.get('revenue', gb.get('scoring', 0))
                            )
                        )
                    except Exception as e3:
                        # If that also fails due to dates missing, drop those too
                        msg3 = str(e3)
                        if "Unknown column 'revenue'" in msg3:
                            try:
                                cur.execute(
                                    """
                                    INSERT INTO bid_assign (g_id, b_name, in_date, due_date, state, scope, type, company, depart, person_name, status, value)
                                    VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,'assigned',%s)
                                    """,
                                    (
                                        gb['g_id'], gb.get('b_name'), gb.get('in_date'), gb.get('due_date'), new_stage,
                                        gb.get('scope'), gb.get('type'), gb.get('company'), team, (first_emp or {}).get('name'),
                                        gb.get('scoring', 0)
                                    )
                                )
                            except Exception as e3b:
                                if "Unknown column 'in_date'" in str(e3b) or "Unknown column 'due_date'" in str(e3b):
                                    cur.execute(
                                        """
                                        INSERT INTO bid_assign (g_id, b_name, state, scope, type, company, depart, person_name, status, value)
                                        VALUES (%s,%s,%s,%s,%s,%s,%s,%s,'assigned',%s)
                                        """,
                                        (
                                            gb['g_id'], gb.get('b_name'), new_stage,
                                            gb.get('scope'), gb.get('type'), gb.get('company'), team, (first_emp or {}).get('name'),
                                            gb.get('scoring', 0)
                                        )
                                    )
                                else:
                                    raise
                        elif "Unknown column 'in_date'" in msg3 or "Unknown column 'due_date'" in msg3:
                            cur.execute(
                                """
                                INSERT INTO bid_assign (g_id, b_name, state, scope, type, company, depart, person_name, status, value, revenue)
                                VALUES (%s,%s,%s,%s,%s,%s,%s,%s,'assigned',%s,%s)
                                """,
                                (
                                    gb['g_id'], gb.get('b_name'), new_stage,
                                    gb.get('scope'), gb.get('type'), gb.get('company'), team, (first_emp or {}).get('name'),
                                    gb.get('scoring', 0), gb.get('revenue', gb.get('scoring', 0))
                                )
                            )
                        else:
                            raise
                else:
                    raise
        else:
            try:
                # Safe fallbacks for legacy schemas:
                # If 'state' and/or 'assignee_email' columns are missing in bid_assign,
                # we progressively retry the UPDATE without them to keep assignment working.
                cur.execute(
                    "UPDATE bid_assign SET depart=%s, person_name=%s, assignee_email=%s, state=%s, status='assigned' WHERE g_id=%s",
                    (team, (first_emp or {}).get('name'), (first_emp or {}).get('email'), new_stage, g_id)
                )
            except Exception as e:
                msg = str(e)
                if "Unknown column 'assignee_email'" in msg:
                    # Try without assignee_email; if state also missing, fall back again
                    try:
                        cur.execute(
                            "UPDATE bid_assign SET depart=%s, person_name=%s, state=%s, status='assigned' WHERE g_id=%s",
                            (team, (first_emp or {}).get('name'), new_stage, g_id)
                        )
                    except Exception as e2:
                        if "Unknown column 'state'" in str(e2):
                            cur.execute(
                                "UPDATE bid_assign SET depart=%s, person_name=%s, status='assigned' WHERE g_id=%s",
                                (team, (first_emp or {}).get('name'), g_id)
                            )
                        else:
                            raise
                elif "Unknown column 'state'" in msg:
                    # Try without state; if assignee_email also missing, fall back again
                    try:
                        cur.execute(
                            "UPDATE bid_assign SET depart=%s, person_name=%s, assignee_email=%s, status='assigned' WHERE g_id=%s",
                            (team, (first_emp or {}).get('name'), (first_emp or {}).get('email'), g_id)
                        )
                    except Exception as e3:
                        if "Unknown column 'assignee_email'" in str(e3):
                            cur.execute(
                                "UPDATE bid_assign SET depart=%s, person_name=%s, status='assigned' WHERE g_id=%s",
                                (team, (first_emp or {}).get('name'), g_id)
                            )
                        else:
                            raise
                else:
                    raise

        # Keep go_bids.state aligned with department
        try:
            cur.execute("UPDATE go_bids SET state=%s WHERE g_id=%s", (new_stage, g_id))
        except Exception as e:
            # Allow running against older schemas that don't yet have go_bids.state
            if "Unknown column 'state'" in str(e):
                pass
            else:
                raise

        # Update mapping table for multiple assignees (team-scoped replace)
        cur.execute(
            "DELETE FROM bid_assignment_members WHERE g_id=%s AND employee_id IN (SELECT id FROM employees WHERE department=%s)",
            (g_id, team)
        )
        if employee_ids:
            for emp_id in employee_ids:
                try:
                    # Prefer saving Team Lead -> Employee completion date when available
                    if task_completion_date:
                        try:
                            cur.execute(
                                """
                                INSERT INTO bid_assignment_members (g_id, employee_id, task_completion_date, assigned_by_email)
                                VALUES (%s,%s,%s,%s)
                                ON DUPLICATE KEY UPDATE
                                    task_completion_date = VALUES(task_completion_date),
                                    assigned_by_email = VALUES(assigned_by_email),
                                    updated_at = CURRENT_TIMESTAMP
                                """,
                                (g_id, emp_id, task_completion_date, current_user.email),
                            )
                        except Exception as e_ins:
                            # Fallback for older schemas
                            if "Unknown column" in str(e_ins):
                                cur.execute(
                                    "INSERT IGNORE INTO bid_assignment_members (g_id, employee_id) VALUES (%s,%s)",
                                    (g_id, emp_id),
                                )
                            else:
                                raise
                    else:
                        cur.execute(
                            "INSERT IGNORE INTO bid_assignment_members (g_id, employee_id) VALUES (%s,%s)",
                            (g_id, emp_id)
                        )
                except Exception:
                    pass

        # Log + emit
        display_name = (first_emp or {}).get('name') or (f"{len(employee_ids)} member(s)" if employee_ids else 'Unassigned')
        log_action = f"Assigned bid '{gb.get('b_name')}' (ID: {g_id}) to {display_name} [{team}]"
        cur.execute("INSERT INTO logs (action, user_id) VALUES (%s, %s)", (log_action, current_user.id))
        mysql.connection.commit()

        try:
            socketio.emit('master_update', {
                'log': {'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'action': log_action, 'user_email': current_user.email, 'user_role': getattr(current_user, 'role', '')},
                'assignment': True
            })
        except Exception:
            pass

        cur.close()
        return jsonify({'ok': True})
    except Exception as e:
        mysql.connection.rollback()
        try:
            cur.close()
        except Exception:
            pass


def _ensure_bid_assign_meta_table():
    cur = mysql.connection.cursor()
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS bid_assign_meta (
            g_id INT PRIMARY KEY,
            data TEXT,
            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
        )
        """
    )
    mysql.connection.commit()
    cur.close()


def _ensure_bid_incoming_project_code_column(cur=None):
    close_cur = False
    if cur is None:
        cur = mysql.connection.cursor()
        close_cur = True
    try:
        cur.execute("SHOW COLUMNS FROM bid_incoming LIKE 'ik_project_code'")
        if cur.fetchone() is None:
            cur.execute("ALTER TABLE bid_incoming ADD COLUMN ik_project_code VARCHAR(32) NULL")
            mysql.connection.commit()
    finally:
        if close_cur:
            try:
                cur.close()
            except Exception:
                pass


def _ensure_ik_project_sequence_table():
    cur = mysql.connection.cursor()
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS ik_project_sequence (
            code_prefix VARCHAR(10) PRIMARY KEY,
            last_num INT NOT NULL
        )
        """
    )
    mysql.connection.commit()
    cur.close()


def _infer_ik_project_prefix(scope_text: str | None, type_text: str | None = None) -> str | None:
    blob = f"{scope_text or ''} {type_text or ''}".lower()
    if 'solar' in blob:
        return 'SLR'
    if 'hvac' in blob:
        return 'HVC'
    if 'light' in blob or 'lighting' in blob or 'led' in blob:
        return 'LTG'
    return None


def _resolve_bid_incoming_id_for_go_bid(cur, g_id: int | None) -> int | None:
    if not g_id:
        return None
    try:
        cur.execute("SELECT id FROM go_bids WHERE g_id=%s", (g_id,))
        row = cur.fetchone()
        if isinstance(row, dict):
            val = row.get('id')
        else:
            val = row[0] if row else None
        return int(val) if val is not None else None
    except Exception:
        return None


def _get_bid_incoming_project_code(cur, bid_incoming_id: int | None) -> str:
    if not bid_incoming_id:
        return ''
    _ensure_bid_incoming_project_code_column(cur)
    try:
        cur.execute("SELECT ik_project_code FROM bid_incoming WHERE id=%s", (bid_incoming_id,))
        row = cur.fetchone()
        if isinstance(row, dict):
            return (row.get('ik_project_code') or '').strip()
        if row:
            return (row[0] or '').strip()
    except Exception:
        return ''
    return ''


def _set_bid_incoming_project_code(cur, bid_incoming_id: int | None, code: str) -> None:
    if not bid_incoming_id or not code:
        return
    _ensure_bid_incoming_project_code_column(cur)
    try:
        cur.execute("UPDATE bid_incoming SET ik_project_code=%s WHERE id=%s", (code, bid_incoming_id))
    except Exception:
        pass


def _next_ik_project_number(cur, prefix: str) -> int | None:
    if not prefix:
        return None
    _ensure_ik_project_sequence_table()
    cur.execute(
        """
        INSERT INTO ik_project_sequence (code_prefix, last_num)
        VALUES (%s, %s)
        ON DUPLICATE KEY UPDATE last_num = last_num
        """,
        (prefix, 847000),
    )
    cur.execute(
        "UPDATE ik_project_sequence SET last_num = last_num + 1 WHERE code_prefix = %s",
        (prefix,),
    )
    cur.execute("SELECT last_num FROM ik_project_sequence WHERE code_prefix = %s", (prefix,))
    row = cur.fetchone()
    if isinstance(row, dict):
        return int(row.get('last_num') or 0) or None
    if row:
        return int(row[0] or 0) or None
    return None


def _get_bid_scope_type(cur, g_id: int) -> tuple[str, str]:
    scope = ''
    type_text = ''
    try:
        cur.execute("SELECT scope, type FROM go_bids WHERE g_id=%s", (g_id,))
        row = cur.fetchone() or {}
        if isinstance(row, dict):
            scope = row.get('scope') or ''
            type_text = row.get('type') or ''
        elif row:
            scope = row[0] or ''
            if len(row) > 1:
                type_text = row[1] or ''
    except Exception:
        try:
            cur.execute("SELECT scope FROM go_bids WHERE g_id=%s", (g_id,))
            row = cur.fetchone()
            if isinstance(row, dict):
                scope = row.get('scope') or ''
            elif row:
                scope = row[0] or ''
        except Exception:
            pass
    if not scope:
        try:
            cur.execute("SELECT scope FROM bid_incoming WHERE id=%s", (g_id,))
            row = cur.fetchone()
            if isinstance(row, dict):
                scope = row.get('scope') or ''
            elif row:
                scope = row[0] or ''
        except Exception:
            pass
    return scope, type_text


def _ensure_ik_project_code(cur, g_id: int, meta: dict | None, scope_text: str | None, type_text: str | None) -> str | None:
    if not g_id:
        return None
    if not isinstance(meta, dict):
        meta = {}
    existing = (meta.get('ik_project_code') or '').strip()
    if existing:
        incoming_id = _resolve_bid_incoming_id_for_go_bid(cur, g_id) or g_id
        _set_bid_incoming_project_code(cur, incoming_id, existing)
        return existing
    incoming_id = _resolve_bid_incoming_id_for_go_bid(cur, g_id) or g_id
    incoming_code = _get_bid_incoming_project_code(cur, incoming_id)
    if incoming_code:
        meta['ik_project_code'] = incoming_code
        _ensure_bid_assign_meta_table()
        cur.execute(
            """
            INSERT INTO bid_assign_meta (g_id, data)
            VALUES (%s, %s)
            ON DUPLICATE KEY UPDATE data=VALUES(data), updated_at=CURRENT_TIMESTAMP
            """,
            (g_id, json.dumps(meta)),
        )
        return incoming_code
    prefix = _infer_ik_project_prefix(scope_text, type_text)
    if not prefix:
        return None
    seq_num = _next_ik_project_number(cur, prefix)
    if not seq_num:
        return None
    project_code = f"IK-P/{prefix}/{seq_num:06d}"
    meta['ik_project_code'] = project_code
    _ensure_bid_assign_meta_table()
    _ensure_bid_incoming_project_code_column(cur)
    cur.execute(
        """
        INSERT INTO bid_assign_meta (g_id, data)
        VALUES (%s, %s)
        ON DUPLICATE KEY UPDATE data=VALUES(data), updated_at=CURRENT_TIMESTAMP
        """,
        (g_id, json.dumps(meta)),
    )
    _set_bid_incoming_project_code(cur, incoming_id, project_code)
    return project_code


def _ensure_go_bid_from_incoming(bid_id: int):
    """Return (g_id, go_bid_row) ensuring a go_bids row exists for a bid_incoming id."""
    cur = mysql.connection.cursor(DictCursor)
    try:
        # Prefer explicit linkage via go_bids.id (bid_incoming.id)
        cur.execute("SELECT * FROM go_bids WHERE id=%s", (bid_id,))
        gb = cur.fetchone()
        if gb:
            return gb.get('g_id'), gb
        # Fallback: legacy check by g_id
        cur.execute("SELECT * FROM go_bids WHERE g_id=%s", (bid_id,))
        gb = cur.fetchone()
        if gb:
            return gb.get('g_id'), gb

        cur.execute("SELECT * FROM bid_incoming WHERE id=%s", (bid_id,))
        inc = cur.fetchone()
        if inc:
            # Try name match
            cur.execute("SELECT * FROM go_bids WHERE b_name=%s ORDER BY g_id DESC LIMIT 1", (inc.get('b_name'),))
            gb2 = cur.fetchone()
            if gb2:
                return gb2.get('g_id'), gb2

            try:
                cur.execute(
                    """
                    INSERT INTO go_bids (id, b_name, state, scope, company, due_date, in_date, decision, scoring)
                    VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s)
                    """,
                    (
                        inc.get('id'),
                        inc.get('b_name'),
                        inc.get('state'),
                        inc.get('scope'),
                        inc.get('comp_name'),
                        inc.get('due_date'),
                        inc.get('in_date'),
                        inc.get('decision'),
                        inc.get('scoring', 0),
                    ),
                )
                mysql.connection.commit()
                new_id = cur.lastrowid
                cur.execute("SELECT * FROM go_bids WHERE g_id=%s", (new_id,))
                gb_new = cur.fetchone()
                return new_id, gb_new
            except Exception:
                return None, None
    finally:
        try:
            cur.close()
        except Exception:
            pass
    return None, None


@app.route('/api/bid-analyzer/ensure-go/<int:bid_id>')
@login_required
def api_ensure_go_bid(bid_id):
    g_id, gb = _ensure_go_bid_from_incoming(bid_id)
    if not g_id:
        return jsonify({'ok': False, 'error': 'Bid not found'}), 404
    # If meta was stored under bid_incoming id, migrate to go_bids g_id.
    if int(g_id) != int(bid_id):
        try:
            _ensure_bid_assign_meta_table()
            cur = mysql.connection.cursor(DictCursor)
            cur.execute("SELECT data FROM bid_assign_meta WHERE g_id=%s", (bid_id,))
            old_row = cur.fetchone() or {}
            cur.execute("SELECT data FROM bid_assign_meta WHERE g_id=%s", (g_id,))
            new_row = cur.fetchone() or {}
            if old_row.get('data') and not new_row.get('data'):
                cur.execute(
                    """
                    INSERT INTO bid_assign_meta (g_id, data)
                    VALUES (%s, %s)
                    ON DUPLICATE KEY UPDATE data=VALUES(data), updated_at=CURRENT_TIMESTAMP
                    """,
                    (int(g_id), old_row.get('data')),
                )
                cur.execute("DELETE FROM bid_assign_meta WHERE g_id=%s", (bid_id,))
                mysql.connection.commit()
            cur.close()
        except Exception:
            try:
                mysql.connection.rollback()
            except Exception:
                pass
    return jsonify({'ok': True, 'g_id': int(g_id)})


@app.route('/api/bid-analyzer/update-summary', methods=['POST'])
@login_required
def api_update_bid_analyzer_summary():
    user_role = getattr(current_user, 'role', '').lower()
    is_top_admin = user_role in ['top_level_admin', 'top level admin']
    if not current_user.is_admin and not is_top_admin and not check_module_access_db('bid_analyzer'):
        return jsonify({'ok': False, 'error': "You don't have permission to access the Bid Analyzer."}), 403
    data = request.get_json(silent=True) or {}
    try:
        bid_id = int(data.get('bid_id') or 0)
    except Exception:
        bid_id = 0
    summary = (data.get('summary') or '').strip()
    if not bid_id:
        return jsonify({'ok': False, 'error': 'bid_id_required'}), 400
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("UPDATE bid_incoming SET summary=%s WHERE id=%s", (summary, bid_id))
        mysql.connection.commit()
        return jsonify({'ok': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'ok': False, 'error': 'db', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/api/bid-analyzer/assign-detail/<int:g_id>', methods=['GET'])
@login_required
def api_get_assign_detail(g_id):
    _ensure_bid_assign_meta_table()
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SELECT data FROM bid_assign_meta WHERE g_id=%s", (g_id,))
        row = cur.fetchone()
        if not row or not row.get('data'):
            return jsonify({'ok': True, 'data': {}})
        try:
            data = json.loads(row.get('data') or "{}")
        except Exception:
            data = {}
        return jsonify({'ok': True, 'data': data})
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/api/bid-analyzer/assign-detail', methods=['POST'])
@login_required
def api_save_assign_detail():
    _ensure_bid_assign_meta_table()
    try:
        payload = request.get_json(silent=True) or {}
        g_id = int(payload.get('g_id') or 0)
        data = payload.get('data') or {}
    except Exception:
        return jsonify({'ok': False, 'error': 'invalid_payload'}), 400
    if not g_id:
        return jsonify({'ok': False, 'error': 'g_id_required'}), 400
    cur = mysql.connection.cursor(DictCursor)
    try:
        existing = {}
        try:
            cur.execute("SELECT data FROM bid_assign_meta WHERE g_id=%s", (g_id,))
            row = cur.fetchone()
            if row and row.get('data'):
                existing = json.loads(row.get('data') or "{}")
        except Exception:
            existing = {}

        if not isinstance(existing, dict):
            existing = {}
        if not isinstance(data, dict):
            data = {}

        if isinstance(data, dict) and 'uploaded_files' in data:
            incoming_files = data.get('uploaded_files')
            if isinstance(incoming_files, list):
                existing_files = existing.get('uploaded_files') if isinstance(existing, dict) else []
                merged_files = []
                seen_keys = set()
                for f in (existing_files or []):
                    if not isinstance(f, dict):
                        continue
                    key = (str(f.get('name') or ''), int(f.get('size') or 0))
                    if key in seen_keys:
                        continue
                    seen_keys.add(key)
                    merged_files.append(f)
                for f in incoming_files:
                    if not isinstance(f, dict):
                        continue
                    key = (str(f.get('name') or ''), int(f.get('size') or 0))
                    if key in seen_keys:
                        continue
                    seen_keys.add(key)
                    merged_files.append(f)
                data = dict(data)
                data['uploaded_files'] = merged_files

        merged = dict(existing)
        merged.update(data)

        incoming_code = (data.get('ik_project_code') or '').strip()
        existing_code = (existing.get('ik_project_code') or '').strip()
        project_code = incoming_code or existing_code
        if not project_code:
            scope_text, type_text = _get_bid_scope_type(cur, g_id)
            prefix = _infer_ik_project_prefix(scope_text, type_text)
            if prefix:
                seq_num = _next_ik_project_number(cur, prefix)
                if seq_num:
                    project_code = f"IK-P/{prefix}/{seq_num:06d}"
        if project_code:
            merged['ik_project_code'] = project_code

        cur.execute(
            """
            INSERT INTO bid_assign_meta (g_id, data)
            VALUES (%s, %s)
            ON DUPLICATE KEY UPDATE data=VALUES(data), updated_at=CURRENT_TIMESTAMP
            """,
            (g_id, json.dumps(merged)),
        )
        try:
            _recalc_bid_team_progress(cur, int(g_id))
        except Exception:
            pass
        mysql.connection.commit()
        return jsonify({'ok': True, 'ik_project_code': project_code})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'ok': False, 'error': 'db', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


def _append_project_activity(g_id: int, entry: dict) -> None:
    """Append a project activity entry into bid_assign_meta.meta_json."""
    if not g_id or not isinstance(entry, dict):
        return
    _ensure_bid_assign_meta_table()
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SELECT data FROM bid_assign_meta WHERE g_id=%s", (int(g_id),))
        row = cur.fetchone() or {}
        try:
            meta = json.loads(row.get('data') or "{}")
        except Exception:
            meta = {}
        if not isinstance(meta, dict):
            meta = {}
        activity = meta.get('project_activity') or []
        if not isinstance(activity, list):
            activity = []
        activity.append(entry)
        meta['project_activity'] = activity
        cur.execute(
            """
            INSERT INTO bid_assign_meta (g_id, data)
            VALUES (%s, %s)
            ON DUPLICATE KEY UPDATE data=VALUES(data), updated_at=CURRENT_TIMESTAMP
            """,
            (int(g_id), json.dumps(meta)),
        )
        mysql.connection.commit()
    except Exception:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/api/bid-analyzer/assign-attachment', methods=['POST'])
@login_required
def api_assign_attachment():
    try:
        g_id = int(request.form.get('g_id') or 0)
    except Exception:
        g_id = 0
    upload = request.files.get('file')
    if not g_id or not upload:
        return jsonify({'ok': False, 'error': 'missing_fields'}), 400

    safe_name = secure_filename(upload.filename) or f"file_{uuid.uuid4().hex}.bin"
    folder = os.path.join(app.root_path, 'static', 'assign_attachments', str(g_id))
    try:
        os.makedirs(folder, exist_ok=True)
    except Exception:
        return jsonify({'ok': False, 'error': 'storage_failed'}), 500
    filename = f"{uuid.uuid4().hex}_{safe_name}"
    path = os.path.join(folder, filename)
    try:
        upload.save(path)
    except Exception:
        return jsonify({'ok': False, 'error': 'save_failed'}), 500
    url = url_for('static', filename=f"assign_attachments/{g_id}/{filename}")
    return jsonify({'ok': True, 'name': safe_name, 'url': url, 'path': path})


@app.route('/api/bid-analyzer/upload-docs', methods=['POST'])
@login_required
def api_bid_analyzer_upload_docs():
    user_role = getattr(current_user, 'role', '').lower()
    is_top_admin = user_role in ['top_level_admin', 'top level admin']
    if not current_user.is_admin and not is_top_admin and not check_module_access_db('bid_analyzer'):
        return jsonify({'ok': False, 'error': "You don't have permission to access the Bid Analyzer."}), 403
    try:
        g_id = int(request.form.get('g_id') or 0)
    except Exception:
        g_id = 0
    try:
        bid_id = int(request.form.get('bid_id') or 0)
    except Exception:
        bid_id = 0
    files = request.files.getlist('rfp_files')
    files = [f for f in (files or []) if f and getattr(f, 'filename', '')]
    if not files:
        return jsonify({'ok': False, 'error': 'missing_fields'}), 400
    if not g_id and bid_id:
        try:
            g_id, _ = _ensure_go_bid_from_incoming(bid_id)
        except Exception:
            g_id = 0
    if not g_id:
        return jsonify({'ok': False, 'error': 'missing_fields'}), 400

    folder = os.path.join(app.root_path, 'static', 'bid_documents', str(g_id))
    try:
        os.makedirs(folder, exist_ok=True)
    except Exception:
        return jsonify({'ok': False, 'error': 'storage_failed'}), 500

    uploaded = []
    for f in files:
        safe_name = secure_filename(f.filename) or f"file_{uuid.uuid4().hex}.bin"
        filename = f"{uuid.uuid4().hex}_{safe_name}"
        path = os.path.join(folder, filename)
        try:
            f.save(path)
        except Exception:
            continue
        url = url_for('static', filename=f"bid_documents/{g_id}/{filename}")
        size = 0
        try:
            size = os.path.getsize(path)
        except Exception:
            size = 0
        uploaded.append({
            'name': safe_name,
            'size': size,
            'type': f.mimetype or '',
            'url': url,
            'uploaded_at': datetime.utcnow().isoformat(),
        })

    if not uploaded:
        return jsonify({'ok': False, 'error': 'save_failed'}), 500

    try:
        _ensure_bid_assign_meta_table()
        cur = mysql.connection.cursor(DictCursor)
        try:
            cur.execute("SELECT data FROM bid_assign_meta WHERE g_id=%s", (g_id,))
            row = cur.fetchone()
            existing = {}
            if row and row.get('data'):
                try:
                    existing = json.loads(row.get('data') or "{}")
                except Exception:
                    existing = {}
            if not isinstance(existing, dict):
                existing = {}
            existing_files = existing.get('uploaded_files') if isinstance(existing, dict) else []
            merged_files = []
            seen_keys = set()
            for f in (existing_files or []):
                if not isinstance(f, dict):
                    continue
                key = (str(f.get('name') or ''), int(f.get('size') or 0))
                if key in seen_keys:
                    continue
                seen_keys.add(key)
                merged_files.append(f)
            for f in uploaded:
                key = (str(f.get('name') or ''), int(f.get('size') or 0))
                if key in seen_keys:
                    continue
                seen_keys.add(key)
                merged_files.append(f)
            existing['uploaded_files'] = merged_files
            cur.execute(
                """
                INSERT INTO bid_assign_meta (g_id, data)
                VALUES (%s, %s)
                ON DUPLICATE KEY UPDATE data=VALUES(data), updated_at=CURRENT_TIMESTAMP
                """,
                (g_id, json.dumps(existing)),
            )
            mysql.connection.commit()
        finally:
            try:
                cur.close()
            except Exception:
                pass
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        return jsonify({'ok': False, 'error': 'db', 'message': str(e)}), 500

    return jsonify({'ok': True, 'g_id': int(g_id), 'files': uploaded})


@app.route('/api/team/<team>/bids/<int:g_id>/checklist/bulk-assign', methods=['POST'])
@login_required
def api_bulk_assign_checklist(team, g_id):
    """Create bid_checklists tasks for selected employees from assigned_tasks modal."""
    data = request.get_json(silent=True) or {}
    tasks = data.get('tasks') or []
    employee_ids = data.get('employee_ids') or []
    try:
        employee_ids = [int(x) for x in employee_ids if x is not None]
    except Exception:
        employee_ids = []
    if not g_id or not tasks or not employee_ids:
        return jsonify({'ok': False, 'error': 'missing_fields'}), 400

    stage_name = (team or '').strip().lower()
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_task_manager_attachments_table(cur)
        prefix, next_num = _next_task_code_number(cur, stage_name)
        for task in tasks:
            task_name = (task.get('text') or '').strip()
            if not task_name:
                continue
            description = (task.get('notes') or '').strip()
            priority = (task.get('priority') or 'normal').strip().lower()
            due_date = (task.get('due_date') or '').strip() or None
            attachment_name = (task.get('attachment') or '').strip()
            attachment_url = (task.get('attachment_url') or '').strip()
            attachment_path = ''
            if attachment_url and attachment_url.startswith('/static/assign_attachments/'):
                attachment_path = os.path.join(app.root_path, attachment_url.lstrip('/'))
            for emp_id in employee_ids:
                task_code = f"{prefix}-{next_num:03d}" if prefix and next_num else None
                cur.execute(
                    """
                    INSERT INTO bid_checklists (g_id, task_code, task_name, description, assigned_to, priority, due_date, progress_pct, stage, created_by)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    """,
                    (
                        g_id,
                        task_code,
                        task_name,
                        description,
                        emp_id,
                        priority,
                        due_date,
                        0,
                        stage_name,
                        getattr(current_user, 'id', None),
                    ),
                )
                if prefix and next_num:
                    next_num += 1
                task_id = cur.lastrowid
                if attachment_path and os.path.exists(attachment_path):
                    cur.execute(
                        """
                        INSERT INTO task_manager_attachments (task_id, user_id, file_path, original_filename, approval_target)
                        VALUES (%s, %s, %s, %s, %s)
                        """,
                        (
                            task_id,
                            getattr(current_user, 'id', None),
                            attachment_path,
                            attachment_name or os.path.basename(attachment_path),
                            'admin',
                        ),
                    )
        mysql.connection.commit()
        return jsonify({'ok': True})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'ok': False, 'error': 'db', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


@app.route('/api/team/<team>/bids/<int:g_id>/checklist/sync', methods=['POST'])
@login_required
def sync_checklist_tasks(team, g_id):
    """Upsert checklist tasks into bid_checklists for a team (dedupe by task name)."""
    data = request.get_json(silent=True) or {}
    tasks = data.get('tasks') or []
    stage_name = (team or '').strip().lower()
    if not stage_name or not tasks:
        return jsonify({'ok': True, 'inserted': 0, 'updated': 0})
    inserted = 0
    updated = 0
    task_refs = []
    cur = mysql.connection.cursor(DictCursor)
    try:
        prefix, next_num = _next_task_code_number(cur, stage_name)
        for task in tasks:
            task_name = (task.get('text') or '').strip()
            if not task_name:
                continue
            description = (task.get('notes') or '').strip()
            priority = (task.get('priority') or 'normal').strip().lower()
            due_date = (task.get('due_date') or '').strip() or None
            cur.execute(
                """
                SELECT COUNT(*) AS cnt
                FROM bid_checklists
                WHERE g_id=%s
                  AND LOWER(COALESCE(stage,''))=%s
                  AND LOWER(COALESCE(task_name,''))=LOWER(%s)
                  AND team_archive IS NULL
                """,
                (g_id, stage_name, task_name),
            )
            row = cur.fetchone() or {}
            if row.get('cnt'):
                cur.execute(
                    """
                    UPDATE bid_checklists
                    SET description=%s, priority=%s, due_date=%s
                    WHERE g_id=%s
                      AND LOWER(COALESCE(stage,''))=%s
                      AND LOWER(COALESCE(task_name,''))=LOWER(%s)
                      AND team_archive IS NULL
                    """,
                    (description, priority, due_date, g_id, stage_name, task_name),
                )
                updated += int(row.get('cnt') or 0)
                cur.execute(
                    """
                    SELECT id
                    FROM bid_checklists
                    WHERE g_id=%s
                      AND LOWER(COALESCE(stage,''))=%s
                      AND LOWER(COALESCE(task_name,''))=LOWER(%s)
                      AND team_archive IS NULL
                    ORDER BY id DESC
                    LIMIT 1
                    """,
                    (g_id, stage_name, task_name),
                )
                row_id = cur.fetchone() or {}
                if row_id.get('id'):
                    task_refs.append({'id': row_id.get('id'), 'task_name': task_name, 'stage': stage_name})
            else:
                task_code = f"{prefix}-{next_num:03d}" if prefix and next_num else None
                cur.execute(
                    """
                    INSERT INTO bid_checklists (g_id, task_code, task_name, description, assigned_to, priority, due_date,
                                                progress_pct, stage, created_by)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    """,
                    (
                        g_id,
                        task_code,
                        task_name,
                        description,
                        None,
                        priority,
                        due_date,
                        0,
                        stage_name,
                        getattr(current_user, 'id', None),
                    ),
                )
                if cur.lastrowid:
                    task_refs.append({'id': cur.lastrowid, 'task_name': task_name, 'stage': stage_name})
                if prefix and next_num:
                    next_num += 1
                inserted += 1
        try:
            _recalc_bid_team_progress(cur, int(g_id))
        except Exception:
            pass
        mysql.connection.commit()
        return jsonify({'ok': True, 'inserted': inserted, 'updated': updated, 'tasks': task_refs})
    except Exception as e:
        mysql.connection.rollback()
        return jsonify({'ok': False, 'error': 'db', 'message': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass


def _load_assigned_tasks_for_department(dept_key: str, limit: int = 200):
    _ensure_bid_assign_meta_table()
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute(
            """
            SELECT gb.*, bi.id AS bid_id, bi.state AS bid_state, bi.summary AS bid_summary, bam.data AS meta_json
            FROM bid_assign_meta bam
            LEFT JOIN go_bids gb ON gb.g_id = bam.g_id
            LEFT JOIN bid_incoming bi ON bi.id = gb.id
            ORDER BY bam.updated_at DESC, bam.g_id DESC
            LIMIT %s
            """,
            (limit,),
        )
        rows = cur.fetchall() or []
    finally:
        try:
            cur.close()
        except Exception:
            pass

    rfp_files_map = {}
    try:
        g_ids = [r.get('g_id') for r in rows if r.get('g_id')]
        if g_ids:
            rfp_cur = mysql.connection.cursor(DictCursor)
            try:
                _ensure_uploaded_rfp_table_exists(rfp_cur)
                placeholders = ",".join(["%s"] * len(g_ids))
                rfp_cur.execute(
                    f"""
                    SELECT id, g_id, original_filename, filename, uploaded_at
                    FROM uploaded_rfp_files
                    WHERE g_id IN ({placeholders})
                    ORDER BY uploaded_at DESC, id DESC
                    """,
                    tuple(g_ids),
                )
                for row in rfp_cur.fetchall() or []:
                    g_id = row.get('g_id')
                    if not g_id:
                        continue
                    rfp_files_map.setdefault(g_id, []).append({
                        'id': row.get('id'),
                        'filename': row.get('original_filename') or row.get('filename') or 'Document',
                        'uploaded_at': row.get('uploaded_at'),
                    })
            finally:
                try:
                    rfp_cur.close()
                except Exception:
                    pass
    except Exception:
        rfp_files_map = {}

    task_files_map = {}
    try:
        g_ids = [r.get('g_id') for r in rows if r.get('g_id')]
        if g_ids:
            task_cur = mysql.connection.cursor(DictCursor)
            try:
                placeholders = ",".join(["%s"] * len(g_ids))
                task_cur.execute(
                    f"""
                    SELECT id, g_id
                    FROM bid_checklists
                    WHERE g_id IN ({placeholders})
                      AND team_archive IS NULL
                    """,
                    tuple(g_ids),
                )
                task_rows = task_cur.fetchall() or []
                task_ids = []
                task_id_to_gid = {}
                for row in task_rows:
                    tid = row.get('id')
                    gid = row.get('g_id')
                    if not tid or not gid:
                        continue
                    task_ids.append(tid)
                    task_id_to_gid[tid] = gid
                if task_ids:
                    _ensure_task_work_files_table(task_cur)
                    _ensure_task_manager_attachments_table(task_cur)
                    task_placeholders = ",".join(["%s"] * len(task_ids))
                    task_cur.execute(
                        f"""
                        SELECT id, task_id, original_filename, filename, uploaded_at
                        FROM task_work_files
                        WHERE task_id IN ({task_placeholders})
                        ORDER BY uploaded_at DESC, id DESC
                        """,
                        tuple(task_ids),
                    )
                    for row in task_cur.fetchall() or []:
                        tid = row.get('task_id')
                        gid = task_id_to_gid.get(tid)
                        if not gid:
                            continue
                        task_files_map.setdefault(gid, []).append({
                            'id': row.get('id'),
                            'filename': row.get('original_filename') or row.get('filename') or 'Upload',
                            'uploaded_at': row.get('uploaded_at'),
                            'download_url': f"/task/file/{row.get('id')}/download",
                            'source': 'task',
                        })
                    task_cur.execute(
                        f"""
                        SELECT id, task_id, original_filename, filename, uploaded_at
                        FROM task_manager_attachments
                        WHERE task_id IN ({task_placeholders})
                        ORDER BY uploaded_at DESC, id DESC
                        """,
                        tuple(task_ids),
                    )
                    for row in task_cur.fetchall() or []:
                        tid = row.get('task_id')
                        gid = task_id_to_gid.get(tid)
                        if not gid:
                            continue
                        task_files_map.setdefault(gid, []).append({
                            'id': row.get('id'),
                            'filename': row.get('original_filename') or row.get('filename') or 'File',
                            'uploaded_at': row.get('uploaded_at'),
                            'download_url': f"/task/manager-file/{row.get('id')}/download",
                            'source': 'manager',
                        })
            finally:
                try:
                    task_cur.close()
                except Exception:
                    pass
    except Exception:
        task_files_map = {}

    items = []
    update_cur = mysql.connection.cursor(DictCursor)
    updated_any = False
    for r in rows:
        try:
            meta = json.loads(r.get('meta_json') or "{}")
        except Exception:
            meta = {}
        # Skip placeholder rows without a valid bid id or name
        try:
            if not r.get('g_id'):
                continue
        except Exception:
            continue
        scope_text = r.get('scope') or meta.get('scope') or ''
        type_text = r.get('type') or meta.get('type') or ''
        try:
            ik_code = _ensure_ik_project_code(update_cur, int(r.get('g_id')), meta, scope_text, type_text)
            if ik_code:
                updated_any = True
        except Exception:
            ik_code = meta.get('ik_project_code') or ''
        departments = meta.get('departments') or []
        if dept_key not in departments:
            continue
        # Filter checklist to this department only
        checklist = meta.get('checklist') or []
        dept_checklist = [c for c in checklist if not c.get('dept') or c.get('dept') == dept_key]
        meta_files = []
        try:
            raw_files = meta.get('uploaded_files') or []
            if isinstance(raw_files, list):
                for f in raw_files:
                    if not isinstance(f, dict):
                        continue
                    url = (f.get('url') or f.get('download_url') or '').strip()
                    name = (f.get('name') or f.get('filename') or 'Document').strip()
                    uploaded_at = f.get('uploaded_at') or ''
                    if url or name:
                        meta_files.append({
                            'id': f.get('id'),
                            'filename': name or 'Document',
                            'uploaded_at': uploaded_at,
                            'download_url': url,
                            'source': 'bid',
                        })
        except Exception:
            meta_files = []

        items.append({
              'g_id': r.get('g_id'),
              'bid_id': r.get('bid_id') or r.get('id'),
              'name': r.get('b_name') or meta.get('name') or 'Bid',
              'company': r.get('company') or r.get('comp_name') or '',
              'state': r.get('bid_state') or r.get('state') or '',
              'due_date': r.get('due_date') or '',
              'scope': scope_text,
              'type': type_text,
              'summary': r.get('bid_summary') or r.get('summary') or meta.get('summary') or '',
              'ik_project_code': ik_code or meta.get('ik_project_code') or '',
              'departments': departments,
              'start_date': meta.get('start_date') or '',
              'assign_due_date': meta.get('due_date') or '',
              'notes': meta.get('notes') or '',
              'project_activity': meta.get('project_activity') or [],
            'progress': meta.get('progress') or '',
            'priority': meta.get('priority') or '',
            'checklist': dept_checklist,
            'rfp_files': meta_files or rfp_files_map.get(r.get('g_id'), []),
            'task_files': task_files_map.get(r.get('g_id'), []),
        })
    if updated_any:
        try:
            mysql.connection.commit()
        except Exception:
            mysql.connection.rollback()
    try:
        update_cur.close()
    except Exception:
        pass
    return items


def _load_assigned_projects_for_manager(user_id: int, limit: int = 200):
    _ensure_bid_assign_meta_table()
    cur = mysql.connection.cursor(DictCursor)
    g_ids = []
    try:
        _ensure_project_manager_assignments_table(cur)
        cur.execute(
            """
            SELECT DISTINCT pma.g_id
            FROM project_manager_assignments pma
            LEFT JOIN win_lost_results wlr ON wlr.g_id = pma.g_id
            LEFT JOIN won_bids_result wbr ON wbr.w_id = wlr.w_id
            WHERE pma.manager_user_id=%s AND pma.g_id IS NOT NULL
              AND (
                LOWER(COALESCE(wlr.status,'')) LIKE '%%won%%'
                OR LOWER(COALESCE(wlr.result,'')) LIKE '%%won%%'
                OR LOWER(COALESCE(wlr.result,'')) LIKE '%%award%%'
                OR wbr.w_id IS NOT NULL
              )
            ORDER BY assigned_at DESC
            LIMIT %s
            """,
            (int(user_id), int(limit)),
        )
        g_ids = [r.get('g_id') for r in (cur.fetchall() or []) if r.get('g_id')]
    except Exception:
        g_ids = []
    finally:
        try:
            cur.close()
        except Exception:
            pass

    # Fallback: if no explicit PM assignments exist, show won bids from win/lost tables
    # so the Project Manager dashboard still has data sourced from bid_incoming/win_lost_results/won_bids_result.
    if not g_ids:
        cur = mysql.connection.cursor(DictCursor)
        try:
            company_sql_clause, company_params = _company_filter_for_go_bids(cur)
            cur.execute(
                """
                SELECT DISTINCT wlr.g_id
                FROM win_lost_results wlr
                LEFT JOIN won_bids_result wbr ON wbr.w_id = wlr.w_id
                LEFT JOIN go_bids gb ON gb.g_id = wlr.g_id
                WHERE wlr.g_id IS NOT NULL
                  AND (
                    LOWER(COALESCE(wlr.status,'')) LIKE '%%won%%'
                    OR LOWER(COALESCE(wlr.result,'')) LIKE '%%won%%'
                    OR LOWER(COALESCE(wlr.result,'')) LIKE '%%award%%'
                    OR wbr.w_id IS NOT NULL
                  )
                """ + (company_sql_clause if company_sql_clause else "") + """
                ORDER BY wlr.w_id DESC
                LIMIT %s
                """,
                tuple(company_params) + (int(limit),),
            )
            g_ids = [r.get('g_id') for r in (cur.fetchall() or []) if r.get('g_id')]
        except Exception:
            g_ids = []
        finally:
            try:
                cur.close()
            except Exception:
                pass

    if not g_ids:
        return []

    cur = mysql.connection.cursor(DictCursor)
    try:
        placeholders = ",".join(["%s"] * len(g_ids))
        cur.execute(
            f"""
            SELECT
                gb.*,
                bi.id AS bid_id,
                bi.state AS bid_state,
                bi.summary AS bid_summary,
                bam.data AS meta_json,
                wlr.result AS win_result,
                wlr.status AS win_status,
                wbr.closure_status,
                wbr.work_progress_status
            FROM go_bids gb
            LEFT JOIN bid_assign_meta bam ON bam.g_id = gb.g_id
            LEFT JOIN bid_incoming bi ON bi.id = gb.id
            LEFT JOIN win_lost_results wlr ON wlr.g_id = gb.g_id
            LEFT JOIN won_bids_result wbr ON wbr.w_id = wlr.w_id
            WHERE gb.g_id IN ({placeholders})
            ORDER BY COALESCE(bam.updated_at, gb.due_date, gb.created_at) DESC, gb.g_id DESC
            """,
            tuple(g_ids),
        )
        rows = cur.fetchall() or []
    finally:
        try:
            cur.close()
        except Exception:
            pass

    rfp_files_map = {}
    try:
        if g_ids:
            rfp_cur = mysql.connection.cursor(DictCursor)
            try:
                _ensure_uploaded_rfp_table_exists(rfp_cur)
                placeholders = ",".join(["%s"] * len(g_ids))
                rfp_cur.execute(
                    f"""
                    SELECT id, g_id, bid_id, original_filename, filename, uploaded_at
                    FROM uploaded_rfp_files
                    WHERE g_id IN ({placeholders})
                    ORDER BY uploaded_at DESC, id DESC
                    """,
                    tuple(g_ids),
                )
                for row in rfp_cur.fetchall() or []:
                    g_id = row.get('g_id')
                    if not g_id:
                        continue
                    rfp_files_map.setdefault(g_id, []).append({
                        'id': row.get('id'),
                        'filename': row.get('original_filename') or row.get('filename') or 'Document',
                        'uploaded_at': row.get('uploaded_at'),
                    })
            finally:
                try:
                    rfp_cur.close()
                except Exception:
                    pass
    except Exception:
        rfp_files_map = {}

    # Fallback: attach RFP files by bid_id if g_id is missing in uploaded_rfp_files
    try:
        bid_id_to_gid = {}
        for rr in (rows or []):
            bid_id = rr.get('bid_id') or rr.get('id')
            gid = rr.get('g_id')
            if bid_id and gid:
                bid_id_to_gid[int(bid_id)] = int(gid)
        bid_ids = list(bid_id_to_gid.keys())
        if bid_ids:
            rfp_cur = mysql.connection.cursor(DictCursor)
            try:
                _ensure_uploaded_rfp_table_exists(rfp_cur)
                placeholders = ",".join(["%s"] * len(bid_ids))
                rfp_cur.execute(
                    f"""
                    SELECT id, bid_id, original_filename, filename, uploaded_at
                    FROM uploaded_rfp_files
                    WHERE bid_id IN ({placeholders})
                    ORDER BY uploaded_at DESC, id DESC
                    """,
                    tuple(bid_ids),
                )
                for row in rfp_cur.fetchall() or []:
                    bid_id = row.get('bid_id')
                    gid = bid_id_to_gid.get(int(bid_id)) if bid_id else None
                    if not gid:
                        continue
                    rfp_files_map.setdefault(gid, []).append({
                        'id': row.get('id'),
                        'filename': row.get('original_filename') or row.get('filename') or 'Document',
                        'uploaded_at': row.get('uploaded_at'),
                    })
            finally:
                try:
                    rfp_cur.close()
                except Exception:
                    pass
    except Exception:
        pass

    task_files_map = {}
    checklist_map = {}
    try:
        if g_ids:
            task_cur = mysql.connection.cursor(DictCursor)
            try:
                placeholders = ",".join(["%s"] * len(g_ids))
                task_cur.execute(
                    f"""
                    SELECT
                        bc.id,
                        bc.g_id,
                        bc.task_name,
                        bc.description,
                        bc.status,
                        bc.priority,
                        bc.due_date,
                        bc.stage,
                        bc.assigned_to,
                        bc.attachment_path,
                        e.name AS assigned_employee_name,
                        e.email AS employee_email
                    FROM bid_checklists bc
                    LEFT JOIN employees e ON e.id = bc.assigned_to
                    WHERE g_id IN ({placeholders})
                      AND team_archive IS NULL
                    """,
                    tuple(g_ids),
                )
                task_rows = task_cur.fetchall() or []
                task_ids = []
                task_id_to_gid = {}
                for row in task_rows:
                    tid = row.get('id')
                    gid = row.get('g_id')
                    if not tid or not gid:
                        continue
                    task_ids.append(tid)
                    try:
                        gid_key = int(gid)
                    except Exception:
                        gid_key = gid
                    task_id_to_gid[tid] = gid_key
                    checklist_map.setdefault(gid_key, []).append({
                        'id': tid,
                        'task_name': row.get('task_name') or 'Task',
                        'description': row.get('description') or '',
                        'status': normalize_task_status(row.get('status') or ''),
                        'priority': row.get('priority') or '',
                        'due_date': row.get('due_date') or '',
                        'stage': row.get('stage') or '',
                        'assigned_to': row.get('assigned_to'),
                        'assigned_employee_name': row.get('assigned_employee_name') or '',
                        'employee_email': row.get('employee_email') or '',
                        'attachment': row.get('attachment_path') or '',
                    })
                if task_ids:
                    _ensure_task_work_files_table(task_cur)
                    _ensure_task_manager_attachments_table(task_cur)
                    task_placeholders = ",".join(["%s"] * len(task_ids))
                    task_cur.execute(
                        f"""
                        SELECT id, task_id, original_filename, filename, uploaded_at
                        FROM task_work_files
                        WHERE task_id IN ({task_placeholders})
                        ORDER BY uploaded_at DESC, id DESC
                        """,
                        tuple(task_ids),
                    )
                    for row in task_cur.fetchall() or []:
                        tid = row.get('task_id')
                        gid = task_id_to_gid.get(tid)
                        if not gid:
                            continue
                        task_files_map.setdefault(gid, []).append({
                            'id': row.get('id'),
                            'filename': row.get('original_filename') or row.get('filename') or 'Upload',
                            'uploaded_at': row.get('uploaded_at'),
                            'download_url': f"/task/file/{row.get('id')}/download",
                            'source': 'task',
                        })
                    task_cur.execute(
                        f"""
                        SELECT id, task_id, original_filename, filename, uploaded_at
                        FROM task_manager_attachments
                        WHERE task_id IN ({task_placeholders})
                        ORDER BY uploaded_at DESC, id DESC
                        """,
                        tuple(task_ids),
                    )
                    for row in task_cur.fetchall() or []:
                        tid = row.get('task_id')
                        gid = task_id_to_gid.get(tid)
                        if not gid:
                            continue
                        task_files_map.setdefault(gid, []).append({
                            'id': row.get('id'),
                            'filename': row.get('original_filename') or row.get('filename') or 'File',
                            'uploaded_at': row.get('uploaded_at'),
                            'download_url': f"/task/manager-file/{row.get('id')}/download",
                            'source': 'manager',
                        })
            finally:
                try:
                    task_cur.close()
                except Exception:
                    pass
    except Exception:
        task_files_map = {}
        checklist_map = {}

    def _table_exists(cur, name: str) -> bool:
        try:
            cur.execute(
                "SELECT 1 FROM information_schema.tables WHERE table_schema = DATABASE() AND table_name = %s",
                (name,),
            )
            return cur.fetchone() is not None
        except Exception:
            return False

    def _table_columns(cur, name: str) -> list[str]:
        try:
            cur.execute(f"SHOW COLUMNS FROM `{name}`")
            rows = cur.fetchall() or []
            return [r.get('Field') or r.get('field') or r[0] for r in rows]
        except Exception:
            return []

    def _pick_col(cols: set[str], candidates: list[str]) -> str | None:
        for c in candidates:
            if c in cols:
                return c
        return None

    def _load_extra_docs(table_name: str, source_label: str):
        try:
            extra_cur = mysql.connection.cursor(DictCursor)
            if not _table_exists(extra_cur, table_name):
                extra_cur.close()
                return
            cols = set([c.lower() for c in _table_columns(extra_cur, table_name)])
            if not cols:
                extra_cur.close()
                return
            g_col = _pick_col(cols, ['g_id', 'gid'])
            bid_col = _pick_col(cols, ['bid_id', 'bidid', 'bid'])
            name_col = _pick_col(cols, ['original_filename', 'filename', 'file_name', 'name', 'doc_name', 'title'])
            url_col = _pick_col(cols, ['download_url', 'file_url', 'web_url', 'url', 'link', 'share_url'])
            path_col = _pick_col(cols, ['file_path', 'path', 'local_path'])
            uploaded_col = _pick_col(cols, ['uploaded_at', 'created_at', 'updated_at', 'modified_at'])
            id_col = _pick_col(cols, ['id'])
            if not url_col:
                for c in cols:
                    if 'url' in c:
                        url_col = c
                        break
            if not name_col:
                for c in cols:
                    if 'name' in c:
                        name_col = c
                        break
            if not g_col and not bid_col:
                extra_cur.close()
                return

            def _select_cols():
                parts = []
                if id_col:
                    parts.append(f"{id_col} AS id")
                if g_col:
                    parts.append(f"{g_col} AS g_id")
                if bid_col:
                    parts.append(f"{bid_col} AS bid_id")
                if name_col:
                    parts.append(f"{name_col} AS filename")
                if url_col:
                    parts.append(f"{url_col} AS url")
                if path_col:
                    parts.append(f"{path_col} AS file_path")
                if uploaded_col:
                    parts.append(f"{uploaded_col} AS uploaded_at")
                if not parts:
                    parts.append("*")
                return ", ".join(parts)

            select_cols = _select_cols()
            if g_col and g_ids:
                placeholders = ",".join(["%s"] * len(g_ids))
                extra_cur.execute(
                    f"SELECT {select_cols} FROM `{table_name}` WHERE {g_col} IN ({placeholders})",
                    tuple(g_ids),
                )
            elif bid_col:
                bid_id_to_gid = {}
                for rr in (rows or []):
                    bid_id = rr.get('bid_id') or rr.get('id')
                    gid = rr.get('g_id')
                    if bid_id and gid:
                        bid_id_to_gid[int(bid_id)] = int(gid)
                bid_ids = list(bid_id_to_gid.keys())
                if not bid_ids:
                    extra_cur.close()
                    return
                placeholders = ",".join(["%s"] * len(bid_ids))
                extra_cur.execute(
                    f"SELECT {select_cols} FROM `{table_name}` WHERE {bid_col} IN ({placeholders})",
                    tuple(bid_ids),
                )
            else:
                extra_cur.close()
                return

            for row in extra_cur.fetchall() or []:
                gid_val = row.get('g_id') or (row.get('bid_id') and bid_id_to_gid.get(int(row.get('bid_id'))))
                if not gid_val:
                    continue
                url = row.get('url') or ''
                if not url and row.get('file_path'):
                    url = row.get('file_path')
                    if url and not str(url).startswith(('http://', 'https://', '/')):
                        url = '/' + str(url)
                if not url:
                    continue
                rfp_files_map.setdefault(gid_val, []).append({
                    'id': row.get('id'),
                    'filename': row.get('filename') or 'Document',
                    'uploaded_at': row.get('uploaded_at'),
                    'download_url': url,
                    'source': source_label,
                })
        except Exception:
            pass
        finally:
            try:
                extra_cur.close()
            except Exception:
                pass

    # Extra document sources requested by PM view.
    _load_extra_docs('uploaded_rfps', 'rfp')
    # OneDrive folder state: attach folder path as a document entry.
    try:
        od_cur = mysql.connection.cursor(DictCursor)
        try:
            if _table_exists(od_cur, 'onedrive_folder_state'):
                # Map bid_incoming_id -> g_id via bid_id_to_gid
                bid_id_to_gid = {}
                for rr in (rows or []):
                    bid_id = rr.get('bid_id') or rr.get('id')
                    gid = rr.get('g_id')
                    if bid_id and gid:
                        bid_id_to_gid[int(bid_id)] = int(gid)
                bid_ids = list(bid_id_to_gid.keys())
                if bid_ids:
                    placeholders = ",".join(["%s"] * len(bid_ids))
                    od_cur.execute(
                        f"""
                        SELECT id, folder_path, folder_label, last_scan_at, last_eval_at, created_at, bid_incoming_id
                        FROM onedrive_folder_state
                        WHERE bid_incoming_id IN ({placeholders})
                        ORDER BY last_scan_at DESC, id DESC
                        """,
                        tuple(bid_ids),
                    )
                    for row in (od_cur.fetchall() or []):
                        bid_id = row.get('bid_incoming_id')
                        gid = bid_id_to_gid.get(int(bid_id)) if bid_id else None
                        if not gid:
                            continue
                        folder_path = (row.get('folder_path') or '').strip()
                        if not folder_path:
                            continue
                        rfp_files_map.setdefault(gid, []).append({
                            'id': row.get('id'),
                            'filename': row.get('folder_label') or 'OneDrive Folder',
                            'uploaded_at': row.get('last_scan_at') or row.get('created_at') or '',
                            'download_url': folder_path,
                            'source': 'onedrive',
                        })
        finally:
            try:
                od_cur.close()
            except Exception:
                pass
    except Exception:
        pass

    items = []
    update_cur = mysql.connection.cursor(DictCursor)
    updated_any = False
    for r in rows:
        try:
            meta = json.loads(r.get('meta_json') or "{}")
        except Exception:
            meta = {}
        try:
            if not r.get('g_id'):
                continue
        except Exception:
            continue
        scope_text = (r.get('scope') or meta.get('scope') or meta.get('scope_of_work') or meta.get('scope_of_work_text') or '').strip()
        type_text = (r.get('type') or meta.get('type') or '').strip()
        try:
            ik_code = _ensure_ik_project_code(update_cur, int(r.get('g_id')), meta, scope_text, type_text)
            if ik_code:
                updated_any = True
        except Exception:
            ik_code = meta.get('ik_project_code') or ''

        meta_files = []
        try:
            raw_files = meta.get('uploaded_files') or []
            if isinstance(raw_files, list):
                for f in raw_files:
                    if not isinstance(f, dict):
                        continue
                    url = (f.get('url') or f.get('download_url') or '').strip()
                    name = (f.get('name') or f.get('filename') or 'Document').strip()
                    uploaded_at = f.get('uploaded_at') or ''
                    if url or name:
                        meta_files.append({
                            'id': f.get('id'),
                            'filename': name or 'Document',
                            'uploaded_at': uploaded_at,
                            'download_url': url,
                            'source': 'bid',
                        })
        except Exception:
            meta_files = []

        summary_text = (
            r.get('bid_summary')
            or r.get('summary')
            or meta.get('summary')
            or meta.get('summary_text')
            or meta.get('executive_summary')
            or ''
        ).strip()
        if not summary_text:
            summary_text = scope_text or ''

        merged_rfp_files = []
        try:
            if meta_files:
                merged_rfp_files.extend(meta_files)
            extra_files = rfp_files_map.get(r.get('g_id'), [])
            if extra_files:
                merged_rfp_files.extend(extra_files)
        except Exception:
            merged_rfp_files = meta_files or rfp_files_map.get(r.get('g_id'), [])

        meta_checklist = meta.get('checklist') or []
        for mt in meta_checklist:
            if isinstance(mt, dict):
                mt['status'] = normalize_task_status(mt.get('status') or mt.get('state') or '')
        g_key = int(r.get('g_id')) if str(r.get('g_id')).isdigit() else r.get('g_id')
        items.append({
            'g_id': r.get('g_id'),
            'bid_id': r.get('bid_id') or r.get('id'),
            'name': r.get('b_name') or meta.get('name') or 'Bid',
            'company': r.get('company') or r.get('comp_name') or '',
            'state': r.get('bid_state') or r.get('state') or '',
            'due_date': r.get('due_date') or '',
            'scope': scope_text,
            'type': type_text,
            'summary': summary_text,
            'ik_project_code': ik_code or meta.get('ik_project_code') or '',
            'departments': meta.get('departments') or [],
            'start_date': meta.get('start_date') or '',
            'assign_due_date': meta.get('due_date') or '',
            'notes': meta.get('notes') or '',
            'project_activity': meta.get('project_activity') or [],
            'progress': meta.get('progress') or '',
            'priority': meta.get('priority') or '',
            'checklist': checklist_map.get(g_key) or meta_checklist,
            'rfp_files': merged_rfp_files,
            'task_files': task_files_map.get(g_key, []) or task_files_map.get(r.get('g_id'), []),
        })
    if updated_any:
        try:
            mysql.connection.commit()
        except Exception:
            mysql.connection.rollback()
    try:
        update_cur.close()
    except Exception:
        pass
    return items

def _load_assigned_tasks_for_team_lead(dept_key: str, team_lead_email: str, limit: int = 200):
    _ensure_bid_assign_meta_table()
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute(
            """
            SELECT gb.*, bi.id AS bid_id, bi.state AS bid_state, bi.summary AS bid_summary, bam.data AS meta_json
            FROM bid_assign_meta bam
            LEFT JOIN go_bids gb ON gb.g_id = bam.g_id
            LEFT JOIN bid_incoming bi ON bi.id = gb.id
            ORDER BY bam.updated_at DESC, bam.g_id DESC
            LIMIT %s
            """,
            (limit,),
        )
        rows = cur.fetchall() or []
    finally:
        try:
            cur.close()
        except Exception:
            pass

    # Map bid ids that have tasks assigned to this team lead (separate from employees)
    assigned_bid_ids = set()
    team_lead_user_id = None
    try:
        cur = mysql.connection.cursor(DictCursor)
        cur.execute("SELECT id FROM users WHERE LOWER(email)=LOWER(%s) LIMIT 1", (team_lead_email,))
        row = cur.fetchone() or {}
        if row.get('id'):
            team_lead_user_id = int(row.get('id'))
    except Exception:
        team_lead_user_id = None
    finally:
        try:
            cur.close()
        except Exception:
            pass

    if team_lead_user_id:
        try:
            cur = mysql.connection.cursor(DictCursor)
            _ensure_task_team_lead_assignments_table(cur)
            g_ids = [r.get('g_id') for r in rows if r.get('g_id')]
            if g_ids:
                placeholders = ",".join(["%s"] * len(g_ids))
                cur.execute(
                    f"""
                    SELECT DISTINCT bc.g_id
                    FROM task_team_lead_assignments tta
                    JOIN bid_checklists bc ON bc.id = tta.task_id
                    WHERE tta.team_lead_user_id = %s
                      AND bc.g_id IN ({placeholders})
                      AND (LOWER(COALESCE(bc.stage,'')) = LOWER(%s) OR LOWER(COALESCE(bc.department,'')) = LOWER(%s))
                    """,
                    tuple([team_lead_user_id, *g_ids, dept_key, dept_key]),
                )
                for r in (cur.fetchall() or []):
                    if r.get('g_id'):
                        assigned_bid_ids.add(int(r.get('g_id')))
        except Exception:
            assigned_bid_ids = set()
        finally:
            try:
                cur.close()
            except Exception:
                pass

    rfp_files_map = {}
    try:
        g_ids = [r.get('g_id') for r in rows if r.get('g_id')]
        if g_ids:
            rfp_cur = mysql.connection.cursor(DictCursor)
            try:
                _ensure_uploaded_rfp_table_exists(rfp_cur)
                placeholders = ",".join(["%s"] * len(g_ids))
                rfp_cur.execute(
                    f"""
                    SELECT id, g_id, original_filename, filename, uploaded_at
                    FROM uploaded_rfp_files
                    WHERE g_id IN ({placeholders})
                    ORDER BY uploaded_at DESC, id DESC
                    """,
                    tuple(g_ids),
                )
                for row in rfp_cur.fetchall() or []:
                    g_id = row.get('g_id')
                    if not g_id:
                        continue
                    rfp_files_map.setdefault(g_id, []).append({
                        'id': row.get('id'),
                        'filename': row.get('original_filename') or row.get('filename') or 'Document',
                        'uploaded_at': row.get('uploaded_at'),
                    })
            finally:
                try:
                    rfp_cur.close()
                except Exception:
                    pass
    except Exception:
        rfp_files_map = {}

    task_files_map = {}
    try:
        g_ids = [r.get('g_id') for r in rows if r.get('g_id')]
        if g_ids:
            task_cur = mysql.connection.cursor(DictCursor)
            try:
                placeholders = ",".join(["%s"] * len(g_ids))
                task_cur.execute(
                    f"""
                    SELECT id, g_id
                    FROM bid_checklists
                    WHERE g_id IN ({placeholders})
                      AND team_archive IS NULL
                    """,
                    tuple(g_ids),
                )
                task_rows = task_cur.fetchall() or []
                task_ids = []
                task_id_to_gid = {}
                for row in task_rows:
                    tid = row.get('id')
                    gid = row.get('g_id')
                    if not tid or not gid:
                        continue
                    task_ids.append(tid)
                    task_id_to_gid[tid] = gid
                if task_ids:
                    _ensure_task_work_files_table(task_cur)
                    _ensure_task_manager_attachments_table(task_cur)
                    task_placeholders = ",".join(["%s"] * len(task_ids))
                    task_cur.execute(
                        f"""
                        SELECT id, task_id, original_filename, filename, uploaded_at
                        FROM task_work_files
                        WHERE task_id IN ({task_placeholders})
                        ORDER BY uploaded_at DESC, id DESC
                        """,
                        tuple(task_ids),
                    )
                    for row in task_cur.fetchall() or []:
                        tid = row.get('task_id')
                        gid = task_id_to_gid.get(tid)
                        if not gid:
                            continue
                        task_files_map.setdefault(gid, []).append({
                            'id': row.get('id'),
                            'filename': row.get('original_filename') or row.get('filename') or 'Upload',
                            'uploaded_at': row.get('uploaded_at'),
                            'download_url': f"/task/file/{row.get('id')}/download",
                            'source': 'task',
                        })
                    task_cur.execute(
                        f"""
                        SELECT id, task_id, original_filename, filename, uploaded_at
                        FROM task_manager_attachments
                        WHERE task_id IN ({task_placeholders})
                        ORDER BY uploaded_at DESC, id DESC
                        """,
                        tuple(task_ids),
                    )
                    for row in task_cur.fetchall() or []:
                        tid = row.get('task_id')
                        gid = task_id_to_gid.get(tid)
                        if not gid:
                            continue
                        task_files_map.setdefault(gid, []).append({
                            'id': row.get('id'),
                            'filename': row.get('original_filename') or row.get('filename') or 'File',
                            'uploaded_at': row.get('uploaded_at'),
                            'download_url': f"/task/manager-file/{row.get('id')}/download",
                            'source': 'manager',
                        })
            finally:
                try:
                    task_cur.close()
                except Exception:
                    pass
    except Exception:
        task_files_map = {}

    items = []
    update_cur = mysql.connection.cursor(DictCursor)
    updated_any = False
    for r in rows:
        try:
            meta = json.loads(r.get('meta_json') or "{}")
        except Exception:
            meta = {}
        try:
            if not r.get('g_id'):
                continue
        except Exception:
            continue
        scope_text = r.get('scope') or meta.get('scope') or ''
        type_text = r.get('type') or meta.get('type') or ''
        try:
            ik_code = _ensure_ik_project_code(update_cur, int(r.get('g_id')), meta, scope_text, type_text)
            if ik_code:
                updated_any = True
        except Exception:
            ik_code = meta.get('ik_project_code') or ''
        checklist = meta.get('checklist') or []
        dept_checklist = [
            c for c in checklist
            if (not c.get('dept') or c.get('dept') == dept_key)
        ]
        meta_files = []
        try:
            raw_files = meta.get('uploaded_files') or []
            if isinstance(raw_files, list):
                for f in raw_files:
                    if not isinstance(f, dict):
                        continue
                    url = (f.get('url') or f.get('download_url') or '').strip()
                    name = (f.get('name') or f.get('filename') or 'Document').strip()
                    uploaded_at = f.get('uploaded_at') or ''
                    if url or name:
                        meta_files.append({
                            'id': f.get('id'),
                            'filename': name or 'Document',
                            'uploaded_at': uploaded_at,
                            'download_url': url,
                            'source': 'bid',
                        })
        except Exception:
            meta_files = []
        has_assigned = bool(r.get('g_id') and int(r.get('g_id')) in assigned_bid_ids)
        if not dept_checklist and not has_assigned:
            continue
        items.append({
              'g_id': r.get('g_id'),
              'bid_id': r.get('bid_id') or r.get('id'),
              'name': r.get('b_name') or meta.get('name') or 'Bid',
              'company': r.get('company') or r.get('comp_name') or '',
              'state': r.get('bid_state') or r.get('state') or '',
              'due_date': r.get('due_date') or '',
              'scope': scope_text,
              'type': type_text,
              'summary': r.get('bid_summary') or r.get('summary') or meta.get('summary') or '',
              'ik_project_code': ik_code or meta.get('ik_project_code') or '',
              'departments': meta.get('departments') or [],
              'start_date': meta.get('start_date') or '',
              'assign_due_date': meta.get('due_date') or '',
              'notes': meta.get('notes') or '',
              'project_activity': meta.get('project_activity') or [],
            'progress': meta.get('progress') or '',
            'priority': meta.get('priority') or '',
            'checklist': dept_checklist,
            'rfp_files': meta_files or rfp_files_map.get(r.get('g_id'), []),
            'task_files': task_files_map.get(r.get('g_id'), []),
        })
    if updated_any:
        try:
            mysql.connection.commit()
        except Exception:
            mysql.connection.rollback()
    try:
        update_cur.close()
    except Exception:
        pass
    return items


def _load_project_timeline_items_for_manager(user_id: int, limit: int = 200):
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_project_manager_assignments_table(cur)
        cur.execute(
            """
            SELECT DISTINCT pma.project_id, pma.g_id
            FROM project_manager_assignments pma
            LEFT JOIN win_lost_results wlr ON wlr.w_id = pma.project_id
            WHERE pma.manager_user_id=%s
              AND (
                LOWER(COALESCE(wlr.status,'')) LIKE '%%won%%'
                OR LOWER(COALESCE(wlr.result,'')) LIKE '%%won%%'
                OR LOWER(COALESCE(wlr.result,'')) LIKE '%%award%%'
              )
            ORDER BY assigned_at DESC
            LIMIT %s
            """,
            (int(user_id), int(limit)),
        )
        rows = cur.fetchall() or []
    except Exception:
        rows = []
    finally:
        try:
            cur.close()
        except Exception:
            pass

    if not rows:
        return []

    project_ids = [int(r.get('project_id')) for r in rows if r.get('project_id')]
    g_id_map = {int(r.get('project_id')): r.get('g_id') for r in rows if r.get('project_id')}

    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_project_timeline_tables(cur)
        items = []
        for project_id in project_ids:
            try:
                _seed_project_timeline(cur, int(project_id), ['Engineering Team', 'Procurement Team', 'Accounts & Finance Team'])
            except Exception:
                pass

            cur.execute(
                """
                SELECT id, stage_name, stage_order
                FROM project_timeline_stages
                WHERE project_id=%s
                ORDER BY stage_order ASC, id ASC
                """,
                (project_id,),
            )
            stage_rows = cur.fetchall() or []
            stage_ids = [sr.get('id') for sr in stage_rows if sr.get('id') is not None]
            progress_map = {}
            if stage_ids:
                in_clause = ','.join(['%s'] * len(stage_ids))
                cur.execute(
                    f"""
                    SELECT stage_id, progress_pct
                    FROM project_timeline_progress
                    WHERE project_id=%s AND stage_id IN ({in_clause})
                    """,
                    tuple([project_id] + stage_ids),
                )
                for pr in (cur.fetchall() or []):
                    progress_map[int(pr.get('stage_id'))] = int(pr.get('progress_pct') or 0)

            b_name = f"Project #{project_id}"
            company = ''
            g_id = g_id_map.get(int(project_id))
            try:
                cur.execute(
                    "SELECT b_name, company, g_id FROM win_lost_results WHERE w_id=%s",
                    (project_id,),
                )
                row = cur.fetchone() or {}
                if row.get('b_name'):
                    b_name = row.get('b_name')
                if row.get('company'):
                    company = row.get('company')
                if row.get('g_id') and not g_id:
                    g_id = row.get('g_id')
            except Exception:
                pass

            checklist_progress = {}
            if g_id:
                try:
                    checklist_progress = _compute_checklist_stage_progress(cur, int(g_id))
                except Exception:
                    checklist_progress = {}

            cur.execute(
                "SELECT stage_id FROM project_timeline_current WHERE project_id=%s",
                (project_id,),
            )
            current_row = cur.fetchone() or {}
            current_stage_id = current_row.get('stage_id')
            if not current_stage_id and stage_rows:
                current_stage_id = stage_rows[0].get('id')

            stages = []
            current_index = 0
            for idx, sr in enumerate(stage_rows):
                sid = sr.get('id')
                if sid == current_stage_id:
                    current_index = idx
                stage_name = sr.get('stage_name') or ''
                stage_key = _normalize_department_key(stage_name) or stage_name.lower().replace(' ', '_')
                computed_pct = checklist_progress.get(stage_key)
                stages.append({
                    'id': sid,
                    'name': stage_name,
                    'order': int(sr.get('stage_order') or 0),
                    'progress': int(computed_pct if computed_pct is not None else progress_map.get(int(sid), 0)) if sid is not None else 0,
                })

            items.append({
                'project_id': project_id,
                'g_id': g_id,
                'b_name': b_name,
                'company': company,
                'current_stage_id': current_stage_id,
                'current_stage_index': current_index,
                'stages': stages,
            })
        return items
    except Exception:
        return []
    finally:
        try:
            cur.close()
        except Exception:
            pass

def _load_assigned_tasks_for_employee(dept_key: str, employee_id: int | None, limit: int = 200):
    if not employee_id:
        return []
    dept_key_norm = _normalize_department_key(dept_key or '') or (dept_key or '').strip().lower()
    items = _load_assigned_tasks_for_department(dept_key_norm or dept_key, limit)
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute(
            """
            SELECT DISTINCT g_id
            FROM bid_checklists
            WHERE assigned_to = %s
            """,
            (int(employee_id),),
        )
        g_ids = {int(r.get('g_id')) for r in (cur.fetchall() or []) if r.get('g_id')}
    except Exception:
        g_ids = set()
    finally:
        try:
            cur.close()
        except Exception:
            pass
    if not g_ids:
        return []
    filtered = [it for it in (items or []) if it.get('g_id') in g_ids]
    if filtered:
        return filtered

    # Fallback: build minimal items directly from go_bids/bid_incoming when bid_assign_meta is empty.
    try:
        cur = mysql.connection.cursor(DictCursor)
        placeholders = ",".join(["%s"] * len(g_ids))
        cur.execute(
            f"""
            SELECT gb.g_id,
                   gb.b_name,
                   gb.company,
                   gb.state,
                   gb.due_date,
                   gb.summary,
                   gb.type,
                   gb.id AS incoming_id,
                   bi.id AS bid_id,
                   bi.b_name AS bi_name,
                   bi.comp_name,
                   bi.state AS bi_state,
                   bi.summary AS bi_summary,
                   bi.type AS bi_type,
                   bi.scope AS bi_scope
            FROM go_bids gb
            LEFT JOIN bid_incoming bi ON bi.id = gb.id
            WHERE gb.g_id IN ({placeholders})
            """,
            tuple(g_ids),
        )
        rows = cur.fetchall() or []
    except Exception:
        rows = []
    finally:
        try:
            cur.close()
        except Exception:
            pass

    items = []
    update_cur = mysql.connection.cursor(DictCursor)
    updated_any = False
    for r in rows:
        scope_text = r.get('bi_scope') or ''
        type_text = r.get('type') or r.get('bi_type') or ''
        try:
            meta = {}
            ik_code = _ensure_ik_project_code(update_cur, int(r.get('g_id') or 0), meta, scope_text, type_text)
            if ik_code:
                updated_any = True
        except Exception:
            ik_code = ''
        items.append({
            'g_id': r.get('g_id'),
            'bid_id': r.get('bid_id') or r.get('incoming_id'),
            'name': r.get('b_name') or r.get('bi_name') or 'Bid',
            'company': r.get('company') or r.get('comp_name') or '',
            'state': r.get('state') or r.get('bi_state') or '',
            'summary': r.get('summary') or r.get('bi_summary') or '',
            'scope': r.get('bi_scope') or '',
            'type': r.get('type') or r.get('bi_type') or '',
            'priority': 'normal',
            'ik_project_code': ik_code or '',
            'project_activity': [],
            'rfp_files': [],
            'task_files': [],
        })
    if updated_any:
        try:
            mysql.connection.commit()
        except Exception:
            mysql.connection.rollback()
    try:
        update_cur.close()
    except Exception:
        pass
    return items


def _render_employee_assigned_tasks(dept_key: str, employee_id: int | None, title: str):
    is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
    if is_flask_user:
        if not getattr(current_user, 'is_admin', False) and not check_module_access_db('assigned_tasks'):
            return render_template('access_denied.html', message="You don't have access to Assigned Tasks."), 403
    else:
        session_emp_id = session.get('employee_id')
        if not session_emp_id or (employee_id and int(session_emp_id) != int(employee_id)):
            return render_template('access_denied.html', message="You don't have access to Assigned Tasks."), 403
    items = _load_assigned_tasks_for_employee(dept_key, employee_id)
    employee_email = ''
    employee_name = ''
    try:
        if employee_id:
            cur = mysql.connection.cursor(DictCursor)
            cur.execute("SELECT email, name FROM employees WHERE id=%s LIMIT 1", (int(employee_id),))
            row = cur.fetchone() or {}
            employee_email = (row.get('email') or '').strip()
            employee_name = (row.get('name') or '').strip()
            cur.close()
    except Exception:
        employee_email = ''
        employee_name = ''
    try:
        dept_keys = ['engineering_team', 'procurement_team', 'accounts_finance', 'business', 'design', 'operations', 'engineer']
        dept_metrics = {}
        for k in dept_keys:
            try:
                lst = _load_assigned_tasks_for_employee(k, employee_id)
                dept_metrics[k] = len(lst or [])
            except Exception:
                dept_metrics[k] = 0
        total_assigned = sum(dept_metrics.values())
    except Exception:
        dept_metrics = {'business': 0, 'design': 0, 'operations': 0, 'engineer': 0}
        total_assigned = len(items or [])

    try:
        cur = mysql.connection.cursor(DictCursor)
        cur.execute(
            """
            SELECT g_id, status
            FROM bid_checklists
            WHERE assigned_to = %s
              AND (%s = '' OR LOWER(COALESCE(stage,'')) = %s)
            """,
            (int(employee_id or 0), dept_key or '', dept_key or ''),
        )
        task_rows = cur.fetchall() or []
        total_tasks = len(task_rows)
        pending_tasks = len([t for t in task_rows if (t.get('status') or '').lower() in ('pending', 'rejected')])
        in_progress_tasks = len([t for t in task_rows if (t.get('status') or '').lower() in ('in_progress', 'submitted')])
        completed_tasks = len([t for t in task_rows if (t.get('status') or '').lower() == 'completed'])
        total_bids = len({t.get('g_id') for t in task_rows if t.get('g_id')})
        approvals_pending = 0
        try:
            _ensure_document_approvals_table(cur)
            cur.execute(
                """
                SELECT COUNT(*) AS cnt
                FROM document_approvals da
                JOIN task_work_files twf ON da.source_table='task_work_files' AND da.source_id=twf.id
                WHERE twf.employee_id=%s AND da.status='pending'
                """,
                (int(employee_id or 0),),
            )
            approvals_pending += int((cur.fetchone() or {}).get('cnt') or 0)
            cur.execute(
                """
                SELECT COUNT(*) AS cnt
                FROM document_approvals da
                JOIN task_comments tc ON da.source_table='task_comments' AND da.source_id=tc.id
                WHERE tc.employee_id=%s AND da.status='pending'
                """,
                (int(employee_id or 0),),
            )
            approvals_pending += int((cur.fetchone() or {}).get('cnt') or 0)
        except Exception:
            approvals_pending = 0
    except Exception:
        total_bids = total_tasks = pending_tasks = in_progress_tasks = completed_tasks = approvals_pending = 0
    finally:
        try:
            cur.close()
        except Exception:
            pass

    kpis = {
        'total_bids': total_bids,
        'total_tasks': total_tasks,
        'pending_tasks': pending_tasks,
        'in_progress_tasks': in_progress_tasks,
        'completed_tasks': completed_tasks,
        'overdue_tasks': 0,
        'today_bids': 0,
        'today_due_tasks': 0,
        'unassigned_tasks': 0,
        'uploaded_files': 0,
        'approvals_pending': approvals_pending,
    }

    return render_template(
        'assigned_tasks.html',
        title=title,
        dept_key=dept_key,
        items=items,
        user={'email': employee_email, 'name': employee_name},
        user_role='employee',
        is_team_lead_view=False,
        is_employee_view=True,
        sidebar_mode='employee',
        team=dept_key,
        dept_metrics=dept_metrics,
        total_assigned=total_assigned,
        kpis=kpis,
        assigned_tasks_base_url=None,
        allowed_dept_keys=[dept_key],
        employee_id=employee_id,
    )

def _team_key_from_access(dept_key: str | None) -> str | None:
    d = (dept_key or '').strip().lower().replace(' ', '_')
    if not d:
        return None
    if d in ['business', 'business_dev', 'business_development']:
        return 'business'
    if d in ['design', 'marketing']:
        return 'design'
    if d in ['operations', 'operation', 'ops']:
        return 'operations'
    if d in ['site_engineer', 'site_engineering', 'engineer', 'engineering']:
        return 'engineer'
    if d in ['engineering_team', 'engineering team']:
        return 'engineering_team'
    if d in ['procurement_team', 'procurement team']:
        return 'procurement_team'
    if d in ['accounts_finance', 'accounts & finance team', 'accounts finance', 'accounts team', 'finance team']:
        return 'accounts_finance'
    return None


def _render_assigned_tasks(
    dept_key: str,
    template_name: str,
    title: str,
    sidebar_mode: str | None = None,
    assigned_tasks_base_url_override: str | None = None,
):
    if not current_user.is_admin and not check_module_access_db('assigned_tasks'):
        return render_template('access_denied.html', message="You don't have access to Assigned Tasks."), 403
    items = _load_assigned_tasks_for_department(dept_key)
    role_raw = (getattr(current_user, 'role', '') or '').strip().lower().replace('_', ' ')
    role_compact = role_raw.replace(' ', '')
    admin_like = bool(
        getattr(current_user, 'is_admin', False)
        or getattr(current_user, 'is_supervisor', False)
        or role_compact in ('itadmin', 'topleveladmin', 'supervisor')
    )
    allowed_dept_keys = []
    if admin_like:
        allowed_dept_keys = ['engineering_team', 'procurement_team', 'accounts_finance', 'business', 'design', 'operations', 'engineer']
    else:
        dept_role_map = {
            'business manager': 'business',
            'design manager': 'design',
            'operation manager': 'operations',
            'operations manager': 'operations',
            'site manager': 'engineer',
            'engineer': 'engineer',
            'engineering manager': 'engineering_team',
            'procurement manager': 'procurement_team',
            'accounts manager': 'accounts_finance',
            'finance manager': 'accounts_finance',
        }
        if role_raw in dept_role_map:
            allowed_dept_keys = [dept_role_map[role_raw]]
        elif role_compact == 'manager':
            access_rows = _fetch_user_access_rows(int(current_user.id))
            try:
                active_cid = session.get('active_company_id')
            except Exception:
                active_cid = None
            mgr_rows = []
            for r in (access_rows or []):
                if (r.get('role') or '').strip().lower() != 'manager':
                    continue
                if active_cid and int(r.get('company_id') or 0) != int(active_cid):
                    continue
                mgr_rows.append(r)

            if any(r.get('department_key') in [None, '', 'null'] for r in mgr_rows):
                allowed_dept_keys = ['business', 'design', 'operations', 'engineer']
            else:
                allowed = {_team_key_from_access(r.get('department_key')) for r in mgr_rows}
                allowed_dept_keys = [k for k in allowed if k]

            if not allowed_dept_keys:
                allowed_dept_keys = ['business', 'design', 'operations', 'engineer']
        else:
            allowed_dept_keys = [dept_key]

    can_switch_dept = bool(len(allowed_dept_keys) > 1)
    if assigned_tasks_base_url_override:
        assigned_tasks_base_url = assigned_tasks_base_url_override if can_switch_dept else None
    else:
        assigned_tasks_base_url = url_for('manager_assigned_tasks') if can_switch_dept else None

    # Compute simple department metrics (counts of assigned bids per department)
    try:
        dept_keys = ['business', 'design', 'operations', 'engineer']
        dept_metrics = {}
        for k in dept_keys:
            try:
                lst = _load_assigned_tasks_for_department(k)
                dept_metrics[k] = len(lst or [])
            except Exception:
                dept_metrics[k] = 0
        total_assigned = sum(dept_metrics.values())
    except Exception:
        dept_metrics = {'business': 0, 'design': 0, 'operations': 0, 'engineer': 0}
        total_assigned = len(items or [])

    # Compute KPIs across the returned items
    try:
        today = datetime.utcnow().date()
        total_bids = len(items or [])
        total_tasks = 0
        pending_tasks = 0
        in_progress_tasks = 0
        completed_tasks = 0
        overdue_tasks = 0
        today_bids = 0
        today_due_tasks = 0
        unassigned_tasks = 0
        uploaded_files = 0
        approvals_pending = 0

        def _parse_date(dval):
            if not dval:
                return None
            try:
                s = str(dval).strip()
                s = s[:10]
                parts = s.split('-')
                if len(parts) == 3:
                    y, m, d = parts
                    return date(int(y), int(m), int(d))
            except Exception:
                return None
            return None

        for it in (items or []):
            checklist = it.get('checklist') or []
            total_tasks += len(checklist)
            uploaded_files += len(it.get('task_files') or [])
            # consider a bid as 'today' when its assign_due_date or start_date falls today
            bid_date = _parse_date(it.get('assign_due_date') or it.get('start_date') or it.get('due_date'))
            if bid_date == today:
                today_bids += 1
            for t in checklist:
                status = (t.get('status') or t.get('state') or t.get('progress') or '').strip().lower()
                due = _parse_date(t.get('due_date') or t.get('assign_due_date') or '')
                if status in ('done', 'completed', 'submitted'):
                    completed_tasks += 1
                elif status in ('in_progress', 'in progress'):
                    in_progress_tasks += 1
                else:
                    pending_tasks += 1
                if due and due < today:
                    overdue_tasks += 1
                if due and due == today:
                    today_due_tasks += 1
                has_assignees = bool(t.get('assignees'))
                has_direct_assignee = bool(t.get('assigned_to') or t.get('assigned_to_id') or t.get('assigned_employee_name') or t.get('employee_email'))
                has_team_lead = bool((t.get('team_lead') or '').strip())
                if not (has_assignees or has_direct_assignee or has_team_lead):
                    unassigned_tasks += 1
                if t.get('attachment') or t.get('attachment_url'):
                    uploaded_files += 1

        try:
            role_key = (getattr(current_user, 'role', '') or '').strip().lower().replace('_', ' ')
            role_key_compact = role_key.replace(' ', '')
            if getattr(current_user, 'is_admin', False) or getattr(current_user, 'is_supervisor', False) or role_key_compact in ('itadmin', 'topleveladmin', 'supervisor'):
                approval_target = 'admin'
            else:
                approval_target = 'manager'
            cur = mysql.connection.cursor(DictCursor)
            try:
                approvals = _collect_approval_items(cur, department_key=dept_key, approval_target=approval_target, limit=500)
            finally:
                try:
                    cur.close()
                except Exception:
                    pass
            approvals_pending = len([a for a in (approvals or []) if (a.get('status') or '').strip().lower() == 'pending'])
        except Exception:
            approvals_pending = 0

        kpis = {
            'total_bids': total_bids,
            'total_tasks': total_tasks,
            'pending_tasks': pending_tasks,
            'in_progress_tasks': in_progress_tasks,
            'completed_tasks': completed_tasks,
            'overdue_tasks': overdue_tasks,
            'today_bids': today_bids,
            'today_due_tasks': today_due_tasks,
            'unassigned_tasks': unassigned_tasks,
            'uploaded_files': uploaded_files,
            'approvals_pending': approvals_pending,
        }
    except Exception:
        kpis = {
            'total_bids': 0,
            'total_tasks': 0,
            'pending_tasks': 0,
            'in_progress_tasks': 0,
            'completed_tasks': 0,
            'overdue_tasks': 0,
            'today_bids': 0,
            'today_due_tasks': 0,
            'unassigned_tasks': 0,
            'uploaded_files': 0,
            'approvals_pending': 0,
        }

    return render_template(
        template_name,
        title=title,
        dept_key=dept_key,
        items=items,
        user=current_user,
        user_role=getattr(current_user, 'role', ''),
        is_team_lead_view=False,
        is_employee_view=False,
        sidebar_mode=sidebar_mode,
        team=dept_key,
        dept_metrics=dept_metrics,
        total_assigned=total_assigned,
        kpis=kpis,
        assigned_tasks_base_url=assigned_tasks_base_url,
        allowed_dept_keys=allowed_dept_keys,
    )


def _render_team_lead_assigned_tasks(dept_key: str, template_name: str, title: str):
    if not current_user.is_admin and not check_module_access_db('assigned_tasks'):
        return render_template('access_denied.html', message="You don't have access to Assigned Tasks."), 403
    email = (getattr(current_user, 'email', '') or '').strip()
    items = _load_assigned_tasks_for_team_lead(dept_key, email)
    # Compute department metrics as well for consistent template variables
    try:
        dept_keys = ['business', 'design', 'operations', 'engineer']
        dept_metrics = {}
        for k in dept_keys:
            try:
                lst = _load_assigned_tasks_for_department(k)
                dept_metrics[k] = len(lst or [])
            except Exception:
                dept_metrics[k] = 0
        total_assigned = sum(dept_metrics.values())
    except Exception:
        dept_metrics = {'business': 0, 'design': 0, 'operations': 0, 'engineer': 0}
        total_assigned = len(items or [])

    # Compute same KPIs as manager view so template can render identical cards
    try:
        today = datetime.utcnow().date()
        total_bids = len(items or [])
        total_tasks = 0
        pending_tasks = 0
        in_progress_tasks = 0
        completed_tasks = 0
        overdue_tasks = 0
        today_bids = 0
        today_due_tasks = 0
        unassigned_tasks = 0
        uploaded_files = 0
        approvals_pending = 0

        def _parse_date(dval):
            if not dval:
                return None
            try:
                s = str(dval).strip()
                s = s[:10]
                parts = s.split('-')
                if len(parts) == 3:
                    y, m, d = parts
                    return date(int(y), int(m), int(d))
            except Exception:
                return None
            return None

        for it in (items or []):
            checklist = it.get('checklist') or []
            total_tasks += len(checklist)
            uploaded_files += len(it.get('task_files') or [])
            bid_date = _parse_date(it.get('assign_due_date') or it.get('start_date') or it.get('due_date'))
            if bid_date == today:
                today_bids += 1
            for t in checklist:
                status = (t.get('status') or t.get('state') or t.get('progress') or '').strip().lower()
                due = _parse_date(t.get('due_date') or t.get('assign_due_date') or '')
                if status in ('done', 'completed', 'submitted'):
                    completed_tasks += 1
                elif status in ('in_progress', 'in progress'):
                    in_progress_tasks += 1
                else:
                    pending_tasks += 1
                if due and due < today:
                    overdue_tasks += 1
                if due and due == today:
                    today_due_tasks += 1
                has_assignees = bool(t.get('assignees'))
                has_direct_assignee = bool(t.get('assigned_to') or t.get('assigned_to_id') or t.get('assigned_employee_name') or t.get('employee_email'))
                has_team_lead = bool((t.get('team_lead') or '').strip())
                if not (has_assignees or has_direct_assignee or has_team_lead):
                    unassigned_tasks += 1
                if t.get('attachment') or t.get('attachment_url'):
                    uploaded_files += 1

        try:
            cur = mysql.connection.cursor(DictCursor)
            try:
                approvals = _collect_approval_items(cur, department_key=dept_key, approval_target='team_lead', limit=500)
            finally:
                try:
                    cur.close()
                except Exception:
                    pass
            approvals_pending = len([a for a in (approvals or []) if (a.get('status') or '').strip().lower() == 'pending'])
        except Exception:
            approvals_pending = 0

        kpis = {
            'total_bids': total_bids,
            'total_tasks': total_tasks,
            'pending_tasks': pending_tasks,
            'in_progress_tasks': in_progress_tasks,
            'completed_tasks': completed_tasks,
            'overdue_tasks': overdue_tasks,
            'today_bids': today_bids,
            'today_due_tasks': today_due_tasks,
            'unassigned_tasks': unassigned_tasks,
            'uploaded_files': uploaded_files,
            'approvals_pending': approvals_pending,
        }
    except Exception:
        kpis = {
            'total_bids': 0,
            'total_tasks': 0,
            'pending_tasks': 0,
            'in_progress_tasks': 0,
            'completed_tasks': 0,
            'overdue_tasks': 0,
            'today_bids': 0,
            'today_due_tasks': 0,
            'unassigned_tasks': 0,
            'uploaded_files': 0,
            'approvals_pending': 0,
        }

    return render_template(
        template_name,
        title=title,
        dept_key=dept_key,
        items=items,
        user=current_user,
        user_role=getattr(current_user, 'role', ''),
        is_team_lead_view=True,
        is_employee_view=False,
        sidebar_mode='team_lead',
        team=dept_key,
        dept_metrics=dept_metrics,
        total_assigned=total_assigned,
        kpis=kpis,
    )


@app.route('/business-manager/assigned-tasks')
@login_required
def business_manager_assigned_tasks():
    denied = _require_business_manager_access(None)
    if denied:
        return denied
    return _render_assigned_tasks('business', 'assigned_tasks.html', 'Business Manager - Assigned Tasks')


@app.route('/design-manager/assigned-tasks')
@login_required
def design_manager_assigned_tasks():
    role_norm = (get_user_role() or '').lower().replace('_', ' ')
    if not (current_user.is_admin or current_user.is_supervisor or role_norm in ['manager', 'design manager', 'topleveladmin', 'itadmin']):
        return render_template('access_denied.html', message="You don't have access to Design Assigned Tasks."), 403
    return _render_assigned_tasks('design', 'assigned_tasks.html', 'Design Manager - Assigned Tasks')


@app.route('/operation-manager/assigned-tasks')
@login_required
def operation_manager_assigned_tasks():
    role_norm = (get_user_role() or '').lower().replace('_', ' ')
    if not (current_user.is_admin or current_user.is_supervisor or role_norm in ['manager', 'operations manager', 'operation manager', 'topleveladmin', 'itadmin']):
        return render_template('access_denied.html', message="You don't have access to Operations Assigned Tasks."), 403
    return _render_assigned_tasks('operations', 'assigned_tasks.html', 'Operations Manager - Assigned Tasks')


@app.route('/site-manager/assigned-tasks')
@login_required
def site_manager_assigned_tasks():
    role_norm = (get_user_role() or '').lower().replace('_', ' ')
    if not (current_user.is_admin or current_user.is_supervisor or role_norm in ['manager', 'site manager', 'engineer', 'topleveladmin', 'itadmin']):
        return render_template('access_denied.html', message="You don't have access to Site Assigned Tasks."), 403
    return _render_assigned_tasks('engineer', 'assigned_tasks.html', 'Site Manager - Assigned Tasks')


@app.route('/team-lead/<team>/assigned-tasks')
@login_required
def team_lead_assigned_tasks(team):
    team_key = (team or '').strip().lower()
    allowed_team_keys = ['business', 'design', 'operations', 'engineer', 'engineering_team', 'procurement_team', 'accounts_finance']
    if team_key not in allowed_team_keys:
        return render_template('access_denied.html', message="Invalid team."), 400
    role_norm = (get_user_role() or '').strip().lower().replace('_', ' ')
    if role_norm in ['manager', 'topleveladmin', 'itadmin'] or getattr(current_user, 'is_admin', False):
        return _render_team_lead_assigned_tasks(team_key, 'assigned_tasks.html', 'Team Lead - Assigned Tasks')
    # Allow role-access overrides (e.g., employee granted Team Lead modules)
    if check_module_access_db('team_lead_dashboard'):
        dept_key = None
        try:
            dept_key = session.get('active_department_key') or None
        except Exception:
            dept_key = None
        if not dept_key:
            try:
                cur = mysql.connection.cursor(DictCursor)
                cur.execute(
                    "SELECT department FROM employees WHERE LOWER(email)=LOWER(%s) LIMIT 1",
                    ((getattr(current_user, 'email', '') or '').strip(),),
                )
                row = cur.fetchone() or {}
                dept_key = row.get('department')
            except Exception:
                dept_key = None
            finally:
                try:
                    cur.close()
                except Exception:
                    pass
        mapped_key = _team_key_from_access(dept_key)
        if mapped_key == team_key:
            return _render_team_lead_assigned_tasks(team_key, 'assigned_tasks.html', 'Team Lead - Assigned Tasks')
        if mapped_key and mapped_key in allowed_team_keys:
            return redirect(url_for('team_lead_assigned_tasks', team=mapped_key))
    try:
        access_rows = _fetch_user_access_rows(int(current_user.id))
    except Exception:
        access_rows = []
    allowed = False
    for r in (access_rows or []):
        if (r.get('role') or '').strip().lower() != 'teamlead':
            continue
        mapped = _team_key_from_access(r.get('department_key'))
        if mapped == team_key:
            allowed = True
            break
        if mapped and mapped in allowed_team_keys:
            return redirect(url_for('team_lead_assigned_tasks', team=mapped))
    if not allowed:
        return render_template('access_denied.html', message="You don't have access to Team Lead Assigned Tasks."), 403
    return _render_team_lead_assigned_tasks(team_key, 'assigned_tasks.html', 'Team Lead - Assigned Tasks')

@app.route('/api/team/<team>/bids/<int:g_id>/tasks')
@login_required
def api_bid_tasks(team, g_id):
    """API endpoint to get tasks for a specific bid.

    Default behavior: return tasks for the requested `team` only (stage-based).
    For Business Manager (and admin/top-admin/supervisor), `?scope=all` returns tasks across ALL teams for the bid.
    """
    scope = (request.args.get('scope') or '').strip().lower()
    want_all = scope in ('all', '*')
    # Allow broader view for managers/admins
    try:
        role_raw = (getattr(current_user, 'role', '') or '').strip().lower().replace('_', ' ')
        is_top_admin = role_raw in ['top level admin']
        is_manager = role_raw in ['manager', 'project manager', 'business manager', 'design manager', 'operation manager', 'operations manager', 'site manager']
        can_view_all = bool(getattr(current_user, 'is_admin', False) or getattr(current_user, 'is_supervisor', False) or is_top_admin or is_manager)
    except Exception:
        can_view_all = False
    want_all = bool(want_all and can_view_all)

    cur = mysql.connection.cursor(DictCursor)
    
    # Allow access if bid is in this team OR there are tasks for this team's stage
    try:
        cur.execute("SELECT state FROM go_bids WHERE g_id = %s", (g_id,))
        bid = cur.fetchone()
    except Exception as e:
        if "Unknown column 'state'" in str(e):
            bid = {'state': team}
        else:
            raise

    # "All teams" view for managers: skip team-gating entirely, only filter by g_id.
    if want_all:
        try:
            for stage in ('business', 'design', 'operations', 'engineer'):
                _backfill_task_codes_for_stage(cur, stage)
            cur.execute(
                """
                SELECT bc.*, e.name as assigned_employee_name, e.email as employee_email, e.department
                FROM bid_checklists bc
                LEFT JOIN employees e ON bc.assigned_to = e.id
                WHERE bc.g_id = %s
                  AND bc.team_archive IS NULL
                ORDER BY
                    LOWER(COALESCE(bc.stage, '')) ASC,
                    bc.priority DESC,
                    bc.created_at ASC
                """,
                (g_id,),
            )
            tasks = cur.fetchall()
        except Exception:
            tasks = []
        try:
            _assign_missing_task_codes(cur, tasks)
            mysql.connection.commit()
        except Exception:
            mysql.connection.rollback()
        # Load related activity + files for each task (same as team-scoped view)
        task_ids = [t['id'] for t in tasks if t.get('id')]
        # Attach team lead assignments (no employee row required)
        try:
            _ensure_task_team_lead_assignments_table(cur)
            if task_ids:
                placeholders = ','.join(['%s'] * len(task_ids))
                cur.execute(
                    f"""
                    SELECT tta.task_id, u.email, COALESCE(u.full_name, u.email) AS name
                    FROM task_team_lead_assignments tta
                    JOIN users u ON u.id = tta.team_lead_user_id
                    WHERE tta.task_id IN ({placeholders})
                    """,
                    tuple(task_ids),
                )
                tl_map = {int(r.get('task_id')): r for r in (cur.fetchall() or []) if r.get('task_id')}
            else:
                tl_map = {}
            for t in tasks:
                tl = tl_map.get(int(t.get('id') or 0)) if t.get('id') else None
                if tl:
                    t['assigned_team_lead_email'] = tl.get('email') or ''
                    t['assigned_team_lead_name'] = tl.get('name') or ''
        except Exception:
            pass
        if task_ids:
            try:
                placeholders = ','.join(['%s'] * len(task_ids))
            except Exception:
                placeholders = ''
            # Load comments
            try:
                cur.execute(f"""
                    SELECT tc.*, e.name as employee_name, u.email as user_email, da.status as approval_status, da.decision_note as decision_note
                    FROM task_comments tc
                    LEFT JOIN employees e ON tc.employee_id = e.id
                    LEFT JOIN users u ON tc.user_id = u.id
                    LEFT JOIN document_approvals da ON da.source_table='task_comments' AND da.source_id=tc.id
                    WHERE tc.task_id IN ({placeholders})
                    ORDER BY tc.created_at DESC
                """, tuple(task_ids))
                all_comments = cur.fetchall()
                comments_map = {}
                for c in all_comments:
                    tid = c['task_id']
                    if tid not in comments_map:
                        comments_map[tid] = []
                    author = c.get('employee_name') or c.get('user_email') or 'User'
                    comments_map[tid].append({
                        'id': c['id'],
                        'comment': c['comment'],
                        'employee_name': author,
                        'created_at': c['created_at'].strftime('%Y-%m-%d %H:%M') if c.get('created_at') else '',
                        'approval_status': ((c.get('approval_status') or '').strip().lower() or None),
                        'approval_target': (c.get('approval_target') or 'admin'),
                        'needs_approval': bool(c.get('needs_approval')),
                        'decision_note': c.get('decision_note') or ''
                    })
                for t in tasks:
                    t['employee_comments'] = comments_map.get(t['id'], [])
            except Exception:
                for t in tasks:
                    t['employee_comments'] = []

            # Load uploaded work files
            try:
                cur.execute(f"""
                SELECT twf.*, e.name as employee_name, e.email as employee_email, da.status as approval_status, da.decision_note as decision_note
                FROM task_work_files twf
                LEFT JOIN employees e ON twf.employee_id = e.id
                LEFT JOIN document_approvals da ON da.source_table='task_work_files' AND da.source_id=twf.id
                WHERE twf.task_id IN ({placeholders})
                ORDER BY twf.uploaded_at DESC
            """, tuple(task_ids))
                all_files = cur.fetchall()
                files_map = {}
                for f in all_files:
                    tid = f['task_id']
                    if tid not in files_map:
                        files_map[tid] = []
                files_map[tid].append({
                    'id': f['id'],
                    'filename': f['original_filename'],
                    'description': f.get('description', ''),
                    'employee_name': f.get('employee_name', ''),
                    'employee_email': f.get('employee_email', ''),
                    'uploaded_at': f['uploaded_at'].strftime('%Y-%m-%d %H:%M') if f.get('uploaded_at') else '',
                    'download_url': f"/task/file/{f['id']}/download",
                    'approval_status': ((f.get('approval_status') or '').strip().lower() or None),
                    'approval_target': f.get('approval_target') or 'admin',
                    'decision_note': f.get('decision_note') or ''
                })
                for t in tasks:
                    t['employee_files'] = files_map.get(t['id'], [])
            except Exception:
                for t in tasks:
                    t['employee_files'] = []

            # Load manager attachments
            try:
                cur.execute(f"""
                    SELECT tma.*, u.email as manager_email, da.status as approval_status, da.decision_note as decision_note
                    FROM task_manager_attachments tma
                    LEFT JOIN users u ON tma.user_id = u.id
                    LEFT JOIN document_approvals da ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
                    WHERE tma.task_id IN ({placeholders})
                    ORDER BY tma.uploaded_at DESC
                """, tuple(task_ids))
                all_manager_files = cur.fetchall()
                manager_files_map = {}
                for f in all_manager_files:
                    tid = f['task_id']
                    if tid not in manager_files_map:
                        manager_files_map[tid] = []
                manager_files_map[tid].append({
                    'id': f['id'],
                    'filename': f.get('original_filename', f.get('filename', 'File')),
                    'manager_email': f.get('manager_email', 'Manager'),
                    'uploaded_at': f['uploaded_at'].strftime('%Y-%m-%d %H:%M') if f.get('uploaded_at') else '',
                    'download_url': f"/task/manager-file/{f['id']}/download",
                    'approval_status': ((f.get('approval_status') or '').strip().lower() or None),
                    'approval_target': f.get('approval_target') or 'admin',
                    'decision_note': f.get('decision_note') or ''
                })
                for t in tasks:
                    t['manager_files'] = manager_files_map.get(t['id'], [])
            except Exception:
                for t in tasks:
                    t['manager_files'] = []
        else:
            for t in tasks:
                t['employee_comments'] = []
                t['employee_files'] = []
                t['manager_files'] = []
        team_lead_emails = []
        try:
            cur.execute("SELECT team_lead FROM teamlead_assign_bids WHERE g_id=%s", (g_id,))
            team_lead_emails = [(r.get('team_lead') or '').strip() for r in (cur.fetchall() or []) if (r.get('team_lead') or '').strip()]
        except Exception:
            team_lead_emails = []
        try:
            for t in tasks:
                ap = (t.get('attachment_path') or '').strip() if isinstance(t, dict) else None
                t['attachment_url'] = url_for('get_task_attachment', task_id=t.get('id')) if ap else None
                t['assigned_team_leads'] = team_lead_emails
        except Exception:
            pass
        cur.close()
        return jsonify({'tasks': tasks})

    cur.execute("SELECT 1 FROM bid_checklists WHERE g_id=%s AND LOWER(COALESCE(stage,''))=%s LIMIT 1", (g_id, team))
    has_team_tasks = cur.fetchone() is not None
    if not bid and not has_team_tasks:
        cur.close()
        return jsonify({'tasks': []})
    if bid and bid.get('state') != team and not has_team_tasks:
        cur.close()
        return jsonify({'tasks': []})
    
    # Get checklist items for this bid for this team:
    # - Prefer stage-based filtering (bc.stage == team) so BDM-created tasks for a team show up correctly.
    # - Keep a legacy fallback for old rows missing stage: filter by creator role set.
    roles_for_team = {
        'business': ('business dev', 'business', 'bdm', 'business_manager'),
        'design': ('design', 'design_manager', 'business_manager'),
        'operations': ('operations', 'operation_manager', 'operations_manager', 'business_manager'),
        'engineer': ('site manager', 'engineer', 'site_manager', 'business_manager'),
    }
    acceptable_roles = roles_for_team.get(team, (team, 'business_manager'))
    placeholders = ','.join(['%s'] * len(acceptable_roles))
    try:
        _backfill_task_codes_for_stage(cur, team)
    except Exception:
        pass
    cur.execute(f"""
        SELECT bc.*, e.name as assigned_employee_name, e.email as employee_email, e.department
        FROM bid_checklists bc
        LEFT JOIN employees e ON bc.assigned_to = e.id
        LEFT JOIN users u ON bc.created_by = u.id
        WHERE bc.g_id = %s 
        AND (
            (
                LOWER(COALESCE(bc.stage,'')) = %s
                AND bc.team_archive IS NULL
            )
            OR (
                bc.team_archive = %s
            )
            OR (
                (COALESCE(bc.stage,'') = '' OR bc.stage IS NULL)
                AND u.role IN ({placeholders})
                AND bc.team_archive IS NULL
            )
        )
        ORDER BY bc.priority DESC, bc.created_at ASC
    """, (g_id, team, team, *acceptable_roles))
    tasks = cur.fetchall()
    try:
        _assign_missing_task_codes(cur, tasks, team)
        mysql.connection.commit()
    except Exception:
        mysql.connection.rollback()
    # Attach team lead assignments (no employee row required)
    try:
        _ensure_task_team_lead_assignments_table(cur)
        task_ids = [t['id'] for t in tasks if t.get('id')]
        if task_ids:
            placeholders = ','.join(['%s'] * len(task_ids))
            cur.execute(
                f"""
                SELECT tta.task_id, u.email, COALESCE(u.full_name, u.email) AS name
                FROM task_team_lead_assignments tta
                JOIN users u ON u.id = tta.team_lead_user_id
                WHERE tta.task_id IN ({placeholders})
                """,
                tuple(task_ids),
            )
            tl_map = {int(r.get('task_id')): r for r in (cur.fetchall() or []) if r.get('task_id')}
        else:
            tl_map = {}
        for t in tasks:
            tl = tl_map.get(int(t.get('id') or 0)) if t.get('id') else None
            if tl:
                t['assigned_team_lead_email'] = tl.get('email') or ''
                t['assigned_team_lead_name'] = tl.get('name') or ''
    except Exception:
        pass
    team_lead_emails = []
    try:
        cur.execute("SELECT team_lead FROM teamlead_assign_bids WHERE g_id=%s", (g_id,))
        team_lead_emails = [(r.get('team_lead') or '').strip() for r in (cur.fetchall() or []) if (r.get('team_lead') or '').strip()]
    except Exception:
        team_lead_emails = []
    # Add attachment_url for easier consumption in UI
    try:
        for t in tasks:
            ap = (t.get('attachment_path') or '').strip() if isinstance(t, dict) else None
            t['attachment_url'] = url_for('get_task_attachment', task_id=t.get('id')) if ap else None
            t['assigned_team_leads'] = team_lead_emails
    except Exception:
        pass

    # Load employee comments and files for each task
    task_ids = [t['id'] for t in tasks if t.get('id')]
    if task_ids:
        # Load comments
        try:
            placeholders = ','.join(['%s'] * len(task_ids))
            cur.execute(f"""
                SELECT tc.*, e.name as employee_name, u.email as user_email, da.status as approval_status, da.decision_note as decision_note
                FROM task_comments tc
                LEFT JOIN employees e ON tc.employee_id = e.id
                LEFT JOIN users u ON tc.user_id = u.id
                LEFT JOIN document_approvals da ON da.source_table='task_comments' AND da.source_id=tc.id
                WHERE tc.task_id IN ({placeholders})
                ORDER BY tc.created_at DESC
            """, tuple(task_ids))
            all_comments = cur.fetchall()
            comments_map = {}
            for c in all_comments:
                tid = c['task_id']
                if tid not in comments_map:
                    comments_map[tid] = []
                author = c.get('employee_name') or c.get('user_email') or 'User'
                comments_map[tid].append({
                    'id': c['id'],
                    'comment': c['comment'],
                    'employee_name': author,
                    'created_at': c['created_at'].strftime('%Y-%m-%d %H:%M') if c.get('created_at') else '',
                    'approval_status': ((c.get('approval_status') or '').strip().lower() or None),
                    'approval_target': (c.get('approval_target') or 'admin'),
                    'needs_approval': bool(c.get('needs_approval')),
                    'decision_note': c.get('decision_note') or ''
                })
            for t in tasks:
                t['employee_comments'] = comments_map.get(t['id'], [])
        except Exception:
            for t in tasks:
                t['employee_comments'] = []
        
        # Load uploaded work files
        try:
            try:
                _ensure_document_approvals_table(cur)
            except Exception:
                pass
            cur.execute(f"""
                SELECT twf.*, e.name as employee_name, e.email as employee_email, da.status as approval_status, da.decision_note as decision_note
                FROM task_work_files twf
                LEFT JOIN employees e ON twf.employee_id = e.id
                LEFT JOIN document_approvals da ON da.source_table='task_work_files' AND da.source_id=twf.id
                WHERE twf.task_id IN ({placeholders})
                ORDER BY twf.uploaded_at DESC
            """, tuple(task_ids))
            all_files = cur.fetchall()
            files_map = {}
            for f in all_files:
                tid = f['task_id']
                if tid not in files_map:
                    files_map[tid] = []
                    files_map[tid].append({
                        'id': f['id'],
                        'filename': f['original_filename'],
                        'description': f.get('description', ''),
                        'employee_name': f.get('employee_name', ''),
                        'employee_email': f.get('employee_email', ''),
                        'uploaded_at': f['uploaded_at'].strftime('%Y-%m-%d %H:%M') if f.get('uploaded_at') else '',
                        'download_url': f"/task/file/{f['id']}/download",
                        'approval_status': ((f.get('approval_status') or '').strip().lower() or None),
                        'approval_target': f.get('approval_target') or 'admin',
                        'decision_note': f.get('decision_note') or ''
                    })
            for t in tasks:
                t['employee_files'] = files_map.get(t['id'], [])
        except Exception:
            for t in tasks:
                t['employee_files'] = []
        
        # Load manager attachments
        try:
            try:
                _ensure_document_approvals_table(cur)
            except Exception:
                pass
            cur.execute(f"""
                SELECT tma.*, u.email as manager_email, da.status as approval_status, da.decision_note as decision_note
                FROM task_manager_attachments tma
                LEFT JOIN users u ON tma.user_id = u.id
                LEFT JOIN document_approvals da ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
                WHERE tma.task_id IN ({placeholders})
                ORDER BY tma.uploaded_at DESC
            """, tuple(task_ids))
            all_manager_files = cur.fetchall()
            manager_files_map = {}
            for f in all_manager_files:
                tid = f['task_id']
                if tid not in manager_files_map:
                    manager_files_map[tid] = []
                    manager_files_map[tid].append({
                        'id': f['id'],
                        'filename': f.get('original_filename', f.get('filename', 'File')),
                        'manager_email': f.get('manager_email', 'Manager'),
                        'uploaded_at': f['uploaded_at'].strftime('%Y-%m-%d %H:%M') if f.get('uploaded_at') else '',
                        'download_url': f"/task/manager-file/{f['id']}/download",
                        'approval_status': ((f.get('approval_status') or '').strip().lower() or None),
                        'approval_target': f.get('approval_target') or 'admin',
                        'decision_note': f.get('decision_note') or ''
                    })
            for t in tasks:
                t['manager_files'] = manager_files_map.get(t['id'], [])
        except Exception:
            for t in tasks:
                t['manager_files'] = []
    else:
        for t in tasks:
            t['employee_comments'] = []
            t['employee_files'] = []
            t['manager_files'] = []

    # Emit per-stage map for this bid so master dashboard reflects progress
    try:
        def _pct(rows):
            if not rows:
                return 0
            t = len(rows)
            d = len([r for r in rows if (r.get('status') or '').lower() == 'completed'])
            return int(round((d / max(1, t)) * 100))

        def _q(role_filter):
            cur.execute(f"SELECT status FROM bid_checklists WHERE g_id=%s AND created_by IN (SELECT id FROM users WHERE role {role_filter})", (g_id,))
            return cur.fetchall()

        spm = {
            'business': _pct(_q("='business dev'")),
            'design': _pct(_q("='design'")),
            'operations': _pct(_q("='operations'")),
            'engineer': _pct(_q("IN ('site manager','engineer')")),
        }
        socketio.emit('master_update', {
            'summary': {
                'bid_id': g_id,
                'work_progress_pct': spm.get(team, 0),
                'project_status': 'ongoing',
                'work_status': f'{team.title()} tasks updated',
                'stage_progress_map': spm
            }
        })
    except Exception:
        pass

    cur.close()
    return jsonify({'tasks': tasks})


@app.route('/api/tasks/<int:task_id>/activity')
@login_required
def api_task_activity(task_id):
    """Return activity + approvals for a single task."""
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SELECT * FROM bid_checklists WHERE id=%s", (task_id,))
        task = cur.fetchone()
        if not task:
            return jsonify({'error': 'Task not found'}), 404

        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        employee_id = session.get('employee_id')
        if not is_flask_user and (not employee_id or task.get('assigned_to') != employee_id):
            return jsonify({'error': 'Forbidden'}), 403

        try:
            _ensure_document_approvals_table(cur)
            _ensure_task_comments_table(cur)
            _ensure_task_work_files_table(cur)
            _ensure_task_manager_attachments_table(cur)
        except Exception:
            pass

        comments = []
        try:
            cur.execute(
                """
                SELECT tc.*, e.name as employee_name, u.email as user_email, da.status as approval_status
                FROM task_comments tc
                LEFT JOIN employees e ON tc.employee_id = e.id
                LEFT JOIN users u ON tc.user_id = u.id
                LEFT JOIN document_approvals da ON da.source_table='task_comments' AND da.source_id=tc.id
                WHERE tc.task_id=%s
                ORDER BY tc.created_at DESC
                """,
                (task_id,),
            )
            for c in (cur.fetchall() or []):
                author = c.get('employee_name') or c.get('user_email') or 'User'
                comments.append({
                    'id': c.get('id'),
                    'comment': c.get('comment'),
                    'employee_name': author,
                    'created_at': c.get('created_at').strftime('%Y-%m-%d %H:%M') if c.get('created_at') else '',
                    'approval_status': ((c.get('approval_status') or '').strip().lower() or None),
                    'approval_target': (c.get('approval_target') or 'admin'),
                    'needs_approval': bool(c.get('needs_approval')),
                    'decision_note': c.get('decision_note') or '',
                })
        except Exception:
            comments = []

        employee_files = []
        try:
            cur.execute(
                """
                SELECT twf.*, e.name as employee_name, e.email as employee_email, da.status as approval_status, da.decision_note as decision_note
                FROM task_work_files twf
                LEFT JOIN employees e ON twf.employee_id = e.id
                LEFT JOIN document_approvals da ON da.source_table='task_work_files' AND da.source_id=twf.id
                WHERE twf.task_id=%s
                ORDER BY twf.uploaded_at DESC
                """,
                (task_id,),
            )
            for f in (cur.fetchall() or []):
                employee_files.append({
                    'id': f.get('id'),
                    'filename': f.get('original_filename'),
                    'description': f.get('description', ''),
                    'employee_name': f.get('employee_name', ''),
                    'employee_email': f.get('employee_email', ''),
                    'uploaded_at': f.get('uploaded_at').strftime('%Y-%m-%d %H:%M') if f.get('uploaded_at') else '',
                    'download_url': f"/task/file/{int(f.get('id') or 0)}/download",
                    'approval_status': ((f.get('approval_status') or '').strip().lower() or None),
                    'approval_target': f.get('approval_target') or 'admin',
                    'decision_note': f.get('decision_note') or '',
                })
        except Exception:
            employee_files = []

        manager_files = []
        try:
            cur.execute(
                """
                SELECT tma.*, u.email as manager_email, da.status as approval_status, da.decision_note as decision_note
                FROM task_manager_attachments tma
                LEFT JOIN users u ON tma.user_id = u.id
                LEFT JOIN document_approvals da ON da.source_table='task_manager_attachments' AND da.source_id=tma.id
                WHERE tma.task_id=%s
                ORDER BY tma.uploaded_at DESC
                """,
                (task_id,),
            )
            for f in (cur.fetchall() or []):
                manager_files.append({
                    'id': f.get('id'),
                    'filename': f.get('original_filename') or f.get('filename') or 'File',
                    'manager_email': f.get('manager_email', 'Manager'),
                    'uploaded_at': f.get('uploaded_at').strftime('%Y-%m-%d %H:%M') if f.get('uploaded_at') else '',
                    'download_url': f"/task/manager-file/{int(f.get('id') or 0)}/download",
                    'approval_status': ((f.get('approval_status') or '').strip().lower() or None),
                    'approval_target': f.get('approval_target') or 'admin',
                    'decision_note': f.get('decision_note') or '',
                })
        except Exception:
            manager_files = []

        attachment_url = None
        try:
            ap = (task.get('attachment_path') or '').strip()
            if ap:
                attachment_url = url_for('get_task_attachment', task_id=task_id)
        except Exception:
            attachment_url = None

        return jsonify({
            'ok': True,
            'task_id': task_id,
            'comments': comments,
            'employee_files': employee_files,
            'manager_files': manager_files,
            'attachment_url': attachment_url,
            'task_name': task.get('task_name') or 'Task',
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass

@app.route('/api/tasks/<int:task_id>/attachments/zip')
@login_required
def api_task_attachments_zip(task_id):
    """Download all attachments for a task as a zip file."""
    cur = mysql.connection.cursor(DictCursor)
    try:
        cur.execute("SELECT id, assigned_to, attachment_path, task_name FROM bid_checklists WHERE id=%s", (task_id,))
        task = cur.fetchone()
        if not task:
            return jsonify({'error': 'Task not found'}), 404

        is_flask_user = hasattr(current_user, 'is_authenticated') and current_user.is_authenticated
        employee_id = session.get('employee_id')
        if not is_flask_user and (not employee_id or task.get('assigned_to') != employee_id):
            return jsonify({'error': 'Forbidden'}), 403

        try:
            _ensure_task_work_files_table(cur)
            _ensure_task_manager_attachments_table(cur)
        except Exception:
            pass

        files = []

        def _add_file(path, name_hint):
            if not path:
                return
            abs_path = path
            if not os.path.isabs(abs_path):
                abs_path = os.path.join(os.getcwd(), abs_path)
            if not os.path.exists(abs_path):
                return
            base = os.path.basename(name_hint or abs_path)
            files.append((abs_path, base))

        try:
            cur.execute("SELECT original_filename, file_path FROM task_work_files WHERE task_id=%s", (task_id,))
            for row in (cur.fetchall() or []):
                _add_file(row.get('file_path'), row.get('original_filename') or row.get('file_path'))
        except Exception:
            pass

        try:
            cur.execute("SELECT original_filename, file_path FROM task_manager_attachments WHERE task_id=%s", (task_id,))
            for row in (cur.fetchall() or []):
                _add_file(row.get('file_path'), row.get('original_filename') or row.get('file_path'))
        except Exception:
            pass

        attachment_path = (task.get('attachment_path') or '').strip()
        if attachment_path:
            _add_file(attachment_path, attachment_path)

        if not files:
            return jsonify({'error': 'No attachments found'}), 404

        used_names = set()
        output = io.BytesIO()
        with zipfile.ZipFile(output, 'w', zipfile.ZIP_DEFLATED) as zf:
            for abs_path, base in files:
                name = base or os.path.basename(abs_path)
                if not name:
                    name = f"file_{len(used_names) + 1}"
                if name in used_names:
                    root, ext = os.path.splitext(name)
                    i = 1
                    while f"{root}_{i}{ext}" in used_names:
                        i += 1
                    name = f"{root}_{i}{ext}"
                used_names.add(name)
                zf.write(abs_path, name)
        output.seek(0)
        safe_name = f"task_{task_id}_attachments.zip"
        return send_file(output, mimetype='application/zip', as_attachment=True, download_name=safe_name)
    except Exception as e:
        return jsonify({'error': str(e)}), 500
    finally:
        try:
            cur.close()
        except Exception:
            pass

# --- Simple API to update a bid summary (notes) ---
@app.route('/api/bids/<int:g_id>/summary', methods=['POST'])
@login_required
def api_update_bid_summary(g_id):
    try:
        summary = (request.form.get('summary') or '').strip()
        cur = mysql.connection.cursor()
        cur.execute("UPDATE go_bids SET summary=%s WHERE g_id=%s", (summary, g_id))
        mysql.connection.commit()
        cur.close()
        return jsonify({'ok': True})
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        return jsonify({'ok': False, 'error': str(e)}), 500

# Update bid dates (start/due)
@app.route('/api/bids/<int:g_id>/dates', methods=['POST'])
@login_required
def api_update_bid_dates(g_id):
    try:
        
        due_date = request.form.get('due_date')
        cur = mysql.connection.cursor()
        # Build dynamic set
        fields = []
        values = []
        if due_date:
            fields.append('due_date=%s'); values.append(due_date)
        if not fields:
            return jsonify({'ok': False, 'error': 'No fields provided'}), 400
        values.append(g_id)
        cur.execute(f"UPDATE go_bids SET {', '.join(fields)} WHERE g_id=%s", tuple(values))
        mysql.connection.commit()
        cur.close()
        return jsonify({'ok': True})
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        return jsonify({'ok': False, 'error': str(e)}), 500

# Comments CRUD (list + add)
@app.route('/api/bids/<int:g_id>/comments', methods=['GET', 'POST'])
@login_required
def api_bid_comments(g_id):
    if request.method == 'GET':
        cur = mysql.connection.cursor(DictCursor)
        cur.execute(
            """
            SELECT c.id, c.g_id, c.comment_text, c.created_at, u.email AS user_email
            FROM bid_comments c
            LEFT JOIN users u ON u.id = c.user_id
            WHERE c.g_id=%s
            ORDER BY c.created_at DESC
            """,
            (g_id,)
        )
        rows = cur.fetchall()
        cur.close()
        return jsonify({'comments': rows})
    else:
        text = (request.form.get('comment') or '').strip()
        if not text:
            return jsonify({'ok': False, 'error': 'Empty comment'}), 400
        try:
            cur = mysql.connection.cursor()
            uid = getattr(current_user, 'id', None)
            cur.execute("INSERT INTO bid_comments (g_id, user_id, comment_text) VALUES (%s,%s,%s)", (g_id, uid, text))
            mysql.connection.commit()
            cur.close()
            return jsonify({'ok': True})
        except Exception as e:
            try:
                mysql.connection.rollback()
            except Exception:
                pass
            return jsonify({'ok': False, 'error': str(e)}), 500

# Update Submission Status
@app.route('/api/bids/<int:g_id>/update_submission', methods=['POST'])
@login_required
def api_update_submission_status(g_id):
    """Update the submission status for a bid"""
    try:
        # Enforce Top Admin read-only team views (set by /team-lead/<team>/overview?readonly=1)
        try:
            if (get_user_role() or '').strip().lower() == 'topleveladmin':
                ro = session.get('readonly_team_views') or []
                if isinstance(ro, list) and len(ro) > 0:
                    return jsonify({'success': False, 'error': 'read_only'}), 403
        except Exception:
            pass

        submission_status = (request.form.get('submission_status') or '').strip()
        submission_reason = (request.form.get('submission_reason') or '').strip()
        if not submission_status:
            return jsonify({'success': False, 'error': 'Submission status is required'}), 400
        
        cur = mysql.connection.cursor(DictCursor)
        
        # Check if submission_reason column exists, if not create it
        try:
            cur.execute("SHOW COLUMNS FROM go_bids LIKE 'submission_reason'")
            if not cur.fetchone():
                cur.execute("ALTER TABLE go_bids ADD COLUMN submission_reason TEXT")
        except Exception:
            pass
        
        # Update submission_status and submission_reason in go_bids table
        cur.execute("UPDATE go_bids SET submission_status = %s, submission_reason = %s WHERE g_id = %s", 
                    (submission_status, submission_reason, g_id))
        
        # Log the action
        reason_log = f" (Reason: {submission_reason})" if submission_reason else ""
        log_write('submission_update', f"Submission status for bid ID {g_id} updated to '{submission_status}'{reason_log} by {current_user.email}")
        
        mysql.connection.commit()
        cur.close()
        
        return jsonify({'success': True, 'message': f'Submission status updated to {submission_status}'})
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        return jsonify({'success': False, 'error': str(e)}), 500

# Update Win/Lost Result
@app.route('/api/bids/<int:g_id>/update_result', methods=['POST'])
@login_required
def api_update_result_status(g_id):
    """Update the win/lost result for a bid and store in win_lost_results table"""
    try:
        # Enforce Top Admin read-only team views (set by /team-lead/<team>/overview?readonly=1)
        try:
            if (get_user_role() or '').strip().lower() == 'topleveladmin':
                ro = session.get('readonly_team_views') or []
                if isinstance(ro, list) and len(ro) > 0:
                    return jsonify({'success': False, 'error': 'read_only'}), 403
        except Exception:
            pass

        result = (request.form.get('result') or '').strip()
        feedback = (request.form.get('feedback') or '').strip()
        
        if not result:
            return jsonify({'success': False, 'error': 'Result is required'}), 400
        
        cur = mysql.connection.cursor(DictCursor)
        
        # Get bid information
        cur.execute("SELECT g_id, b_name, company, due_date, state, scope FROM go_bids WHERE g_id = %s", (g_id,))
        bid = cur.fetchone()
        
        if not bid:
            cur.close()
            return jsonify({'success': False, 'error': 'Bid not found'}), 404
        
        # Check if a win_lost_results record exists for this bid (by g_id)
        cur.execute("SELECT w_id FROM win_lost_results WHERE g_id = %s", (g_id,))
        existing = cur.fetchone()
        
        if existing:
            # Update existing record
            cur.execute("""
                UPDATE win_lost_results 
                SET result = %s, feedback = %s, b_name = %s, company = %s, state = %s
                WHERE g_id = %s
            """, (result, feedback, bid.get('b_name'), bid.get('company'), bid.get('state'), g_id))
        else:
            # First check if there's a bid_assign record
            cur.execute("SELECT a_id FROM bid_assign WHERE g_id = %s LIMIT 1", (g_id,))
            assign_record = cur.fetchone()
            a_id = assign_record.get('a_id') if assign_record else None
            
            # Insert new record
            cur.execute("""
                INSERT INTO win_lost_results (g_id, a_id, b_name, company, state, result, feedback)
                VALUES (%s, %s, %s, %s, %s, %s, %s)
            """, (g_id, a_id, bid.get('b_name'), bid.get('company'), bid.get('state'), result, feedback))
        
        # If result is WON, also create/update won_bids_result record
        if result.upper() == 'WON':
            # Get the w_id for this bid
            cur.execute("SELECT w_id FROM win_lost_results WHERE g_id = %s", (g_id,))
            wlr = cur.fetchone()
            if wlr:
                w_id = wlr.get('w_id')
                # Check if won_bids_result exists
                cur.execute("SELECT won_id FROM won_bids_result WHERE w_id = %s", (w_id,))
                existing_won = cur.fetchone()
                
                if not existing_won:
                    # Create won_bids_result record
                    cur.execute("""
                        INSERT INTO won_bids_result (w_id, closure_status, work_progress_status)
                        VALUES (%s, 'Open', 'Not Started')
                    """, (w_id,))
        
        # Log the action
        log_write('result_update', f"Result for bid '{bid.get('b_name')}' (ID: {g_id}) updated to '{result}' by {current_user.email}. Feedback: {feedback}")
        
        mysql.connection.commit()
        cur.close()
        
        return jsonify({'success': True, 'message': f'Result updated to {result}'})
    except Exception as e:
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        return jsonify({'success': False, 'error': str(e)}), 500

def generate_complete_proposal(pdf_path, company, template, output_path, bid_name=None, sections_outline=None, user_email=None):
    """
    Generate a complete structured proposal document from RFP PDF using AI.
    Creates a comprehensive proposal with all required sections.
    """
    try:
        import os
        from datetime import datetime
        from rfp_analyzer_routes import extract_page_texts, api_json, trim_text_to_token_limit
        from docx import Document
        from docx.shared import Inches, Pt, RGBColor
        from docx.enum.text import WD_ALIGN_PARAGRAPH
        from docx.oxml.ns import qn
        from docx.oxml import OxmlElement
        from docx.enum.table import WD_TABLE_ALIGNMENT
        import re
        
        # Read PDF file
        with open(pdf_path, 'rb') as pdf_file:
            pages = extract_page_texts(pdf_file)
        
        if not pages or len(pages) == 0:
            raise Exception("Could not extract text from PDF")
        
        full_text = "\n\n".join(pages)
        
        # Extract key information from RFP
        rfp_text_limited = trim_text_to_token_limit(full_text, 8000)  # Limit for prompt
        
        # Extract project title
        project_title = bid_name or "Project"
        title_match = re.search(r'(?i)(?:project|title|proposal|rfp)[:\s]+([A-Z][^\n]{10,100})', full_text[:2000])
        if title_match:
            project_title = title_match.group(1).strip()
        
        # Extract deadline
        deadline = None
        deadline_patterns = [
            r'(?i)(?:deadline|due\s+date|submission\s+date)[:\s]+([A-Za-z]+\s+\d{1,2},?\s+\d{4})',
            r'(?i)(?:deadline|due\s+date)[:\s]+(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})',
            r'(?i)August\s+31,?\s+2026',
        ]
        for pattern in deadline_patterns:
            match = re.search(pattern, full_text[:5000])
            if match:
                deadline = match.group(1) if match.groups() else match.group(0)
                break
        
        # Build dynamic proposal prompt based on provided sections
        company_display = company or "Our Company"
        project_label = project_title or bid_name or "Project"

        if not sections_outline:
            sections_outline = [
                {'title': 'Executive Summary', 'guidance': 'Summarize the opportunity, objectives, and how the proposed solution delivers value.'},
                {'title': 'Company Profile', 'guidance': 'Describe the company background, capabilities, and relevant experience.'},
                {'title': 'Technical Approach & Scope', 'guidance': 'Detail the technical solution, methodology, schedule, and risk mitigation strategies.'},
                {'title': 'Project Management & Schedule', 'guidance': 'Outline management structure, milestones, resource plan, and communication strategy.'},
                {'title': 'Price Proposal Form (Attachment A)', 'guidance': 'Explain pricing assumptions, cost elements, and any exclusions.'},
                {'title': 'Compliance Matrix & Deliverables', 'guidance': 'Summarize compliance approach, required deliverables, and submission checklist.'},
                {'title': 'Project Team', 'guidance': '.'},
                {'title': 'Corporate Qualifications', 'guidance': ''}
            ]

        section_prompt_lines = []
        for sec in sections_outline:
            guidance = sec.get('guidance') or 'Provide a comprehensive, proposal-ready narrative aligned with this heading.'
            sub_titles = ', '.join(sub.get('title') for sub in sec.get('sub_categories') or [] if sub.get('title'))
            if sub_titles:
                guidance += f" Include coverage of: {sub_titles}."
            section_prompt_lines.append(f'- {sec.get("title", "Section")}: {guidance}')
        sections_prompt = "\n".join(section_prompt_lines)

        proposal_prompt = f"""You are a professional proposal generation assistant specialized in government and infrastructure RFPs. Analyze the uploaded RFP document in full detail and automatically create a draft proposal narrative that follows the section headers provided.

RFP Document Content:
{rfp_text_limited}

Company Name: {company_display}
Project Title: {project_label}
Deadline: {deadline or 'To be determined'}

Sections to include (in this exact order):
{sections_prompt}

Return JSON with the following structure:
{{
  "sections": [
    {{
      "title": "Exact Section Title",
      "content": [
        "Paragraph 1",
        "Paragraph 2",
        "Paragraph 3"
      ],
      "sub_sections": [
        {{
          "title": "Optional Subheading",
          "content": [
            "Paragraph 1",
            "Paragraph 2"
          ]
        }}
      ]
    }}
  ]
}}

Ensure each section contains multiple detailed paragraphs tailored to the RFP requirements, referencing specific compliance, schedule, and technical expectations whenever possible."""

        # Generate proposal content using OpenAI (from .env OPENAI_API_KEY / OPENAI_MODEL)
        print("Generating proposal content with OpenAI...")
        import json
        api_key = (app.config.get('OPENAI_API_KEY') or os.getenv('OPENAI_API_KEY') or os.getenv('GROQ_API_KEY') or '').strip()
        if not api_key:
            raise Exception("OPENAI_API_KEY is not configured (check .env in project folder)")
        base_url = (app.config.get('OPENAI_BASE_URL') or os.getenv('OPENAI_BASE_URL') or 'https://api.groq.com/openai/v1').strip()
        model = (app.config.get('OPENAI_MODEL') or os.getenv('OPENAI_MODEL') or 'meta-llama/llama-4-scout-17b-16e-instruct').strip()
        endpoint = base_url.rstrip('/')
        if not endpoint.endswith('/chat/completions'):
            endpoint = f"{endpoint}/chat/completions"
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json',
        }
        system_prompt = (
            "You are a proposal generation assistant. Return ONLY valid JSON with a 'sections' array as described. "
            "Do not include any markdown code fences or commentary. Ensure output is compact JSON."
        )
        body = {
            'model': model,
            'messages': [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': proposal_prompt},
            ],
            'temperature': 0.2,
            'max_tokens': 4000
        }
        try:
            response = requests.post(endpoint, headers=headers, json=body, timeout=120)
        except requests.RequestException as net_err:
            raise Exception(f"OpenAI network error: {net_err}")
        raw_text = response.text
        try:
            data = response.json()
        except ValueError:
            raise Exception(f"OpenAI returned non-JSON response (status {response.status_code})")
        if response.status_code >= 400:
            err_message = data.get('error') if isinstance(data, dict) else None
            detail = ''
            if isinstance(err_message, dict):
                detail = err_message.get('message') or err_message.get('code') or ''
            elif isinstance(err_message, str):
                detail = err_message
            if not detail:
                detail = f"Upstream error {response.status_code}"
            raise Exception(f"OpenAI error: {detail}")
        choices = data.get('choices') or []
        if not choices:
            raise Exception("OpenAI returned no choices")
        content_text = (choices[0].get('message', {}) or {}).get('content', '') or ''
        # Strip markdown code fences if present
        content_text_stripped = content_text.strip()
        if content_text_stripped.startswith("```"):
            # remove first fence line and possible language tag
            content_text_stripped = content_text_stripped.lstrip('`')
            # Find the next fence
            fence_idx = content_text_stripped.find("```")
            if fence_idx != -1:
                content_text_stripped = content_text_stripped[:fence_idx]
        try:
            proposal_result = json.loads(content_text_stripped)
        except Exception:
            # Fallback: deliver raw content; downstream logic can still build sections
            proposal_result = {'raw': content_text}

        def normalize_title(value):
            return re.sub(r'\s+', ' ', str(value).strip().lower())

        sections_output = []
        if isinstance(proposal_result, dict):
            if isinstance(proposal_result.get('sections'), list):
                sections_output = proposal_result['sections']
            else:
                # Interpret as dictionary of section -> content
                sections_output = [
                    {'title': key, 'content': value}
                    for key, value in proposal_result.items()
                    if key not in ('raw', 'error')
                ]

        sections_map = {}
        for entry in sections_output:
            title = entry.get('title')
            if not title:
                continue
            sections_map[normalize_title(title)] = entry

        normalized_sections = []
        for sec in sections_outline:
            title = sec.get('title', 'Section').strip()
            entry = sections_map.get(normalize_title(title))

            content = []
            sub_sections = []

            if entry:
                entry_content = entry.get('content')
                if isinstance(entry_content, str):
                    content = [entry_content]
                elif isinstance(entry_content, list):
                    content = [item for item in entry_content if item]
                elif isinstance(entry_content, dict):
                    # Flatten dict content
                    content = [v for v in entry_content.values() if v]
                sub_sections = entry.get('sub_sections') or []

            if not content:
                fallback_content = sec.get('content') or []
                if isinstance(fallback_content, str):
                    fallback_content = [fallback_content]
                if not fallback_content and sec.get('guidance'):
                    fallback_content = [sec['guidance']]
                if not fallback_content:
                    fallback_content = ['Content will be added once capture information is finalized.']
                content = fallback_content

            normalized_subsections = []
            for sub in sub_sections:
                sub_title = sub.get('title')
                if not sub_title:
                    continue
                sub_content = sub.get('content')
                if isinstance(sub_content, str):
                    sub_content = [sub_content]
                elif isinstance(sub_content, list):
                    sub_content = [item for item in sub_content if item]
                else:
                    sub_content = []
                if not sub_content:
                    sub_content = [f'Additional guidance for {sub_title} will be incorporated.']
                normalized_subsections.append({
                    'title': sub_title,
                    'content': sub_content
                })

            normalized_sections.append({
                'title': title,
                'content': content,
                'sub_sections': normalized_subsections
            })

        # Create Word document using brand-aware template selection
        try:
            chosen_path = choose_company_template(company_display)
            if chosen_path:
                doc = Document(chosen_path)
            else:
                doc = Document()
        except Exception:
            doc = Document()

        # Title Page
        doc.add_heading(project_label or 'Proposal Draft', 0)
        doc.add_paragraph(f'Prepared for: {project_label}')
        doc.add_paragraph(f'Prepared by: {company_display}')
        doc.add_paragraph(f'Generated: {datetime.now().strftime("%B %d, %Y")}')
        doc.add_paragraph()
        doc.add_page_break()

        # Table of Contents
        doc.add_heading('Table of Contents', 1)
        for idx, section in enumerate(normalized_sections, 1):
            doc.add_paragraph(f'{idx}. {section["title"]}')
        doc.add_page_break()

        # Sections
        for idx, section in enumerate(normalized_sections):
            doc.add_heading(section['title'], level=1)
            for paragraph in section.get('content', []):
                for part in str(paragraph).split('\n\n'):
                    if part.strip():
                        doc.add_paragraph(part.strip())

            for sub_section in section.get('sub_sections', []):
                sub_title = sub_section.get('title')
                if sub_title:
                    doc.add_heading(sub_title, level=2)
                for paragraph in sub_section.get('content', []):
                    for part in str(paragraph).split('\n\n'):
                        if part.strip():
                            doc.add_paragraph(part.strip())

            if idx != len(normalized_sections) - 1:
                doc.add_page_break()

        # IKIO-only appendices: include data from IKIO-specific tables when BD user from ikioledlighting
        try:
            viewer_email = (user_email or '').lower()
            is_ikio_user = viewer_email.endswith('@ikioledlighting.com')
            is_bd_user = False
            if is_ikio_user:
                try:
                    curx = mysql.connection.cursor(DictCursor)
                    # Try to determine department from employees/users
                    curx.execute("SELECT department FROM employees WHERE LOWER(email)=%s LIMIT 1", (viewer_email,))
                    row_dep = curx.fetchone()
                    dep_val = (row_dep or {}).get('department') or ''
                    if dep_val:
                        dep_val_l = str(dep_val).strip().lower()
                        is_bd_user = ('bd' in dep_val_l) or ('business' in dep_val_l and 'dev' in dep_val_l)
                    else:
                        # Fall back to users.role if department not found
                        curx.execute("SELECT role FROM users WHERE LOWER(email)=%s LIMIT 1", (viewer_email,))
                        row_role = curx.fetchone()
                        role_val = (row_role or {}).get('role') or ''
                        role_l = str(role_val).strip().lower()
                        is_bd_user = ('business' in role_l) or ('bd' in role_l) or ('bde' in role_l)
                except Exception:
                    is_bd_user = False
                if is_bd_user:
                    def fetch_rows(table_name: str, limit: int = 12) -> list[dict]:
                        try:
                            curx.execute(f"SELECT * FROM `{table_name}` LIMIT %s", (limit,))
                            return curx.fetchall() or []
                        except Exception:
                            return []
                    def choose_cols(rows: list[dict], max_cols: int = 6) -> list[str]:
                        if not rows:
                            return []
                        # Prefer commonly useful columns if present
                        preferred = ['project_name','bid_name','title','scope','client','owner','status','value','amount','date','due_date','role','name','designation','qualification','experience','email','phone']
                        keys = list(rows[0].keys())
                        cols = [c for c in preferred if c in keys]
                        # Append additional keys (skip internal ids/paths)
                        extra = [k for k in keys if k not in cols and k.lower() not in ('id','created_at','updated_at')]
                        cols = (cols + extra)[:max_cols]
                        return cols
                    def add_table_section(title: str, rows: list[dict]):
                        if not rows:
                            return
                        doc.add_page_break()
                        doc.add_heading(title, level=1)
                        columns = choose_cols(rows)
                        if not columns:
                            # Fallback to simple bullet list of first 10 rows
                            for r in rows:
                                line = "; ".join(f"{k}: {v}" for k, v in r.items() if k.lower() not in ('id','created_at','updated_at') and v not in (None,''))
                                if line:
                                    doc.add_paragraph(line)
                            return
                        tbl = doc.add_table(rows=1, cols=len(columns))
                        tbl.alignment = WD_TABLE_ALIGNMENT.CENTER
                        hdr_cells = tbl.rows[0].cells
                        for i, col_name in enumerate(columns):
                            hdr_cells[i].text = col_name.replace('_',' ').title()
                        for r in rows:
                            row_cells = tbl.add_row().cells
                            for i, col_name in enumerate(columns):
                                val = r.get(col_name)
                                row_cells[i].text = '' if val is None else str(val)
                    # Fetch IKIO tables
                    rows_pb = fetch_rows('project_bids')
                    rows_pp = fetch_rows('past_performance')
                    rows_pe = fetch_rows('personnel')
                    if rows_pb or rows_pp or rows_pe:
                        doc.add_page_break()
                        doc.add_heading('IKIO Supplemental Information', level=1)
                        doc.add_paragraph('The following sections include IKIO-specific data curated for Business Development use.')
                        add_table_section('IKIO Project Bids', rows_pb)
                        add_table_section('IKIO Past Performance', rows_pp)
                        add_table_section('IKIO Key Personnel', rows_pe)
                    try:
                        curx.close()
                    except Exception:
                        pass
        except Exception:
            # Never fail proposal generation due to supplemental data
            pass

        # Save document
        try:
            # Link headers/footers to the first section so they are consistent
            for _s_idx, _section in enumerate(doc.sections):
                if _s_idx > 0:
                    try:
                        _section.header.is_linked_to_previous = True
                        _section.footer.is_linked_to_previous = True
                    except Exception:
                        pass
                # Disable special first/odd-even to make header/footer consistent on all pages
                try:
                    _section.different_first_page_header_footer = False
                except Exception:
                    pass
                try:
                    _section.odd_and_even_pages_header_footer = False
                except Exception:
                    pass
            # Ensure continuous page numbering across sections
            from docx.oxml import OxmlElement
            from docx.oxml.ns import qn
            for _s_idx, _section in enumerate(doc.sections):
                _sectPr = _section._sectPr
                _pgNumType = _sectPr.find(qn('w:pgNumType'))
                if _pgNumType is None:
                    _pgNumType = OxmlElement('w:pgNumType')
                    _sectPr.append(_pgNumType)
                if _s_idx == 0:
                    _pgNumType.set(qn('w:start'), "1")
                else:
                    try:
                        _pgNumType.attrib.pop(qn('w:start'), None)
                    except Exception:
                        pass
        except Exception:
            pass
        doc.save(output_path)
        print(f"Proposal saved to: {output_path}")
        return True
        
    except Exception as e:
        print(f"Error generating complete proposal: {str(e)}")
        import traceback
        traceback.print_exc()
        # Create a basic document as fallback
        try:
            from docx import Document
            from datetime import datetime
            doc = Document()
            doc.add_heading('Proposal Generation Error', 0)
            doc.add_paragraph(f'RFP Document: {os.path.basename(pdf_path)}')
            doc.add_paragraph(f'Company: {company}')
            doc.add_paragraph(f'Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
            doc.add_paragraph('\nNote: An error occurred during proposal generation.')
            doc.add_paragraph(f'Error: {str(e)}')
            doc.save(output_path)
            return True
        except:
            return False

def generate_executive_summary_with_toc(pdf_path, company, template, output_path):
    """
    Generate an executive summary document with table of contents from RFP PDF.
    Uses RFP analyzer functions to extract and summarize content.
    """
    try:
        import os
        from datetime import datetime
        from rfp_analyzer_routes import extract_page_texts, summarize_batch_with_llama, build_master_summary, api_json, trim_text_to_token_limit
        from docx import Document
        from docx.shared import Inches, Pt
        from docx.enum.text import WD_ALIGN_PARAGRAPH
        from docx.oxml.ns import qn
        from docx.oxml import OxmlElement
        import re
        
        # Read PDF file
        with open(pdf_path, 'rb') as pdf_file:
            pages = extract_page_texts(pdf_file)
        
        if not pages or len(pages) == 0:
            raise Exception("Could not extract text from PDF")
        
        full_text = "\n\n".join(pages)
        
        # Process in batches for summarization
        DEFAULT_BATCH_PAGES = 10
        batch_summaries = []
        total_pages = len(pages)
        
        for i in range(0, total_pages, DEFAULT_BATCH_PAGES):
            batch_pages = pages[i:min(i + DEFAULT_BATCH_PAGES, total_pages)]
            batch_text = "\n\n".join(batch_pages)
            batch_idx = (i // DEFAULT_BATCH_PAGES) + 1
            summary = summarize_batch_with_llama(batch_text, batch_idx)
            if summary and not summary.get('error'):
                batch_summaries.append(summary)
        
        # Build master summary
        if batch_summaries:
            master_summary = build_master_summary(batch_summaries)
        else:
            # Fallback: create basic summary from text
            master_summary = {
                "project_type": "General Project",
                "scope": full_text[:500] + "..." if len(full_text) > 500 else full_text,
                "summary": full_text[:1000] + "..." if len(full_text) > 1000 else full_text,
                "key_requirements": [],
                "technical_requirements": [],
                "bid_requirements": []
            }
        
        # Generate executive summary using LLM
        summary_text = trim_text_to_token_limit(master_summary.get('summary', full_text[:2000]), 4000)
        exec_prompt = f"""Create a comprehensive executive summary for this RFP document.
        
The summary should include:
1. Project Overview
2. Key Objectives
3. Scope of Work
4. Key Requirements
5. Timeline and Deadlines
6. Budget Information (if available)
7. Technical Specifications (highlights)
8. Submission Requirements

RFP Content Summary:
{summary_text}

Return a well-structured executive summary in clear, professional language suitable for senior management."""
        
        # Use OpenAI to generate executive summary
        api_key = (app.config.get('OPENAI_API_KEY') or os.getenv('OPENAI_API_KEY') or os.getenv('GROQ_API_KEY') or '').strip()
        if not api_key:
            raise Exception("OPENAI_API_KEY is not configured (check .env in project folder)")
        base_url = (app.config.get('OPENAI_BASE_URL') or os.getenv('OPENAI_BASE_URL') or 'https://api.groq.com/openai/v1').strip()
        model = (app.config.get('OPENAI_MODEL') or os.getenv('OPENAI_MODEL') or 'meta-llama/llama-4-scout-17b-16e-instruct').strip()
        endpoint = base_url.rstrip('/')
        if not endpoint.endswith('/chat/completions'):
            endpoint = f"{endpoint}/chat/completions"
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json',
        }
        body = {
            'model': model,
            'messages': [
                {'role': 'system', 'content': 'You are a proposal generation assistant. Return only the executive summary text.'},
                {'role': 'user', 'content': exec_prompt},
            ],
            'temperature': 0.2,
            'max_tokens': 2000
        }
        try:
            response = requests.post(endpoint, headers=headers, json=body, timeout=90)
        except requests.RequestException as net_err:
            raise Exception(f"OpenAI network error: {net_err}")
        try:
            data = response.json()
        except ValueError:
            raise Exception(f"OpenAI returned non-JSON response (status {response.status_code})")
        if response.status_code >= 400:
            err_message = data.get('error') if isinstance(data, dict) else None
            detail = ''
            if isinstance(err_message, dict):
                detail = err_message.get('message') or err_message.get('code') or ''
            elif isinstance(err_message, str):
                detail = err_message
            if not detail:
                detail = f"Upstream error {response.status_code}"
            raise Exception(f"OpenAI error: {detail}")
        choices = data.get('choices') or []
        summary_text_generated = (choices[0].get('message', {}) or {}).get('content', '') if choices else ''
        executive_summary = summary_text_generated.strip() or master_summary.get('summary', 'Executive summary could not be generated.')
        
        # Extract table of contents from PDF text
        toc_items = []
        toc_patterns = [
            r'(?i)^\s*(?:table\s+of\s+contents?|contents?|toc)\s*$',
            r'(?i)^\s*\d+\.?\s+[A-Z][^\n]{10,100}\s+\.\.\.?\s*\d+',
            r'(?i)^\s*[A-Z][A-Z\s]{5,50}\s+\.\.\.?\s*\d+',
        ]
        
        # Try to find existing TOC in PDF
        lines = full_text.split('\n')
        in_toc = False
        for line in lines[:100]:  # Check first 100 lines
            line_clean = line.strip()
            if re.search(toc_patterns[0], line_clean):
                in_toc = True
                continue
            if in_toc and line_clean:
                # Look for TOC entries
                match = re.search(r'^(.+?)\s+\.\.\.?\s*(\d+)$', line_clean)
                if match:
                    toc_items.append({
                        'title': match.group(1).strip(),
                        'page': match.group(2).strip()
                    })
                elif len(toc_items) > 0 and len(line_clean) > 5:
                    # Continue previous entry
                    toc_items[-1]['title'] += ' ' + line_clean
                if len(toc_items) > 20:  # Limit TOC items
                    break
        
        # If no TOC found, generate one from sections
        if not toc_items:
            section_patterns = [
                r'(?i)^\s*\d+\.?\s+([A-Z][^\n]{10,80})',
                r'(?i)^\s*([A-Z][A-Z\s]{5,50})\s*$',
                r'(?i)^\s*(?:section|chapter|part)\s+\d+[:\s]+([^\n]{10,80})',
            ]
            seen_sections = set()
            for line in lines[:200]:
                for pattern in section_patterns:
                    match = re.search(pattern, line)
                    if match:
                        section_title = match.group(1).strip()
                        if len(section_title) > 10 and section_title not in seen_sections:
                            toc_items.append({'title': section_title, 'page': ''})
                            seen_sections.add(section_title)
                            if len(toc_items) >= 15:
                                break
                if len(toc_items) >= 15:
                    break
        
        # Create Word document (prefer H & F template to inherit header/footer)
        try:
            base_dir = app.root_path if hasattr(app, 'root_path') else os.getcwd()
            hf_template_path = os.path.join(base_dir, 'H & F.docx')
            if os.path.exists(hf_template_path):
                doc = Document(hf_template_path)
            else:
                doc = Document()
        except Exception:
            doc = Document()
        
        # Title page
        title_para = doc.add_heading('Executive Summary', 0)
        title_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        doc.add_paragraph(f'RFP Document: {os.path.basename(pdf_path)}')
        doc.add_paragraph(f'Company: {company}')
        doc.add_paragraph(f'Template: {template}')
        doc.add_paragraph(f'Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
        doc.add_page_break()
        
        # Table of Contents
        doc.add_heading('Table of Contents', 1)
        toc_para = doc.add_paragraph()
        
        if toc_items:
            for item in toc_items:
                p = doc.add_paragraph()
                run1 = p.add_run(item['title'])
                run1.font.size = Pt(11)
                if item['page']:
                    run2 = p.add_run(f'\t{item["page"]}')
                    run2.font.size = Pt(11)
                    # Add tab stop for alignment
                    p.paragraph_format.tab_stops.add_tab_stop(Inches(5.5))
        else:
            doc.add_paragraph('1. Executive Summary')
            doc.add_paragraph('2. Project Overview')
            doc.add_paragraph('3. Scope of Work')
            doc.add_paragraph('4. Key Requirements')
            doc.add_paragraph('5. Technical Specifications')
            doc.add_paragraph('6. Timeline and Deadlines')
            doc.add_paragraph('7. Budget Information')
            doc.add_paragraph('8. Submission Requirements')
        
        doc.add_page_break()
        
        # Executive Summary Section
        doc.add_heading('Executive Summary', 1)
        exec_para = doc.add_paragraph(executive_summary)
        exec_para_format = exec_para.paragraph_format
        exec_para_format.space_after = Pt(12)
        
        # Project Overview
        if master_summary.get('project_type') or master_summary.get('scope'):
            doc.add_heading('Project Overview', 1)
            if master_summary.get('project_type'):
                doc.add_paragraph(f"Project Type: {master_summary['project_type']}", style='List Bullet')
            if master_summary.get('scope'):
                scope_text = master_summary['scope'][:2000] if len(master_summary.get('scope', '')) > 2000 else master_summary.get('scope', '')
                doc.add_paragraph(scope_text)
        
        # Key Requirements
        if master_summary.get('key_requirements') and len(master_summary['key_requirements']) > 0:
            doc.add_heading('Key Requirements', 1)
            for req in master_summary['key_requirements'][:10]:  # Limit to 10
                if isinstance(req, str) and len(req.strip()) > 0:
                    doc.add_paragraph(req, style='List Bullet')
        
        # Technical Requirements
        if master_summary.get('technical_requirements') and len(master_summary['technical_requirements']) > 0:
            doc.add_heading('Technical Requirements', 1)
            for req in master_summary['technical_requirements'][:10]:  # Limit to 10
                if isinstance(req, str) and len(req.strip()) > 0:
                    doc.add_paragraph(req, style='List Bullet')
        
        # Bid Requirements
        if master_summary.get('bid_requirements') and len(master_summary['bid_requirements']) > 0:
            doc.add_heading('Bid Submission Requirements', 1)
            for req in master_summary['bid_requirements'][:10]:  # Limit to 10
                if isinstance(req, str) and len(req.strip()) > 0:
                    doc.add_paragraph(req, style='List Bullet')
        
        # Additional Information
        doc.add_heading('Document Information', 1)
        doc.add_paragraph(f'Total Pages: {total_pages}', style='List Bullet')
        doc.add_paragraph(f'Total Characters: {len(full_text):,}', style='List Bullet')
        if master_summary.get('due_date'):
            doc.add_paragraph(f'Due Date: {master_summary["due_date"]}', style='List Bullet')
        if master_summary.get('total_cost'):
            doc.add_paragraph(f'Estimated Cost: {master_summary["total_cost"]}', style='List Bullet')
        
        # Save document
        try:
            # Link headers/footers to the first section so they are consistent
            for _s_idx, _section in enumerate(doc.sections):
                if _s_idx > 0:
                    try:
                        _section.header.is_linked_to_previous = True
                        _section.footer.is_linked_to_previous = True
                    except Exception:
                        pass
                # Disable special first/odd-even to make header/footer consistent on all pages
                try:
                    _section.different_first_page_header_footer = False
                except Exception:
                    pass
                try:
                    _section.odd_and_even_pages_header_footer = False
                except Exception:
                    pass
            # Ensure continuous page numbering across sections
            from docx.oxml import OxmlElement
            from docx.oxml.ns import qn
            for _s_idx, _section in enumerate(doc.sections):
                _sectPr = _section._sectPr
                _pgNumType = _sectPr.find(qn('w:pgNumType'))
                if _pgNumType is None:
                    _pgNumType = OxmlElement('w:pgNumType')
                    _sectPr.append(_pgNumType)
                if _s_idx == 0:
                    _pgNumType.set(qn('w:start'), "1")
                else:
                    try:
                        _pgNumType.attrib.pop(qn('w:start'), None)
                    except Exception:
                        pass
        except Exception:
            pass
        doc.save(output_path)
        return True
        
    except Exception as e:
        print(f"Error generating executive summary: {str(e)}")
        import traceback
        traceback.print_exc()
        # Create a basic document as fallback
        try:
            from docx import Document
            from datetime import datetime
            doc = Document()
            doc.add_heading('Executive Summary', 0)
            doc.add_paragraph(f'RFP Document: {os.path.basename(pdf_path)}')
            doc.add_paragraph(f'Company: {company}')
            doc.add_paragraph(f'Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
            doc.add_paragraph('\nNote: An error occurred during executive summary generation.')
            doc.add_paragraph(f'Error: {str(e)}')
            doc.save(output_path)
            return True
        except:
            return False

@app.route('/proposals-making', methods=['GET', 'POST'])
@login_required
def proposals_making():
    # Allow all logged-in users to access proposals-making (removed admin-only restriction)
    import os
    import re
    from datetime import datetime, date

    contact_email = getattr(current_user, 'email', '')

    def safe_str(value):
        if value is None:
            return ''
        return str(value).strip()

    def normalize_company_choice(value: str) -> str:
        """
        Map various database/company aliases to canonical select values used by the UI:
          - any name containing 'ikio' -> 'IKIO'
          - any name containing 'metco' -> 'METCO'
          - any name containing 'sunsprint' -> 'SUNSPRINT'
        Returns empty string if the input is falsy.
        """
        s = (value or '').strip().lower()
        if not s:
            return ''
        if 'ikio' in s:
            return 'IKIO'
        if 'metco' in s:
            return 'METCO'
        if 'sunsprint' in s:
            return 'SUNSPRINT'
        return value or ''

    def format_date_for_display(value):
        if not value:
            return ''
        if isinstance(value, (datetime, date)):
            return value.strftime('%B %d, %Y')
        try:
            parsed = datetime.strptime(str(value), '%Y-%m-%d')
            return parsed.strftime('%B %d, %Y')
        except Exception:
            return str(value)

    def split_text_blocks(text, max_blocks=3):
        if not text:
            return []
        blocks = [
            safe_str(piece).strip('???- ') for piece in re.split(r'(?:\r?\n){2,}', str(text))
            if safe_str(piece)
        ]
        if not blocks and safe_str(text):
            blocks = [safe_str(text)]
        return blocks[:max_blocks]

    def compact_list(items):
        result = []
        for item in items:
            if item is None:
                continue
            text = safe_str(item)
            if text:
                result.append(text)
        return result

    def get_bid_metadata(g_id):
        if not g_id:
            return None
        meta_cursor = mysql.connection.cursor(DictCursor)
        try:
            meta_cursor.execute("SELECT * FROM go_bids WHERE g_id=%s", (g_id,))
            return meta_cursor.fetchone()
        except Exception as meta_err:
            print(f"Error loading bid context for proposal view: {meta_err}")
            return None
        finally:
            meta_cursor.close()

    def build_sections_outline(bid_info, fallback_title, company_name, primary_contact):
        bid = bid_info or {}
        project_name = safe_str(bid.get('b_name')) or safe_str(fallback_title) or 'Current Opportunity'
        due_text = format_date_for_display(bid.get('due_date'))
        client_name = safe_str(
            bid.get('agency') or bid.get('customer') or bid.get('client') or bid.get('owner') or bid.get('comp_name')
        )
        scope_text = safe_str(bid.get('scope'))
        summary_text = safe_str(bid.get('summary'))
        type_text = safe_str(bid.get('type'))
        location_text = safe_str(bid.get('location') or bid.get('city') or bid.get('state'))
        stage_text = safe_str(bid.get('state'))
        company_display = safe_str(company_name) or safe_str(bid.get('company')) or 'Offer or'
        revenue_value = bid.get('revenue') if bid.get('revenue') not in (None, '') else bid.get('value')
        scoring_value = bid.get('scoring')

        summary_blocks = split_text_blocks(summary_text, 4)
        scope_blocks = split_text_blocks(scope_text, 5)

        revenue_text = ''
        if revenue_value not in (None, ''):
            try:
                revenue_text = f"${float(revenue_value):,.0f}"
            except Exception:
                revenue_text = safe_str(revenue_value)

        scoring_text = ''
        if scoring_value not in (None, ''):
            try:
                scoring_text = f"{float(scoring_value):.0f}"
            except Exception:
                scoring_text = safe_str(scoring_value)

        sections = []

        cover_content = compact_list([
            f"{company_display} is pleased to submit this proposal for {project_name}.",
            f"Issuing agency / customer: {client_name}." if client_name else '',
            f"Solicitation reference: {project_name}.",
            f"Proposal due date: {due_text}." if due_text else '',
            f"Primary point of contact: {primary_contact}." if primary_contact else '',
            f"Contract type: {type_text}." if type_text else '',
            f"Performance location: {location_text}." if location_text else '',
            f"Opportunity priority score: {scoring_text}." if scoring_text else ''
        ])
        sections.append({
            'id': 'section-cover',
            'title': 'Letter of Transmittal',
            'status': 'Saved' if cover_content else 'Draft',
            'guidance': 'Confirm the solicitation title, client information, offer or contact details, and submission identifiers before releasing the cover page.',
            'content': cover_content or ['Add cover page details once the capture team confirms the solicitation data.'],
            'sub_categories': [
                {'id': 'cover-company-info', 'title': 'Company Information'},
                {'id': 'cover-contact-details', 'title': 'Contact Details'},
                {'id': 'cover-solicitation-ref', 'title': 'Solicitation Reference'},
                {'id': 'cover-submission-date', 'title': 'Submission Date & Deadline'}
            ]
        })

        exec_content = summary_blocks or (
            [f"{company_display} will deliver a compliant, value-focused response for {project_name}."]
            if project_name else []
        )
        if scope_text and not summary_blocks:
            exec_content.append(scope_text)
        sections.append({
            'id': 'section-executive-summary',
            'title': 'Executive Summary',
            'status': 'In Progress' if summary_blocks else 'Draft',
            'guidance': "Summarize win themes, differentiators, and alignment to the customer's objectives captured during bid qualification.",
            'content': exec_content or ['Executive summary content will be generated as soon as capture notes are available.'],
            'sub_categories': [
                {'id': 'exec-overview', 'title': 'Project Overview'},
                {'id': 'exec-win-themes', 'title': 'Win Themes & Differentiators'},
                {'id': 'exec-value-proposition', 'title': 'Value Proposition'},
                {'id': 'exec-key-highlights', 'title': 'Key Highlights'}
            ]
        })

        compliance_content = compact_list([
            "Track each requirement in the compliance matrix to ensure every section of the RFP is addressed.",
            scope_blocks[0] if scope_blocks else '',
            summary_blocks[0] if summary_blocks else ''
        ])
        sections.append({
            'id': 'section-compliance',
            'title': 'Requirements Compliance',
            'status': 'In Progress',
            'guidance': 'Reference the compliance matrix and list every deliverable, attachment, and form demanded by the solicitation.',
            'content': compliance_content or [
                'Populate this section with compliance findings once the RFP analysis is complete.'
            ],
            'sub_categories': [
                {'id': 'comp-matrix', 'title': 'Compliance Matrix'},
                {'id': 'comp-deliverables', 'title': 'Deliverables List'},
                {'id': 'comp-attachments', 'title': 'Required Attachments'},
                {'id': 'comp-forms', 'title': 'Required Forms'}
            ]
        })

        sections.append({
            'id': 'section-scope-objectives',
            'title': 'Understanding of Scope & Objectives',
            'status': 'In Progress',
            'guidance': 'Demonstrate a clear understanding of the project scope, objectives, and expected outcomes.',
            'content': scope_blocks or [
                'Detail your understanding of the project scope and objectives based on the solicitation requirements.'
            ],
            'sub_categories': [
                {'id': 'scope-project-scope', 'title': 'Project Scope'},
                {'id': 'scope-objectives', 'title': 'Project Objectives'},
                {'id': 'scope-expected-outcomes', 'title': 'Expected Outcomes'},
                {'id': 'scope-assumptions', 'title': 'Key Assumptions'}
            ]
        })

        sections.append({
            'id': 'section-deviations',
            'title': 'Deviations, Assumptions, and Dependencies (if any)',
            'status': 'Draft',
            'guidance': 'Document any deviations from the solicitation requirements, key assumptions, and dependencies that may impact project delivery.',
            'content': [
                'List any deviations from the solicitation requirements, if applicable.',
                'Document key assumptions made during proposal development.',
                'Identify dependencies that may affect project execution.'
            ],
            'sub_categories': [
                {'id': 'dev-deviations', 'title': 'Deviations'},
                {'id': 'dev-assumptions', 'title': 'Assumptions'},
                {'id': 'dev-dependencies', 'title': 'Dependencies'},
                {'id': 'dev-risks', 'title': 'Risk Considerations'}
            ]
        })

        tech_content = scope_blocks or [
            'Detail the technical solution, materials, and implementation methodology once the RFP requirements are parsed.'
        ]
        sections.append({
            'id': 'section-technical',
            'title': 'Proposed Technical Solution',
            'status': 'In Progress' if scope_blocks else 'Draft',
            'guidance': 'Translate the solicitation Statement of Work into your delivery plan, highlighting compliance, innovations, and risk mitigations.',
            'content': tech_content,
            'sub_categories': [
                {'id': 'tech-approach', 'title': 'Technical Approach'},
                {'id': 'tech-methodology', 'title': 'Methodology'},
                {'id': 'tech-innovations', 'title': 'Innovations & Best Practices'},
                {'id': 'tech-compliance', 'title': 'Compliance & Standards'},
                {'id': 'tech-risk-mitigation', 'title': 'Risk Mitigation'}
            ]
        })

        sections.append({
            'id': 'section-implementation',
            'title': 'Implementation & Work Plan',
            'status': 'In Progress',
            'guidance': 'Provide a detailed implementation plan and work breakdown structure for project execution.',
            'content': [
                'Outline the step-by-step implementation approach.',
                'Detail the work breakdown structure and key activities.',
                'Describe the workflow and processes for project delivery.'
            ],
            'sub_categories': [
                {'id': 'impl-approach', 'title': 'Implementation Approach'},
                {'id': 'impl-work-breakdown', 'title': 'Work Breakdown Structure'},
                {'id': 'impl-phases', 'title': 'Implementation Phases'},
                {'id': 'impl-processes', 'title': 'Key Processes'}
            ]
        })

        sections.append({
            'id': 'section-deliverables',
            'title': 'Solution Deliverables',
            'status': 'In Progress',
            'guidance': 'List all deliverables that will be provided as part of the solution, including documentation, reports, and physical items.',
            'content': [
                'Comprehensive list of all solution deliverables.',
                'Documentation and reports to be provided.',
                'Physical deliverables, if applicable.'
            ],
            'sub_categories': [
                {'id': 'del-documentation', 'title': 'Documentation Deliverables'},
                {'id': 'del-reports', 'title': 'Reports & Analysis'},
                {'id': 'del-physical', 'title': 'Physical Deliverables'},
                {'id': 'del-schedule', 'title': 'Delivery Schedule'}
            ]
        })

        management_content = compact_list([
            f"Target submission date: {due_text}." if due_text else 'Submission date will be updated when the procurement schedule is confirmed.',
            f"Contract type guidance: {type_text}." if type_text else '',
            "Outline major milestones, design reviews, and government touchpoints that support a compliant response."
        ])
        sections.append({
            'id': 'section-management',
            'title': 'Project Management Plan',
            'status': 'In Progress',
            'guidance': 'Map the internal review cycle, color team dates, and delivery milestones to ensure on-time submission.',
            'content': management_content or [
                'Add the project management narrative and schedule once the capture calendar is finalized.'
            ],
            'sub_categories': [
                {'id': 'mgmt-organization', 'title': 'Project Organization'},
                {'id': 'mgmt-resources', 'title': 'Resource Management'},
                {'id': 'mgmt-quality', 'title': 'Quality Assurance'},
                {'id': 'mgmt-communication', 'title': 'Communication Plan'}
            ]
        })

        sections.append({
            'id': 'section-schedule',
            'title': 'Project Schedule & Milestones',
            'status': 'In Progress',
            'guidance': 'Provide a detailed project schedule with key milestones, deliverables, and timeline.',
            'content': [
                'Detailed project timeline with start and end dates.',
                'Key milestones and their target dates.',
                'Critical path and dependencies.'
            ],
            'sub_categories': [
                {'id': 'schedule-timeline', 'title': 'Project Timeline'},
                {'id': 'schedule-milestones', 'title': 'Key Milestones'},
                {'id': 'schedule-critical-path', 'title': 'Critical Path'},
                {'id': 'schedule-dependencies', 'title': 'Dependencies'}
            ]
        })

        sections.append({
            'id': 'section-team',
            'title': 'Project Team',
            'status': 'In Progress',
            'guidance': 'Introduce the project team members, their roles, qualifications, and responsibilities.',
            'content': [
                'List of key team members and their roles.',
                'Qualifications and experience of team members.',
                'Organizational structure and reporting lines.'
            ],
            'sub_categories': [
                {'id': 'team-members', 'title': 'Team Members'},
                {'id': 'team-roles', 'title': 'Roles & Responsibilities'},
                {'id': 'team-qualifications', 'title': 'Qualifications'},
                {'id': 'team-organization', 'title': 'Organization Structure'}
            ]
        })

        sections.append({
            'id': 'section-corporate',
            'title': 'Corporate Qualifications',
            'status': 'Saved',
            'guidance': 'Highlight corporate experience, past performance, certifications, and qualifications relevant to this opportunity.',
            'content': [
                'Company background and history.',
                'Relevant past performance and case studies.',
                'Certifications, accreditations, and qualifications.'
            ],
            'sub_categories': [
                {'id': 'corp-background', 'title': 'Company Background'},
                {'id': 'corp-past-performance', 'title': 'Past Performance'},
                {'id': 'corp-certifications', 'title': 'Certifications & Accreditations'},
                {'id': 'corp-capabilities', 'title': 'Key Capabilities'}
            ]
        })

        price_content = compact_list([
            f"Estimated contract value: {revenue_text}." if revenue_text else '',
            "Attachment A pricing will mirror the government-provided workbook with CLIN-level details.",
            "Document all pricing assumptions, escalation factors, and exclusions for contracting officer review."
        ])
        sections.append({
            'id': 'section-pricing',
            'title': 'Pricing Proposals',
            'status': 'Saved' if revenue_text else 'Draft',
            'guidance': 'Ensure Attachment A reflects current quantities, rates, and assumptions. Cross-check CLIN totals before submission.',
            'content': price_content or [
                'Populate Attachment A once final quantities and labor categories are confirmed.'
            ],
            'sub_categories': [
                {'id': 'price-clin-breakdown', 'title': 'CLIN Breakdown'},
                {'id': 'price-labor-rates', 'title': 'Labor Rates & Categories'},
                {'id': 'price-materials', 'title': 'Materials & Equipment'},
                {'id': 'price-assumptions', 'title': 'Pricing Assumptions'},
                {'id': 'price-total-summary', 'title': 'Total Cost Summary'}
            ]
        })

        sections.append({
            'id': 'section-contractual',
            'title': 'Contractual Terms',
            'status': 'Saved',
            'guidance': 'Outline key contractual terms, conditions, and agreements proposed for this engagement.',
            'content': [
                'Key contractual terms and conditions.',
                'Payment terms and conditions.',
                'Terms of service and deliverables.'
            ],
            'sub_categories': [
                {'id': 'contract-terms', 'title': 'Terms & Conditions'},
                {'id': 'contract-payment', 'title': 'Payment Terms'},
                {'id': 'contract-service', 'title': 'Service Terms'},
                {'id': 'contract-legal', 'title': 'Legal Considerations'}
            ]
        })

        sections.append({
            'id': 'section-project-schedule',
            'title': 'Project Schedule & Milestones',
            'status': 'Pending',
            'guidance': 'Confirm the bond amount, surety approval, and Treasury Circular 570 listing for the guarantor.',
            'content': [
                f"{company_display} will coordinate with the approved surety to furnish the required Project Schedule & Milestones prior to submission.",
                "Include the original bid bond or irrevocable letter of credit documentation in the final package."
            ],
           
        })

        sections.append({
            'id': 'requirements-attachments',
            'title': 'Requirements and Attachments',
            'status': 'Special Section',
            'guidance': 'List mandatory submission requirements, certifications, and attachment references extracted from the RFP.',
            'content': [
                'Compile all mandatory attachments, compliance documents, and certifications referenced throughout the solicitation.',
                'Ensure each attachment is labeled clearly and referenced in the compliance matrix.'
            ],
            'sub_categories': [
                {'id': 'req-mandatory', 'title': 'Mandatory Documents'},
                {'id': 'req-forms', 'title': 'Forms & Certifications'},
                {'id': 'req-checklist', 'title': 'Submission Checklist'}
            ]
        })

        sections.append({
            'id': 'section-amendments',
            'title': 'Addenda',
            'status': 'Pending',
            'guidance': 'Log each amendment number and release date. If no amendments were issued, include a statement confirming that status.',
            'content': [
                f"The offer or acknowledges receipt of all amendments released for {project_name} as of {datetime.now().strftime('%B %d, %Y')}." if project_name else
                f"The offer or acknowledges receipt of all solicitation amendments issued as of {datetime.now().strftime('%B %d, %Y')}.",
                "Update this section with individual amendment numbers and dates when the contracting officer publishes them."
            ],
            'sub_categories': [
                {'id': 'amend-list', 'title': 'Amendment List'},
                {'id': 'amend-acknowledgment', 'title': 'Acknowledgment Statement'},
                {'id': 'amend-impact', 'title': 'Impact Assessment'}
            ]
        })

        sections.append({
            'id': 'section-appendix',
            'title': 'Appendix',
            'status': 'Draft',
            'guidance': 'Include all supporting documents, references, and additional materials referenced in the proposal.',
            'content': [
                'Supporting documents and references.',
                'Additional technical specifications.',
                'Supplementary materials and exhibits.'
            ],
            'sub_categories': [
                {'id': 'appendix-documents', 'title': 'Supporting Documents'},
                {'id': 'appendix-references', 'title': 'References'},
                {'id': 'appendix-exhibits', 'title': 'Exhibits'},
                {'id': 'appendix-other', 'title': 'Other Materials'}
            ]
        })

        sections.append({
            'id': 'section-safety',
            'title': 'Safety',
            'status': 'Draft',
            'guidance': 'Describe safety management systems, OSHA compliance, hazard mitigation, and jobsite safety protocols. Include training, PPE, incident reporting, and continuous improvement practices.',
            'content': [
                'Overview of Safety Management System (SMS) and accountability.',
                'OSHA compliance approach and hazard identification and mitigation processes.',
                'Jobsite safety plan, tailgate meetings, and Job Hazard Analysis (JHA) procedures.',
                'Training matrix, certifications, and PPE standards.',
                'Incident reporting, root cause analysis, and corrective actions.'
            ],
            'sub_categories': [
                {'id': 'safety-plan', 'title': 'Safety Plan'},
                {'id': 'safety-compliance', 'title': 'Regulatory Compliance'},
                {'id': 'safety-training', 'title': 'Training & Certifications'},
                {'id': 'safety-incident', 'title': 'Incident Response & Reporting'}
            ]
        })

        sections.append({
            'id': 'section-interconnection',
            'title': 'Interconnection',
            'status': 'Draft',
            'guidance': 'Detail utility interconnection strategy including application, studies, protection coordination, metering, and commissioning. Align with applicable tariffs, IEEE 1547, and utility standards.',
            'content': [
                'Interconnection application workflow and milestone tracking.',
                'Load flow, short circuit, and protection coordination study assumptions.',
                'Protection scheme, relays, and anti-islanding compliance.',
                'Metering, telemetry/SCADA, and communications architecture.',
                'Commissioning, witness testing, and as-built documentation.'
            ],
            'sub_categories': [
                {'id': 'ic-applications', 'title': 'Applications & Permits'},
                {'id': 'ic-studies', 'title': 'Engineering Studies'},
                {'id': 'ic-protection', 'title': 'Protection & Controls'},
                {'id': 'ic-commissioning', 'title': 'Commissioning & Testing'}
            ]
        })

        sections.append({
            'id': 'section-safety',
            'title': 'Safety',
            'status': 'Draft',
            'guidance': 'Describe safety management systems, OSHA compliance, hazard mitigation, and jobsite safety protocols. Include training, PPE, incident reporting, and continuous improvement practices.',
            'content': [
                'Overview of Safety Management System (SMS) and accountability.',
                'OSHA compliance approach and hazard identification and mitigation processes.',
                'Jobsite safety plan, tailgate meetings, and Job Hazard Analysis (JHA) procedures.',
                'Training matrix, certifications, and PPE standards.',
                'Incident reporting, root cause analysis, and corrective actions.'
            ],
            'sub_categories': [
                {'id': 'safety-plan', 'title': 'Safety Plan'},
                {'id': 'safety-compliance', 'title': 'Regulatory Compliance'},
                {'id': 'safety-training', 'title': 'Training & Certifications'},
                {'id': 'safety-incident', 'title': 'Incident Response & Reporting'}
            ]
        })

        sections.append({
            'id': 'section-interconnection',
            'title': 'Interconnection',
            'status': 'Draft',
            'guidance': 'Detail utility interconnection strategy including application, studies, protection coordination, metering, and commissioning. Align with applicable tariffs, IEEE 1547, and utility standards.',
            'content': [
                'Interconnection application workflow and milestone tracking.',
                'Load flow, short circuit, and protection coordination study assumptions.',
                'Protection scheme, relays, and anti-islanding compliance.',
                'Metering, telemetry/SCADA, and communications architecture.',
                'Commissioning, witness testing, and as-built documentation.'
            ],
            'sub_categories': [
                {'id': 'ic-applications', 'title': 'Applications & Permits'},
                {'id': 'ic-studies', 'title': 'Engineering Studies'},
                {'id': 'ic-protection', 'title': 'Protection & Controls'},
                {'id': 'ic-commissioning', 'title': 'Commissioning & Testing'}
            ]
        })

        return sections

    if request.method == 'POST':
        try:
            files = request.files.getlist('rfp_files')
            company = normalize_company_choice(request.form.get('company', '').strip())
            template = request.form.get('template', 'standard').strip()
            bid_name = request.args.get('bid_name', '') or request.form.get('bid_name', '')
            bid_id_value = (
                request.args.get('bid_id', type=int)
                or request.form.get('bid_id', type=int)
                or request.args.get('g_id', type=int)
                or request.form.get('g_id', type=int)
            )
            bid_meta_for_generation = get_bid_metadata(bid_id_value)
            sections_outline_for_generation = build_sections_outline(
                bid_meta_for_generation,
                bid_name,
                company,
                contact_email
            )
            
            if not files or len(files) == 0:
                # No new file uploaded; try using the latest RFP file already saved for this bid
                try:
                    g_id_for_lookup = (
                        request.args.get('bid_id', type=int)
                        or request.form.get('bid_id', type=int)
                        or request.args.get('g_id', type=int)
                        or request.form.get('g_id', type=int)
                        or bid_id_value
                    )
                    rfp_row = _get_latest_rfp_file_for_bid(g_id_for_lookup) if g_id_for_lookup else None
                    rfp_path = rfp_row.get('file_path') if rfp_row else None
                    rfp_name = rfp_row.get('filename') if rfp_row else None
                except Exception:
                    rfp_path = None
                    rfp_name = None
                if not rfp_path or not os.path.exists(rfp_path):
                    flash('Please attach an RFP PDF or ensure an RFP is uploaded for this bid.', 'error')
                    return redirect(url_for('proposals_making'))
                
                # Generate proposal from database RFP file
                import uuid
                proposals_dir = 'uploads/proposals'
                os.makedirs(proposals_dir, exist_ok=True)
                processed_files = []
                errors = []
                try:
                    unique_id = str(uuid.uuid4())[:8]
                    filename = rfp_name or os.path.basename(rfp_path)
                    proposal_filename = f"proposal_{unique_id}_{(filename or 'rfp').replace('.pdf', '.docx')}"
                    proposal_path = os.path.join(proposals_dir, proposal_filename)
                    
                    success = generate_complete_proposal(
                        rfp_path,
                        company,
                        template,
                        proposal_path,
                        bid_name=bid_name,
                        sections_outline=sections_outline_for_generation,
                        user_email=contact_email
                    )
                    if success:
                        cur = mysql.connection.cursor(DictCursor)
                        try:
                            # Ensure table exists (idempotent)
                            cur.execute("""
                                CREATE TABLE IF NOT EXISTS proposals (
                                    id INT AUTO_INCREMENT PRIMARY KEY,
                                    unique_id VARCHAR(50) NOT NULL UNIQUE,
                                    rfp_name VARCHAR(500) NOT NULL,
                                    rfp_filename VARCHAR(500),
                                    proposal_filename VARCHAR(500) NOT NULL,
                                    proposal_path VARCHAR(1000) NOT NULL,
                                    company VARCHAR(100) NOT NULL,
                                    template VARCHAR(100),
                                    bid_id INT NULL,
                                    bid_name VARCHAR(500) NULL,
                                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                                    INDEX idx_unique_id (unique_id),
                                    INDEX idx_rfp_name (rfp_name),
                                    INDEX idx_company (company),
                                    INDEX idx_bid_id (bid_id)
                                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
                            """)
                            bid_id = (
                                request.args.get('bid_id', type=int)
                                or request.form.get('bid_id', type=int)
                                or request.args.get('g_id', type=int)
                                or request.form.get('g_id', type=int)
                            )
                            cur.execute("""
                                INSERT INTO proposals 
                                (unique_id, rfp_name, rfp_filename, proposal_filename, proposal_path, company, template, bid_id, bid_name)
                                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                            """, (
                                unique_id,
                                filename or '',
                                filename or '',
                                proposal_filename,
                                proposal_path,
                                company,
                                template,
                                bid_id if bid_id else None,
                                bid_name if bid_name else None
                            ))
                            mysql.connection.commit()
                            processed_files.append({
                                'original': filename,
                                'proposal': proposal_filename,
                                'path': proposal_path,
                                'unique_id': unique_id,
                                'rfp_name': filename
                            })
                            log_write('proposal_generated', f"file={filename} company={company} template={template} unique_id={unique_id} bid_id={bid_id}")
                        except Exception as db_error:
                            mysql.connection.rollback()
                            print(f"Database error: {str(db_error)}")
                            processed_files.append({
                                'original': filename,
                                'proposal': proposal_filename,
                                'path': proposal_path,
                                'unique_id': unique_id,
                                'rfp_name': filename
                            })
                        finally:
                            cur.close()
                    else:
                        errors.append(f"Failed to generate proposal for {rfp_name or os.path.basename(rfp_path)}")
                except Exception as e:
                    errors.append(f"Error processing database RFP: {str(e)}")
                
                if processed_files:
                    flash(f'Successfully generated {len(processed_files)} proposal(s).', 'success')
                if errors:
                    flash(f'Errors: {"; ".join(errors)}', 'error')
                return redirect(url_for('proposals_making'))
            
            if not company:
                flash('Please select a company.', 'error')
                return redirect(url_for('proposals_making'))
            
            import uuid
            from werkzeug.utils import secure_filename
            
            # Create proposals directory
            proposals_dir = 'uploads/proposals'
            os.makedirs(proposals_dir, exist_ok=True)
            
            processed_files = []
            errors = []
            
            for file in files:
                if file and file.filename:
                    if not file.filename.lower().endswith('.pdf'):
                        errors.append(f"{file.filename} is not a PDF file")
                        continue
                    
                    # Save uploaded file temporarily
                    filename = secure_filename(file.filename)
                    unique_id = str(uuid.uuid4())[:8]
                    temp_filename = f"{unique_id}_{filename}"
                    temp_path = os.path.join('uploads/rfp', temp_filename)
                    os.makedirs('uploads/rfp', exist_ok=True)
                    file.save(temp_path)
                    
                    try:
                        # Generate complete proposal with all sections
                        proposal_filename = f"proposal_{unique_id}_{filename.replace('.pdf', '.docx')}"
                        proposal_path = os.path.join(proposals_dir, proposal_filename)
                        
                        # Generate complete proposal using AI
                        success = generate_complete_proposal(
                            temp_path,
                            company,
                            template,
                            proposal_path,
                            bid_name=bid_name,
                            sections_outline=sections_outline_for_generation,
                            user_email=contact_email
                        )
                        
                        if success:
                            # Save proposal data to database
                            cur = mysql.connection.cursor(DictCursor)
                            try:
                                # Create proposals table if it doesn't exist
                                cur.execute("""
                                    CREATE TABLE IF NOT EXISTS proposals (
                                        id INT AUTO_INCREMENT PRIMARY KEY,
                                        unique_id VARCHAR(50) NOT NULL UNIQUE,
                                        rfp_name VARCHAR(500) NOT NULL,
                                        rfp_filename VARCHAR(500),
                                        proposal_filename VARCHAR(500) NOT NULL,
                                        proposal_path VARCHAR(1000) NOT NULL,
                                        company VARCHAR(100) NOT NULL,
                                        template VARCHAR(100),
                                        bid_id INT NULL,
                                        bid_name VARCHAR(500) NULL,
                                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                                        INDEX idx_unique_id (unique_id),
                                        INDEX idx_rfp_name (rfp_name),
                                        INDEX idx_company (company),
                                        INDEX idx_bid_id (bid_id)
                                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
                                """)
                                
                                # Get bid_id (aka g_id) and bid_name from query parameters if available
                                bid_id = (
                                    request.args.get('bid_id', type=int)
                                    or request.form.get('bid_id', type=int)
                                    or request.args.get('g_id', type=int)
                                    or request.form.get('g_id', type=int)
                                )
                                bid_name = request.args.get('bid_name', '') or request.form.get('bid_name', '')
                                
                                # Insert proposal record
                                cur.execute("""
                                    INSERT INTO proposals 
                                    (unique_id, rfp_name, rfp_filename, proposal_filename, proposal_path, company, template, bid_id, bid_name)
                                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                                """, (
                                    unique_id,
                                    filename,  # RFP name
                                    filename,  # RFP filename
                                    proposal_filename,
                                    proposal_path,
                                    company,
                                    template,
                                    bid_id if bid_id else None,
                                    bid_name if bid_name else None
                                ))
                                mysql.connection.commit()
                                
                                processed_files.append({
                                    'original': filename,
                                    'proposal': proposal_filename,
                                    'path': proposal_path,
                                    'unique_id': unique_id,
                                    'rfp_name': filename
                                })
                                log_write('proposal_generated', f"file={filename} company={company} template={template} unique_id={unique_id} bid_id={bid_id}")
                            except Exception as db_error:
                                mysql.connection.rollback()
                                print(f"Database error: {str(db_error)}")
                                # Still add to processed_files even if DB save fails
                                processed_files.append({
                                    'original': filename,
                                    'proposal': proposal_filename,
                                    'path': proposal_path,
                                    'unique_id': unique_id,
                                    'rfp_name': filename
                                })
                            finally:
                                cur.close()
                        else:
                            errors.append(f"Failed to generate executive summary for {filename}")
                    except Exception as e:
                        errors.append(f"Error processing {filename}: {str(e)}")
                        if os.path.exists(temp_path):
                            os.remove(temp_path)
            
            if processed_files:
                flash(f'Successfully generated {len(processed_files)} proposal(s).', 'success')
            if errors:
                flash(f'Errors: {"; ".join(errors)}', 'error')
            
            return redirect(url_for('proposals_making'))
        
        except Exception as e:
            flash(f'Error: {str(e)}', 'error')
            return redirect(url_for('proposals_making'))
    
    # GET request - show page
    import os
    from datetime import datetime
    
    # Get bid_id (a.k.a g_id) and bid_name from query parameters if available (from Generate Proposals button)
    bid_id = request.args.get('bid_id', type=int)
    if bid_id is None:
        bid_id = request.args.get('g_id', type=int)
    bid_name = request.args.get('bid_name', '')
    company = request.args.get('company', '')

    contact_email = getattr(current_user, 'email', '')

    def safe_str(value):
        if value is None:
            return ''
        return str(value).strip()

    def format_date_for_display(value):
        if not value:
            return ''
        if isinstance(value, (datetime, date)):
            return value.strftime('%B %d, %Y')
        try:
            parsed = datetime.strptime(str(value), '%Y-%m-%d')
            return parsed.strftime('%B %d, %Y')
        except Exception:
            return str(value)

    def split_text_blocks(text, max_blocks=3):
        if not text:
            return []
        blocks = [
            safe_str(piece).strip('???- ') for piece in re.split(r'(?:\r?\n){2,}', str(text))
            if safe_str(piece)
        ]
        if not blocks and safe_str(text):
            blocks = [safe_str(text)]
        return blocks[:max_blocks]

    def compact_list(items):
        result = []
        for item in items:
            if item is None:
                continue
            text = safe_str(item)
            if text:
                result.append(text)
        return result

    def build_sections_outline(bid_info, fallback_title, company_name, primary_contact):
        bid = bid_info or {}
        project_name = safe_str(bid.get('b_name')) or safe_str(fallback_title) or 'Current Opportunity'
        due_text = format_date_for_display(bid.get('due_date'))
        client_name = safe_str(
            bid.get('agency') or bid.get('customer') or bid.get('client') or bid.get('owner') or bid.get('comp_name')
        )
        scope_text = safe_str(bid.get('scope'))
        summary_text = safe_str(bid.get('summary'))
        type_text = safe_str(bid.get('type'))
        location_text = safe_str(bid.get('location') or bid.get('city') or bid.get('state'))
        stage_text = safe_str(bid.get('state'))
        company_display = safe_str(company_name) or safe_str(bid.get('company')) or 'Offer or'
        revenue_value = bid.get('revenue') if bid.get('revenue') not in (None, '') else bid.get('value')
        scoring_value = bid.get('scoring')

        summary_blocks = split_text_blocks(summary_text, 4)
        scope_blocks = split_text_blocks(scope_text, 5)

        revenue_text = ''
        if revenue_value not in (None, ''):
            try:
                revenue_text = f"${float(revenue_value):,.0f}"
            except Exception:
                revenue_text = safe_str(revenue_value)

        scoring_text = ''
        if scoring_value not in (None, ''):
            try:
                scoring_text = f"{float(scoring_value):.0f}"
            except Exception:
                scoring_text = safe_str(scoring_value)

        sections = []

        cover_content = compact_list([
            f"{company_display} is pleased to submit this proposal for {project_name}.",
            f"Issuing agency / customer: {client_name}." if client_name else '',
            f"Solicitation reference: {project_name}.",
            f"Proposal due date: {due_text}." if due_text else '',
            f"Primary point of contact: {primary_contact}." if primary_contact else '',
            f"Contract type: {type_text}." if type_text else '',
            f"Performance location: {location_text}." if location_text else '',
            f"Opportunity priority score: {scoring_text}." if scoring_text else ''
        ])
        sections.append({
            'id': 'section-cover',
            'title': 'Letter of Transmittal',
            'status': 'Saved' if cover_content else 'Draft',
            'guidance': 'Confirm the solicitation title, client information, offer or contact details, and submission identifiers before releasing the cover page.',
            'content': cover_content or ['Add cover page details once the capture team confirms the solicitation data.'],
            'sub_categories': [
                {'id': 'cover-company-info', 'title': 'Company Information'},
                {'id': 'cover-contact-details', 'title': 'Contact Details'},
                {'id': 'cover-solicitation-ref', 'title': 'Solicitation Reference'},
                {'id': 'cover-submission-date', 'title': 'Submission Date & Deadline'}
            ]
        })

        sections.append({
            'id': 'section-toc',
            'title': 'Table of Contents',
            'status': 'Saved',
            'guidance': 'Generate a comprehensive table of contents listing all proposal sections and their page numbers.',
            'content': [
                'The table of contents will be automatically generated once all sections are finalized.',
                'Ensure all major sections and subsections are included with accurate page references.'
            ],
            'sub_categories': [
                {'id': 'toc-main-sections', 'title': 'Main Sections'},
                {'id': 'toc-appendices', 'title': 'Appendices'},
                {'id': 'toc-figures-tables', 'title': 'Figures & Tables'}
            ]
        })

        exec_content = summary_blocks or (
            [f"{company_display} will deliver a compliant, value-focused response for {project_name}."]
            if project_name else []
        )
        if scope_text and not summary_blocks:
            exec_content.append(scope_text)
        sections.append({
            'id': 'section-executive-summary',
            'title': 'Executive Summary',
            'status': 'In Progress' if summary_blocks else 'Draft',
            'guidance': "Summarize win themes, differentiators, and alignment to the customer's objectives captured during bid qualification.",
            'content': exec_content or ['Executive summary content will be generated as soon as capture notes are available.'],
            'sub_categories': [
                {'id': 'exec-overview', 'title': 'Project Overview'},
                {'id': 'exec-win-themes', 'title': 'Win Themes & Differentiators'},
                {'id': 'exec-value-proposition', 'title': 'Value Proposition'},
                {'id': 'exec-key-highlights', 'title': 'Key Highlights'}
            ]
        })

        compliance_content = compact_list([
            "Track each requirement in the compliance matrix to ensure every section of the RFP is addressed.",
            scope_blocks[0] if scope_blocks else '',
            summary_blocks[0] if summary_blocks else ''
        ])
        sections.append({
            'id': 'section-compliance',
            'title': 'Requirements Compliance',
            'status': 'In Progress',
            'guidance': 'Reference the compliance matrix and list every deliverable, attachment, and form demanded by the solicitation.',
            'content': compliance_content or [
                'Populate this section with compliance findings once the RFP analysis is complete.'
            ],
            'sub_categories': [
                {'id': 'comp-matrix', 'title': 'Compliance Matrix'},
                {'id': 'comp-deliverables', 'title': 'Deliverables List'},
                {'id': 'comp-attachments', 'title': 'Required Attachments'},
                {'id': 'comp-forms', 'title': 'Required Forms'}
            ]
        })

        sections.append({
            'id': 'section-scope-objectives',
            'title': 'Understanding of Scope & Objectives',
            'status': 'In Progress',
            'guidance': 'Demonstrate a clear understanding of the project scope, objectives, and expected outcomes.',
            'content': scope_blocks or [
                'Detail your understanding of the project scope and objectives based on the solicitation requirements.'
            ],
            'sub_categories': [
                {'id': 'scope-project-scope', 'title': 'Project Scope'},
                {'id': 'scope-objectives', 'title': 'Project Objectives'},
                {'id': 'scope-expected-outcomes', 'title': 'Expected Outcomes'},
                {'id': 'scope-assumptions', 'title': 'Key Assumptions'}
            ]
        })

        sections.append({
            'id': 'section-deviations',
            'title': 'Deviations, Assumptions, and Dependencies (if any)',
            'status': 'Draft',
            'guidance': 'Document any deviations from the solicitation requirements, key assumptions, and dependencies that may impact project delivery.',
            'content': [
                'List any deviations from the solicitation requirements, if applicable.',
                'Document key assumptions made during proposal development.',
                'Identify dependencies that may affect project execution.'
            ],
            'sub_categories': [
                {'id': 'dev-deviations', 'title': 'Deviations'},
                {'id': 'dev-assumptions', 'title': 'Assumptions'},
                {'id': 'dev-dependencies', 'title': 'Dependencies'},
                {'id': 'dev-risks', 'title': 'Risk Considerations'}
            ]
        })

        tech_content = scope_blocks or [
            'Detail the technical solution, materials, and implementation methodology once the RFP requirements are parsed.'
        ]
        sections.append({
            'id': 'section-technical',
            'title': 'Proposed Technical Solution',
            'status': 'In Progress' if scope_blocks else 'Draft',
            'guidance': 'Translate the solicitation Statement of Work into your delivery plan, highlighting compliance, innovations, and risk mitigations.',
            'content': tech_content,
            'sub_categories': [
                {'id': 'tech-approach', 'title': 'Technical Approach'},
                {'id': 'tech-methodology', 'title': 'Methodology'},
                {'id': 'tech-innovations', 'title': 'Innovations & Best Practices'},
                {'id': 'tech-compliance', 'title': 'Compliance & Standards'},
                {'id': 'tech-risk-mitigation', 'title': 'Risk Mitigation'}
            ]
        })

        sections.append({
            'id': 'section-implementation',
            'title': 'Implementation & Work Plan',
            'status': 'In Progress',
            'guidance': 'Provide a detailed implementation plan and work breakdown structure for project execution.',
            'content': [
                'Outline the step-by-step implementation approach.',
                'Detail the work breakdown structure and key activities.',
                'Describe the workflow and processes for project delivery.'
            ],
            'sub_categories': [
                {'id': 'impl-approach', 'title': 'Implementation Approach'},
                {'id': 'impl-work-breakdown', 'title': 'Work Breakdown Structure'},
                {'id': 'impl-phases', 'title': 'Implementation Phases'},
                {'id': 'impl-processes', 'title': 'Key Processes'}
            ]
        })

        sections.append({
            'id': 'section-deliverables',
            'title': 'Solution Deliverables',
            'status': 'In Progress',
            'guidance': 'List all deliverables that will be provided as part of the solution, including documentation, reports, and physical items.',
            'content': [
                'Comprehensive list of all solution deliverables.',
                'Documentation and reports to be provided.',
                'Physical deliverables, if applicable.'
            ],
            'sub_categories': [
                {'id': 'del-documentation', 'title': 'Documentation Deliverables'},
                {'id': 'del-reports', 'title': 'Reports & Analysis'},
                {'id': 'del-physical', 'title': 'Physical Deliverables'},
                {'id': 'del-schedule', 'title': 'Delivery Schedule'}
            ]
        })

        management_content = compact_list([
            f"Target submission date: {due_text}." if due_text else 'Submission date will be updated when the procurement schedule is confirmed.',
          
            f"Contract type guidance: {type_text}." if type_text else '',
            "Outline major milestones, design reviews, and government touchpoints that support a compliant response."
        ])
        sections.append({
            'id': 'section-management',
            'title': 'Project Management Plan',
            'status': 'In Progress',
            'guidance': 'Map the internal review cycle, color team dates, and delivery milestones to ensure on-time submission.',
            'content': management_content or [
                'Add the project management narrative and schedule once the capture calendar is finalized.'
            ],
            'sub_categories': [
                {'id': 'mgmt-organization', 'title': 'Project Organization'},
                {'id': 'mgmt-schedule', 'title': 'Project Schedule & Milestones'},
                {'id': 'mgmt-resources', 'title': 'Resource Management'},
                {'id': 'mgmt-quality', 'title': 'Quality Assurance'},
                {'id': 'mgmt-communication', 'title': 'Communication Plan'}
            ]
        })

        price_content = compact_list([
            f"Estimated contract value: {revenue_text}." if revenue_text else '',
            "Attachment A pricing will mirror the government-provided workbook with CLIN-level details.",
            "Document all pricing assumptions, escalation factors, and exclusions for contracting officer review."
        ])
        sections.append({
            'id': 'section-pricing',
            'title': 'Pricing Proposals',
            'status': 'Saved' if revenue_text else 'Draft',
            'guidance': 'Ensure Attachment A reflects current quantities, rates, and assumptions. Cross-check CLIN totals before submission.',
            'content': price_content or [
                'Populate Attachment A once final quantities and labor categories are confirmed.'
            ],
            'sub_categories': [
                {'id': 'price-clin-breakdown', 'title': 'CLIN Breakdown'},
                {'id': 'price-labor-rates', 'title': 'Labor Rates & Categories'},
                {'id': 'price-materials', 'title': 'Materials & Equipment'},
                {'id': 'price-assumptions', 'title': 'Pricing Assumptions'},
                {'id': 'price-total-summary', 'title': 'Total Cost Summary'}
            ]
        })

        sections.append({
            'id': 'section-contractual',
            'title': 'Contractual Terms',
            'status': 'Saved',
            'guidance': 'Outline key contractual terms, conditions, and agreements proposed for this engagement.',
            'content': [
                'Key contractual terms and conditions.',
                'Payment terms and conditions.',
                'Terms of service and deliverables.'
            ],
            'sub_categories': [
                {'id': 'contract-terms', 'title': 'Terms & Conditions'},
                {'id': 'contract-payment', 'title': 'Payment Terms'},
                {'id': 'contract-service', 'title': 'Service Terms'},
                {'id': 'contract-legal', 'title': 'Legal Considerations'}
            ]
        })

        sections.append({
            'id': 'section-project-schedule',
            'title': 'Project Schedule & Milestones',
            'status': 'Pending',
            'guidance': 'Confirm the bond amount, surety approval, and Treasury Circular 570 listing for the guarantor.',
            'content': [
                f"{company_display} will coordinate with the approved surety to furnish the required Project Schedule & Milestones prior to submission.",
                "Include the original bid bond or irrevocable letter of credit documentation in the final package."
            ],
           
        })

        sections.append({
            'id': 'section-team',
            'title': 'Project Team',
            'status': 'In Progress',
            'guidance': 'Introduce the project team members, their roles, qualifications, and responsibilities.',
            'content': [
                'List of key team members and their roles.',
                'Qualifications and experience of team members.',
                'Organizational structure and reporting lines.'
            ],
            'sub_categories': [
                {'id': 'team-members', 'title': 'Team Members'},
                {'id': 'team-roles', 'title': 'Roles & Responsibilities'},
                {'id': 'team-qualifications', 'title': 'Qualifications'},
                {'id': 'team-organization', 'title': 'Organization Structure'}
            ]
        })

        sections.append({
            'id': 'section-corporate',
            'title': 'Corporate Qualifications',
            'status': 'Saved',
            'guidance': 'Highlight corporate experience, past performance, certifications, and qualifications relevant to this opportunity.',
            'content': [
                'Company background and history.',
                'Relevant past performance and case studies.',
                'Certifications, accreditations, and qualifications.'
            ],
            'sub_categories': [
                {'id': 'corp-background', 'title': 'Company Background'},
                {'id': 'corp-past-performance', 'title': 'Past Performance'},
                {'id': 'corp-certifications', 'title': 'Certifications & Accreditations'},
                {'id': 'corp-capabilities', 'title': 'Key Capabilities'}
            ]
        })

        sections.append({
            'id': 'section-reps-certs',
            'title': 'Representations and Certifications',
            'status': 'Saved',
            'guidance': 'Confirm FAR, DFARS, SAM.gov, and agency-specific representations are current and included.',
            'content': [
                'All FAR and DFARS representations will be validated against the active SAM registration prior to submission.',
                'Include any agency-specific attestations or forms requested in the solicitation instructions.'
            ],
            'sub_categories': [
                {'id': 'reps-far', 'title': 'FAR Representations'},
                {'id': 'reps-dfars', 'title': 'DFARS Representations'},
                {'id': 'reps-sam', 'title': 'SAM.gov Certifications'},
                {'id': 'reps-agency', 'title': 'Agency-Specific Certifications'}
            ]
        })

        sections.append({
            'id': 'section-amendments',
            'title': 'Addenda',
            'status': 'Pending',
            'guidance': 'Log each amendment number and release date. If no amendments were issued, include a statement confirming that status.',
            'content': [
                f"The offer or acknowledges receipt of all amendments released for {project_name} as of {datetime.now().strftime('%B %d, %Y')}." if project_name else
                f"The offer or acknowledges receipt of all solicitation amendments issued as of {datetime.now().strftime('%B %d, %Y')}.",
                "Update this section with individual amendment numbers and dates when the contracting officer publishes them."
            ],
            'sub_categories': [
                {'id': 'amend-list', 'title': 'Amendment List'},
                {'id': 'amend-acknowledgment', 'title': 'Acknowledgment Statement'},
                {'id': 'amend-impact', 'title': 'Impact Assessment'}
            ]
        })

        sections.append({
            'id': 'section-appendix',
            'title': 'Appendix',
            'status': 'Draft',
            'guidance': 'Include all supporting documents, references, and additional materials referenced in the proposal.',
            'content': [
                'Supporting documents and references.',
                'Additional technical specifications.',
                'Supplementary materials and exhibits.'
            ],
            'sub_categories': [
                {'id': 'appendix-documents', 'title': 'Supporting Documents'},
                {'id': 'appendix-references', 'title': 'References'},
                {'id': 'appendix-exhibits', 'title': 'Exhibits'},
                {'id': 'appendix-other', 'title': 'Other Materials'}
            ]
        })

        return sections

    def build_bid_context(bid_info, fallback_title, company_name):
        info = bid_info or {}
        project_name = safe_str(info.get('b_name')) or safe_str(fallback_title)
        due_text = format_date_for_display(info.get('due_date'))
        summary_text = safe_str(info.get('summary'))
        scope_text = safe_str(info.get('scope'))
        location_text = safe_str(info.get('location') or info.get('city') or info.get('state'))
        type_text = safe_str(info.get('type'))
        stage_text = safe_str(info.get('state'))
        revenue_value = info.get('revenue') if info.get('revenue') not in (None, '') else info.get('value')
        scoring_value = info.get('scoring')

        revenue_text = ''
        if revenue_value not in (None, ''):
            try:
                revenue_text = f"${float(revenue_value):,.0f}"
            except Exception:
                revenue_text = safe_str(revenue_value)

        scoring_text = ''
        if scoring_value not in (None, ''):
            try:
                scoring_text = f"{float(scoring_value):.0f}"
            except Exception:
                scoring_text = safe_str(scoring_value)

        summary_excerpt = ''
        source_text = summary_text or scope_text
        if source_text:
            summary_excerpt = source_text if len(source_text) <= 220 else source_text[:217].rstrip() + '???'

        info_chips = []
        if due_text:
            info_chips.append({'label': 'Due', 'value': due_text, 'icon': 'calendar-days'})
        if type_text:
            info_chips.append({'label': 'Type', 'value': type_text, 'icon': 'diagram-project'})
        if location_text:
            info_chips.append({'label': 'Location', 'value': location_text, 'icon': 'location-dot'})
        if revenue_text:
            info_chips.append({'label': 'Est. Value', 'value': revenue_text, 'icon': 'sack-dollar'})
        if stage_text:
            info_chips.append({'label': 'Stage', 'value': stage_text.title() if stage_text else stage_text, 'icon': 'gauge-high'})
        if scoring_text:
            info_chips.append({'label': 'Score', 'value': scoring_text, 'icon': 'star-half-stroke'})

        context = {
            'project_name': project_name or safe_str(fallback_title),
            'client': safe_str(
                info.get('agency') or info.get('customer') or info.get('client') or info.get('owner')
            ),
            'company': safe_str(company_name) or safe_str(info.get('company')),
            'due_date_display': due_text,
            'summary_excerpt': summary_excerpt,
            'scope': scope_text,
            'type': type_text,
            'location': location_text,
            'rfp_label': project_name or safe_str(fallback_title),
            'info_chips': info_chips,
            'bid_id': info.get('g_id') or info.get('id'),
            'g_id': info.get('g_id')
        }
        # Remove empty values for cleaner JSON payloads
        return {k: v for k, v in context.items() if v}

    bid_meta_raw = None
    if bid_id:
        meta_cursor = mysql.connection.cursor(DictCursor)
        try:
            meta_cursor.execute("SELECT * FROM go_bids WHERE g_id=%s", (bid_id,))
            bid_meta_raw = meta_cursor.fetchone()
        except Exception as meta_err:
            print(f"Error loading bid context for proposal view: {meta_err}")
        finally:
            meta_cursor.close()

    if not company and bid_meta_raw:
        company = safe_str(bid_meta_raw.get('company'))
    # Normalize company so aliases like 'METCO Engineering' or 'Metco' select the Metco dashboard/workflow
    company = normalize_company_choice(company)

    sections_outline = build_sections_outline(bid_meta_raw, bid_name, company or (bid_meta_raw or {}).get('company'), contact_email)
    bid_context = build_bid_context(bid_meta_raw, bid_name, company or (bid_meta_raw or {}).get('company'))

    # Load proposals from database
    proposals_list = []
    cur = mysql.connection.cursor(DictCursor)
    try:
        # Create table if it doesn't exist
        cur.execute("""
            CREATE TABLE IF NOT EXISTS proposals (
                id INT AUTO_INCREMENT PRIMARY KEY,
                unique_id VARCHAR(50) NOT NULL UNIQUE,
                rfp_name VARCHAR(500) NOT NULL,
                rfp_filename VARCHAR(500),
                proposal_filename VARCHAR(500) NOT NULL,
                proposal_path VARCHAR(1000) NOT NULL,
                company VARCHAR(100) NOT NULL,
                template VARCHAR(100),
                bid_id INT NULL,
                bid_name VARCHAR(500) NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                INDEX idx_unique_id (unique_id),
                INDEX idx_rfp_name (rfp_name),
                INDEX idx_company (company),
                INDEX idx_bid_id (bid_id)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """)
        
        # Query proposals from database
        if bid_id:
            cur.execute("""
                SELECT * FROM proposals 
                WHERE bid_id = %s 
                ORDER BY created_at DESC
            """, (bid_id,))
        else:
            cur.execute("""
                SELECT * FROM proposals 
                ORDER BY created_at DESC
                LIMIT 100
            """)
        
        db_proposals = cur.fetchall()
        
        # Convert database results to list format
        for prop in db_proposals:
            proposals_list.append({
                'id': prop['id'],
                'unique_id': prop['unique_id'],
                'name': prop['proposal_filename'],
                'rfp_name': prop['rfp_name'],
                'company': prop['company'],
                'template': prop.get('template', ''),
                'bid_id': prop.get('bid_id'),
                'bid_name': prop.get('bid_name', ''),
                'created_at': prop['created_at'].strftime('%Y-%m-%d %H:%M:%S') if prop['created_at'] else '',
                'download_url': url_for('download_proposal', filename=prop['proposal_filename'])
            })
    except Exception as e:
        print(f"Error loading proposals from database: {str(e)}")
        # Fallback to file system if database fails
        proposals_dir = 'uploads/proposals'
        if os.path.exists(proposals_dir):
            for filename in os.listdir(proposals_dir):
                if filename.endswith('.docx'):
                    filepath = os.path.join(proposals_dir, filename)
                    stat = os.stat(filepath)
                    proposals_list.append({
                        'name': filename,
                        'rfp_name': filename.replace('executive_summary_', '').replace('.docx', '.pdf'),
                        'created_at': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
                        'download_url': url_for('download_proposal', filename=filename)
                    })
    finally:
        cur.close()
    
    # Load RFP files from database for this bid
    rfp_files_list = []
    if bid_id:
        rfp_cursor = mysql.connection.cursor(DictCursor)
        try:
            _ensure_uploaded_rfp_table_exists(rfp_cursor)
            # Fetch only true RFP source PDFs for this bid (exclude per-section attachments and non-PDFs)
            rfp_cursor.execute("""
                SELECT id, g_id, bid_id, filename, original_filename, saved_filename, file_path, file_size, uploaded_at, file_type, section_id
                FROM uploaded_rfp_files
                WHERE (g_id = %s OR bid_id = %s)
                  AND (section_id IS NULL OR section_id = '')
                  AND (
                        LOWER(COALESCE(file_type, '')) = 'pdf'
                     OR LOWER(filename) LIKE '%%.pdf'
                     OR LOWER(saved_filename) LIKE '%%.pdf'
                     OR LOWER(file_path) LIKE '%%.pdf'
                  )
                ORDER BY uploaded_at DESC
            """, (bid_id, bid_id))
            rfp_files = rfp_cursor.fetchall()
            
            for rfp_file in rfp_files:
                file_path = rfp_file.get('file_path')
                if file_path and os.path.exists(file_path):
                    rfp_files_list.append({
                        'id': rfp_file.get('id'),
                        'filename': rfp_file.get('filename') or rfp_file.get('original_filename', ''),
                        'file_path': file_path,
                        'file_size': rfp_file.get('file_size', 0),
                        'uploaded_at': rfp_file.get('uploaded_at'),
                        'view_url': url_for('view_rfp_file', file_id=rfp_file.get('id')),
                        'parsed_url': url_for('api_rfp_file_parsed', g_id=bid_id)
                    })
        except Exception as e:
            print(f"Error loading RFP files from database: {str(e)}")
        finally:
            rfp_cursor.close()
    
    return render_template(
        'proposals_making.html',
        proposals=proposals_list,
        bid_id=bid_id,
        bid_name=bid_name,
        company=company,
        sections_outline=sections_outline,
        bid_context=bid_context,
        contact_email=contact_email,
        rfp_files=rfp_files_list
    )

@app.route('/api/section-attachments/<int:g_id>', methods=['GET'])
@login_required
def api_list_section_attachments(g_id):
    """Return JSON list of attachments for a given section of a bid."""
    section_id = request.args.get('section_id', '').strip()
    if not section_id:
        return jsonify({'success': False, 'message': 'section_id is required'}), 400
    limit = request.args.get('limit', type=int) or 30
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_uploaded_rfp_table_exists(cur)
        cur.execute(
            """
            SELECT id, filename, file_path, file_type, uploaded_at
            FROM uploaded_rfp_files
            WHERE (g_id = %s OR bid_id = %s)
              AND section_id = %s
              AND (
                   file_type IN ('image','pdf')
                OR LOWER(filename) LIKE '%%.png'
                OR LOWER(filename) LIKE '%%.jpg'
                OR LOWER(filename) LIKE '%%.jpeg'
                OR LOWER(filename) LIKE '%%.webp'
                OR LOWER(filename) LIKE '%%.pdf'
              )
            ORDER BY uploaded_at DESC
            LIMIT %s
            """,
            (g_id, g_id, section_id, limit),
        )
        rows = cur.fetchall() or []
        files = []
        for row in rows:
            files.append({
                'id': row.get('id'),
                'filename': row.get('filename'),
                'file_type': row.get('file_type') or '',
                'view_url': url_for('view_rfp_file', file_id=row.get('id')),
                'is_pdf': bool((row.get('file_type') or '').lower() == 'pdf' or str(row.get('filename') or '').lower().endswith('.pdf')),
            })
        return jsonify({'success': True, 'files': files})
    except Exception as exc:
        app.logger.warning(f"Error listing section attachments for {g_id}/{section_id}: {exc}")
        return jsonify({'success': False, 'message': 'Failed to load attachments'}), 500
    finally:
        cur.close()

@app.route('/api/proposals-agent', methods=['POST'])
@login_required
def proposals_agent():
    """Lightweight assistant endpoint for the proposals workspace."""
    payload = request.get_json(silent=True) or {}
    message = (payload.get('message') or '').strip()
    if not message:
        return jsonify({'error': 'missing_message', 'message': 'Please provide a question for the agent.'}), 400

    history = payload.get('history') or []
    if not isinstance(history, list):
        history = []
    history = history[-10:]

    context = payload.get('context') or {}
    try:
        context_summary = {
            'workspace': 'Proposals Making',
            'user': getattr(current_user, 'email', ''),
            'company': context.get('company') or '',
            'contact_email': context.get('contactEmail') or '',
        }
        bid_info = context.get('bid') or {}
        g_id = None
        if isinstance(bid_info, dict) and bid_info:
            g_id = bid_info.get('g_id') or bid_info.get('bid_id')
            context_summary['bid'] = {
                'project_name': bid_info.get('project_name') or bid_info.get('b_name') or '',
                'bid_id': bid_info.get('bid_id') or bid_info.get('g_id') or '',
                'due_date': bid_info.get('due_date') or '',
            }
        sections = context.get('sections') or []
        if isinstance(sections, list) and sections:
            context_summary['sections'] = [
                {
                    'title': sec.get('title', ''),
                    'status': sec.get('status', ''),
                    'guidance': (sec.get('guidance') or '')[:280],
                }
                for sec in sections[:5]
                if isinstance(sec, dict)
            ]
    except Exception:
        context_summary = {}

    # Retrieve RFP document content for RAG
    rfp_content = ""
    if g_id:
        cur = None
        try:
            cur = mysql.connection.cursor(DictCursor)
            _ensure_uploaded_rfp_table_exists(cur)
            # Get the latest RFP file for this bid
            rfp_file = _get_latest_rfp_file_for_bid(g_id)
            if rfp_file and rfp_file.get('file_path'):
                file_path = rfp_file['file_path']
                if os.path.exists(file_path):
                    # Extract text from first 50 pages (to avoid token limits)
                    pages, total_pages = _extract_pdf_pages(file_path, start_page=1, limit=50)
                    if pages:
                        # Combine all page texts
                        rfp_texts = [page.get('text', '') for page in pages if page.get('text')]
                        if rfp_texts:
                            # Limit total content to ~8000 characters to stay within token limits
                            combined_text = "\n\n--- PAGE BREAK ---\n\n".join(rfp_texts)
                            if len(combined_text) > 8000:
                                combined_text = combined_text[:8000] + "... [Content truncated]"
                            rfp_content = f"\n\n--- RFP DOCUMENT CONTENT (Pages 1-{min(50, total_pages)} of {total_pages}) ---\n{combined_text}\n--- END RFP CONTENT ---"
        except Exception as e:
            app.logger.warning(f"Error retrieving RFP content for RAG: {e}")
            rfp_content = ""
        finally:
            if cur:
                cur.close()

    system_prompt = (
        "You are the ESCO proposal workspace assistant. "
        "Provide concise, actionable support for crafting winning proposals. "
        "Use the workspace context when relevant, and be explicit when information is unavailable or uncertain."
    )
    if context_summary:
        try:
            system_prompt += "\n\nWorkspace context:\n" + json.dumps(context_summary, ensure_ascii=False, indent=2)
        except Exception:
            system_prompt += "\n\nWorkspace context:\n" + str(context_summary)
    
    # Add RFP document content for RAG
    if rfp_content:
        system_prompt += "\n\nIMPORTANT: The following RFP document content is available for reference. Use this content to answer questions about the RFP requirements, specifications, deadlines, and other details. Always base your responses on the actual RFP content when available:"
        system_prompt += rfp_content

    messages = [{'role': 'system', 'content': system_prompt}]
    for entry in history:
        if not isinstance(entry, dict):
            continue
        role = entry.get('role', 'user')
        if role not in {'user', 'assistant', 'system'}:
            role = 'user'
        content = entry.get('content')
        if not content:
            continue
        messages.append({'role': role, 'content': str(content)})
    messages.append({'role': 'user', 'content': message})

    # Local Ollama fallback removed to avoid local usage
    def _try_ollama_fallback(messages_local, temperature_local=0.2):
        return None, None, None

    # Attempt primary provider (OpenAI/GROQ-compatible), then Ollama fallback on failure/rate-limit
    api_key = (os.getenv('OPENAI_API_KEY') or os.getenv('GROQ_API_KEY') or '').strip()
    base_url = (app.config.get('OPENAI_BASE_URL') or os.getenv('OPENAI_BASE_URL') or 'https://api.groq.com/openai/v1').strip()
    model = (app.config.get('OPENAI_MODEL') or os.getenv('OPENAI_MODEL') or 'meta-llama/llama-4-scout-17b-16e-instruct').strip()

    data = None
    reply = ''
    if api_key:
        endpoint = base_url.rstrip('/')
        if not endpoint.endswith('/chat/completions'):
            endpoint = f"{endpoint}/chat/completions"
        headers = {'Authorization': f'Bearer {api_key}', 'Content-Type': 'application/json'}
        body = {'model': model, 'messages': messages, 'temperature': 0.2}
        try:
            response = requests.post(endpoint, headers=headers, json=body, timeout=60)
            raw_text = response.text
            try:
                data = response.json()
            except ValueError:
                app.logger.error("Primary provider returned non-JSON (status %s): %s", response.status_code, raw_text[:400])
                data = None
            if data and response.status_code < 400:
                choices = data.get('choices') or []
                if choices:
                    reply = choices[0].get('message', {}).get('content', '') or ''
        except requests.RequestException as err:
            app.logger.exception("Primary provider network failure: %s", err)

    # If primary failed or empty, surface minimal error
    if not reply:
        if isinstance(data, dict):
            err_message = data.get('error')
            detail = ''
            if isinstance(err_message, dict):
                detail = err_message.get('message') or err_message.get('code') or ''
            elif isinstance(err_message, str):
                detail = err_message
            if not detail:
                detail = 'Upstream error'
            return jsonify({'error': 'agent_unavailable', 'message': f'AI provider error: {detail}'}), 502
        return jsonify({'error': 'agent_unavailable', 'message': 'The proposal agent could not generate a response at this time.'}), 502

    return jsonify({'reply': reply.strip(), 'model': data.get('model', model) if isinstance(data, dict) else model, 'usage': data.get('usage', {}) if isinstance(data, dict) else {}})


def _fetch_rfp_content_for_bid(bid_id, page_limit=50, char_limit=12000):
    """Load RFP text from the uploaded files for a given bid or g_id."""
    if not bid_id:
        return ''

    rfp_content = ''
    try:
        cur = mysql.connection.cursor(DictCursor)
        cur.execute(
            """
            SELECT file_path
            FROM uploaded_rfp_files
            WHERE g_id = %s OR bid_id = %s
            ORDER BY uploaded_at DESC
            LIMIT 1
            """,
            (bid_id, bid_id),
        )
        rfp_file = cur.fetchone()
        cur.close()
    except Exception as exc:
        app.logger.warning(f"Error retrieving RFP content for bid {bid_id}: {exc}")
        return ''

    file_path = rfp_file.get('file_path') if rfp_file else None
    if not file_path or not os.path.exists(file_path):
        return ''

    try:
        if _FITZ_AVAILABLE:
            doc = _pymupdf.open(file_path)
            try:
                pages = []
                for page_num in range(min(page_limit, len(doc))):
                    page = doc[page_num]
                    pages.append(page.get_text())
                rfp_content = "\n\n--- PAGE BREAK ---\n\n".join(pages)
            finally:
                doc.close()
        else:
            app.logger.info("PyMuPDF not available; skipping PDF text extraction.")
    except Exception as exc:
        app.logger.warning(f"Error reading RFP PDF for bid {bid_id}: {exc}")
        rfp_content = ''

    if rfp_content and len(rfp_content) > char_limit:
        rfp_content = rfp_content[:char_limit] + "... [Content truncated]"

    return rfp_content


def _get_section_image_files_for_bid(bid_id, section_id, limit=10):
    """Return latest image file records for a bid and section."""
    if not bid_id or not section_id:
        return []
    try:
        cur = mysql.connection.cursor(DictCursor)
        cur.execute(
            """
            SELECT file_path, filename
            FROM uploaded_rfp_files
            WHERE (g_id = %s OR bid_id = %s)
              AND section_id = %s
              AND (file_type = 'image'
                   OR LOWER(filename) LIKE '%%.png'
                   OR LOWER(filename) LIKE '%%.jpg'
                   OR LOWER(filename) LIKE '%%.jpeg'
                   OR LOWER(filename) LIKE '%%.webp')
            ORDER BY uploaded_at DESC
            LIMIT %s
            """,
            (bid_id, bid_id, section_id, limit),
        )
        rows = cur.fetchall() or []
        cur.close()
        return rows
    except Exception as exc:
        app.logger.warning(f"Error fetching section images for bid {bid_id}: {exc}")
        return []


def _extract_text_from_image(image_path: str) -> str:
    """Best-effort OCR for image files; returns empty string on failure.

    Strategy:
    1) Try pytesseract with auto-detected tesseract.exe (Windows-friendly) and light preprocessing.
    2) Fallback to EasyOCR if available (no system tesseract dependency).
    3) Gracefully return '' on any error.
    """
    try:
        import os as _os
        import shutil as _shutil
        import importlib
        from PIL import Image as _PILImage, ImageOps as _ImageOps, ImageFilter as _ImageFilter

        # Open image
        pil_img = _PILImage.open(image_path)
        # Normalize mode and improve contrast for OCR
        if 'A' in pil_img.getbands():
            pil_img = pil_img.convert('RGB')  # type: ignore[assignment]
        try:
            # Convert to grayscale and apply slight sharpening to help OCR
            pil_img = _ImageOps.grayscale(pil_img)
            pil_img = pil_img.filter(_ImageFilter.UnsharpMask(radius=1, percent=150, threshold=3))
        except Exception:
            # Continue with original if preprocessing fails
            pass

        # Attempt pytesseract first
        try:
            _pytesseract = importlib.import_module('pytesseract')
            # If tesseract is not on PATH on Windows, try common install paths or env var
            tcmd_env = _os.getenv('TESSERACT_CMD') or _os.getenv('TESSERACT_EXE')
            probable_paths = [
                tcmd_env,
                r'C:\Program Files\Tesseract-OCR\tesseract.exe',
                r'C:\Program Files (x86)\Tesseract-OCR\tesseract.exe',
            ]
            found_cmd = None
            for p in probable_paths:
                if p and _os.path.exists(p):
                    found_cmd = p
                    break
            if not found_cmd:
                found_cmd = _shutil.which('tesseract')
            if found_cmd:
                try:
                    _pytesseract.pytesseract.tesseract_cmd = found_cmd  # type: ignore[attr-defined]
                except Exception:
                    pass

            text = _pytesseract.image_to_string(pil_img) or ''  # type: ignore[attr-defined]
            text = (text or '').strip()
            if text:
                return text
        except Exception as _pt_err:
            app.logger.info(f"pytesseract OCR not available or failed for {image_path}: {_pt_err}")

        # Fallback to EasyOCR if installed (may be heavy, so optional)
        try:
            _easyocr = importlib.import_module('easyocr')
            reader = _easyocr.Reader(['en'], gpu=False)  # type: ignore[call-arg]
            # EasyOCR works with file paths directly
            result = reader.readtext(image_path, detail=0) or []  # type: ignore[assignment]
            text = '\n'.join([seg for seg in result if isinstance(seg, str)]).strip()
            if text:
                return text
        except Exception as _eo_err:
            app.logger.info(f"EasyOCR fallback not available or failed for {image_path}: {_eo_err}")

    except Exception as exc:
        app.logger.info(f"OCR pipeline failed for {image_path}: {exc}")
    return ''


def _extract_text_from_pdf(pdf_path: str, page_limit: int = 5) -> str:
    """Extract text from a PDF using PyMuPDF if available; returns '' on failure."""
    try:
        # These are defined earlier in the file for PDF support; reuse if present
        _has = globals().get('_FITZ_AVAILABLE', False)
        _mod = globals().get('_pymupdf')
        if not _has or not _mod:
            return ''
        text_parts = []
        with _mod.open(pdf_path) as doc:
            total = min(page_limit, doc.page_count or 0)
            for i in range(total):
                page = doc.load_page(i)
                text_parts.append(page.get_text('text') or '')
        return '\n'.join(text_parts).strip()
    except Exception as exc:
        app.logger.info(f"PDF extraction failed for {pdf_path}: {exc}")
        return ''


def _get_section_files_for_bid(bid_id, section_id, limit=20):
    """Return recent uploaded files for a specific section (images and PDFs)."""
    cur = mysql.connection.cursor(DictCursor)
    try:
        _ensure_uploaded_rfp_table_exists(cur)
        cur.execute(
            """
            SELECT id, filename, file_path, file_type, uploaded_at
            FROM uploaded_rfp_files
            WHERE (g_id = %s OR bid_id = %s)
              AND section_id = %s
              AND (
                   file_type IN ('image','pdf')
                   OR LOWER(filename) LIKE '%%.png'
                   OR LOWER(filename) LIKE '%%.jpg'
                   OR LOWER(filename) LIKE '%%.jpeg'
                   OR LOWER(filename) LIKE '%%.webp'
                   OR LOWER(filename) LIKE '%%.pdf'
              )
            ORDER BY uploaded_at DESC
            LIMIT %s
            """,
            (bid_id, bid_id, section_id, limit),
        )
        rows = cur.fetchall() or []
        cur.close()
        return rows
    except Exception as exc:
        app.logger.warning(f"Error fetching section files for bid {bid_id}: {exc}")
        return []


def _fetch_section_attachments_text(bid_id, section_id, char_limit=8000):
    """Aggregate text from section attachments (images + PDFs)."""
    attachments = _get_section_files_for_bid(bid_id, section_id, limit=20)
    if not attachments:
        return ''
    parts = []
    for idx, item in enumerate(attachments, start=1):
        fp = item.get('file_path')
        if not fp or not os.path.exists(fp):
            continue
        label = item.get('filename') or os.path.basename(fp)
        ftype = (item.get('file_type') or '').lower()
        extracted = ''
        try:
            if ftype == 'pdf' or fp.lower().endswith('.pdf'):
                extracted = _extract_text_from_pdf(fp, page_limit=5)
            else:
                extracted = _extract_text_from_image(fp)
        except Exception:
            extracted = ''
        if extracted:
            parts.append(f"[{idx}] {label}:\n{extracted}")
        else:
            parts.append(f"[{idx}] {label}: [No text detected]")
        if sum(len(p) for p in parts) > char_limit:
            break
    combined = "\n\n--- ATTACHMENT BREAK ---\n\n".join(parts)
    if len(combined) > char_limit:
        combined = combined[:char_limit] + "... [Content truncated]"
    return combined


def _fetch_section_images_text(bid_id, section_id, char_limit=6000):
    """Aggregate OCR text from section image attachments."""
    attachments = _get_section_image_files_for_bid(bid_id, section_id, limit=12)
    if not attachments:
        return ''
    parts = []
    for idx, item in enumerate(attachments, start=1):
        fp = item.get('file_path')
        if not fp or not os.path.exists(fp):
            continue
        ocr_text = _extract_text_from_image(fp)
        label = item.get('filename') or os.path.basename(fp)
        if ocr_text:
            parts.append(f"[{idx}] {label}:\n{ocr_text}")
        else:
            parts.append(f"[{idx}] {label}: [No text detected]")
        if sum(len(p) for p in parts) > char_limit:
            break
    combined = "\n\n--- IMAGE BREAK ---\n\n".join(parts)
    if len(combined) > char_limit:
        combined = combined[:char_limit] + "... [Content truncated]"
    return combined


@app.route('/api/analyze-rfp-master', methods=['POST'])
@login_required
def analyze_rfp_master():
    """Run an end-to-end compliance and outline analysis for the active RFP."""
    payload = request.get_json(silent=True) or {}
    bid_id = payload.get('bid_id')

    if not bid_id:
        return jsonify({'error': 'missing_params', 'message': 'Bid ID is required.'}), 400

    rfp_content = _fetch_rfp_content_for_bid(bid_id, page_limit=120, char_limit=22000)
    if not rfp_content:
        return jsonify({'error': 'no_rfp', 'message': 'No RFP content found for this bid. Please upload an RFP file first.'}), 404

    truncated_rfp = rfp_content[:22000]

    analysis_instructions = """
You are an expert Proposal Analyst and Writer specialized in public procurement (RFP/RFQ/IFB) across construction, energy, IT, and professional services. Using the provided RFP corpus, produce a compliance-first analysis and proposal blueprint.

Requirements:
- Output valid HTML only. No Markdown, JSON, or plain text.
- Use <h2> headings in this exact order:
  1. Executive Brief
  2. Key Dates and Submission Rules
  3. Compliance Matrix
  4. Proposal Table of Contents
  5. Section-by-Section Guidance and Drafts
  6. Pricing Package Instructions
  7. SBE/DBE and Compliance Plan
  8. Bonds, Insurance, and Financials
  9. Risk Register and Clarifications
  10. Submission Checklist
- Provide concise, action-oriented guidance. Quote or paraphrase RFP sections with citations (e.g., Section 4, Instructions to Bidders).
- The Compliance Matrix must be a <table> with columns: Requirement, RFP Reference, Mandatory?, Proposal Location, Owner Role, Notes. Keep rows CSV-friendly (no extra commas unless inside quotes).
- In Section-by-Section Guidance, create a <section> per entry that includes:
    * <h3> heading for the section name.
    * <p> summarizing purpose and linkage.
    * <ul> of required content bullets.
    * <ul class="placeholders"> for data placeholders (e.g., [Vendor_Name]).
    * <pre class="boilerplate"> containing draft boilerplate text with placeholders.
    * <ul class="evidence"> listing evidence artifacts/forms to attach.
- Supply copy-paste templates wrapped in <pre class="template"> blocks for: Cover Letter, Executive Summary, Technical Approach, Safety Program, Small Business Plan, Pricing Cover, Bonds/Insurance Acknowledgment, References, Appendices List.
- Flag assumptions as ???Assumption ??? verify???.
- If SBE/DBE goals exist, include a subcontracting plan template and tracking approach.
- Emphasize sealed bid compliance, bonding thresholds, signatures/notarization, pricing forms, safety stats, and portal rules when relevant to construction/MEP.
- Highlight phasing, technical standards, monitoring, and access coordination for solar/energy scopes when applicable.
- Never invent data; if missing, call it out explicitly.
- Finish with a concise checklist aligned to submission portal/file rules and include a Go/No-Go gate summary.
"""

    user_prompt = f"""
RFP / IFB Source Content:
{truncated_rfp}

Generate the HTML deliverable now, following every rule above.
"""

    # Use OpenAI for master analysis
    api_key = (app.config.get('OPENAI_API_KEY') or os.getenv('OPENAI_API_KEY') or os.getenv('GROQ_API_KEY') or '').strip()
    if not api_key:
        return jsonify({'error': 'api_unavailable', 'message': 'OpenAI API key is not configured on the server.'}), 500
    base_url = (app.config.get('OPENAI_BASE_URL') or os.getenv('OPENAI_BASE_URL') or 'https://api.groq.com/openai/v1').strip()
    model = (app.config.get('OPENAI_MODEL') or os.getenv('OPENAI_MODEL') or 'meta-llama/llama-4-scout-17b-16e-instruct').strip()
    endpoint = base_url.rstrip('/')
    if not endpoint.endswith('/chat/completions'):
        endpoint = f"{endpoint}/chat/completions"
    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json',
    }
    body = {
        'model': model,
        'messages': [
            {'role': 'system', 'content': 'You are an expert proposal analyst. Return ONLY valid HTML per instructions.'},
            {'role': 'user', 'content': analysis_instructions + "\n\n" + user_prompt}
        ],
        'temperature': 0.2,
        'max_tokens': 6000
    }
    try:
        response = requests.post(endpoint, headers=headers, json=body, timeout=120)
    except requests.RequestException as err:
        app.logger.exception("OpenAI master analysis network failure: %s", err)
        return jsonify({'error': 'api_unavailable', 'message': 'Could not reach the AI service. Please try again shortly.'}), 502
    try:
        data = response.json()
    except ValueError:
        app.logger.error("OpenAI master analysis returned non-JSON response (status %s): %s", response.status_code, response.text[:400])
        return jsonify({'error': 'api_unavailable', 'message': 'Received an invalid response from the AI service.'}), 502
    if response.status_code >= 400:
        err_message = data.get('error') if isinstance(data, dict) else None
        detail = ''
        if isinstance(err_message, dict):
            detail = err_message.get('message') or err_message.get('code') or ''
        elif isinstance(err_message, str):
            detail = err_message
        if not detail:
            detail = f"Upstream error {response.status_code}"
        app.logger.error("OpenAI master analysis error %s: %s", response.status_code, detail)
        return jsonify({'error': 'api_unavailable', 'message': f'AI service returned an error: {detail}'}), 502
    choices = data.get('choices') or []
    analysis_html = (choices[0].get('message', {}) or {}).get('content', '') if choices else ''

    if not analysis_html:
        analysis_html = "<p class='text-sm text-gray-500'>No analysis output was generated.</p>"

    return jsonify({'analysis_html': analysis_html})


@app.route('/api/analyze-subcategory', methods=['POST'])
@login_required
def analyze_subcategory():
    """Analyze a sub-category section using AI based on RFP content."""
    payload = request.get_json(silent=True) or {}
    section_id = payload.get('section_id', '').strip()
    subcategory_id = payload.get('subcategory_id', '').strip()
    subcategory_title = payload.get('subcategory_title', '').strip()
    bid_id = payload.get('bid_id')
    rfp_content = payload.get('rfp_content', '')
    
    if not section_id or not subcategory_id or not subcategory_title:
        return jsonify({'error': 'missing_params', 'message': 'Section ID, subcategory ID, and title are required.'}), 400
    
    # Get RFP content from database if bid_id is provided
    if bid_id and not rfp_content:
        rfp_content = _fetch_rfp_content_for_bid(bid_id, page_limit=50, char_limit=8000)
    
    # Build AI prompt for sub-category analysis
    system_prompt = (
        "You are an expert proposal writer helping to draft specific sections of a government proposal. "
        "Analyze the RFP content and generate comprehensive, compliant content for the requested sub-category. "
        "Your response should be professional, detailed, and aligned with the RFP requirements."
    )
    
    user_prompt = f"""Generate content for the sub-category: "{subcategory_title}" within the section "{section_id}".

Requirements:
1. Analyze the provided RFP content to understand requirements relevant to this sub-category
2. Generate professional, compliant content that addresses the sub-category topic
3. Ensure the content is specific, actionable, and aligned with government proposal standards
4. If RFP content is limited, provide a well-structured template that can be customized

RFP Content:
{rfp_content[:8000] if rfp_content else "No RFP content available. Generate a professional template for this sub-category."}

Please provide the content for "{subcategory_title}" in a clear, well-formatted manner."""
    
    api_key = (app.config.get('OPENAI_API_KEY') or os.getenv('OPENAI_API_KEY') or os.getenv('GROQ_API_KEY') or '').strip()
    if not api_key:
        return jsonify({'error': 'api_unavailable', 'message': 'OpenAI API key is not configured on the server.'}), 500
    
    base_url = (app.config.get('OPENAI_BASE_URL') or os.getenv('OPENAI_BASE_URL') or 'https://api.groq.com/openai/v1').strip()
    model = (app.config.get('OPENAI_MODEL') or os.getenv('OPENAI_MODEL') or 'meta-llama/llama-4-scout-17b-16e-instruct').strip()
    endpoint = base_url.rstrip('/')
    if not endpoint.endswith('/chat/completions'):
        endpoint = f"{endpoint}/chat/completions"
    
    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json',
    }
    body = {
        'model': model,
        'messages': [
            {'role': 'system', 'content': system_prompt},
            {'role': 'user', 'content': user_prompt}
        ],
        'temperature': 0.3,
    }
    
    try:
        response = requests.post(endpoint, headers=headers, json=body, timeout=90)
    except requests.RequestException as err:
        app.logger.exception("OpenAI subcategory analysis network failure: %s", err)
        return jsonify({'error': 'api_unavailable', 'message': 'Could not reach the AI service. Please try again shortly.'}), 502
    
    try:
        data = response.json()
    except ValueError:
        app.logger.error("OpenAI subcategory analysis returned non-JSON response (status %s): %s", response.status_code, response.text[:400])
        return jsonify({'error': 'api_unavailable', 'message': 'Received an invalid response from the AI service.'}), 502
    
    if response.status_code >= 400:
        err_message = data.get('error') if isinstance(data, dict) else None
        detail = ''
        if isinstance(err_message, dict):
            detail = err_message.get('message') or err_message.get('code') or ''
        elif isinstance(err_message, str):
            detail = err_message
        if not detail:
            detail = f"Upstream error {response.status_code}"
        app.logger.error("OpenAI subcategory analysis error %s: %s", response.status_code, detail)
        return jsonify({'error': 'api_unavailable', 'message': f'AI service returned an error: {detail}'}), 502
    
    choices = data.get('choices') or []
    if not choices:
        return jsonify({'error': 'api_unavailable', 'message': 'No response returned by the AI service.'}), 502
    
    content = choices[0].get('message', {}).get('content', '')
    if not content:
        return jsonify({'error': 'api_unavailable', 'message': 'The AI service returned an empty response.'}), 502
    
    return jsonify({
        'content': content.strip(),
        'subcategory_id': subcategory_id,
        'subcategory_title': subcategory_title,
        'model': data.get('model', model),
        'usage': data.get('usage', {}),
    })


@app.route('/api/analyze-section-outline', methods=['POST'])
@login_required
def analyze_section_outline():
    """Extract key requirements and a summary for a proposal section directly from the RFP."""
    payload = request.get_json(silent=True) or {}
    section_id = (payload.get('section_id') or '').strip()
    section_title = (payload.get('section_title') or '').strip() or section_id or 'Proposal Section'
    bid_id = payload.get('bid_id')
    rfp_content = payload.get('rfp_content', '')

    if not section_id:
        return jsonify({'error': 'missing_params', 'message': 'Section ID is required.'}), 400

    if bid_id and not rfp_content:
        rfp_content = _fetch_rfp_content_for_bid(bid_id, page_limit=60, char_limit=12000)

    truncated_rfp = rfp_content[:12000] if rfp_content else ''

    system_prompt = (
        "You are an expert RFP and bid document analyst. "
        "Read RFP, IFB, and tender documents carefully and extract only the actionable requirements, eligibility criteria, "
        "and specifications needed for a compliant proposal submission. Present results in clear proposal-ready language."
    )

    user_prompt = f"""
Carefully read the following RFP content and produce an output that follows the exact template below. Use concise bullet points. Do not invent information that is not present.

Template to follow:

???? **Project Overview**
- Project title, number, client/issuing agency, location
- Procurement officer/contact email
- Submission portal/platform
- Important bid dates and schedule (release, pre-bid, submission, opening, award)
- Estimated project value or budget (if mentioned)

???? **Scope of Work / Technical Requirements**
- Summarize required deliverables, materials, installation, testing, safety, coordination, warranty, and quality standards.

???? **Eligibility & Qualification Requirements**
- Experience, licenses, certifications, references, safety, financial, insurance, staffing requirements, mandatory forms, bonds.

?????? **Bid Submission Requirements**
- Submission method, required documents, pricing forms, conflict forms, bonding instructions, clarification procedures.

???? **Evaluation & Award Criteria**
- List all evaluation factors, scoring parameters, participation goals, best-value or low-bid rules.

???? **Contract & Performance Requirements**
- Contract term, start/completion dates, liquidated damages, compliance obligations, minimum self-performed work.

???? **Bonds, Warranty & Insurance**
- Bid/performance/payment bonds with percentages, warranty coverage, insurance types and limits.

???? **Added Value / Special Notes**
- Unique clauses, sustainability requirements, community programs, optional value-add proposals.

??????? **Key Dates Summary Table**
| Milestone | Date |
|------------|-------|
| IFB/RFP Release | |
| Pre-Bid Meeting | |
| Questions Deadline | |
| Bid Submission | |
| Bid Opening | |
| Board/Contract Award | |

??? **Summary for Proposal Preparation**
- Summarize everything a bidder must ensure for compliance (eligibility, documents, bonds, pricing, schedule, goals).

Formatting rules:
- Use the headings exactly as shown.
- Use bullet points for lists; keep them short and factual.
- Skip any sub-bullet if the RFP does not mention it (do not fabricate content).
- End the response with the sentence: ???These are the complete actionable requirements, eligibility criteria, and specifications extracted from this RFP for proposal preparation.???

RFP_CONTENT_START
{truncated_rfp if truncated_rfp else "No RFP content is available."}
RFP_CONTENT_END
"""

    api_key = (app.config.get('OPENAI_API_KEY') or os.getenv('OPENAI_API_KEY') or os.getenv('GROQ_API_KEY') or '').strip()
    if not api_key:
        return jsonify({'error': 'api_unavailable', 'message': 'OpenAI API key is not configured on the server.'}), 500

    base_url = (app.config.get('OPENAI_BASE_URL') or os.getenv('OPENAI_BASE_URL') or 'https://api.groq.com/openai/v1').strip()
    model = (app.config.get('OPENAI_MODEL') or os.getenv('OPENAI_MODEL') or 'meta-llama/llama-4-scout-17b-16e-instruct').strip()
    endpoint = base_url.rstrip('/')
    if not endpoint.endswith('/chat/completions'):
        endpoint = f"{endpoint}/chat/completions"

    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json',
    }
    body = {
        'model': model,
        'messages': [
            {'role': 'system', 'content': system_prompt},
            {'role': 'user', 'content': user_prompt}
        ],
        'temperature': 0.2,
    }

    try:
        response = requests.post(endpoint, headers=headers, json=body, timeout=90)
    except requests.RequestException as err:
        app.logger.exception("OpenAI section outline network failure: %s", err)
        return jsonify({'error': 'api_unavailable', 'message': 'Could not reach the AI service. Please try again shortly.'}), 502

    try:
        data = response.json()
    except ValueError:
        app.logger.error("OpenAI section outline returned non-JSON response (status %s): %s", response.status_code, response.text[:400])
        return jsonify({'error': 'api_unavailable', 'message': 'Received an invalid response from the AI service.'}), 502

    if response.status_code >= 400:
        err_message = data.get('error') if isinstance(data, dict) else None
        detail = ''
        if isinstance(err_message, dict):
            detail = err_message.get('message') or err_message.get('code') or ''
        elif isinstance(err_message, str):
            detail = err_message
        if not detail:
            detail = f"Upstream error {response.status_code}"
        app.logger.error("OpenAI section outline error %s: %s", response.status_code, detail)
        return jsonify({'error': 'api_unavailable', 'message': f'AI service returned an error: {detail}'}), 502

    choices = data.get('choices') or []
    if not choices:
        return jsonify({'error': 'api_unavailable', 'message': 'No response returned by the AI service.'}), 502

    content = choices[0].get('message', {}).get('content', '')
    if not content:
        return jsonify({'error': 'api_unavailable', 'message': 'The AI service returned an empty response.'}), 502

    return jsonify({
        'output': content.strip(),
        'raw': content.strip(),
        'model': data.get('model', model),
        'usage': data.get('usage', {}),
    })

@app.route('/api/analyze-requirements-attachments', methods=['POST'])
@login_required
def analyze_requirements_attachments():
    """Extract requirements and required attachments from RFP document."""
    payload = request.get_json(silent=True) or {}
    bid_id = payload.get('bid_id')
    
    if not bid_id:
        return jsonify({'error': 'missing_params', 'message': 'Bid ID is required.'}), 400

    # Fetch RFP content
    rfp_content = _fetch_rfp_content_for_bid(bid_id, page_limit=80, char_limit=15000)
    
    if not rfp_content:
        return jsonify({'error': 'no_rfp', 'message': 'No RFP content found for this bid. Please upload an RFP file first.'}), 404

    truncated_rfp = rfp_content[:15000] if rfp_content else ''

    system_prompt = (
        "You are a professional RFP analysis assistant. "
        "Your only task is to analyze the provided RFP / IFB document and extract **only the mandatory attachments, forms, and documents** that bidders are required to submit with their bid or proposal. "
        "Do NOT include scope of work, eligibility, or background text. "
        "Do NOT infer or assume anything ??? extract only what is explicitly listed in the RFP as required attachments, forms, or bid documents."
    )

    user_prompt = f"""
Analyze the following RFP content and extract **only the mandatory attachments, forms, and documents** that bidders are required to submit.

### ???? OUTPUT FORMAT (strictly follow this structure)

???? **Mandatory Attachments & Documents to Include with the Bid**

List each required document or form in clean bullet points.  
If attachment numbers or names are mentioned, list them exactly as written in the RFP.

Example output format:

- Attachment 1 ??? Contract Award Form  
- Attachment 2 ??? Acknowledgment Form  
- Attachment 3 ??? Bidder's Certifications  
- Attachment 4 ??? Conflict of Interest Questionnaire  
- Attachment 5 ??? Financial Interests and Potential Conflicts Form  
- Attachment 6 ??? References  
- Attachment 7 ??? Insurance Requirements  
- Attachment 8 ??? Small Business Development (SBD) Forms  
- Attachment 9 ??? Contractor Certification Sheet  
- Bid Bond (if required)  
- Payment Bond (if contract value > $25,000)  
- Performance Bond (if contract value > $100,000)  
- Company Profile / Cover Letter  
- Safety Record / EMR Report  
- Proof of Experience and References  
- Licenses / Certifications  
- Financial Stability Statement  
- Bid Pricing Sheet / Cost Proposal  
- Small Business Participation Documentation  
- Any other forms explicitly listed in the RFP

If no attachments are mentioned in the document, write:  
**"No specific attachments or mandatory bid documents listed in this RFP."**

### ???? RULES FOR EXTRACTION

- Include **only** attachment titles, form names, or document names mentioned in the RFP.  
- Remove all explanation text or surrounding sentences.  
- One line per attachment or required document.  
- Use plain, clean formatting ??? perfect for UI display next to an "Attach File" button.  
- Do not generate or assume missing data.

### ???? GOAL

Output must contain **only the explicit list of required attachments and documents** found in the RFP.  
No commentary. No assumptions. No descriptions.

End your response with:  
**"These are the mandatory attachments and documents explicitly required for bid submission in this RFP."**

RFP_CONTENT_START
{truncated_rfp if truncated_rfp else "No RFP content is available."}
RFP_CONTENT_END
"""

    api_key = (app.config.get('OPENAI_API_KEY') or os.getenv('OPENAI_API_KEY') or os.getenv('GROQ_API_KEY') or '').strip()
    if not api_key:
        return jsonify({'error': 'api_unavailable', 'message': 'OpenAI API key is not configured on the server.'}), 500

    base_url = (app.config.get('OPENAI_BASE_URL') or os.getenv('OPENAI_BASE_URL') or 'https://api.groq.com/openai/v1').strip()
    model = (app.config.get('OPENAI_MODEL') or os.getenv('OPENAI_MODEL') or 'meta-llama/llama-4-scout-17b-16e-instruct').strip()
    endpoint = base_url.rstrip('/')
    if not endpoint.endswith('/chat/completions'):
        endpoint = f"{endpoint}/chat/completions"

    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json',
    }
    body = {
        'model': model,
        'messages': [
            {'role': 'system', 'content': system_prompt},
            {'role': 'user', 'content': user_prompt}
        ],
        'temperature': 0.2,
    }

    try:
        response = requests.post(endpoint, headers=headers, json=body, timeout=90)
    except requests.RequestException as err:
        app.logger.exception("OpenAI requirements analysis network failure: %s", err)
        return jsonify({'error': 'api_unavailable', 'message': 'Could not reach the AI service. Please try again shortly.'}), 502

    try:
        data = response.json()
    except ValueError:
        app.logger.error("OpenAI requirements analysis returned non-JSON response (status %s): %s", response.status_code, response.text[:400])
        return jsonify({'error': 'api_unavailable', 'message': 'Received an invalid response from the AI service.'}), 502

    if response.status_code >= 400:
        err_message = data.get('error') if isinstance(data, dict) else None
        detail = ''
        if isinstance(err_message, dict):
            detail = err_message.get('message') or err_message.get('code') or ''
        elif isinstance(err_message, str):
            detail = err_message
        if not detail:
            detail = f"Upstream error {response.status_code}"
        app.logger.error("OpenAI requirements analysis error %s: %s", response.status_code, detail)
        return jsonify({'error': 'api_unavailable', 'message': f'AI service returned an error: {detail}'}), 502

    choices = data.get('choices') or []
    if not choices:
        return jsonify({'error': 'api_unavailable', 'message': 'No response returned by the AI service.'}), 502

    content = choices[0].get('message', {}).get('content', '')
    if not content:
        return jsonify({'error': 'api_unavailable', 'message': 'The AI service returned an empty response.'}), 502

    return jsonify({
        'output': content.strip(),
        'requirements': content.strip(),
        'raw': content.strip(),
        'model': data.get('model', model),
        'usage': data.get('usage', {}),
    })

@app.route('/api/generate-section-content', methods=['POST'])
@login_required
def generate_section_content():
    """Generate content for a specific proposal section, especially Letter of Transmittal."""
    payload = request.get_json(silent=True) or {}
    section_id = (payload.get('section_id') or '').strip()
    section_title = (payload.get('section_title') or '').strip()
    bid_id = payload.get('bid_id')
    company = (payload.get('company') or '').strip()
    contact_email = (payload.get('contact_email') or '').strip()
    override_api_key = (payload.get('api_key') or '').strip()
    
    if not section_id:
        return jsonify({'error': 'missing_params', 'message': 'Section ID is required.'}), 400
    
    # Get RFP content from database if bid_id is provided
    rfp_content = ''
    if bid_id:
        # Use higher limits for sections that need thorough analysis
        rfp_content = _fetch_rfp_content_for_bid(bid_id, page_limit=100, char_limit=25000)
    
    # Get bid information for context
    bid_info = {}
    if bid_id:
        try:
            cur = mysql.connection.cursor(DictCursor)
            cur.execute("SELECT * FROM go_bids WHERE g_id=%s", (bid_id,))
            bid_info = cur.fetchone() or {}
            cur.close()
        except Exception as e:
            app.logger.warning(f"Error loading bid info: {e}")
    
    # Extract relevant bid information
    project_name = bid_info.get('b_name') or bid_info.get('project_name') or ''
    client_name = bid_info.get('agency') or bid_info.get('customer') or bid_info.get('client') or ''
    due_date = bid_info.get('due_date') or ''
    
    # Format due date
    if due_date:
        try:
            from datetime import datetime, date
            if isinstance(due_date, (datetime, date)):
                due_date_str = due_date.strftime('%B %d, %Y')
            else:
                parsed = datetime.strptime(str(due_date), '%Y-%m-%d')
                due_date_str = parsed.strftime('%B %d, %Y')
        except Exception:
            due_date_str = str(due_date)
    else:
        due_date_str = ''
    
    # Check if this is Letter of Transmittal section
    is_letter_of_transmittal = (
        section_id == 'section-cover' or 
        'letter of transmittal' in (section_title or '').lower() or
        'transmittal' in (section_title or '').lower()
    )
    
    # Check if this is Executive Summary section
    is_executive_summary = (
        section_id == 'section-executive-summary' or
        'executive summary' in (section_title or '').lower()
    )
    
    # Check if this is Requirements Compliance section
    is_requirements_compliance = (
        section_id == 'section-compliance' or
        'requirements compliance' in (section_title or '').lower() or
        'compliance' in (section_title or '').lower() and 'requirements' in (section_title or '').lower()
    )
    
    # Check if this is Understanding of Scope & Objectives section
    is_scope_objectives = (
        section_id == 'section-scope-objectives' or
        'understanding of scope' in (section_title or '').lower() or
        'scope & objectives' in (section_title or '').lower() or
        ('scope' in (section_title or '').lower() and 'objectives' in (section_title or '').lower())
    )
    
    # Check if this is Deviations, Assumptions, and Dependencies section
    is_deviations_assumptions = (
        section_id == 'section-deviations' or
        'deviations' in (section_title or '').lower() or
        ('deviations' in (section_title or '').lower() and 'assumptions' in (section_title or '').lower() and 'dependencies' in (section_title or '').lower())
    )
    
    # Check if this is Proposed Technical Solution section
    is_proposed_technical_solution = (
        section_id == 'section-technical' or
        'proposed technical solution' in (section_title or '').lower() or
        ('technical solution' in (section_title or '').lower() and 'proposed' in (section_title or '').lower())
    )
    
    # Check if this is Implementation & Work Plan section
    is_implementation_work_plan = (
        section_id == 'section-implementation' or
        'implementation & work plan' in (section_title or '').lower() or
        'implementation and work plan' in (section_title or '').lower() or
        ('implementation' in (section_title or '').lower() and 'work plan' in (section_title or '').lower())
    )
    
    # Check if this is Solution Deliverables section
    is_solution_deliverables = (
        section_id == 'section-deliverables' or
        'solution deliverables' in (section_title or '').lower() or
        ('solution' in (section_title or '').lower() and 'deliverables' in (section_title or '').lower())
    )
    
    # Check if this is Project Management Plan section
    is_project_management_plan = (
        section_id == 'section-management' or
        'project management plan' in (section_title or '').lower() or
        ('project management' in (section_title or '').lower() and 'plan' in (section_title or '').lower())
    )
    
    # Check if this is Pricing Proposals section
    is_pricing_proposals = (
        section_id == 'section-pricing' or
        'pricing proposals' in (section_title or '').lower() or
        ('pricing' in (section_title or '').lower() and 'proposals' in (section_title or '').lower())
    )
    
    # Check if this is Contractual Terms section
    is_contractual_terms = (
        section_id == 'section-contractual' or
        'contractual terms' in (section_title or '').lower() or
        ('contractual' in (section_title or '').lower() and 'terms' in (section_title or '').lower())
    )
    
    # Check if this is Corporate Qualifications section
    is_corporate_qualifications = (
        section_id == 'section-corporate-qualifications' or
        section_id == 'section-corporate' or
        'corporate qualifications' in (section_title or '').lower() or
        ('corporate' in (section_title or '').lower() and 'qualifications' in (section_title or '').lower())
    )
    
    # Check if this is Project Schedule & Milestones section
    is_project_schedule_milestones = (
        section_id == 'section-schedule-milestones' or
        section_id == 'section-schedule' or
        ('project schedule' in (section_title or '').lower() and 'milestones' in (section_title or '').lower()) or
        ('schedule' in (section_title or '').lower() and 'milestone' in (section_title or '').lower())
    )
    
    # Check if this is Project Team section
    is_project_team = (
        section_id == 'section-project-team' or
        section_id == 'section-team' or
        'project team' in (section_title or '').lower() or
        ('team' in (section_title or '').lower() and 'project' in (section_title or '').lower())
    )
    
    # Check if this is Addenda section
    is_addenda = (
        section_id == 'section-amendments' or
        'addenda' in (section_title or '').lower() or
        'amendments' in (section_title or '').lower()
    )
    
    # Check if this is Appendix section
    is_appendix = (
        section_id == 'section-appendix' or
        'appendix' in (section_title or '').lower()
    )
    
    if is_letter_of_transmittal:
        # Use the specific prompt for Letter of Transmittal
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to draft a formal, professional Letter of Transmittal that meets all standard business letter requirements. "
            "The letter must be written from our company to the client, be technical in nature, and include all necessary points."
        )
        
        user_prompt = f"""Draft a formal, one-page Letter of Transmittal to be signed by an authorized executive. The letter must be in a standard business-letter format with clear paragraphs. It must:

1. State our formal intent to bid for this specific RFP.

2. Acknowledge receipt and review of all addenda.

3. Provide a concise statement of compliance with all mandatory requirements.

4. Briefly highlight our single most compelling technical differentiator.

5. Conclude by affirming our enthusiasm for the partnership.

This must be from our company to the client. It should be technical and should include all necessary points as mentioned in the RFP/RFI/RFQ/Bid Document.

At the very top of the letter, include exactly one header line with the client name, city/state, and the date (e.g., "The City of Oxford, Ohio ??? {due_date_str or 'October 17, 2025'}"). Do NOT include any company information before this line.

Company Information:
- Company Name: {company or 'Our Company'}
- Primary Contact: {contact_email or 'Contact information to be provided'}

RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

RFP Content (for context):
{rfp_content[:15000] if rfp_content else 'No RFP content available. Generate a professional Letter of Transmittal template.'}

Please generate a complete, professional Letter of Transmittal that addresses all six requirements listed above. The letter should be technical, comprehensive, and written from our company to the client. Format it as a standard business letter with proper paragraphs and not write sub heading . Return the content as a single formatted text that can be split into paragraphs."""
    elif is_executive_summary:
        # Use the specific prompt for Executive Summary
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to draft a persuasive, one-page Executive Summary that is standalone and written for a high-level, non-technical decision-maker."
        )
        
        user_prompt = f"""With reference to the requirement mentioned in the RFP/RFI/RFQ/BID document, generate a persuasive, one-page Executive Summary. This summary must be standalone and written for a high-level, non-technical/technical decision-maker. It should be from our company to the client. Use the following for structure:

??? In a single paragraph, summarize our understanding of the client's core problem, goals, and desired outcomes as stated in the bid.

??? In two paragraphs, provide a high-level, benefit-focused overview of our technical and management solution. Avoid deep jargon.

??? Highlight 3-5 specific, unique advantages our solution offers (e.g., proprietary technology, faster deployment, specific expertise).

??? Mention the tangible, measurable results the client will receive.

??? State the total, all-inclusive price in a clear, and concise manner.

??? This should not have any subheadings and should be in paragraph only. Do not include any header line such as client name/state/date at the top; begin directly with the executive narrative.


Company Information:
- Company Name: {company or 'Our Company'}


RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

RFP Content (for context):
{rfp_content[:15000] if rfp_content else 'No RFP content available. Generate a professional Executive Summary template.'}

Please generate a complete Executive Summary written entirely in paragraph format with NO subheadings. The content should follow the structure outlined above but present everything as continuous paragraphs without any headings, bullet points, or lists. All content should flow as continuous, well-structured paragraphs. The content should be persuasive, clear, and suitable for high-level decision-makers. Return the content as a single flowing narrative that can be split into paragraphs."""
    elif is_requirements_compliance:
        # Use the specific prompt for Requirements Compliance
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to draft a formal Statement of Compliance that thoroughly addresses all requirements and key activities from the RFP document."
        )
        
        user_prompt = f"""As per the requirement mentioned in the document, draft a formal 'Statement of Compliance.' State that we have read, understood, and will comply with all mandatory requirements, terms, and conditions set forth in the bid document. Include all key points in detail and in a technical manner. Do not skip any important points to be discussed.

Company Information:
- Company Name: {company or 'Our Company'}
- Primary Contact: {contact_email or 'Contact information to be provided'}

RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

RFP Content (analyze thoroughly to identify ALL requirements, key activities, deliverables, attachments, forms, technical specifications, and compliance obligations):
{rfp_content[:25000] if rfp_content else 'No RFP content available. Generate a professional Statement of Compliance template.'}

Please generate the Statement of Compliance as exactly TWO paragraphs only, no headings, lists, bullets, or numbering:
- Paragraph 1: Provide the formal compliance assertion that we have read, understood, and will comply with all mandatory requirements, terms, and conditions of the bid.
- Paragraph 2: Note that any exceptions will be listed in the 'Deviations' section and summarize, in technical language, our comprehensive adherence to the RFP???s requirements, deliverables, forms, technical specifications, certifications, and compliance obligations.

Strictly limit the output to two paragraphs with complete sentences and professional tone."""
    elif is_scope_objectives:
        # Use the specific prompt for Understanding of Scope & Objectives
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to draft a comprehensive 'Understanding of Scope & Objectives' section that demonstrates deep subject-matter expertise by adding value and insight, not just repeating the RFP's text."
        )
        
        user_prompt = f"""As per the requirement mentioned in the document, draft a section titled 'Understanding of Scope & Objectives.' Using narrative paragraphs, analyse and re-state the client's core challenges, operational problems, and strategic goals. This section must demonstrate our deep subject-matter expertise by adding value and insight, not just repeating the RFP's text. Show that we understand the 'why' behind the 'what.' Include all key points in technical manner and in detail. Do not skip any important points to be discussed. Use pointers and table if necessary. Make it completely informative and elaborative.

Company Information:
- Company Name: {company or 'Our Company'}
- Primary Contact: {contact_email or 'Contact information to be provided'}

RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

RFP Content (analyze thoroughly to understand scope, objectives, challenges, phases, key activities, technical requirements, and all important points):
{rfp_content[:25000] if rfp_content else 'No RFP content available. Generate a professional Understanding of Scope & Objectives template.'}

Please generate a comprehensive 'Understanding of Scope & Objectives' section that:
- Uses narrative paragraphs to demonstrate deep understanding, supplemented with pointers and tables where necessary
- Analyzes and re-states the client's core challenges, operational problems, and strategic goals in technical detail
- Adds value and insight beyond just repeating the RFP text - demonstrates subject-matter expertise
- Shows understanding of the 'why' behind the 'what' - explains the reasoning, context, strategic importance, and technical implications
- Includes ALL key points in technical manner and in detail - do not skip any important points to be discussed
- Uses pointers (bullet points) and tables where appropriate to organize information clearly and make it completely informative
- Makes it completely informative and elaborative - comprehensive coverage of all aspects with technical precision

Return the content as well-structured narrative paragraphs with appropriate use of pointers and tables to organize key activities, phases, technical requirements, and all important points. The content must be completely informative and elaborative, technically detailed, and comprehensive without omitting any important information."""
    elif is_deviations_assumptions:
        # Use the specific prompt for Deviations, Assumptions, and Dependencies
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to generate a section that manages expectations by clearly documenting deviations, assumptions, and dependencies."
        )
        
        user_prompt = f"""As per mentioned in the document (if any), generate a section to manage expectations (if any). Use the following

??? Use a numbered list to detail every item marked as 'Partial' or 'Exception'. Provide a clear justification for each.

??? Use a numbered list to state all assumptions our technical solution and pricing are based on (e.g., 'We assume client will provide network access...').

??? Use a numbered list to explicitly state all items, data, access, or resources we require from the client to ensure project success."

It should be completely technical and should include all key points. Do not skip any key points mentioned in RFP.

Company Information:
- Company Name: {company or 'Our Company'}
- Primary Contact: {contact_email or 'Contact information to be provided'}

RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

RFP Content (analyze thoroughly to identify ALL deviations, assumptions, dependencies, technical requirements, and key points):
{rfp_content[:25000] if rfp_content else 'No RFP content available. Generate a professional Deviations, Assumptions, and Dependencies template.'}

Please generate a comprehensive, completely technical section that:
- Uses numbered lists for: Deviations and Exceptions; Technical & Operational Assumptions; Client-Furnished Dependencies
- Details every item marked as 'Partial' or 'Exception' in the compliance matrix (if applicable) with technical justifications
- States ALL assumptions our technical solution and pricing are based on
- Explicitly states ALL client-furnished items, data, access, resources, and dependencies required
- Includes ALL key points mentioned in the RFP - do not skip any important technical details, requirements, or specifications
- Is completely technical, specific, and actionable

Return the content with clearly separated parts and numbered lists as specified. The content must be completely technical, comprehensive, and include all key points from the RFP without omitting any important information."""
    elif is_proposed_technical_solution:
        # Use the specific prompt for Proposed Technical Solution
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to generate a comprehensive 'Proposed Technical Solution' section that addresses all technical requirements and work-streams from the RFP document."
        )
        
        # Include OCR text from section-specific image attachments (if any)
        section_images_text = _fetch_section_images_text(bid_id, 'section-technical', char_limit=6000) if bid_id else ''
        
        user_prompt = f"""As per the requirement in the document, generate the core 'Proposed Technical Solution' section. Structure these using headings and subheadings that directly correspond to the technical work-streams defined in the bid document.

??? Before generating, ensure the user has uploaded/attached the RFP/SoW/addenda via the Attach File button. Incorporate all details/information from the attached documents and any provided data inputs.

??? For each subsection, use technical paragraphs, bulleted lists for specifications, and tables for technical data.

??? This section must be highly detailed, addressing how our solution fulfils each technical requirement. Include specific product models, software versions, and methodologies where relevant.

??? Include all key activities/technical requirements. Do not skip any important points to be discussed. Use pointers and table if necessary.

Make it in very detail by including all necessary points. Also, make sure this is completely technical. Include pointers and table where required. The response should be aligned with the requirement in RFP.

Company Information:
- Company Name: {company or 'Our Company'}
- Primary Contact: {contact_email or 'Contact information to be provided'}

RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

RFP Content (analyze thoroughly to identify ALL technical work-streams, requirements, specifications, deliverables, phases, key activities, and technical details):
{rfp_content[:25000] if rfp_content else 'No RFP content available. Generate a professional Proposed Technical Solution template.'}

Section Image Attachments (OCR text extracted from images uploaded for this section):
{section_images_text if section_images_text else 'No image attachments provided for this section.'}

Please generate a comprehensive, highly detailed, and completely technical 'Proposed Technical Solution' section that:
- Uses headings and subheadings that directly correspond to technical work-streams from the RFP
- For each subsection, uses technical paragraphs, bulleted lists (pointers) for specifications, and tables for technical data
- Is highly detailed and addresses how our solution fulfils each technical requirement with technical precision
- Includes specific product models, software versions, hardware specifications, methodologies, standards, and protocols where relevant
- Includes ALL key activities/technical requirements, specifications, and important points - does not skip any important points
- Uses pointers (bullet points) and tables where required to organize and present technical information clearly
- Is completely technical and comprehensive
- Is aligned with the requirements in RFP - addresses every technical requirement, specification, and work-stream
- Makes it in very detail by including all necessary points
- Includes all necessary technical details: configurations, specifications, methodologies, protocols, standards, tools, technologies, and implementation approaches

Return the content as well-structured, highly detailed, and completely technical content with appropriate headings and subheadings, paragraphs, bulleted lists (pointers), and tables. The response must be aligned with all requirements in the RFP and include all necessary points without omitting any important information."""
    elif is_implementation_work_plan:
        # Use the specific prompt for Implementation & Work Plan
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to generate a comprehensive 'Implementation & Work Plan' section that details the methodology, project phases, and key activities for successful project delivery."
        )
        
        user_prompt = f"""Generate a comprehensive 'Implementation & Work Plan' section with two main subsections:

1. Methodology

As per the requirement in the document, draft methodology section based on the project scope. In narrative paragraphs, describe the specific project management and technical implementation methodology we will use. Include all key activities. Do not skip any important points to be discussed. Use pointers and table if necessary. Make it in very detail by including all necessary points. Also, make sure this is completely technical. Include pointers and table where required. The response should be aligned with the requirement in RFP. Use headings, subheadings, pointers and tables where required.

2. Project Phases & Activities

As per the requirement in the document, "daft a 'Project Phases & Activities' subsection based on the project scope. Use subheadings for each distinct project phase. Use weeks for each phase in the form Week1-Week2 etc. These weeks should be practically feasible as per the requirement in the project document. Includer all key activities in each phase. Do not skip any important points to be discussed. Use pointers and tables where necessary. Make it in very detail by including all necessary points. Also, make sure this is completely technical and feasible. Include pointers and table where required. The response should be aligned with the requirement in the project.

Include all key activities in each phase. Do not skip any important points to be discussed. Use pointers and tables where necessary. Make it in very detail by including all necessary points. Also, make sure this is completely technical and feasible. Include pointers and table where required. The response should be aligned with the requirement in RFP.

Company Information:
- Company Name: {company or 'Our Company'}
- Primary Contact: {contact_email or 'Contact information to be provided'}

RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

RFP Content (analyze thoroughly to identify ALL project phases, activities, tasks, objectives, methodology requirements, technical implementation details, and all important points):
{rfp_content[:25000] if rfp_content else 'No RFP content available. Generate a professional Implementation & Work Plan template.'}

Please generate a comprehensive 'Implementation & Work Plan' section that includes:

1. Methodology (use headings/subheadings as appropriate):
   - Narrative paragraphs describing the specific project management and technical implementation methodology in very detail
   - Justification for why this methodology is the best fit for this specific project and client
   - ALL key activities related to methodology included - no important points skipped
   - Use of pointers (bullet points) and tables where required to organize and present technical information clearly
   - Very detailed coverage including all necessary points
   - Completely technical content
   - Response aligned with the requirements in RFP

2. Project Phases & Activities (use subheadings):
   - Subheadings for each distinct project phase (e.g., 'Phase 1: Discovery & Design,' 'Phase 2: Build & Test,' 'Phase 3: Deployment & Go-Live')
   - For each phase, include a practical week range label (e.g., 'Week 1???Week 2', 'Week 3???Week 6') aligned with the bid timeline
   - Under each phase, bulleted lists detailing key activities, tasks, and objectives in very detail
   - ALL key activities in each phase included - no important points skipped
   - Use of pointers (bullet points) and tables where required to organize and present technical information clearly
   - Very detailed coverage including all necessary points
   - Completely technical content
   - Response aligned with the requirements in RFP

Return the content as well-structured, highly detailed, and completely technical content with appropriate headings and subheadings, narrative paragraphs, bulleted lists (pointers), and tables. Both the Methodology and Project Phases & Activities subsections must be in very detail, completely technical, include all key activities, use pointers and tables where required, and be aligned with all requirements in the RFP."""
    elif is_solution_deliverables:
        # Use the specific prompt for Solution Deliverables
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to generate a comprehensive 'Solution Deliverables' section that lists all tangible items the client will receive in a structured table format."
        )
        
        user_prompt = f"""As per the requirement in the project information document, generate a 'Solution Deliverables' section based on the scope of the work. Create a table that lists all tangible items the client will receive. The table columns must be:

1. Deliverable Title: must include what will be delivered.

2. Description: (A brief explanation).

3. Format: (e.g., 'PDF Document,' 'Online Dashboard').

4. Delivery Milestone: (When it will be delivered, e.g., 'End of Phase 1').

Make it in very detail by including all necessary points. Also, make sure this is completely technical. Include pointers and table where required. The response should be aligned with the requirement in RFP.

Company Information:
- Company Name: {company or 'Our Company'}
- Primary Contact: {contact_email or 'Contact information to be provided'}

RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

RFP Content (analyze thoroughly to identify ALL deliverables, their descriptions, formats, delivery milestones, technical specifications, and all important points):
{rfp_content[:25000] if rfp_content else 'No RFP content available. Generate a professional Solution Deliverables template.'}

Please generate a comprehensive, highly detailed, and completely technical 'Solution Deliverables' section that:
- Creates a table with exactly 4 columns: Deliverable Title, Description, Format, Delivery Milestone
- Lists ALL tangible items the client will receive with technical precision
- Includes ALL deliverables from the RFP - does not skip any items or important points
- Provides very specific and detailed technical descriptions for each deliverable
- Matches delivery milestones to project phases from the RFP
- Uses appropriate technical formats for each deliverable
- Is well-structured, comprehensive, and includes all technical details
- Is aligned with the requirements in RFP - addresses every deliverable requirement, specification, and item
- Includes pointers (bullet points) and tables where required to organize and present technical information clearly
- Makes it in very detail by including all necessary points
- Is completely technical

Return the content as a well-structured, highly detailed, and completely technical table with all deliverables listed. The table format must be clear, comprehensive, include all required columns, and be aligned with all requirements in the RFP. Include pointers and tables where required to make it completely informative and technical."""
    elif is_project_management_plan:
        # Use the specific prompt for Project Management Plan
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to generate a comprehensive 'Project Management Plan' section that includes project governance, communication plan, risk management, and quality assurance."
        )
        
        user_prompt = f"""As per the requirement in the bid document, generate a comprehensive, highly detailed, and completely technical 'Project Management Plan' with four main subsections:

1. Project Governance

Prompt: As per the requirement in the project document, draft a 'Project Governance' subsection based on the scope of the project. In paragraphs, describe the management structure involved in the project. Include all key activities in each phase. Do not skip any important points to be discussed. Use pointers and table if necessary. Make it in very detail by including all necessary points. Also, make sure this is completely technical. Include pointers and table where required. The response should be aligned with the requirement in RFP.

2. Communication Plan

Prompt: As per the requirement in the project document, generate a 'Communication Plan as per the scope of the work. Create a table that defines the communication protocols. Includer all key activities. Do not skip any important points to be discussed. Use pointers and table if necessary. Make it in very detail by including all necessary points. Also, make sure this is completely technical. Include pointers and table where required. The response should be aligned with the requirement in RFP.

3. Risk Management Plan

Prompt: As per the requirement in the project document, generate a 'Risk Management Plan based on the scope of the work. Create a table. Do not skip any important points to be discussed. Use pointers and table if necessary. Make it in very detail by including all necessary points. Also, make sure this is completely technical. Include pointers and table where required. The response should be aligned with the requirement in RFP.

4. Quality Assurance Plan

Prompt: A per the requirement in the bid document, draft a 'Quality Assurance Plan based on the scope of work. Includer all key activities. Do not skip any important points to be discussed. Use pointers and table if necessary. Make it in very detail by including all necessary points. Also, make sure this is completely technical. Include pointers and table where required. The response should be aligned with the requirement in RFP.

Include all key activities. Do not skip any important points to be discussed. Use pointers and tables if necessary.

Company Information:
- Company Name: {company or 'Our Company'}
- Primary Contact: {contact_email or 'Contact information to be provided'}

RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

RFP Content (analyze thoroughly to identify all project management requirements, communication protocols, risks, quality standards, and key activities):
{rfp_content[:25000] if rfp_content else 'No RFP content available. Generate a professional Project Management Plan template.'}

Please generate a comprehensive, highly detailed, and completely technical 'Project Management Plan' section. Use appropriate H3 subheadings for each subsection and ensure alignment with the RFP. Include all key activities and do not skip any important points. Use pointers and tables where required."""
    elif is_pricing_proposals:
        # Use the specific prompt for Pricing Proposals
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to generate a comprehensive, highly detailed, and completely technical 'Pricing Proposals' section aligned with RFP requirements."
        )
        # Include text extracted from Pricing section image attachments only
        attachments_text = _fetch_section_images_text(bid_id, 'section-pricing', char_limit=8000) if bid_id else ''
        
        user_prompt = f"""Prompt: Generate space for this and give placeholders for each of this sections.

o Pricing Summary

o Detailed Cost Breakdown

o Payment Schedule

Company Information:
- Company Name: {company or 'Our Company'}
- Primary Contact: {contact_email or 'Contact information to be provided'}

RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

RFP Content:
{rfp_content[:25000] if rfp_content else 'No RFP content available. Generate a professional Pricing Proposals template.'}"""
    elif is_contractual_terms:
        # Use the specific prompt for Contractual Terms
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to generate a comprehensive, highly detailed, and completely technical 'Acceptance of Terms and Conditions' section aligned with RFP requirements."
        )
        
        user_prompt = f"""PROMPT FOR  Contractual Terms:

o Acceptance of Terms and Conditions

Prompt: "Analyse the contract and Terms & Conditions (T&Cs) from the bid document.

If we accept all terms: Draft a single paragraph stating that 'We have reviewed all terms and conditions outlined in the bid document and confirm our full acceptance and compliance without exception.' This should be technical in nature based on the scope of the work.

If we have exceptions: Draft a paragraph stating we accept with exceptions, and then create a table with columns: Clause Number, Clause Title, Proposed Redline / Exception, and Business Justification." Make it in very detail by including all necessary points. Also, make sure this is completely technical. Include pointers and table where required. The response should be aligned with the requirement in RFP.

Company Information:
- Company Name: {company or 'Our Company'}
- Primary Contact: {contact_email or 'Contact information to be provided'}

RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

RFP Content:
{rfp_content[:25000] if rfp_content else 'No RFP content available. Generate a professional Contractual Terms template.'}"""
    elif is_corporate_qualifications:
        # Use the specific prompt for Corporate Qualifications
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to generate a comprehensive 'Corporate Qualifications' section that includes Company Overview, Relevant Past Performance, and Client References aligned with the RFP."
        )
        
        user_prompt = f"""PROMPT FOR Corporate Qualifications

o Company Overview

Prompt: "Draft a 'Company Overview.' In 2-3 concise paragraphs, describe our company's history, size, locations, and core competencies that are directly relevant to this project." Use technical statements.

o Relevant Past Performance

Prompt: As per the requirement in the bid document, generate a 'Relevant Past Performance' section. Under each client, create a table with rows for:

??? Project Title:
??? Period of Performance:
??? Project Value:
??? Challenge: (A brief description of the problem).
??? Solution & Outcome: (A description of our work and the positive, quantifiable result)."

o Client References

Prompt: "Generate a 'Client References' section. Create a table providing 3-5 client references, corresponding to the projects listed in 'Past Performance.' Columns must be: Client Name, Contact Person, Title, Phone, and Email."

Company Information:
- Company Name: {company or 'Our Company'}
- Primary Contact: {contact_email or 'Contact information to be provided'}

RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

RFP Content:
{rfp_content[:25000] if rfp_content else 'No RFP content available. Generate a professional Corporate Qualifications template.'}"""
    elif is_project_schedule_milestones:
        # Use the specific prompt for Project Schedule & Milestones
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to generate a comprehensive, highly detailed, and completely technical 'Project Schedule & Milestones' section that is complete, technical, and feasible practically, aligned with RFP requirements."
        )
        
        user_prompt = f"""As per the requirement in the bid document, generate a 'Project Schedule & Milestones' section. This should be complete technical and feasible practically. Use tables and pointers where necessary.

1. First, insert a placeholder for a visual Gantt chart (e.g., [Insert Gantt Chart Visual Here]).

2. Following the placeholder, create a table that lists the 'Critical Project Milestones.' Columns should be: Milestone, Description, and Target Completion Date (or 'Weeks from Kick-off').

Make it in very detail by including all necessary points. Also, make sure this is completely technical and feasible. Include pointers and table where required. The response should be aligned with the requirement in RFP.

Company Information:
- Company Name: {company or 'Our Company'}
- Primary Contact: {contact_email or 'Contact information to be provided'}

RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

RFP Content (analyze thoroughly to identify all project phases, milestones, timelines, delivery dates, and schedule requirements):
{rfp_content[:25000] if rfp_content else 'No RFP content available. Generate a professional Project Schedule & Milestones template.'}
"""
    elif is_project_team:
        # Use the specific prompt for Project Team
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to generate a comprehensive, highly detailed, and completely technical 'Project Team' section that includes organizational chart, roles & responsibilities, and key personnel information, aligned with RFP requirements."
        )
        
        user_prompt = f"""PROMPT FOR Project Team

o Project Team Organizational Chart

Prompt: "Insert a placeholder for a 'Project Team Organizational Chart.' This visual diagram must show the proposed team structure, reporting lines, and key interfaces with the client's team." 

o Roles & Responsibilities

Prompt: "Generate a 'Roles & Responsibilities' section. Create a table with columns: Project Role, Proposed Name, and Key Responsibilities." Make it in very detail by including all necessary points. Also, make sure this is completely technical. Include pointers and table where required. The response should be aligned with the requirement in RFP.

o Key Personnel Resumes

Prompt: insert a placeholder for key resumes or small bios

Company Information:
- Company Name: {company or 'Our Company'}
- Primary Contact: {contact_email or 'Contact information to be provided'}

RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

RFP Content:
{rfp_content[:25000] if rfp_content else 'No RFP content available. Generate a professional Project Team template.'}"""
    elif is_addenda:
        # Use the specific prompt for Addenda
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to generate an acknowledgment statement for the Addenda section that acknowledges all addenda received with their names and dates."
        )
        
        user_prompt = f"""Generate an acknowledgment statement for the Addenda section. Analyze the RFP thoroughly to identify all addenda that have been issued.

RFP Content (analyze thoroughly to identify all addenda, amendments, and modification notices):
{rfp_content[:25000] if rfp_content else 'No RFP content available. Generate a professional Addenda acknowledgment statement.'}

Company Information:
- Company Name: {company or 'Our Company'}
- Primary Contact: {contact_email or 'Contact information to be provided'}

RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

Prompt: "Write an acknowledgement statement in 5-6 lines acknowledging all addenda received. It should have addenda name and date."

IMPORTANT REQUIREMENTS:
- Write an acknowledgment statement in 5-6 lines (paragraphs)
- Acknowledge all addenda that have been issued for this solicitation
- Include the addenda name/number for each addendum
- Include the release date for each addendum
- If no addenda were issued, include a statement confirming that no addenda were received
- Use professional and formal language appropriate for government proposals
- Ensure the statement is clear and comprehensive

Return the content as a well-structured acknowledgment statement in 5-6 lines, with each addendum clearly identified by name/number and date."""
    elif is_appendix:
        # Use the specific prompt for Appendix
        system_prompt = (
            "You are an expert proposal writer specializing in government and commercial RFP responses. "
            "Your task is to generate a comprehensive 'List of Appendices' section that identifies all supporting documents included at the end of the proposal."
        )
        
        user_prompt = f"""Generate a 'List of Appendices' section. Analyze the RFP thoroughly to identify all supporting documents, references, and additional materials that should be included in the appendices.

RFP Content (analyze thoroughly to identify all supporting documents, attachments, references, and additional materials referenced in the proposal):
{rfp_content[:25000] if rfp_content else 'No RFP content available. Generate a professional List of Appendices template.'}

Company Information:
- Company Name: {company or 'Our Company'}
- Primary Contact: {contact_email or 'Contact information to be provided'}

RFP Information:
- Project/Solicitation Title: {project_name or 'This RFP'}
- Client/Issuing Agency: {client_name or 'The Client'}
- Proposal Due Date: {due_date_str or 'As specified in the RFP'}

Prompt: "Generate a 'List of Appendices.' Use a lettered, nested list to identify all supporting documents included at the end of the proposal. This should include (but is not limited to):

- Appendix A: 
- Appendix B: 
- Appendix C: 
- Appendix D: 
- Appendix E:"

IMPORTANT REQUIREMENTS:
- Generate a 'List of Appendices' section
- Use a lettered, nested list format (Appendix A, Appendix B, Appendix C, etc.)
- Identify all supporting documents that should be included at the end of the proposal
- Include documents such as (but not limited to):
  - Technical specifications and drawings
  - Certifications and accreditations
  - Past performance documentation
  - Key personnel resumes
  - Organizational charts
  - Compliance matrices
  - Pricing details and breakdowns
  - References and testimonials
  - Any other supporting materials referenced in the proposal
- Analyze the RFP to identify which specific appendices are required or referenced
- Provide clear, descriptive titles for each appendix
- Ensure the list is comprehensive and includes all relevant supporting documents
- Use professional formatting with proper lettering (A, B, C, D, E, etc.)

Return the content as a well-structured 'List of Appendices' with a lettered, nested list format. Each appendix should be clearly identified with a letter (A, B, C, D, E, etc.) and a descriptive title indicating what document or material it contains."""
    else:
        # Generic section generation
        system_prompt = (
            "You are an expert proposal writer helping to draft specific sections of a government proposal. "
            "Analyze the RFP content and generate comprehensive, compliant content for the requested section."
        )
        
        user_prompt = f"""Generate content for the section: "{section_title or section_id}".

Requirements:
1. Analyze the provided RFP content to understand requirements relevant to this section
2. Generate professional, compliant content that addresses the section topic
3. Ensure the content is specific, actionable, and aligned with government proposal standards
4. If RFP content is limited, provide a well-structured template that can be customized

RFP Content:
{rfp_content[:15000] if rfp_content else "No RFP content available. Generate a professional template for this section."}

Company: {company or 'Our Company'}
Project: {project_name or 'This Project'}

Please provide the content for "{section_title or section_id}" in a clear, well-formatted manner."""
    
    # Enrich all prompts with company profile context from database
    try:
        cur = mysql.connection.cursor(DictCursor)
        # Helpers for flexible table/column handling
        def _table_exists(table_name: str) -> bool:
            try:
                cur.execute("SHOW TABLES LIKE %s", (table_name,))
                return cur.fetchone() is not None
            except Exception:
                return False
        def _describe_columns(table_name: str) -> list[str]:
            try:
                cur.execute(f"DESCRIBE `{table_name}`")
                rows = cur.fetchall() or []
                cols = []
                for r in rows:
                    # MySQL DictCursor returns {'Field': 'col', 'Type': '...'}
                    cols.append(r.get('Field') or list(r.values())[0])
                return [c for c in cols if isinstance(c, str)]
            except Exception:
                return []
        def _company_where_clause(existing_cols: list[str], company_value: str):
            candidate_cols = [
                'company_name', 'company', 'comp_name', 'organization',
                'org_name', 'vendor', 'contractor', 'client_company'
            ]
            cols = [c for c in candidate_cols if c in (existing_cols or [])]
            if company_value and cols:
                clause = ' OR '.join([f"LOWER(COALESCE({c},'')) = LOWER(%s)"] * len(cols))
                params = tuple([company_value] * len(cols))
                return f"WHERE {clause}", params
            return "", tuple()
        # Latest company profile details
        cur.execute("SELECT * FROM company_details ORDER BY id DESC LIMIT 1")
        _details = cur.fetchone() or {}
        # Company preferences (e.g., registered states)
        cur.execute("SELECT * FROM company_preferences ORDER BY id DESC LIMIT 1")
        _prefs = cur.fetchone() or {}
        # Capabilities (latest uploads first)
        try:
            cur.execute("SELECT * FROM company_capabilities ORDER BY uploaded_at DESC LIMIT 5")
        except Exception:
            cur.execute("SELECT * FROM company_capabilities ORDER BY id DESC LIMIT 5")
        _caps = cur.fetchall() or []
        # Primary context: use projects_bids in place of company_performance, filtered by company
        _perf = []
        selected_company = (company or (_details.get('name') if _details else '') or '').strip()
        try:
            if _table_exists('projects_bids'):
                cols_b = _describe_columns('projects_bids')
                where_sql_b, where_params_b = _company_where_clause(cols_b, selected_company)
                sql_b = f"""
                    SELECT * FROM projects_bids
                    {where_sql_b}
                    ORDER BY COALESCE(due_date, created_at, updated_at) DESC, id DESC
                    LIMIT 10
                """
                cur.execute(sql_b, where_params_b)
                _perf = cur.fetchall() or []
            if not _perf and _table_exists('go_bids') and selected_company:
                cur.execute("""
                    SELECT g_id, b_name, due_date, state, company, summary
                    FROM go_bids
                    WHERE LOWER(COALESCE(company,'')) = LOWER(%s)
                    ORDER BY due_date DESC
                    LIMIT 10
                """, (selected_company,))
                _perf = cur.fetchall() or []
        except Exception:
            _perf = []
        # Optional: table past_performance (if present)
        _past_perf_extra = []
        try:
            pp_table = 'past_performance'
            if not _table_exists(pp_table) and _table_exists('past_performace'):
                pp_table = 'past_performace'  # common misspelling
            if _table_exists(pp_table):
                cols = _describe_columns(pp_table)
                where_sql, where_params = _company_where_clause(cols, selected_company)
                sql = f"SELECT * FROM `{pp_table}` {where_sql} ORDER BY COALESCE(year, 0) DESC, id DESC LIMIT 10"
                cur.execute(sql, where_params)
                _past_perf_extra = cur.fetchall() or []
        except Exception:
            _past_perf_extra = []
        # Optional: include company_performance records (global past performance)
        _company_perf = []
        try:
            if _table_exists('company_performance'):
                cur.execute("""
                    SELECT * 
                    FROM company_performance 
                    ORDER BY COALESCE(year, 0) DESC, id DESC 
                    LIMIT 10
                """)
                _company_perf = cur.fetchall() or []
        except Exception:
            _company_perf = []
        
        # Optional: personnel roster - DISABLED per user request to avoid employee list hallucination/inclusion
        _personnel = []
        # try:
        #     if _table_exists('personnel'):
        #         cols = _describe_columns('personnel')
        #         where_sql, where_params = _company_where_clause(cols, selected_company)
        #         sql = f"SELECT * FROM personnel {where_sql} ORDER BY id DESC LIMIT 15"
        #         cur.execute(sql, where_params)
        #         _personnel = cur.fetchall() or []
        #     else:
        #         # Fallback to generic employees table if available
        #         if _table_exists('employees'):
        #             cur.execute("""
        #                 SELECT name, department AS role, email 
        #                 FROM employees 
        #                 WHERE is_active = TRUE 
        #                 ORDER BY name ASC
        #                 LIMIT 15
        #             """)
        #             _personnel = cur.fetchall() or []
        # except Exception:
        #     _personnel = []
        # Optional: active bids or projects_bids
        _projects_bids = []
        try:
            # projects_bids
            if _table_exists('projects_bids'):
                cols = _describe_columns('projects_bids')
                where_sql, where_params = _company_where_clause(cols, selected_company)
                sql = f"""
                    SELECT * FROM projects_bids
                    {where_sql}
                    ORDER BY COALESCE(due_date, created_at, updated_at) DESC, id DESC
                    LIMIT 10
                """
                cur.execute(sql, where_params)
                _projects_bids = cur.fetchall() or []
            # projects_contracts
            _projects_contracts = []
            if _table_exists('projects_contracts'):
                cols_pc = _describe_columns('projects_contracts')
                where_sql_pc, where_params_pc = _company_where_clause(cols_pc, selected_company)
                sql_pc = f"""
                    SELECT * FROM projects_contracts
                    {where_sql_pc}
                    ORDER BY COALESCE(contract_date, award_date, created_at) DESC, id DESC
                    LIMIT 10
                """
                cur.execute(sql_pc, where_params_pc)
                _projects_contracts = cur.fetchall() or []
            # Fallbacks when neither table is present or results empty
            if not _projects_bids and selected_company:
                if _table_exists('go_bids'):
                    cur.execute("""
                        SELECT g_id, b_name, due_date, state, company, summary
                        FROM go_bids
                        WHERE LOWER(COALESCE(company,'')) = LOWER(%s)
                        ORDER BY due_date DESC
                        LIMIT 10
                    """, (selected_company,))
                    _projects_bids = cur.fetchall() or []
        except Exception:
            _projects_bids, _projects_contracts = [], []
        cur.close()
    except Exception:
        _details, _prefs, _caps, _perf, _past_perf_extra, _company_perf, _personnel, _projects_bids = {}, {}, [], [], [], [], [], []
    
    company_context_lines = []
    if _details:
        company_context_lines.append(f"- Legal Name: {(_details.get('name') or company or 'Our Company')}")
        if _details.get('website'):
            company_context_lines.append(f"- Website: {_details.get('website')}")
        if _details.get('email'):
            company_context_lines.append(f"- Email: {_details.get('email')}")
        if _details.get('phone'):
            company_context_lines.append(f"- Phone: {_details.get('phone')}")
        if _details.get('about'):
            company_context_lines.append(f"- About: {_details.get('about')[:400]}")
    if _prefs and (_prefs.get('registered_states') or '').strip():
        company_context_lines.append(f"- Registered/Eligible States: {_prefs.get('registered_states')}")
    if _caps:
        company_context_lines.append("- Capabilities:")
        for c in _caps[:5]:
            desc = (c.get('description') or '').strip()
            if desc:
                company_context_lines.append(f"  ??? {desc[:160]}")
    if _perf:
        company_context_lines.append("- Relevant Projects/Bids (from projects_bids):")
        for p in _perf[:7]:
            # Support both projects_bids and go_bids fields
            pname = (p.get('project_name') or p.get('b_name') or p.get('name') or '').strip() or 'Project/Bid'
            due = p.get('due_date') or p.get('created_at') or ''
            company_name = (p.get('company_name') or p.get('company') or '').strip()
            psum = (p.get('summary') or p.get('description') or '').strip()
            due_str = str(due)[:10] if due else ''
            snippet = psum[:220] + ('???' if psum and len(psum) > 220 else '')
            tail = []
            if due_str: tail.append(f"Due {due_str}")
            if company_name: tail.append(company_name)
            meta = f" ??? {' | '.join(tail)}" if tail else ''
            company_context_lines.append(f"  ??? {pname}{meta}{f' ??? {snippet}' if snippet else ''}")
    # Include extra past_performance table if available
    if _past_perf_extra:
        company_context_lines.append("- Additional Past Performance (from past_performance):")
        for p in _past_perf_extra[:5]:
            pname = (p.get('project_name') or p.get('title') or '').strip() or 'Project'
            client = (p.get('client') or p.get('owner') or '').strip()
            pyear = p.get('year')
            value = p.get('contract_value') or p.get('value')
            psum = (p.get('summary') or p.get('description') or '').strip()
            snippet = psum[:200] + ('???' if psum and len(psum) > 200 else '')
            line_bits = [pname]
            if pyear: line_bits.append(f"{pyear}")
            if client: line_bits.append(client)
            if value: line_bits.append(str(value))
            line = " ??? ".join([b for b in line_bits if b])
            company_context_lines.append(f"  ??? {line}{f' ??? {snippet}' if snippet else ''}")
    # Include company_performance table if available
    if '_company_perf' in locals() and _company_perf:
        company_context_lines.append("- Additional Past Performance (from company_performance):")
        for p in _company_perf[:5]:
            pname = (p.get('project_name') or '').strip() or 'Project'
            pyear = p.get('year')
            line = f"{pname}{f' ??? {pyear}' if pyear else ''}"
            company_context_lines.append(f"  ??? {line}")
    
    # Personnel roster - DISABLED
    # if _personnel:
    #     company_context_lines.append("- Key Personnel:")
    #     for m in _personnel[:7]:
    #         name = (m.get('name') or m.get('full_name') or '').strip()
    #         role = (m.get('title') or m.get('role') or m.get('position') or m.get('department') or '').strip()
    #         certs = (m.get('certifications') or '').strip()
    #         tail = f" ??? {role}" if role else ""
    #         if certs:
    #             tail += f" ({certs[:80]}{'???' if len(certs) > 80 else ''})"
    #         if name:
    #             company_context_lines.append(f"  ??? {name}{tail}")
    # Projects / Bids snapshot (kept only when not already used as _perf)
    if _projects_bids and not _perf:
        company_context_lines.append("- Active/Recent Bids & Projects:")
        for b in _projects_bids[:7]:
            name = (b.get('b_name') or b.get('project_name') or b.get('name') or '').strip() or 'Bid/Project'
            due = b.get('due_date') or b.get('created_at')
            state = (b.get('state') or b.get('status') or '').strip()
            summary = (b.get('summary') or b.get('description') or '').strip()
            due_str = str(due)[:10] if due else ''
            snippet = summary[:120] + ('???' if summary and len(summary) > 120 else '')
            label = f"{name}{f' ??? Due {due_str}' if due_str else ''}{f' ??? {state}' if state else ''}"
            company_context_lines.append(f"  ??? {label}{f' ??? {snippet}' if snippet else ''}")
    if '_projects_contracts' in locals() and _projects_contracts:
        company_context_lines.append("- Recent Contracts:")
        for c in _projects_contracts[:7]:
            name = (c.get('contract_name') or c.get('project_name') or c.get('name') or '').strip() or 'Contract'
            date = c.get('contract_date') or c.get('award_date') or c.get('created_at')
            value = c.get('contract_value') or c.get('value') or c.get('amount')
            due_str = str(date)[:10] if date else ''
            val_str = f"${value}" if value not in (None, '') else ''
            company_context_lines.append(f"  ??? {name}{f' ??? {due_str}' if due_str else ''}{f' ??? {val_str}' if val_str else ''}")
    company_context_block = "\n".join(company_context_lines).strip()
    if company_context_block:
        user_prompt = f"{user_prompt}\n\nCompany Profile Context (from database):\n{company_context_block}"
    
    # If no AI providers are configured, return a reasonable offline fallback instead of erroring
    _openai_key_present = (override_api_key or app.config.get('OPENAI_API_KEY') or os.getenv('OPENAI_API_KEY') or '').strip()
    _groq_key_present = (app.config.get('GROQ_API_KEY') or os.getenv('GROQ_API_KEY') or '').strip()
    _enable_ollama = False
    if not (_openai_key_present or _groq_key_present or _enable_ollama):
        # Minimal offline templates so the user can proceed without AI
        def _fallback_content() -> str:
            if is_requirements_compliance:
                return (
                    f"Our organization confirms that we have carefully reviewed the solicitation and all associated documents, "
                    f"including addenda, forms, certifications, and submission requirements. We acknowledge and will comply with "
                    f"all mandatory instructions, general and special conditions, technical specifications, and submittal formats. "
                    f"We will submit every required attachment and form in the prescribed manner and by the deadline "
                    f"{f'({due_date_str})' if due_date_str else ''}. "
                    f"Any exceptions, if required, will be listed in the Deviations section; otherwise, none are taken."
                ) + "\n\n" + (
                    f"We further certify that our proposed approach will address all deliverables and key activities mandated by the RFP. "
                    f"We will provide complete documentation, maintain the requested quality standards, and coordinate with the client to "
                    f"ensure smooth execution in accordance with the scope and evaluation criteria. This Statement of Compliance is submitted "
                    f"in good faith and may be customized once the full RFP text is analyzed by the AI service."
                )
            # Generic single-section fallback
            return (
                f"AI is temporarily unavailable. This section can be drafted using the attached RFP and company profile. "
                f"Summarize the client objective, list all required deliverables, and briefly describe our compliant approach. "
                f"Once AI service is restored, click Generate again to expand this into a complete narrative."
            )
        _fc = _fallback_content()
        _paras = [p.strip() for p in re.split(r'\n\s*\n', _fc.strip()) if p.strip()] or [_fc.strip()]
        # Simple heuristic flags to surface potential suggestions
        def _heuristic_flags(section_paragraphs):
            import re as _re
            trig = _re.compile(r'\b(we\s+recommend|we\s+propose|the\s+client\s+should|it\s+is\s+advisable|best\s+practice)\b', _re.I)
            results = []
            for i, para in enumerate(section_paragraphs):
                for s in [s.strip() for s in _re.split(r'(?<=[.!?])\s+', para) if s.strip()]:
                    if trig.search(s):
                        results.append({'paragraph_index': i, 'sentence': s, 'reason': 'suggestion_outside_rfp', 'rationale': 'Heuristic match'})
            return results
        _flags = _heuristic_flags(_paras)
        return jsonify({
            'content': _paras,
            'raw': "\n\n".join(_paras),
            'flags': {'outside_rfp_recommendations': _flags, 'flag_count': len(_flags)},
            'model': 'offline-fallback',
            'usage': {},
        })
    
    def _chat_with_fallback(messages, temperature=0.3):
        # Attempt 1: explicit override or server OpenAI
        api_key_a = (override_api_key or app.config.get('OPENAI_API_KEY') or os.getenv('OPENAI_API_KEY') or '').strip()
        base_url_a = (app.config.get('OPENAI_BASE_URL') or os.getenv('OPENAI_BASE_URL') or 'https://api.openai.com/v1').strip()
        model_a = (app.config.get('OPENAI_MODEL') or os.getenv('OPENAI_MODEL') or 'meta-llama/llama-4-scout-17b-16e-instruct').strip()
        attempts = []
        if api_key_a:
            attempts.append(('openai', api_key_a, base_url_a, model_a))
        # Attempt 2: GROQ fallback (often offers a free tier)
        api_key_b = (app.config.get('GROQ_API_KEY') or os.getenv('GROQ_API_KEY') or '').strip()
        base_url_b = (app.config.get('GROQ_BASE_URL') or os.getenv('GROQ_BASE_URL') or 'https://api.groq.com/openai/v1').strip()
        model_b = (app.config.get('GROQ_MODEL') or os.getenv('GROQ_MODEL') or 'llama-3.1-8b-instant').strip()
        if api_key_b:
            attempts.append(('groq', api_key_b, base_url_b, model_b))
        last_error = None
        for provider, key, base_url, model in attempts:
            try:
                endpoint = base_url.rstrip('/')
                if not endpoint.endswith('/chat/completions'):
                    endpoint = f"{endpoint}/chat/completions"
                headers = {'Authorization': f'Bearer {key}', 'Content-Type': 'application/json'}
                body = {'model': model, 'messages': messages, 'temperature': temperature}
                resp = requests.post(endpoint, headers=headers, json=body, timeout=90)
                data = resp.json()
                if resp.status_code >= 400:
                    err_message = data.get('error') if isinstance(data, dict) else None
                    detail = ''
                    if isinstance(err_message, dict):
                        detail = err_message.get('message') or err_message.get('code') or ''
                    elif isinstance(err_message, str):
                        detail = err_message
                    last_error = f"{provider} error {resp.status_code}: {detail or 'unknown'}"
                    continue
                choices_local = data.get('choices') or []
                if not choices_local:
                    last_error = f"{provider} returned no choices"
                    continue
                return (provider, (choices_local[0].get('message', {}) or {}).get('content', ''), data, model)
            except requests.RequestException as err:
                last_error = f"{provider} network error: {err}"
                continue
            except ValueError:
                last_error = f"{provider} returned non-JSON"
                continue
        raise Exception(last_error or 'No AI provider configured')
    
    try:
        provider_used, content, data, model = _chat_with_fallback(
            [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_prompt}
            ],
            temperature=0.3
        )
    except Exception as e:
        # Graceful fallback if all providers failed (e.g., Ollama not running)
        app.logger.error("Section generation failed, using offline fallback: %s", e)
        _fc = (
            "AI service is temporarily unavailable. The following draft can be customized:\n\n"
            + ("Statement of Compliance: We confirm full compliance with all mandatory requirements, "
               "forms, deliverables, and conditions of the solicitation. Any exceptions will be listed "
               "in the Deviations section; otherwise, none are taken.")
            if is_requirements_compliance else
            "Draft section placeholder. Summarize the RFP objective, our compliant approach, and required deliverables."
        )
        _paras = [p.strip() for p in re.split(r'\n\s*\n', _fc.strip()) if p.strip()] or [_fc.strip()]
        # Heuristic flags
        def _heuristic_flags(section_paragraphs):
            import re as _re
            trig = _re.compile(r'\b(we\s+recommend|we\s+propose|the\s+client\s+should|it\s+is\s+advisable|best\s+practice)\b', _re.I)
            results = []
            for i, para in enumerate(section_paragraphs):
                for s in [s.strip() for s in _re.split(r'(?<=[.!?])\s+', para) if s.strip()]:
                    if trig.search(s):
                        results.append({'paragraph_index': i, 'sentence': s, 'reason': 'suggestion_outside_rfp', 'rationale': 'Heuristic match'})
            return results
        _flags = _heuristic_flags(_paras)
        return jsonify({
            'content': _paras,
            'raw': "\n\n".join(_paras),
            'flags': {'outside_rfp_recommendations': _flags, 'flag_count': len(_flags)},
            'model': 'offline-fallback',
            'usage': {},
        })
    
    if not content:
        return jsonify({'error': 'api_unavailable', 'message': 'The AI service returned an empty response.'}), 502
    
    # Split content into paragraphs for frontend display
    paragraphs = [p.strip() for p in re.split(r'\n\s*\n', content.strip()) if p.strip()]
    if not paragraphs:
        paragraphs = [content.strip()]
    # Executive Summary: defensively remove any accidental header line like "Client, City, State Date"
    if is_executive_summary and paragraphs:
        try:
            import re as _re
            first = paragraphs[0].strip()
            header_like = False
            if len(first) <= 120:
                # Matches "October 17, 2025" etc.
                month_pat = r'(jan|feb|mar|apr|may|jun|jul|aug|sep|sept|oct|nov|dec)[a-z]*'
                if _re.search(rf'\b{month_pat}\b\s+\d{{1,2}},\s*\d{{4}}', first, _re.I):
                    header_like = True
            if not header_like:
                # Heuristic: mentions civic entities plus a year
                civic_terms = ('city', 'county', 'state', 'department', 'school district', 'university', 'college', 'authority')
                if any(t in first.lower() for t in civic_terms) and _re.search(r'\b\d{4}\b', first):
                    header_like = True
            if header_like and len(paragraphs) > 1:
                paragraphs = paragraphs[1:]
        except Exception:
            pass

    # AI guardrail: ask the LLM to identify recommendation/suggestion sentences that are not supported by the RFP
    def _ai_flag_outside_recommendations(section_paragraphs: list[str], rfp_text: str) -> list[dict]:
        try:
            joined_section = "\n\n".join(section_paragraphs)
            # Try OpenAI first, then GROQ fallback (free tier friendly)
            attempts = []
            attempts.append((
                (app.config.get('OPENAI_API_KEY') or os.getenv('OPENAI_API_KEY') or '').strip(),
                (app.config.get('OPENAI_BASE_URL') or os.getenv('OPENAI_BASE_URL') or 'https://api.openai.com/v1').strip(),
                (app.config.get('OPENAI_MODEL') or os.getenv('OPENAI_MODEL') or 'meta-llama/llama-4-scout-17b-16e-instruct').strip()
            ))
            attempts.append((
                (app.config.get('GROQ_API_KEY') or os.getenv('GROQ_API_KEY') or '').strip(),
                (app.config.get('GROQ_BASE_URL') or os.getenv('GROQ_BASE_URL') or 'https://api.groq.com/openai/v1').strip(),
                (app.config.get('GROQ_MODEL') or os.getenv('GROQ_MODEL') or 'llama-3.1-70b-versatile').strip()
            ))

            # Trim RFP to keep request small but useful
            rfp_trimmed = (rfp_text or '')[:20000]
            system_msg = (
                "You are a compliance auditor for proposal content. "
                "Given an RFP and a draft proposal section, identify only those sentences in the proposal text that are recommendations/suggestions/proposals/advice introduced by the bidder and are not explicitly supported, requested, or quoted by the RFP. "
                "Be conservative: flag only when clearly unsupported. "
                "Return ONLY compact JSON: {\"outside\":[{\"sentence\":\"...\",\"rationale\":\"...\"}]}. No commentary."
            )
            user_msg = (
                f"RFP TEXT:\n{rfp_trimmed}\n\n---\n\n"
                f"PROPOSAL SECTION TEXT:\n{joined_section}\n\n"
                "Instructions:\n"
                "- Evaluate proposal sentences in context of the RFP.\n"
                "- A sentence is 'outside' if it expresses a recommendation/suggestion/advice (e.g., 'we recommend', 'we propose', 'the client should', 'it is advisable') that the RFP does not require, request, or imply.\n"
                "- Do NOT list factual descriptions, mandatory compliance assertions, or paraphrases of RFP requirements.\n"
                "- Output JSON only."
            )
            reply = ''
            for key, base_url_local, model_local in attempts:
                if not key:
                    continue
                endpoint_local = base_url_local.rstrip('/')
                if not endpoint_local.endswith('/chat/completions'):
                    endpoint_local = f"{endpoint_local}/chat/completions"
                headers_local = {'Authorization': f'Bearer {key}', 'Content-Type': 'application/json'}
                body_local = {
                    'model': model_local,
                    'messages': [
                        {'role': 'system', 'content': system_msg},
                        {'role': 'user', 'content': user_msg}
                    ],
                    'temperature': 0.1,
                }
                try:
                    resp = requests.post(endpoint_local, headers=headers_local, json=body_local, timeout=90)
                    data = resp.json()
                    if resp.status_code >= 400:
                        continue
                    choices = data.get('choices') or []
                    reply = (choices[0].get('message', {}) or {}).get('content', '') if choices else ''
                    if reply:
                        break
                except Exception:
                    continue
            # Attempt to parse JSON directly; strip code fences if present
            text = reply.strip()
            if text.startswith('```'):
                text = text.lstrip('`')
                fence = text.find('```')
                if fence != -1:
                    text = text[:fence]
            import json as _json
            parsed = {}
            try:
                parsed = _json.loads(text)
            except Exception:
                # Try extracting JSON substring
                m = re.search(r'\{[\s\S]*\}', text)
                if m:
                    try:
                        parsed = _json.loads(m.group(0))
                    except Exception:
                        parsed = {}
            outside = parsed.get('outside') if isinstance(parsed, dict) else None
            if not isinstance(outside, list):
                outside = []

            # Map sentences to paragraph indexes
            lower_paras = [p.lower() for p in section_paragraphs]
            results = []
            for item in outside:
                sentence = (item.get('sentence') or '').strip()
                rationale = (item.get('rationale') or '').strip()
                if not sentence:
                    continue
                target = sentence.lower()
                p_idx = -1
                for i, p in enumerate(lower_paras):
                    if target and target in p:
                        p_idx = i
                        break
                results.append({
                    'paragraph_index': p_idx if p_idx >= 0 else 0,
                    'sentence': sentence,
                    'reason': 'suggestion_outside_rfp',
                    'rationale': rationale
                })
            return results
        except Exception:
            return []

    outside_flags = _ai_flag_outside_recommendations(paragraphs, rfp_content or '')
    # Heuristic fallback when AI flagger is unavailable or returns nothing
    if not outside_flags:
        def _heuristic_flag_outside(section_paragraphs):
            import re as _re
            trigger_phrases = [
                r'\bwe\s+recommend\b', r'\bour\s+recommendation\b', r'\bwe\s+propose\b', r'\bour\s+proposal\b',
                r'\bthe\s+client\s+should\b', r'\bshould\b', r'\bit\s+is\s+advisable\b', r'\brecommend\b',
                r'\bsuggestion\b', r'\badvis(e|ory)\b', r'\bbest\s+practice\b'
            ]
            trig_re = _re.compile('|'.join(trigger_phrases), _re.IGNORECASE)
            results = []
            for idx, para in enumerate(section_paragraphs):
                # Split naive sentences
                sentences = [s.strip() for s in _re.split(r'(?<=[.!?])\s+', para) if s.strip()]
                for s in sentences:
                    if trig_re.search(s):
                        results.append({
                            'paragraph_index': idx,
                            'sentence': s,
                            'reason': 'suggestion_outside_rfp',
                            'rationale': 'Heuristic match for recommendation/suggestion phrasing; verify against RFP.'
                        })
            return results
        outside_flags = _heuristic_flag_outside(paragraphs)

    return jsonify({
        'content': paragraphs,
        'raw': "\n\n".join(paragraphs).strip(),
        'flags': {
            'outside_rfp_recommendations': outside_flags,
            'flag_count': len(outside_flags)
        },
        'model': data.get('model', model),
        'usage': data.get('usage', {}),
    })


@app.route('/api/refine-section-content', methods=['POST'])
@login_required
def refine_section_content():
    """Refine existing section content to strictly align with the RFP and remove unsupported suggestions."""
    payload = request.get_json(silent=True) or {}
    paragraphs = payload.get('paragraphs') or []
    if isinstance(paragraphs, str):
        paragraphs = [p.strip() for p in re.split(r'\n\s*\n', paragraphs) if p.strip()]
    section_id = (payload.get('section_id') or '').strip()
    section_title = (payload.get('section_title') or '').strip()
    bid_id = payload.get('bid_id')
    company = (payload.get('company') or '').strip()
    contact_email = (payload.get('contact_email') or '').strip()
    override_api_key = (payload.get('api_key') or '').strip()
    override_model = (payload.get('model') or '').strip()

    if not paragraphs:
        return jsonify({'error': 'missing_params', 'message': 'No content to refine.'}), 400

    rfp_content = ''
    if bid_id:
        rfp_content = _fetch_rfp_content_for_bid(bid_id, page_limit=100, char_limit=25000)

    # Prepare LLM request with fallback (OpenAI -> GROQ)
    def _chat_with_fallback(messages, temperature=0.2):
        api_key_a = (override_api_key or app.config.get('OPENAI_API_KEY') or os.getenv('OPENAI_API_KEY') or '').strip()
        base_url_a = (app.config.get('OPENAI_BASE_URL') or os.getenv('OPENAI_BASE_URL') or 'https://api.openai.com/v1').strip()
        model_a = (override_model or app.config.get('OPENAI_MODEL') or os.getenv('OPENAI_MODEL') or 'meta-llama/llama-4-scout-17b-16e-instruct').strip()
        attempts = []
        if api_key_a:
            attempts.append((api_key_a, base_url_a, model_a, 'openai'))
        api_key_b = (app.config.get('GROQ_API_KEY') or os.getenv('GROQ_API_KEY') or '').strip()
        base_url_b = (app.config.get('GROQ_BASE_URL') or os.getenv('GROQ_BASE_URL') or 'https://api.groq.com/openai/v1').strip()
        model_b = (app.config.get('GROQ_MODEL') or os.getenv('GROQ_MODEL') or 'llama-3.1-8b-instant').strip()
        if api_key_b:
            attempts.append((api_key_b, base_url_b, model_b, 'groq'))
        # Local Ollama disabled
        last_error = None
        for key, base_url, model, provider in attempts:
            endpoint_local = base_url.rstrip('/')
            if not endpoint_local.endswith('/chat/completions'):
                endpoint_local = f"{endpoint_local}/chat/completions"
            headers_local = {'Authorization': f'Bearer {key}', 'Content-Type': 'application/json'}
            body_local = {'model': model, 'messages': messages, 'temperature': temperature}
            try:
                resp = requests.post(endpoint_local, headers=headers_local, json=body_local, timeout=120)
            except requests.RequestException as err:
                last_error = f"{provider} network error: {err}"
                continue
            try:
                data_local = resp.json()
            except ValueError:
                last_error = f"{provider} returned non-JSON (status {resp.status_code})"
                continue
            if resp.status_code >= 400:
                err_message = data_local.get('error') if isinstance(data_local, dict) else None
                detail = ''
                if isinstance(err_message, dict):
                    detail = err_message.get('message') or err_message.get('code') or ''
                elif isinstance(err_message, str):
                    detail = err_message
                last_error = f"{provider} error {resp.status_code}: {detail or 'unknown'}"
                continue
            choices_local = data_local.get('choices') or []
            if not choices_local:
                last_error = f"{provider} returned no choices"
                continue
            return (provider, (choices_local[0].get('message', {}) or {}).get('content', ''), data_local, model, base_url, endpoint_local)
        raise Exception(last_error or 'No AI provider configured')

    system_prompt = (
        "You are an expert proposal editor for government RFP responses. "
        "Given the RFP and a draft section, rewrite the section to be strictly compliant: "
        "remove or rephrase any unsupported recommendations/suggestions, keep required assertions, "
        "and strengthen alignment with the RFP requirements. Maintain professional tone. "
        "Return only the refined section text that can be split into paragraphs."
    )
    user_prompt = f"""RFP TEXT:
{(rfp_content or '')[:20000]}

---

CURRENT SECTION TEXT:
{'\n\n'.join(paragraphs)}

Rewrite the section so it strictly aligns with the RFP. Do not add any new commitments that the RFP does not imply.
Return only the refined text."""

    try:
        provider_used, refined_text, data, model, base_url, endpoint = _chat_with_fallback(
            [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_prompt}
            ],
            temperature=0.2
        )
    except Exception as e:
        return jsonify({'error': 'api_unavailable', 'message': f'AI service returned an error: {e}'}), 502
    if not refined_text:
        return jsonify({'error': 'api_unavailable', 'message': 'The AI service returned an empty response.'}), 502
    refined_paragraphs = [p.strip() for p in re.split(r'\n\s*\n', refined_text.strip()) if p.strip()] or [refined_text.strip()]

    # Re-run AI guardrail to report any remaining unsupported suggestions
    def _ai_flag_outside_recommendations_ref(section_paragraphs, rfp_text):
        try:
            joined_section = "\n\n".join(section_paragraphs)
            # Try using same provider used for refinement; if unavailable, fall back to GROQ then OpenAI
            attempts = []
            attempts.append((base_url, model))
            attempts.append((app.config.get('GROQ_BASE_URL') or os.getenv('GROQ_BASE_URL') or 'https://api.groq.com/openai/v1', app.config.get('GROQ_MODEL') or os.getenv('GROQ_MODEL') or 'llama-3.1-70b-versatile'))
            attempts.append((app.config.get('OPENAI_BASE_URL') or os.getenv('OPENAI_BASE_URL') or 'https://api.openai.com/v1', app.config.get('OPENAI_MODEL') or os.getenv('OPENAI_MODEL') or 'meta-llama/llama-4-scout-17b-16e-instruct'))
            rfp_trimmed = (rfp_text or '')[:20000]
            system_msg = (
                "You are a compliance auditor for proposal content. "
                "Given an RFP and a draft proposal section, identify only those sentences in the proposal text that are recommendations/suggestions/proposals/advice introduced by the bidder and are not explicitly supported by the RFP. "
                "Return ONLY JSON: {\"outside\":[{\"sentence\":\"...\",\"rationale\":\"...\"}]}"
            )
            user_msg = f"RFP TEXT:\n{rfp_trimmed}\n\n---\n\nPROPOSAL SECTION TEXT:\n{joined_section}\n\nOutput JSON only."
            reply = ''
            for base_url_local, model_local in attempts:
                # Choose key based on base_url
                if 'groq' in (base_url_local or ''):
                    key = (app.config.get('GROQ_API_KEY') or os.getenv('GROQ_API_KEY') or '').strip()
                else:
                    key = (app.config.get('OPENAI_API_KEY') or os.getenv('OPENAI_API_KEY') or '').strip()
                if not key:
                    continue
                endpoint_local = base_url_local.rstrip('/')
                if not endpoint_local.endswith('/chat/completions'):
                    endpoint_local = f"{endpoint_local}/chat/completions"
                headers_local = {'Authorization': f'Bearer {key}', 'Content-Type': 'application/json'}
                body_local = {
                    'model': model_local,
                    'messages': [
                        {'role': 'system', 'content': system_msg},
                        {'role': 'user', 'content': user_msg}
                    ],
                    'temperature': 0.1,
                }
                try:
                    resp = requests.post(endpoint_local, headers=headers_local, json=body_local, timeout=90)
                    data_local = resp.json()
                    if resp.status_code >= 400:
                        continue
                    choices_local = data_local.get('choices') or []
                    reply = (choices_local[0].get('message', {}) or {}).get('content', '') if choices_local else ''
                    if reply:
                        break
                except Exception:
                    continue
            text = reply.strip()
            if text.startswith('```'):
                text = text.lstrip('`')
                fence = text.find('```')
                if fence != -1:
                    text = text[:fence]
            import json as _json
            parsed = {}
            try:
                parsed = _json.loads(text)
            except Exception:
                m = re.search(r'\{[\s\S]*\}', text)
                if m:
                    try:
                        parsed = _json.loads(m.group(0))
                    except Exception:
                        parsed = {}
            outside = parsed.get('outside') if isinstance(parsed, dict) else None
            if not isinstance(outside, list):
                outside = []
            lower_paras = [p.lower() for p in section_paragraphs]
            results = []
            for item in outside:
                sentence = (item.get('sentence') or '').strip()
                rationale = (item.get('rationale') or '').strip()
                if not sentence:
                    continue
                target = sentence.lower()
                p_idx = -1
                for i, p in enumerate(lower_paras):
                    if target and target in p:
                        p_idx = i
                        break
                results.append({
                    'paragraph_index': p_idx if p_idx >= 0 else 0,
                    'sentence': sentence,
                    'reason': 'suggestion_outside_rfp',
                    'rationale': rationale
                })
            return results
        except Exception:
            return []

    outside_flags = _ai_flag_outside_recommendations_ref(refined_paragraphs, rfp_content or '')
    # Heuristic fallback when AI flagger is unavailable or returns nothing
    if not outside_flags:
        def _heuristic_flag_outside_ref(section_paragraphs):
            import re as _re
            trigger_phrases = [
                r'\bwe\s+recommend\b', r'\bour\s+recommendation\b', r'\bwe\s+propose\b', r'\bour\s+proposal\b',
                r'\bthe\s+client\s+should\b', r'\bshould\b', r'\bit\s+is\s+advisable\b', r'\brecommend\b',
                r'\bsuggestion\b', r'\badvis(e|ory)\b', r'\bbest\s+practice\b'
            ]
            trig_re = _re.compile('|'.join(trigger_phrases), _re.IGNORECASE)
            results = []
            for idx, para in enumerate(section_paragraphs):
                sentences = [s.strip() for s in _re.split(r'(?<=[.!?])\s+', para) if s.strip()]
                for s in sentences:
                    if trig_re.search(s):
                        results.append({
                            'paragraph_index': idx,
                            'sentence': s,
                            'reason': 'suggestion_outside_rfp',
                            'rationale': 'Heuristic match for recommendation/suggestion phrasing; verify against RFP.'
                        })
            return results
        outside_flags = _heuristic_flag_outside_ref(refined_paragraphs)

    return jsonify({
        'content': refined_paragraphs,
        'raw': refined_text.strip(),
        'flags': {
            'outside_rfp_recommendations': outside_flags,
            'flag_count': len(outside_flags)
        },
        'model': model,
        'usage': data.get('usage', {}),
    })
@app.route('/api/compile-proposal-sections', methods=['POST'])
@login_required
def compile_proposal_sections():
    """Compile all generated section content into a single downloadable Word document."""
    payload = request.get_json(silent=True) or {}
    sections = payload.get('sections') or []
    bid_id = payload.get('bid_id') or payload.get('g_id') or None
    attachments_cache = {}

    def _get_cached_attachments(section_id):
        if not bid_id or not section_id:
            return []
        if section_id in attachments_cache:
            return attachments_cache[section_id]
        try:
            files = _get_section_files_for_bid(bid_id, section_id, limit=20) or []
        except Exception:
            files = []
        attachments_cache[section_id] = files
        return files

    # Server-side guard: only include sections explicitly marked as Saved and with content
    filtered_sections = []
    for s in sections:
        try:
            status_ok = str((s.get('status') or '')).strip().lower() == 'saved'
            has_content = bool(s.get('raw_content')) or (isinstance(s.get('content'), list) and len(s.get('content')) > 0)
            section_id = (s.get('id') or '').strip()
            has_attachments = bool(_get_cached_attachments(section_id)) if section_id else False
            if status_ok and (has_content or has_attachments):
                filtered_sections.append(s)
        except Exception:
            continue
    sections = filtered_sections
    if not isinstance(sections, list) or not sections:
        return jsonify({'error': 'missing_sections', 'message': 'No sections were provided to compile.'}), 400

    project_title = (payload.get('project_title') or '').strip()
    company_name = (payload.get('company') or '').strip()
    html_fragments = []

    try:
        from docx import Document
        from docx.shared import Inches, Pt
        from docx.enum.text import WD_ALIGN_PARAGRAPH
    except ImportError:
        return jsonify({'error': 'dependency_missing', 'message': 'python-docx library is required to compile proposals.'}), 500

    try:
        # Always prefer the H & F template for consistent formatting
        template_used = None
        document = None
        try:
            chosen_path = choose_company_template(company_name)
            if chosen_path:
                document = Document(chosen_path)
                _bn_lower = os.path.basename(chosen_path).lower()
                if 'sunsprint' in _bn_lower:
                    template_used = 'sunsprint'
                elif 'Proposal ikio' in _bn_lower or _bn_lower.endswith('Proposal ikio.docx'):
                    # IKIO-branded template
                    template_used = 'ikio'
                elif 'h & f' in _bn_lower or 'h&f' in _bn_lower or _bn_lower == 'h' or _bn_lower.endswith('h & f.docx'):
                    # Treat H & F.docx as Metco-branded template
                    template_used = 'metco'
                else:
                    template_used = 'hf'
            else:
                # Fallback to blank document if no template is present
                document = Document()
                template_used = 'blank'
        except Exception:
            # Defensive fallback in case template loading fails
            document = Document()
            template_used = 'blank'
        
        # Enforce universal fonts only when using non-branded templates
        PREFERRED_BODY_FONT_NAME = 'Aptos Display'
        PREFERRED_HEADING_FONT_NAME = 'Aptos Bold'
        if template_used not in ('sunsprint', 'metco', 'ikio'):
            try:
                normal_style = document.styles['Normal']
                normal_style.font.name = PREFERRED_BODY_FONT_NAME
                try:
                    from docx.shared import Pt as _Pt
                    normal_style.font.size = _Pt(11)
                except Exception:
                    pass
            except Exception:
                pass
            # Also try to set common heading/title styles to Aptos
            for _style_name in ['Title', 'Heading 1', 'Heading 2', 'Heading 3', 'Heading 4', 'Heading 5', 'Heading 6', 'Heading 7', 'Heading 8', 'Heading 9']:
                try:
                    document.styles[_style_name].font.name = PREFERRED_HEADING_FONT_NAME
                    try:
                        from docx.shared import Pt as _Pt
                        # Use 16pt for main section headings (Heading 1), keep others at 11pt
                        if _style_name == 'Heading 1':
                            document.styles[_style_name].font.size = _Pt(16)
                        else:
                            document.styles[_style_name].font.size = _Pt(11)
                        document.styles[_style_name].font.bold = True
                    except Exception:
                        pass
                except Exception:
                    continue

        # Ensure Word updates fields (TOC/page numbers) on open.
        try:
            from docx.oxml import OxmlElement
            from docx.oxml.ns import qn
            settings_el = document.settings._element
            update_fields = settings_el.find(qn('w:updateFields'))
            if update_fields is None:
                update_fields = OxmlElement('w:updateFields')
                settings_el.append(update_fields)
            update_fields.set(qn('w:val'), 'true')
        except Exception:
            pass
        
        # Ensure automatic header/footer fields:
        # - Header shows the current main heading via STYLEREF "Heading 1"
        # - Footer shows right-aligned "Page X of Y"
        try:
            section0 = document.sections[0]
            # Only add header/footer if template is blank/hf or existing parts are empty (avoid overriding branded templates)
            def _part_has_text(part):
                try:
                    return any((p.text or '').strip() for p in getattr(part, 'paragraphs', []) or [])
                except Exception:
                    return False
            
            # Header suppressed per requirement: no dynamic heading in header
            try:
                pass
            except Exception:
                pass
            
            # Footer page numbering logic removed per requirement
        except Exception:
            pass
        
        # Helper: style existence
        def _has_style(doc, style_name):
            try:
                _ = doc.styles[style_name]
                return True
            except Exception:
                return False
        
        # Collect section titles for Table of Contents (before processing content)
        section_titles = []
        for section in sections:
            if not isinstance(section, dict):
                continue
            title = (section.get('title') or 'Untitled Section').strip() or 'Untitled Section'
            content_blocks = section.get('content') if isinstance(section.get('content'), list) else []
            raw_html = section.get('raw_content') or ''
            section_id = (section.get('id') or '').strip()
            has_attachments = bool(_get_cached_attachments(section_id)) if section_id else False
            if content_blocks or raw_html or has_attachments:
                section_titles.append(title)
        
        # Add Table of Contents page if we have sections (keep it as the first page)
        if section_titles:
            try:
                if _has_style(document, 'Title'):
                    toc_heading = document.add_paragraph('Table of Contents', style=document.styles['Title'])
                else:
                    toc_heading = document.add_paragraph('Table of Contents')
                try:
                    from docx.shared import Pt as _Pt
                    for run in toc_heading.runs:
                        run.font.name = PREFERRED_HEADING_FONT_NAME
                        run.font.bold = True
                        run.font.size = _Pt(11)
                except Exception:
                    pass
            except Exception:
                toc_heading = document.add_paragraph('Table of Contents')
            document.add_paragraph()  # Add spacing
            # Insert a dynamic, hyperlink-enabled TOC field that auto-calculates page numbers
            try:
                from docx.oxml import OxmlElement
                from docx.oxml.ns import qn
                toc_para = document.add_paragraph()
                r = toc_para.add_run()
                fldChar = OxmlElement('w:fldChar')
                fldChar.set(qn('w:fldCharType'), 'begin')
                # Mark as dirty so Word refreshes the TOC on open
                try:
                    fldChar.set(qn('w:dirty'), 'true')
                except Exception:
                    pass
                r._r.append(fldChar)
                instrText = OxmlElement('w:instrText')
                instrText.set(qn('xml:space'), 'preserve')
                # \o "1-1" includes only Heading 1; \h hyperlinks; \z hides page numbers in web view; \u uses outline levels
                instrText.text = 'TOC \\o "1-3" \\h \\z \\u'
                r._r.append(instrText)
                fldChar = OxmlElement('w:fldChar')
                fldChar.set(qn('w:fldCharType'), 'separate')
                r._r.append(fldChar)
                # Placeholder text that Word replaces after field update
                toc_para.add_run('Table of Contents will update on open.')
                fldChar = OxmlElement('w:fldChar')
                fldChar.set(qn('w:fldCharType'), 'end')
                r._r.append(fldChar)
            except Exception:
                # Fallback: simple static list (no links)
                for idx, toc_title in enumerate(section_titles, 1):
                    toc_para = document.add_paragraph(f'{idx}. {toc_title}')
                    toc_para.paragraph_format.space_after = Pt(6)
                    try:
                        for run in toc_para.runs:
                            run.font.name = 'Aptos Display'
                    except Exception:
                        pass

            document.add_page_break()
            html_fragments.append('<h2>Table of Contents</h2>')
            html_fragments.append('<ol>' + ''.join(f'<li>{escape(title)}</li>' for title in section_titles) + '</ol>')

        # Add title page after TOC so TOC remains the first page
        if project_title:
            try:
                if _has_style(document, 'Title'):
                    title_para = document.add_paragraph(project_title, style=document.styles['Title'])
                elif _has_style(document, 'METCO Title'):
                    title_para = document.add_paragraph(project_title, style=document.styles['METCO Title'])
                else:
                    # Fall back to first-level heading if Title style is unavailable
                    title_para = document.add_heading(project_title, level=1)
                try:
                    title_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
                except Exception:
                    pass
            except Exception:
                # Absolute fallback to avoid style-related failures
                p = document.add_paragraph(project_title)
                try:
                    for run in p.runs:
                        run.font.name = PREFERRED_HEADING_FONT_NAME
                        from docx.shared import Pt as _Pt
                        run.font.bold = True
                        run.font.size = _Pt(11)
                except Exception:
                    pass
            html_fragments.append(f'<h1 style=\"text-align: center;\">{escape(project_title)}</h1>')
            document.add_paragraph()  # Add spacing
            document.add_page_break()
        
        # Process each section with generated content
        first_section_added = False
        # Determine a table style available in the template, prefer METCO-specific if present
        table_style_name = None
        try:
            from docx.enum.style import WD_STYLE_TYPE as _WD_STYLE_TYPE
            for s in document.styles:
                try:
                    if getattr(s, "type", None) == _WD_STYLE_TYPE.TABLE:
                        if s.name in ("METCO Table", "Table Grid", "Light Grid Accent 1", "Grid Table 4 Accent 1"):
                            table_style_name = s.name
                            if table_style_name == "METCO Table":
                                break
                except Exception:
                    continue
            if not table_style_name:
                table_style_name = "Table Grid"
        except Exception:
            table_style_name = "Table Grid"

        # End of initial preparation block
    except Exception as e:
        app.logger.exception('Unexpected error preparing document: %s', e)
        return jsonify({'error': 'unexpected_error', 'message': f'Compilation failed: {str(e)}'}), 500

    # Continue with compilation
    def _render_markdown_to_docx_paragraph(doc, text: str):
        """
        Render a single text block into the Word document, interpreting a minimal Markdown subset:
        - Lines starting with '### ' become Heading 3.
        - Bold spans wrapped in **double asterisks** become bold runs.
        Any remaining stray '*' or '#' characters are removed.
        """
        if not text:
            return
        try:
            import re as __re_md
            heading_match = __re_md.match(r'^\s*#{3,}\s*(.+?)\s*$', text)
            if heading_match:
                heading_text = heading_match.group(1)
                # Add a heading paragraph and style per requirement (Aptos, bold, 16pt)
                para = doc.add_heading(heading_text, level=3)
                try:
                    from docx.shared import Pt as _Pt
                    for run in para.runs:
                        run.font.bold = True
                        run.font.name = PREFERRED_HEADING_FONT_NAME
                        run.font.size = _Pt(11)
                except Exception:
                    pass
                return
            # Detect multi-line bullet list and render each as a bullet paragraph
            lines = [ln for ln in text.splitlines() if ln.strip()]
            has_bullets = any(__re_md.match(r'^\s*[\-\*\+?????????????????]\s+', ln) for ln in lines)
            if has_bullets and len(lines) >= 1:
                for raw in lines:
                    m = __re_md.match(r'^\s*[\-\*\+?????????????????]\s+(.*)$', raw)
                    if m:
                        content = m.group(1).strip()
                        # Strip markdown artifacts like **bold** within bullet items
                        try:
                            content = __re_md.sub(r'\*\*(.+?)\*\*', r'\1', content)
                            content = __re_md.sub(r'[#*]+', '', content)
                        except Exception:
                            pass
                        p = doc.add_paragraph()
                        applied_style = False
                        try:
                            # Prefer Word's built-in bullet list (disc/filled circle)
                            p.style = doc.styles['List Bullet']
                            applied_style = True
                        except Exception:
                            applied_style = False
                        # Fallback: manually prepend a filled circle bullet and a tab
                        try:
                            from docx.shared import Pt as _Pt
                            if not applied_style:
                                rb = p.add_run('???\t')
                                rb.font.name = PREFERRED_BODY_FONT_NAME
                                rb.font.size = _Pt(11)
                            rt = p.add_run(content)
                            rt.font.name = PREFERRED_BODY_FONT_NAME
                            rt.font.size = _Pt(11)
                        except Exception:
                            # Absolute fallback: simple text
                            p.add_run(content)
                    else:
                        # non-bullet line in the block -> normal paragraph
                        p = doc.add_paragraph(__re_md.sub(r'[#*]+', '', raw))
                        try:
                            from docx.shared import Pt as _Pt
                            for run in p.runs:
                                run.font.name = PREFERRED_BODY_FONT_NAME
                                run.font.size = _Pt(11)
                        except Exception:
                            pass
                return
            # Regular paragraph with bold spans
            paragraph = doc.add_paragraph()
            parts = __re_md.split(r'(\*\*.+?\*\*)', text)
            for part in parts:
                if not part:
                    continue
                if part.startswith('**') and part.endswith('**') and len(part) >= 4:
                    content = part[2:-2]
                    run = paragraph.add_run(content)
                    try:
                        run.bold = True
                        run.font.name = PREFERRED_BODY_FONT_NAME
                        from docx.shared import Pt as _Pt
                        run.font.size = _Pt(11)
                    except Exception:
                        pass
                else:
                    # Remove leftover single '*' or '#' characters
                    cleaned = __re_md.sub(r'[#*]+', '', part)
                    run = paragraph.add_run(cleaned)
                    try:
                        run.font.name = PREFERRED_BODY_FONT_NAME
                        from docx.shared import Pt as _Pt
                        run.font.size = _Pt(11)
                    except Exception:
                        pass
        except Exception:
            # Fallback to simple paragraph if anything fails
            doc.add_paragraph(text)

    def _plaintext_markdown_to_html(text: str) -> str:
        """
        Convert a minimal Markdown subset to clean HTML string for preview.
        - '### Title' -> <h3>Title</h3>
        - '**bold**'  -> <strong>bold</strong>
        - Remove stray '*' and '#' characters elsewhere.
        """
        if not text:
            return ''
        import re as __re_md
        # Heading
        heading_match = __re_md.match(r'^\s*#{3,}\s*(.+?)\s*$', text)
        if heading_match:
            return f'<h3>{escape(heading_match.group(1))}</h3>'
        # Bullet lists
        if '\n' in text and any(l.strip().startswith(('-', '*', '+', '???')) for l in text.splitlines()):
            items = []
            for ln in [l for l in text.splitlines() if l.strip()]:
                ln_stripped = ln.strip()
                if ln_stripped[:1] in ('-', '*', '+') or ln_stripped.startswith('???'):
                    inner = ln_stripped[1:].strip()
                    # Remove simple markdown bold markers within list items for clean HTML preview
                    try:
                        import re as __re_md2
                        inner = __re_md2.sub(r'\*\*(.+?)\*\*', r'\1', inner)
                        inner = __re_md2.sub(r'[#*]+', '', inner)
                    except Exception:
                        pass
                    items.append(f'<li>{escape(inner)}</li>')
                else:
                    items.append(f'<li>{escape(ln_stripped)}</li>')
            return '<ul>' + ''.join(items) + '</ul>'
        # Bold spans
        def _bold_repl(m):
            return f'<strong>{escape(m.group(1))}</strong>'
        html = __re_md.sub(r'\*\*(.+?)\*\*', lambda m: _bold_repl(m), text)
        # Escape remaining content safely, but preserve the <strong> tags we just added
        # Strategy: temporarily replace strong tags, escape, then restore
        placeholder_open = '___STRONG_OPEN___'
        placeholder_close = '___STRONG_CLOSE___'
        html = html.replace('<strong>', placeholder_open).replace('</strong>', placeholder_close)
        html = escape(html)
        html = html.replace(placeholder_open, '<strong>').replace(placeholder_close, '</strong>')
        # Remove stray '*' and '#' characters
        html = __re_md.sub(r'[#*]+', '', html)
        # Wrap as paragraph by default
        return f'<p>{html}</p>'
    def _insert_html_with_tables(doc, html_text):
        """
        Render simple HTML content into the Word document.
        - Preserves tables (<table><tr><td>) as real Word tables with a template style.
        - Non-table HTML is converted to paragraphs using _strip_html_tags.
        """
        if not html_text:
            return
        # Helpers to style header rows with blue/green background and white bold text
        def _shade_cell(cell, fill_hex):
            try:
                from docx.oxml import OxmlElement
                from docx.oxml.ns import qn
                tcPr = cell._tc.get_or_add_tcPr()
                shd = OxmlElement('w:shd')
                shd.set(qn('w:val'), 'clear')
                shd.set(qn('w:color'), 'auto')
                shd.set(qn('w:fill'), fill_hex)
                tcPr.append(shd)
            except Exception:
                pass
        def _style_table_header_row(tbl):
            try:
                from docx.shared import RGBColor
                from docx.enum.text import WD_ALIGN_PARAGRAPH as _WD_ALIGN_PARAGRAPH
                from docx.shared import Pt as _Pt
            except Exception:
                return
            if not getattr(tbl, "rows", None) or len(tbl.rows) == 0:
                return
            header_row = tbl.rows[0]
            header_colors = ['2E74B5', '70AD47']  # blue, green
            for idx, cell in enumerate(header_row.cells):
                _shade_cell(cell, header_colors[idx % 2])
                for paragraph in cell.paragraphs:
                    paragraph.alignment = _WD_ALIGN_PARAGRAPH.CENTER
                    try:
                        paragraph.paragraph_format.space_before = _Pt(0)
                        paragraph.paragraph_format.space_after = _Pt(2)
                    except Exception:
                        pass
                    for run in paragraph.runs:
                        run.font.bold = True
                        try:
                            run.font.color.rgb = RGBColor(255, 255, 255)
                            run.font.name = PREFERRED_BODY_FONT_NAME
                            from docx.shared import Pt as _Pt
                            run.font.size = _Pt(11)
                        except Exception:
                            pass
        def _style_table_body(tbl):
            # Ensure body cells have consistent spacing and vertical alignment
            try:
                from docx.shared import Pt as _Pt
                from docx.enum.table import WD_ALIGN_VERTICAL as _WD_ALIGN_VERTICAL
            except Exception:
                return
            if not getattr(tbl, "rows", None) or len(tbl.rows) <= 1:
                return
            for r_idx, row in enumerate(tbl.rows):
                if r_idx == 0:
                    continue  # header handled separately
                for cell in row.cells:
                    try:
                        cell.vertical_alignment = _WD_ALIGN_VERTICAL.TOP
                    except Exception:
                        pass
                    for paragraph in cell.paragraphs:
                        try:
                            paragraph.paragraph_format.space_before = _Pt(0)
                            paragraph.paragraph_format.space_after = _Pt(2)
                        except Exception:
                            pass
                        try:
                            from docx.shared import Pt as _Pt
                            for run in paragraph.runs:
                                run.font.name = PREFERRED_BODY_FONT_NAME
                                run.font.size = _Pt(11)
                        except Exception:
                            pass
        # Helper: ensure visible grid borders on all tables and cells
        def _apply_table_borders(tbl, color="000000", size=8):
            try:
                from docx.oxml import OxmlElement
                from docx.oxml.ns import qn
                tblPr = tbl._tbl.tblPr
                # Remove existing borders to avoid duplicates
                for child in list(tblPr):
                    if child.tag == qn('w:tblBorders'):
                        tblPr.remove(child)
                borders = OxmlElement('w:tblBorders')
                for border_name in ('top', 'left', 'bottom', 'right', 'insideH', 'insideV'):
                    ele = OxmlElement(f'w:{border_name}')
                    ele.set(qn('w:val'), 'single')
                    ele.set(qn('w:sz'), str(size))
                    ele.set(qn('w:color'), color)
                    borders.append(ele)
                tblPr.append(borders)
            except Exception:
                pass
        # Helper: apply pagination preferences so tables stay on same page if they fit
        def _apply_table_pagination_preferences(tbl):
            # Prevent splitting a row across pages and try to keep table together
            try:
                # Avoid splitting table rows across pages
                for row in getattr(tbl, "rows", []) or []:
                    try:
                        from docx.oxml import OxmlElement as _OX
                        trPr = row._tr.get_or_add_trPr()
                        cantSplit = _OX('w:cantSplit')
                        trPr.append(cantSplit)
                    except Exception:
                        pass
                # Keep paragraphs within the table together; allow break after the last row
                total_rows = len(getattr(tbl, "rows", []) or [])
                for r_idx, row in enumerate(getattr(tbl, "rows", []) or []):
                    for cell in getattr(row, "cells", []) or []:
                        for p in getattr(cell, "paragraphs", []) or []:
                            try:
                                pf = p.paragraph_format
                                pf.keep_together = True
                                # keep with next for all rows except last
                                pf.keep_with_next = (r_idx < total_rows - 1)
                            except Exception:
                                pass
            except Exception:
                pass
        # Render general delimited blocks (tabs, 2+ spaces, or key: value pairs)
        def _try_render_delimited_table_block(doc, block_text):
            """
            Detects:
            - Tab-delimited rows across multiple lines
            - Multi-space (2+) delimited rows across multiple lines
            - Repeated 'Key: Value' lines -> 2-column table
            Returns True if a table was rendered.
            """
            if not block_text or '\n' not in block_text:
                return False
            lines = [ln for ln in block_text.splitlines() if ln.strip()]
            if len(lines) < 2:
                return False
            import re as __re
            # 1) Key: Value pairs
            colon_pairs = [__re.split(r'\s*:\s+', ln, maxsplit=1) for ln in lines if ':' in ln]
            if len(colon_pairs) == len(lines) and all(len(p) == 2 for p in colon_pairs):
                # Build 2-col table, first row as header inferred if all keys look like titles
                tbl = doc.add_table(rows=(1 + len(colon_pairs)), cols=2)
                try:
                    if table_style_name:
                        tbl.style = table_style_name
                except Exception:
                    pass
                try:
                    from docx.enum.table import WD_TABLE_ALIGNMENT as _WD_TABLE_ALIGNMENT
                    tbl.alignment = _WD_TABLE_ALIGNMENT.CENTER
                except Exception:
                    pass
                _apply_table_pagination_preferences(tbl)
                # Header
                tbl.cell(0, 0).text = 'Key'
                tbl.cell(0, 1).text = 'Value'
                # Body
                for r_off, (k, v) in enumerate(colon_pairs, start=1):
                    tbl.cell(r_off, 0).text = _strip_html_tags(k.strip())
                    tbl.cell(r_off, 1).text = _strip_html_tags(v.strip())
                _style_table_header_row(tbl)
                _style_table_body(tbl)
                _apply_table_borders(tbl)
                doc.add_paragraph()
                return True
            # 2) Tab-delimited rows
            if any('\t' in ln for ln in lines):
                rows = [ln.split('\t') for ln in lines]
                num_cols = max(len(r) for r in rows)
                if num_cols >= 2:
                    tbl = doc.add_table(rows=len(rows), cols=num_cols)
                    try:
                        if table_style_name:
                            tbl.style = table_style_name
                    except Exception:
                        pass
                    try:
                        from docx.enum.table import WD_TABLE_ALIGNMENT as _WD_TABLE_ALIGNMENT
                        tbl.alignment = _WD_TABLE_ALIGNMENT.CENTER
                    except Exception:
                        pass
                    _apply_table_pagination_preferences(tbl)
                    for r_idx, row_vals in enumerate(rows):
                        for c_idx in range(num_cols):
                            val = row_vals[c_idx] if c_idx < len(row_vals) else ''
                            tbl.cell(r_idx, c_idx).text = _strip_html_tags(val.strip())
                    _style_table_header_row(tbl)
                    _style_table_body(tbl)
                    _apply_table_borders(tbl)
                    doc.add_paragraph()
                    return True
            # 3) Multi-space-delimited rows
            space_split_rows = [__re.split(r'\s{2,}', ln.strip()) for ln in lines]
            num_cols = max(len(r) for r in space_split_rows)
            if num_cols >= 2 and all(len(r) >= 2 for r in space_split_rows):
                tbl = doc.add_table(rows=len(space_split_rows), cols=num_cols)
                try:
                    if table_style_name:
                        tbl.style = table_style_name
                except Exception:
                    pass
                try:
                    from docx.enum.table import WD_TABLE_ALIGNMENT as _WD_TABLE_ALIGNMENT
                    tbl.alignment = _WD_TABLE_ALIGNMENT.CENTER
                except Exception:
                    pass
                _apply_table_pagination_preferences(tbl)
                for r_idx, row_vals in enumerate(space_split_rows):
                    for c_idx in range(num_cols):
                        val = row_vals[c_idx] if c_idx < len(row_vals) else ''
                        tbl.cell(r_idx, c_idx).text = _strip_html_tags(val.strip())
                _style_table_header_row(tbl)
                _style_table_body(tbl)
                _apply_table_borders(tbl)
                doc.add_paragraph()
                return True
            return False
        # Attempt to detect and render Markdown/pipe tables from plain text blocks
        def _try_render_markdown_table_block(doc, block_text):
            """
            Detects Markdown-style tables:
            | H1 | H2 |
            | --- | --- |
            | v1 | v2 |
            Or pipe-delimited rows without explicit alignment row.
            Returns True if a table was rendered, False otherwise.
            """
            lines = [ln for ln in (block_text or '').splitlines() if ln.strip()]
            if len(lines) < 2:
                return False
            import re as __re
            def split_cells(line):
                # Keep inner pipes by splitting and trimming; drop leading/trailing empty caused by outer pipes
                parts = [c.strip() for c in line.strip().split('|')]
                if parts and parts[0] == '':
                    parts = parts[1:]
                if parts and parts[-1] == '':
                    parts = parts[:-1]
                return parts
            def is_pipe_line(ln):
                return '|' in ln and len(split_cells(ln)) >= 2
            def is_align_row(ln, cols):
                # e.g., | --- | :---: | --- |
                cells = split_cells(ln)
                if len(cells) != cols:
                    return False
                for c in cells:
                    if not __re.fullmatch(r':?-{3,}:?', c.replace(' ', '')):
                        return False
                return True
            if not is_pipe_line(lines[0]) or not is_pipe_line(lines[1]):
                return False
            header_cells = split_cells(lines[0])
            cols = len(header_cells)
            has_align = is_align_row(lines[1], cols)
            remaining = lines[2:] if has_align else lines[1:]
            if not remaining:
                return False
            # Assemble rows allowing multi-line cell continuations (lines without pipes)
            assembled_rows = []
            current_row = None
            for raw_ln in remaining:
                ln = raw_ln.rstrip()
                if is_pipe_line(ln):
                    # flush any current row
                    if current_row is not None:
                        if len(current_row) < cols:
                            current_row += [''] * (cols - len(current_row))
                        assembled_rows.append(current_row[:cols])
                    current_row = split_cells(ln)
                else:
                    if current_row is None:
                        return False
                    if not current_row:
                        current_row.append(ln.strip())
                    else:
                        current_row[-1] = (current_row[-1] + '\n' + ln.strip()).strip()
            if current_row is not None:
                if len(current_row) < cols:
                    current_row += [''] * (cols - len(current_row))
                assembled_rows.append(current_row[:cols])
            if not assembled_rows:
                return False
            # Build table
            tbl = doc.add_table(rows=(1 + len(assembled_rows)), cols=cols)
            try:
                if table_style_name:
                    tbl.style = table_style_name
            except Exception:
                pass
            try:
                from docx.enum.table import WD_TABLE_ALIGNMENT as _WD_TABLE_ALIGNMENT
                tbl.alignment = _WD_TABLE_ALIGNMENT.CENTER
            except Exception:
                pass
            _apply_table_pagination_preferences(tbl)
            # Header
            for c_idx, text in enumerate(header_cells):
                tbl.cell(0, c_idx).text = _strip_html_tags(text)
            # Body
            for r_off, row_cells in enumerate(assembled_rows, start=1):
                # ensure length to cols
                if len(row_cells) < cols:
                    row_cells += [''] * (cols - len(row_cells))
                for c_idx, text in enumerate(row_cells[:cols]):
                    tbl.cell(r_off, c_idx).text = _strip_html_tags(text)
            _style_table_header_row(tbl)
            _style_table_body(tbl)
            _apply_table_borders(tbl)
            doc.add_paragraph()
            return True
        import re as _re
        table_splitter = _re.compile(r'(<table[\s\S]*?</table>)', _re.IGNORECASE)
        table_rows_re = _re.compile(r'<tr[\s\S]*?</tr>', _re.IGNORECASE)
        cell_contents_re = _re.compile(r'<t[dh][^>]*?>([\s\S]*?)</t[dh]>', _re.IGNORECASE)

        # Remove images, svg/canvas, and figure blocks (treat as "charts") before parsing
        try:
            html_text = _re.sub(r'<img\b[^>]*?/?>', '', html_text, flags=_re.IGNORECASE)
            html_text = _re.sub(r'<(svg|canvas)[\s\S]*?</\1\s*>', '', html_text, flags=_re.IGNORECASE)
            html_text = _re.sub(r'<figure[\s\S]*?</figure\s*>', '', html_text, flags=_re.IGNORECASE)
            html_text = _re.sub(r'```(?:mermaid|chart)[\s\S]*?```', '', html_text, flags=_re.IGNORECASE)
        except Exception:
            pass

        segments = table_splitter.split(html_text)
        for segment in segments:
            if not segment:
                continue
            if segment.lstrip().lower().startswith('<table'):
                rows = table_rows_re.findall(segment) or []
                num_cols = 0
                for rhtml in rows:
                    num_cols = max(num_cols, len(cell_contents_re.findall(rhtml)))
                if num_cols <= 0:
                    # Fallback: treat as paragraph text
                    text_version = _strip_html_tags(segment)
                    for p in [p for p in text_version.split('\n\n') if p.strip()]:
                        para = doc.add_paragraph(p.strip())
                        try:
                            from docx.shared import Pt as _Pt
                            for run in para.runs:
                                run.font.name = PREFERRED_BODY_FONT_NAME
                                run.font.size = _Pt(11)
                        except Exception:
                            pass
                    continue
                # Insert table inline; Word will move it to next page when it doesn't fit
                tbl = doc.add_table(rows=len(rows), cols=num_cols)
                try:
                    if table_style_name:
                        tbl.style = table_style_name
                except Exception:
                    pass
                try:
                    from docx.enum.table import WD_TABLE_ALIGNMENT as _WD_TABLE_ALIGNMENT
                    tbl.alignment = _WD_TABLE_ALIGNMENT.CENTER
                except Exception:
                    pass
                _apply_table_pagination_preferences(tbl)
                for r_idx, rhtml in enumerate(rows):
                    cells = cell_contents_re.findall(rhtml)
                    for c_idx, cell_html in enumerate(cells):
                        if c_idx >= num_cols:
                            break
                        cell_text = _strip_html_tags(cell_html)
                        tbl.cell(r_idx, c_idx).text = cell_text
                # Style the header row with alternating blue/green colors
                _style_table_header_row(tbl)
                # Apply body cell formatting
                _style_table_body(tbl)
                # Ensure visible grid borders around all cells
                _apply_table_borders(tbl)
                # Add a small spacing after the table for readability
                doc.add_paragraph()
            else:
                text_version = _strip_html_tags(segment)
                # Try to identify markdown/pipe tables by blocks first
                blocks = [b for b in text_version.split('\n\n')]
                for block in blocks:
                    blk = block.strip()
                    if not blk:
                        continue
                    if _try_render_markdown_table_block(doc, blk) or _try_render_delimited_table_block(doc, blk):
                        continue
                    # Fallback: treat as plain paragraphs (split single newlines too)
                    paras = [p.strip() for p in blk.split('\n') if p.strip()]
                    for para_text in paras:
                        para = doc.add_paragraph(para_text)
                        try:
                            for run in para.runs:
                                run.font.name = 'Aptos Display'
                        except Exception:
                            pass

    for section in sections:
        if not isinstance(section, dict):
            continue
        title = (section.get('title') or 'Untitled Section').strip() or 'Untitled Section'
        content_blocks = section.get('content') if isinstance(section.get('content'), list) else []
        raw_html = section.get('raw_content') or ''
        section_id = (section.get('id') or '').strip()
        
        # Fetch any attachments for this section up-front so sections with only images are still rendered
        attachments = _get_cached_attachments(section_id)
        
        # Skip sections that truly have no data at all (no text/html and no attachments)
        if not content_blocks and not raw_html and not attachments:
            continue

        # Ensure every new section begins on a new page
        if first_section_added:
            document.add_page_break()
        first_section_added = True

        # Add section heading
        heading_para = document.add_heading(title, level=1)
        try:
            from docx.shared import Pt as _Pt
            is_transmittal = ('transmittal' in (title or '').lower())
            for run in heading_para.runs:
                run.font.name = PREFERRED_HEADING_FONT_NAME
                run.font.bold = True
                run.font.size = _Pt(16)
                # For Letter of Transmittal, hide the heading in the body but keep it as Heading 1
                # so it still participates in TOC and header STYLEREF.
                if is_transmittal:
                    try:
                        run.font.hidden = True
                    except Exception:
                        pass
            if is_transmittal:
                try:
                    heading_para.paragraph_format.space_after = _Pt(0)
                    heading_para.paragraph_format.space_before = _Pt(0)
                except Exception:
                    pass
        except Exception:
            pass
        html_fragments.append(f'<h2>{escape(title)}</h2>')

        # Process content - prioritize raw_html if available (for HTML tables, etc.)
        if raw_html:
            # Render HTML preserving tables; append raw_html to preview
            _insert_html_with_tables(document, raw_html)
            try:
                # Apply minimal markdown cleanup inside raw_html for preview only
                import re as __re_md
                rh = raw_html
                # Convert bold markers inside raw HTML text content crudely
                rh = __re_md.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', rh)
                # Convert '### ' headings at the start of lines to <h3>
                rh = __re_md.sub(r'(^|\n)\s*#{3,}\s*(.+?)\s*(?=\n|$)', lambda m: f"{m.group(1)}<h3>{escape(m.group(2))}</h3>", rh)
                # Remove remaining stray markers
                rh = __re_md.sub(r'[#*]+', '', rh)
                html_fragments.append(rh)
            except Exception:
                html_fragments.append(raw_html)
        else:
            # Process regular content blocks
            fragment_html = ''
            for paragraph in content_blocks:
                if paragraph and paragraph.strip():
                    para_text = paragraph.strip()
                    # If the paragraph looks like a table block (pipe, tabs, multi-space, or key:value across lines), render it as a real table
                    if '\n' in para_text:
                        try:
                            import re as __re2
                            looks_table = (
                                ('|' in para_text) or
                                ('\t' in para_text) or
                                (__re2.search(r'\s{2,}', para_text) is not None) or
                                (__re2.search(r'^[^:\n]+:\s*.+$', para_text, flags=__re2.M) is not None)
                            )
                        except Exception:
                            looks_table = ('|' in para_text) or ('\t' in para_text)
                    else:
                        looks_table = False
                    if looks_table:
                        _insert_html_with_tables(document, para_text)
                        # Keep preview minimal; embed as preformatted text block
                        fragment_html += f'<pre>{escape(para_text)}</pre>'
                    else:
                        # Render with Markdown interpretation
                        _render_markdown_to_docx_paragraph(document, para_text)
                        fragment_html += _plaintext_markdown_to_html(para_text)
            
            if fragment_html:
                html_fragments.append(fragment_html)

        # Append any section attachments (PDFs/images) directly into the document
        try:
            if attachments:
                # Add a small label in preview
                html_fragments.append('<div><em>Attachments included:</em></div>')
            for att in attachments:
                fp = (att.get('file_path') or '').strip()
                name = (att.get('filename') or os.path.basename(fp) or 'Attachment').strip()
                if not fp or not os.path.exists(fp):
                    continue

                def _img_data_uri(path):
                    try:
                        with open(path, 'rb') as fh:
                            data = fh.read()
                        if not data:
                            return None
                        # Limit preview payload size to ~4 MB per image
                        if len(data) > (4 * 1024 * 1024):
                            return None
                        ext = os.path.splitext(path)[1].lower()
                        mime = 'image/png'
                        if ext in ('.jpg', '.jpeg'):
                            mime = 'image/jpeg'
                        elif ext == '.webp':
                            mime = 'image/webp'
                        return f"data:{mime};base64," + base64.b64encode(data).decode('ascii')
                    except Exception:
                        return None

                try:
                    from docx.shared import Inches
                except Exception:
                    Inches = None  # type: ignore[assignment]

                def _add_picture_centered(doc, image_path, width):
                    try:
                        para = doc.add_paragraph()
                        try:
                            para.alignment = WD_ALIGN_PARAGRAPH.CENTER
                        except Exception:
                            pass
                        run = para.add_run()
                        if width is not None:
                            run.add_picture(image_path, width=width)
                        else:
                            run.add_picture(image_path)
                    except Exception:
                        # Fallback to default insertion on any errors
                        if width is not None:
                            doc.add_picture(image_path, width=width)
                        else:
                            doc.add_picture(image_path)

                # Compute usable width if possible
                usable_width = None
                try:
                    sec = document.sections[-1]
                    usable_width = sec.page_width - sec.left_margin - sec.right_margin
                except Exception:
                    pass

                try:
                    is_pdf = fp.lower().endswith('.pdf') or (att.get('file_type') or '').lower() == 'pdf'
                    if is_pdf and globals().get('_FITZ_AVAILABLE', False):
                        # Render each PDF page as an image and insert
                        import tempfile
                        import shutil as _shutil
                        doc_mod = globals().get('_pymupdf')
                        with doc_mod.open(fp) as _pdf:
                            for i in range(min(_pdf.page_count or 0, 20)):
                                page = _pdf.load_page(i)
                                zoom = 2.0
                                mat = doc_mod.Matrix(zoom, zoom)
                                pix = page.get_pixmap(matrix=mat)
                                tmpdir = tempfile.gettempdir()
                                tmp_png = os.path.join(tmpdir, f"att_{os.path.basename(fp)}_{i}.png")
                                pix.save(tmp_png)
                                if Inches:
                                    if usable_width:
                                        _add_picture_centered(document, tmp_png, usable_width)  # type: ignore[arg-type]
                                    else:
                                        _add_picture_centered(document, tmp_png, Inches(6.5))
                                else:
                                    # Fallback: insert a paragraph with the file name if images unsupported
                                    document.add_paragraph(f"[Attachment page] {name} - page {i+1}")
                                preview_uri = _img_data_uri(tmp_png)
                                if preview_uri:
                                    html_fragments.append(
                                        f'<div class="proposal-attachment"><img src="{preview_uri}" alt="{escape(name)} page {i+1}" /></div>'
                                    )
                                else:
                                    html_fragments.append(
                                        f'<div class="text-xs text-gray-500">Attached PDF page: {name} (page {i+1})</div>'
                                    )
                                try:
                                    _shutil.which('true')  # no-op to keep import
                                except Exception:
                                    pass
                    else:
                        # Treat as image
                        if Inches:
                            if usable_width:
                                _add_picture_centered(document, fp, usable_width)  # type: ignore[arg-type]
                            else:
                                _add_picture_centered(document, fp, Inches(6.5))
                        else:
                            document.add_paragraph(f"[Attachment] {name}")
                        preview_uri = _img_data_uri(fp)
                        if preview_uri:
                            html_fragments.append(
                                f'<div class="proposal-attachment"><img src="{preview_uri}" alt="{escape(name)}" /></div>'
                            )
                        else:
                            html_fragments.append(f'<div class="text-xs text-gray-500">Attached image: {name}</div>')
                except Exception:
                    # Continue on errors for individual attachments
                    continue

            if attachments:
                # Add a page break after attachments to separate from next section
                try:
                    document.add_page_break()
                except Exception:
                    pass
        except Exception:
            # Ignore attachment embedding failures silently to not break main flow
            pass
        # No extra paragraph needed here; page breaks handle separation

        if not html_fragments:
            return jsonify({'error': 'empty_sections', 'message': 'No compiled content available. Generate or enter section content first.'}), 400

        # Generate filename with project title if available
        os.makedirs('uploads/proposals', exist_ok=True)
        timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
        if project_title:
            # Sanitize project title for filename
            safe_title = ''.join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in project_title[:50])
            safe_title = safe_title.replace(' ', '_')
            filename = f"Proposal_{safe_title}_{timestamp}.docx"
        else:
            filename = f"Proposal_{timestamp}.docx"

        filepath = os.path.join('uploads/proposals', filename)

        try:
            # Ensure headers/footers from template apply to all pages/sections
            try:
                # For IKIO template, many templates place logo only in First Page header/footer.
                # Copy first-page header/footer into primary so it repeats on all pages,
                # then link subsequent sections to previous.
                if template_used == 'ikio' and getattr(document, "sections", None):
                    from copy import deepcopy
                    first_sec = document.sections[0]
                    # Helper to clone header/footer XML from src to dst within same section
                    def _clone_part_xml(src_part, dst_part):
                        try:
                            dst_el = dst_part._element  # w:hdr or w:ftr
                            # remove existing children
                            for child in list(dst_el):
                                dst_el.remove(child)
                            # append deep-copied children from source
                            for child in list(src_part._element):
                                dst_el.append(deepcopy(child))
                        except Exception:
                            pass
                    # If first-page header has content, clone to primary header
                    try:
                        if getattr(first_sec, "first_page_header", None):
                            if len(list(first_sec.first_page_header._element)) > 0:
                                _clone_part_xml(first_sec.first_page_header, first_sec.header)
                    except Exception:
                        pass
                    # If first-page footer has content, clone to primary footer
                    try:
                        if getattr(first_sec, "first_page_footer", None):
                            if len(list(first_sec.first_page_footer._element)) > 0:
                                _clone_part_xml(first_sec.first_page_footer, first_sec.footer)
                    except Exception:
                        pass
                    # Disable special header/footer modes across ALL sections to ensure consistency
                    try:
                        for _sec in document.sections:
                            try:
                                _sec.different_first_page_header_footer = False
                            except Exception:
                                pass
                            try:
                                _sec.odd_and_even_pages_header_footer = False
                            except Exception:
                                pass
                    except Exception:
                        pass
                # Link headers/footers after all content is added
                for _s_idx, _section in enumerate(document.sections):
                    if _s_idx > 0:
                        try:
                            _section.header.is_linked_to_previous = True
                            _section.footer.is_linked_to_previous = True
                        except Exception:
                            pass
                # Continuous page numbering: start at 1 on first section, continue thereafter
                from docx.oxml import OxmlElement
                from docx.oxml.ns import qn
                for _s_idx, _section in enumerate(document.sections):
                    _sectPr = _section._sectPr
                    _pgNumType = _sectPr.find(qn('w:pgNumType'))
                    if _pgNumType is None:
                        _pgNumType = OxmlElement('w:pgNumType')
                        _sectPr.append(_pgNumType)
                    if _s_idx == 0:
                        _pgNumType.set(qn('w:start'), "1")
                    else:
                        try:
                            _pgNumType.attrib.pop(qn('w:start'), None)
                        except Exception:
                            pass
            except Exception:
                # If linking or numbering XML manipulation fails, proceed without blocking save
                pass
            # Ask Word to update fields (including TOC) on document open
            try:
                from docx.oxml import OxmlElement
                from docx.oxml.ns import qn
                # Get or create settings part and set updateFields=true
                settings_part = getattr(document._part, "get_or_add_settings", None)
                settings_el = settings_part() if callable(settings_part) else None
                if settings_el is None:
                    # Fallback: try to reach settings element via package (best-effort)
                    settings_el = getattr(document._part, "_settings", None)
                if settings_el is not None:
                    upd = OxmlElement('w:updateFields')
                    upd.set(qn('w:val'), 'true')
                    try:
                        # Remove existing to avoid duplicates
                        for child in list(settings_el):
                            if child.tag == qn('w:updateFields'):
                                settings_el.remove(child)
                    except Exception:
                        pass
                    settings_el.append(upd)
            except Exception:
                pass
            document.save(filepath)
            app.logger.info(f'Successfully compiled proposal with {len(sections)} sections to {filename}')
        except Exception as error:
            app.logger.exception('Failed to save compiled proposal: %s', error)
            return jsonify({'error': 'save_failed', 'message': 'Could not save the compiled proposal. Please try again.'}), 500

        preview_html = ''.join(html_fragments)
        return jsonify({
            'message': f'Proposal compiled successfully with {len(sections)} section(s). Review the preview before downloading.',
            'filename': filename,
            'download_url': url_for('download_proposal', filename=filename),
            'html_preview': preview_html,
            'section_count': len(sections)
        })

class _PreviewHtmlNode:
    def __init__(self, tag, attrs=None, parent=None):
        self.tag = (tag or '').lower()
        self.attrs = dict(attrs or [])
        self.children = []
        self.parent = parent
        self.text = ''

class _PreviewHtmlParser(HTMLParser):
    def __init__(self):
        super().__init__()
        self.root = _PreviewHtmlNode('root')
        self.stack = [self.root]

    def handle_starttag(self, tag, attrs):
        node = _PreviewHtmlNode(tag, attrs, parent=self.stack[-1])
        self.stack[-1].children.append(node)
        self.stack.append(node)

    def handle_startendtag(self, tag, attrs):
        node = _PreviewHtmlNode(tag, attrs, parent=self.stack[-1])
        self.stack[-1].children.append(node)

    def handle_endtag(self, tag):
        normalized = (tag or '').lower()
        for i in range(len(self.stack) - 1, 0, -1):
            if self.stack[i].tag == normalized:
                self.stack = self.stack[:i]
                break

    def handle_data(self, data):
        if data is None:
            return
        text = unescape(data)
        if not text.strip():
            return
        node = _PreviewHtmlNode('#text', parent=self.stack[-1])
        node.text = text
        self.stack[-1].children.append(node)

_PREVIEW_ALLOWED_TAGS = [
    'p', 'br', 'strong', 'b', 'em', 'i', 'u',
    'h1', 'h2', 'h3', 'h4', 'h5', 'h6',
    'ul', 'ol', 'li',
    'table', 'thead', 'tbody', 'tr', 'td', 'th',
    'img', 'div', 'span', 'pre', 'blockquote'
]
_PREVIEW_ALLOWED_ATTRS = {
    'img': ['src', 'alt']
}

def _sanitize_preview_html(html_text):
    return bleach.clean(
        html_text or '',
        tags=_PREVIEW_ALLOWED_TAGS,
        attributes=_PREVIEW_ALLOWED_ATTRS,
        protocols=['http', 'https', 'mailto', 'data'],
        strip=True
    )

def _clear_document_body(document):
    for paragraph in list(document.paragraphs):
        try:
            paragraph._element.getparent().remove(paragraph._element)
        except Exception:
            pass
    for table in list(document.tables):
        try:
            table._element.getparent().remove(table._element)
        except Exception:
            pass

def _extract_image_stream(src):
    if not src:
        return None
    if src.startswith('data:image'):
        try:
            header, b64_data = src.split(',', 1)
            return io.BytesIO(base64.b64decode(b64_data))
        except Exception:
            return None
    return None

def _append_inline_runs(paragraph, node, style):
    for child in node.children:
        if child.tag == '#text':
            run = paragraph.add_run(child.text)
            run.bold = style.get('bold', False)
            run.italic = style.get('italic', False)
            run.underline = style.get('underline', False)
            continue
        if child.tag in ('strong', 'b'):
            next_style = dict(style)
            next_style['bold'] = True
            _append_inline_runs(paragraph, child, next_style)
            continue
        if child.tag in ('em', 'i'):
            next_style = dict(style)
            next_style['italic'] = True
            _append_inline_runs(paragraph, child, next_style)
            continue
        if child.tag == 'u':
            next_style = dict(style)
            next_style['underline'] = True
            _append_inline_runs(paragraph, child, next_style)
            continue
        if child.tag == 'br':
            paragraph.add_run().add_break()
            continue
        if child.tag == 'img':
            stream = _extract_image_stream(child.attrs.get('src'))
            if stream:
                run = paragraph.add_run()
                try:
                    from docx.shared import Inches
                    run.add_picture(stream, width=Inches(5.5))
                except Exception:
                    try:
                        run.add_picture(stream)
                    except Exception:
                        pass
            continue
        _append_inline_runs(paragraph, child, style)

def _add_paragraph_with_inline(document, node, style_name=None):
    paragraph = None
    if style_name:
        try:
            paragraph = document.add_paragraph(style=style_name)
        except Exception:
            paragraph = document.add_paragraph()
    else:
        paragraph = document.add_paragraph()
    _append_inline_runs(paragraph, node, {'bold': False, 'italic': False, 'underline': False})
    return paragraph

def _append_blocks(document, node, list_style=None):
    tag = node.tag
    if tag in ('root', 'body', 'div', 'section', 'article', 'span'):
        for child in node.children:
            _append_blocks(document, child, list_style=list_style)
        return
    if tag in ('h1', 'h2', 'h3', 'h4', 'h5', 'h6'):
        level = min(6, max(1, int(tag[1])))
        heading_style = f'Heading {level}'
        _add_paragraph_with_inline(document, node, heading_style)
        return
    if tag in ('p', 'blockquote', 'pre'):
        _add_paragraph_with_inline(document, node, None)
        return
    if tag in ('ul', 'ol'):
        style = 'List Bullet' if tag == 'ul' else 'List Number'
        for child in node.children:
            _append_blocks(document, child, list_style=style)
        return
    if tag == 'li':
        _add_paragraph_with_inline(document, node, list_style)
        return
    if tag == 'table':
        rows = []
        for child in node.children:
            if child.tag == 'tr':
                rows.append(child)
            elif child.tag in ('tbody', 'thead'):
                rows.extend([r for r in child.children if r.tag == 'tr'])
        if not rows:
            return
        cell_counts = []
        for row in rows:
            cell_counts.append(len([c for c in row.children if c.tag in ('td', 'th')]))
        cols = max(cell_counts) if cell_counts else 0
        if cols <= 0:
            return
        table = document.add_table(rows=len(rows), cols=cols)
        for r_idx, row in enumerate(rows):
            cells = [c for c in row.children if c.tag in ('td', 'th')]
            for c_idx, cell_node in enumerate(cells):
                if c_idx >= cols:
                    continue
                cell = table.cell(r_idx, c_idx)
                cell.text = ''
                _add_paragraph_with_inline(cell, cell_node, None)
        return
    if tag == 'img':
        stream = _extract_image_stream(node.attrs.get('src'))
        if stream:
            paragraph = document.add_paragraph()
            run = paragraph.add_run()
            try:
                from docx.shared import Inches
                run.add_picture(stream, width=Inches(5.5))
            except Exception:
                try:
                    run.add_picture(stream)
                except Exception:
                    pass
        return
    if tag == '#text' and node.text.strip():
        document.add_paragraph(node.text.strip())
        return
    for child in node.children:
        _append_blocks(document, child, list_style=list_style)

@app.route('/api/save-proposal-preview', methods=['POST'])
@login_required
def save_proposal_preview():
    payload = request.get_json(silent=True) or {}
    html_preview = payload.get('html') or ''
    filename = payload.get('filename') or ''
    company = (payload.get('company') or '').strip()
    bid_id = payload.get('bid_id') or payload.get('g_id') or None
    sections = payload.get('sections') or []
    if not html_preview or not filename:
        return jsonify({'error': 'missing_payload', 'message': 'Preview content or filename missing.'}), 400

    safe_filename = secure_filename(filename)
    if not safe_filename:
        return jsonify({'error': 'invalid_filename', 'message': 'Invalid filename.'}), 400

    try:
        from docx import Document
    except ImportError:
        return jsonify({'error': 'dependency_missing', 'message': 'python-docx library is required to save proposals.'}), 500

    proposals_dir = 'uploads/proposals'
    os.makedirs(proposals_dir, exist_ok=True)
    output_path = os.path.join(proposals_dir, safe_filename)

    try:
        template_path = choose_company_template(company) if company else None
        if template_path:
            document = Document(template_path)
            _clear_document_body(document)
        else:
            document = Document()
        # Ensure Word updates fields (TOC/page numbers) on open.
        try:
            from docx.oxml import OxmlElement
            from docx.oxml.ns import qn
            settings_el = document.settings._element
            update_fields = settings_el.find(qn('w:updateFields'))
            if update_fields is None:
                update_fields = OxmlElement('w:updateFields')
                settings_el.append(update_fields)
            update_fields.set(qn('w:val'), 'true')
        except Exception:
            pass

        cleaned_html = _sanitize_preview_html(html_preview)
        # Remove any static TOC list from preview; we'll insert a live TOC field instead.
        try:
            import re as _re
            cleaned_html = _re.sub(
                r'(?is)<h2[^>]*>\s*Table of Contents\s*</h2>\s*<ol[^>]*>.*?</ol>',
                '',
                cleaned_html,
                count=1
            )
        except Exception:
            pass

        # Insert a TOC field as the first page
        try:
            try:
                toc_heading = document.add_paragraph('Table of Contents', style=document.styles['Title'])
            except Exception:
                toc_heading = document.add_paragraph('Table of Contents')
            try:
                from docx.shared import Pt as _Pt
                for run in toc_heading.runs:
                    run.font.name = 'Aptos Bold'
                    run.font.bold = True
                    run.font.size = _Pt(11)
            except Exception:
                pass
            document.add_paragraph()
            try:
                from docx.oxml import OxmlElement
                from docx.oxml.ns import qn
                toc_para = document.add_paragraph()
                r = toc_para.add_run()
                fldChar = OxmlElement('w:fldChar')
                fldChar.set(qn('w:fldCharType'), 'begin')
                try:
                    fldChar.set(qn('w:dirty'), 'true')
                except Exception:
                    pass
                r._r.append(fldChar)
                instrText = OxmlElement('w:instrText')
                instrText.set(qn('xml:space'), 'preserve')
                instrText.text = 'TOC \\o "1-3" \\h \\z \\u'
                r._r.append(instrText)
                fldChar = OxmlElement('w:fldChar')
                fldChar.set(qn('w:fldCharType'), 'separate')
                r._r.append(fldChar)
                toc_para.add_run('Table of Contents will update on open.')
                fldChar = OxmlElement('w:fldChar')
                fldChar.set(qn('w:fldCharType'), 'end')
                r._r.append(fldChar)
            except Exception:
                pass
            document.add_page_break()
        except Exception:
            pass

        parser = _PreviewHtmlParser()
        parser.feed(cleaned_html)
        _append_blocks(document, parser.root)

        # Append section attachments (images/PDFs) if they are not already embedded in the preview HTML.
        try:
            if bid_id and isinstance(sections, list) and sections:
                html_lower = (html_preview or '').lower()
                # Track attachments already visible in preview by filename match
                def _is_already_embedded(name):
                    if not name:
                        return False
                    return name.lower() in html_lower

                # Helper to insert images/PDFs similar to compile flow
                def _insert_attachment(doc, att):
                    fp = (att.get('file_path') or '').strip()
                    name = (att.get('filename') or os.path.basename(fp) or 'Attachment').strip()
                    if not fp or not os.path.exists(fp):
                        return
                    if _is_already_embedded(name):
                        return
                    try:
                        from docx.shared import Inches
                    except Exception:
                        Inches = None  # type: ignore[assignment]
                    try:
                        from docx.enum.text import WD_ALIGN_PARAGRAPH
                    except Exception:
                        WD_ALIGN_PARAGRAPH = None  # type: ignore[assignment]

                    def _add_picture_centered(doc_inner, image_path, width):
                        try:
                            para = doc_inner.add_paragraph()
                            if WD_ALIGN_PARAGRAPH is not None:
                                try:
                                    para.alignment = WD_ALIGN_PARAGRAPH.CENTER
                                except Exception:
                                    pass
                            run = para.add_run()
                            if width is not None:
                                run.add_picture(image_path, width=width)
                            else:
                                run.add_picture(image_path)
                        except Exception:
                            if width is not None:
                                doc_inner.add_picture(image_path, width=width)
                            else:
                                doc_inner.add_picture(image_path)

                    # Compute usable width if possible
                    usable_width = None
                    try:
                        sec = doc.sections[-1]
                        usable_width = sec.page_width - sec.left_margin - sec.right_margin
                    except Exception:
                        pass

                    try:
                        is_pdf = fp.lower().endswith('.pdf') or (att.get('file_type') or '').lower() == 'pdf'
                        if is_pdf and globals().get('_FITZ_AVAILABLE', False):
                            doc_mod = globals().get('_pymupdf')
                            with doc_mod.open(fp) as _pdf:
                                for i in range(min(_pdf.page_count or 0, 20)):
                                    page = _pdf.load_page(i)
                                    zoom = 2.0
                                    mat = doc_mod.Matrix(zoom, zoom)
                                    pix = page.get_pixmap(matrix=mat)
                                    tmpdir = tempfile.gettempdir()
                                    tmp_png = os.path.join(tmpdir, f"att_{os.path.basename(fp)}_{i}.png")
                                    pix.save(tmp_png)
                                    if Inches:
                                        if usable_width:
                                            _add_picture_centered(doc, tmp_png, usable_width)  # type: ignore[arg-type]
                                        else:
                                            _add_picture_centered(doc, tmp_png, Inches(6.5))
                                    else:
                                        doc.add_paragraph(f"[Attachment page] {name} - page {i+1}")
                        else:
                            if Inches:
                                if usable_width:
                                    _add_picture_centered(doc, fp, usable_width)  # type: ignore[arg-type]
                                else:
                                    _add_picture_centered(doc, fp, Inches(6.5))
                            else:
                                doc.add_paragraph(f"[Attachment] {name}")
                    except Exception:
                        # Continue on errors for individual attachments
                        return

                # Walk sections in order and append attachments per section
                for sec in sections:
                    if not isinstance(sec, dict):
                        continue
                    section_id = (sec.get('id') or '').strip()
                    if not section_id:
                        continue
                    attachments = _get_section_files_for_bid(bid_id, section_id, limit=30) or []
                    if not attachments:
                        continue
                    section_title = (sec.get('title') or 'Section Attachments').strip()
                    # Only add a heading if at least one attachment is not already embedded
                    if any(not _is_already_embedded(a.get('filename') or '') for a in attachments):
                        try:
                            document.add_page_break()
                        except Exception:
                            pass
                        try:
                            document.add_heading(f"{section_title} - Attachments", level=2)
                        except Exception:
                            document.add_paragraph(f"{section_title} - Attachments")
                    for att in attachments:
                        _insert_attachment(document, att)
        except Exception:
            pass
        document.save(output_path)
    except Exception as error:
        app.logger.exception('Failed to save proposal preview: %s', error)
        return jsonify({'error': 'save_failed', 'message': 'Could not save the preview edits.'}), 500

    return jsonify({
        'message': 'Preview saved.',
        'download_url': url_for('download_proposal', filename=safe_filename)
    })

def extract_template_header_footer(template_path):
    """
    Safely read a DOCX template and extract visible header/footer text,
    including text that may be inside tables for first/even/primary parts.
    Returns a dict: { 'header_text': str, 'footer_text': str }.
    """
    try:
        from docx import Document
    except Exception:
        return {"header_text": "", "footer_text": ""}
    try:
        doc = Document(template_path)
    except Exception:
        return {"header_text": "", "footer_text": ""}

    try:
        section = doc.sections[0]
    except Exception:
        return {"header_text": "", "footer_text": ""}

    def _collect_text(part):
        lines = []
        if not part:
            return lines
        try:
            for p in getattr(part, 'paragraphs', []) or []:
                t = (p.text or '').strip()
                if t:
                    lines.append(t)
        except Exception:
            pass
        try:
            for tbl in getattr(part, 'tables', []) or []:
                for row in getattr(tbl, 'rows', []) or []:
                    for cell in getattr(row, 'cells', []) or []:
                        for p in getattr(cell, 'paragraphs', []) or []:
                            t = (p.text or '').strip()
                            if t:
                                lines.append(t)
        except Exception:
            pass
        return lines

    # Gather header parts: primary, first-page, even-page
    header_parts = []
    try:
        header_parts.append(getattr(section, 'header', None))
        header_parts.append(getattr(section, 'first_page_header', None))
        header_parts.append(getattr(section, 'even_page_header', None))
    except Exception:
        pass
    # Gather footer parts
    footer_parts = []
    try:
        footer_parts.append(getattr(section, 'footer', None))
        footer_parts.append(getattr(section, 'first_page_footer', None))
        footer_parts.append(getattr(section, 'even_page_footer', None))
    except Exception:
        pass

    header_lines = []
    footer_lines = []
    seen = set()
    for part in header_parts:
        for ln in _collect_text(part):
            if ln not in seen:
                seen.add(ln)
                header_lines.append(ln)
    seen.clear()
    for part in footer_parts:
        for ln in _collect_text(part):
            if ln not in seen:
                seen.add(ln)
                footer_lines.append(ln)

    header_text = '\n'.join(header_lines).strip()
    footer_text = '\n'.join(footer_lines).strip()
    return {"header_text": header_text, "footer_text": footer_text}

def choose_company_template(company_display):
    """
    Returns an absolute path to the preferred template for the given company.
    Search order is brand-aware with sensible fallbacks, and supports common
    filename variants and locations.
    """
    import os as _os
    base_dir = app.root_path if hasattr(app, "root_path") else _os.getcwd()

    # Filename variants per brand (to handle '&' and path differences)
    variants = {
        "ikio": [
            # Primary IKIO template(s)
            "Proposal ikio.docx",
            _os.path.join("formatt", "uploads", "templates", "Proposal ikio.docx"),
        
        ],
        "metco": [
            "H & F.docx",
            "H&F.docx",
            _os.path.join("formatt", "uploads", "templates", "H & F.docx"),
            _os.path.join("formatt", "uploads", "templates", "H&F.docx"),
        ],
        "sunsprint": [
            "Proposal For Sunsprint.docx",
            _os.path.join("formatt", "uploads", "templates", "Proposal For Sunsprint.docx"),
        ],
    }

    company_lower = (company_display or "").lower()
    if "ikio" in company_lower:
        priority = ["ikio", "sunsprint", "metco"]
    elif "metco" in company_lower:
        priority = ["metco", "sunsprint", "ikio"]
    elif "sunsprint" in company_lower:
        priority = ["sunsprint", "metco", "ikio"]
    else:
        priority = ["sunsprint", "metco", "ikio"]

    # Build ordered absolute candidate list
    candidates = []
    for brand in priority:
        for rel in variants[brand]:
            candidates.append(_os.path.join(base_dir, rel))

    # Return first existing path
    for cand in candidates:
        try:
            if _os.path.exists(cand):
                return cand
        except Exception:
            continue
    return None

@app.route('/api/validate-requirement-attachment', methods=['POST'])
@login_required
def validate_requirement_attachment():
    """Validate that an uploaded document matches the required form type."""
    if 'file' not in request.files:
        return jsonify({'error': 'missing_file', 'message': 'No file provided.'}), 400
    
    file = request.files['file']
    requirement_text = request.form.get('requirement_text', '').strip()
    
    if not file or not file.filename:
        return jsonify({'error': 'missing_file', 'message': 'No file provided.'}), 400
    
    if not requirement_text:
        return jsonify({'error': 'missing_requirement', 'message': 'Requirement text is required.'}), 400
    
    # Validate file type
    filename = file.filename.lower()
    if not (filename.endswith('.pdf') or filename.endswith('.jpg') or filename.endswith('.jpeg')):
        return jsonify({'error': 'invalid_format', 'message': 'Only PDF and JPG files are allowed.'}), 400
    
    try:
        # Save file temporarily
        import tempfile
        import os
        from werkzeug.utils import secure_filename
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(filename)[1]) as tmp_file:
            file.save(tmp_file.name)
            tmp_path = tmp_file.name
        
        try:
            # Extract text from document
            extracted_text = ''
            
            if filename.endswith('.pdf'):
                # Extract text from PDF
                if _FITZ_AVAILABLE:
                    with _pymupdf.open(tmp_path) as doc:
                        for page_num in range(min(3, doc.page_count)):  # First 3 pages
                            page = doc.load_page(page_num)
                            extracted_text += page.get_text("text") + "\n\n"
                else:
                    # Fallback to PyPDF2
                    if _PdfReader is not None:
                        with open(tmp_path, "rb") as fh:
                            reader = _PdfReader(fh)
                            for page_num in range(min(3, len(reader.pages))):
                                extracted_text += reader.pages[page_num].extract_text() + "\n\n"
                    else:
                        return jsonify({'error': 'pdf_library_missing', 'message': 'PDF processing library not available.'}), 500
            
            elif filename.endswith('.jpg') or filename.endswith('.jpeg'):
                # For images, we'll use OpenAI Vision API or return limited validation
                # For now, we'll use AI to analyze the image directly
                extracted_text = '[IMAGE_FILE]'  # Placeholder for image files
            
            # Use AI to validate document content
            api_key = (app.config.get('OPENAI_API_KEY') or os.getenv('OPENAI_API_KEY') or os.getenv('GROQ_API_KEY') or '').strip()
            if not api_key:
                return jsonify({'error': 'api_unavailable', 'message': 'OpenAI API key is not configured.'}), 500
            
            base_url = (app.config.get('OPENAI_BASE_URL') or os.getenv('OPENAI_BASE_URL') or 'https://api.openai.com/v1').strip()
            model = (app.config.get('OPENAI_MODEL') or os.getenv('OPENAI_MODEL') or 'gpt-4o-mini').strip()
            
            # For images, use vision model
            if filename.endswith('.jpg') or filename.endswith('.jpeg'):
                # Read image as base64
                import base64
                with open(tmp_path, 'rb') as img_file:
                    image_data = base64.b64encode(img_file.read()).decode('utf-8')
                
                endpoint = base_url.rstrip('/')
                if not endpoint.endswith('/chat/completions'):
                    endpoint = f"{endpoint}/chat/completions"
                
                headers = {
                    'Authorization': f'Bearer {api_key}',
                    'Content-Type': 'application/json',
                }
                
                system_prompt = (
                    "You are a document validation expert. Your task is to analyze uploaded documents "
                    "and determine if they match the required form type specified in the requirement text. "
                    "Return only 'YES' if the document matches the requirement, or 'NO' with a brief reason if it doesn't."
                )
                
                user_prompt = f"""
Analyze the uploaded image and determine if it matches the required document type.

REQUIREMENT: {requirement_text}

The requirement may specify forms like:
- W-9 Form (Request for Taxpayer Identification Number and Certification)
- W-8 Form (Certificate of Foreign Status)
- Insurance Certificate
- Bid Bond
- Performance Bond
- License/Certification
- Company Profile
- References
- Any other specific form or document

Examine the image carefully and check:
1. Does the document title/header match the required form name?
2. Are there identifying markers (form numbers, official headers) that match?
3. Is this the correct document type?

Respond with:
- "YES" if the document matches the requirement
- "NO: [brief reason]" if it doesn't match

Your response should be only "YES" or "NO: [reason]".
"""
                
                body = {
                    'model': 'gpt-4o',  # Use vision-capable model
                    'messages': [
                        {'role': 'system', 'content': system_prompt},
                        {
                            'role': 'user',
                            'content': [
                                {'type': 'text', 'text': user_prompt},
                                {
                                    'type': 'image_url',
                                    'image_url': {
                                        'url': f'data:image/jpeg;base64,{image_data}'
                                    }
                                }
                            ]
                        }
                    ],
                    'temperature': 0.1,
                    'max_tokens': 150
                }
            else:
                # For PDFs, use text-based validation
                endpoint = base_url.rstrip('/')
                if not endpoint.endswith('/chat/completions'):
                    endpoint = f"{endpoint}/chat/completions"
                
                headers = {
                    'Authorization': f'Bearer {api_key}',
                    'Content-Type': 'application/json',
                }
                
                system_prompt = (
                    "You are a document validation expert. Your task is to analyze extracted text from documents "
                    "and determine if they match the required form type specified in the requirement text. "
                    "Return only 'YES' if the document matches the requirement, or 'NO' with a brief reason if it doesn't."
                )
                
                user_prompt = f"""
Analyze the extracted text from the uploaded document and determine if it matches the required document type.

REQUIREMENT: {requirement_text}

The requirement may specify forms like:
- W-9 Form (Request for Taxpayer Identification Number and Certification)
- W-8 Form (Certificate of Foreign Status)
- Insurance Certificate
- Bid Bond
- Performance Bond
- License/Certification
- Company Profile
- References
- Any other specific form or document

EXTRACTED TEXT FROM DOCUMENT:
{extracted_text[:3000] if extracted_text else '[No text extracted]'}

Examine the text carefully and check:
1. Does the document title/header match the required form name?
2. Are there identifying markers (form numbers, official headers, form names) that match?
3. Is this the correct document type?

Respond with:
- "YES" if the document matches the requirement
- "NO: [brief reason]" if it doesn't match

Your response should be only "YES" or "NO: [reason]".
"""
                
                body = {
                    'model': model,
                    'messages': [
                        {'role': 'system', 'content': system_prompt},
                        {'role': 'user', 'content': user_prompt}
                    ],
                    'temperature': 0.1,
                    'max_tokens': 150
                }
            
            # Call OpenAI API
            import requests
            response = requests.post(endpoint, headers=headers, json=body, timeout=30)
            
            if response.status_code >= 400:
                data = response.json() if response.content else {}
                error_msg = data.get('error', {}).get('message', 'Validation failed') if isinstance(data, dict) else 'Validation failed'
                return jsonify({'error': 'validation_failed', 'message': error_msg}), 502
            
            data = response.json()
            choices = data.get('choices', [])
            if not choices:
                return jsonify({'error': 'validation_failed', 'message': 'No response from validation service.'}), 502
            
            validation_result = choices[0].get('message', {}).get('content', '').strip().upper()
            is_valid = validation_result.startswith('YES')
            
            return jsonify({
                'is_valid': is_valid,
                'validation_message': validation_result,
                'requirement': requirement_text
            })
        
        finally:
            # Clean up temporary file
            try:
                os.unlink(tmp_path)
            except Exception:
                pass
    
    except Exception as e:
        app.logger.exception("Error validating attachment: %s", e)
        return jsonify({'error': 'validation_error', 'message': f'Validation failed: {str(e)}'}), 500

@app.route('/proposals-making/download/<filename>')
@login_required
def download_proposal(filename):
    # Allow all logged-in users to download proposals (removed admin-only restriction)
    from werkzeug.utils import secure_filename
    from flask import send_from_directory
    safe_filename = secure_filename(filename)
    proposals_dir = 'uploads/proposals'
    return send_from_directory(proposals_dir, safe_filename, as_attachment=True)

# --- API & Real-time Logic ---
@app.route('/api/update_stage/<int:bid_id>', methods=['POST'])
@login_required
def update_stage(bid_id):
    try:
        data = request.get_json()
        new_stage = (data.get('stage') or '').lower()
        
        # Validate stage
        allowed = {'analyzer', 'business', 'design', 'operations', 'engineer', 'handover'}
        if new_stage not in allowed:
            return jsonify({'error': 'invalid stage'}), 400
        
        cur = mysql.connection.cursor(DictCursor)
        
        # Get bid information from go_bids
        cur.execute("SELECT * FROM go_bids WHERE g_id=%s", (bid_id,))
        bid = cur.fetchone()
        
        if not bid:
            cur.close()
            return jsonify({'error': 'Bid not found or access denied'}), 404

        # Get old stage for logging
        old_stage = (bid.get('state') or 'analyzer').lower()
        
        # Update go_bids state
        cur.execute("UPDATE go_bids SET state=%s WHERE g_id=%s", (new_stage, bid_id))

        # Ensure tasks exist for all departments so they can work in parallel on this bid.
        try:
            team_stages = ['engineering_team', 'procurement_team', 'accounts_finance']
            for st in team_stages:
                cur.execute(
                    """
                    SELECT 1
                    FROM bid_checklists
                    WHERE g_id = %s AND LOWER(COALESCE(stage,'')) = %s
                    LIMIT 1
                    """,
                    (bid_id, st),
                )
                exists = cur.fetchone() is not None
                if not exists:
                    generate_team_checklist(cur, bid_id, st)
        except Exception:
            pass
        
        # Upsert assignment so the next team still sees it
        cur.execute("SELECT a_id FROM bid_assign WHERE g_id=%s", (bid_id,))
        row = cur.fetchone()
        if row:
            cur.execute("UPDATE bid_assign SET depart=%s, state=%s, status='pending' WHERE g_id=%s",
                        (new_stage, new_stage, bid_id))
        else:
            try:
                cur.execute("""
                    INSERT INTO bid_assign (g_id, b_name, due_date, state, scope, type, company, depart,
                                           person_name, assignee_email, status, value, revenue)
                    SELECT g_id, b_name, due_date, state, scope, type, company, %s, '', '', 'pending',
                           COALESCE(scoring, 0), COALESCE(revenue, 0)
                    FROM go_bids WHERE g_id=%s
                """, (new_stage, bid_id))
            except Exception as e_ins:
                if "Unknown column 'revenue'" in str(e_ins):
                    # Retry without 'revenue' column for legacy bid_assign schema
                    cur.execute("""
                        INSERT INTO bid_assign (g_id, b_name, due_date, state, scope, type, company, depart,
                                               person_name, assignee_email, status, value)
                        SELECT g_id, b_name, due_date, state, scope, type, company, %s, '', '', 'pending',
                               COALESCE(scoring, 0)
                        FROM go_bids WHERE g_id=%s
                    """, (new_stage, bid_id))
                else:
                    raise
        
        # Derive dynamic summary line
        from_txt = LABELS.get(old_stage, '')
        to_txt = LABELS.get(new_stage, '')
        summary_line = f"Updated by {from_txt} to {to_txt}"
        
        # Commit the transaction
        mysql.connection.commit()
        
        # Log the stage change
        log_write('stage_change', f"{bid.get('b_name')} | {old_stage} ??? {new_stage}")
        
        # Calculate dynamic progress and status texts for new stage
        pct = pct_for(new_stage)
        proj_status = 'completed' if new_stage == 'handover' else 'ongoing'
        
        # Recompute cards and analyzer stats after update
        # Summary cards across the three companies only
        cur2 = mysql.connection.cursor(DictCursor)
        cur2.execute("SELECT id FROM companies WHERE name IN ('Ikio','Metco','Sunsprint')")
        target_company_ids = [row['id'] for row in cur2.fetchall()]
        if not target_company_ids:
            target_company_ids = [-1]
        in_clause = ','.join(['%s'] * len(target_company_ids))

        # Compute totals from go_bids instead of bids
        cur2.execute("SELECT name FROM companies WHERE name IN ('Ikio','Metco','Sunsprint')")
        target_company_names = [row['name'] for row in cur2.fetchall()] or ['__none__']
        in_clause_names = ','.join(['%s'] * len(target_company_names))
        cur2.execute(f"SELECT COUNT(*) AS total_bids FROM go_bids WHERE company IN ({in_clause_names})", target_company_names)
        total_bids = cur2.fetchone()['total_bids']
        cur2.execute(f"SELECT COUNT(*) AS live_bids FROM go_bids WHERE COALESCE(state,'analyzer') IN ('business','design','operations','engineer') AND company IN ({in_clause_names})", target_company_names)
        live_bids = cur2.fetchone()['live_bids']
        cur2.execute(f"SELECT COUNT(*) AS bids_won FROM go_bids WHERE decision='WON' AND company IN ({in_clause_names})", target_company_names)
        bids_won = cur2.fetchone()['bids_won']
        # Total projects across target companies (fallback to all projects if none linked)
        cur2.execute(f"SELECT COUNT(*) AS projects_linked FROM projects WHERE company_id IN ({in_clause})", target_company_ids)
        projects_linked = cur2.fetchone()['projects_linked']
        if projects_linked > 0:
            cur2.execute(f"SELECT COUNT(*) AS projects_total FROM projects WHERE company_id IN ({in_clause})", target_company_ids)
            projects_total = cur2.fetchone()['projects_total']
        else:
            cur2.execute("SELECT COUNT(*) AS projects_total FROM projects")
            projects_total = cur2.fetchone()['projects_total']

        # Analyzer stats from bid_incoming table
        cur2.execute("SELECT COUNT(*) AS total_bids FROM bid_incoming")
        total_bids_analyzer = cur2.fetchone()['total_bids']
        
        cur2.execute("SELECT COUNT(*) AS bids_go FROM bid_incoming WHERE decision = 'GO'")
        bids_go_analyzer = cur2.fetchone()['bids_go']
        
        cur2.execute("SELECT COUNT(*) AS bids_no_go FROM bid_incoming WHERE decision = 'NO-GO'")
        bids_no_go_analyzer = cur2.fetchone()['bids_no_go']
        
        cur2.execute("SELECT COUNT(*) AS bids_submitted FROM bid_incoming WHERE state IN ('submitted', 'under_review')")
        bids_submitted_analyzer = cur2.fetchone()['bids_submitted']
        
        cur2.execute("SELECT COUNT(*) AS bids_won FROM bid_incoming WHERE decision = 'WON'")
        bids_won_analyzer = cur2.fetchone()['bids_won']
        
        cur2.execute("SELECT COUNT(*) AS bids_lost FROM bid_incoming WHERE decision = 'LOST'")
        bids_lost_analyzer = cur2.fetchone()['bids_lost']

        bid_stats = {
            'total_bids': total_bids_analyzer,
            'bids_go': bids_go_analyzer,
            'bids_no_go': bids_no_go_analyzer,
            'bids_submitted': bids_submitted_analyzer,
            'bids_won': bids_won_analyzer,
            'bids_lost': bids_lost_analyzer
        }

        socketio.emit('master_update', {
            'bid': {
                'id': bid_id,
                'name': bid.get('b_name'),
                'current_stage': new_stage,
                'user_email': getattr(current_user, 'email', '')
            },
            'summary': {
                'work_progress_pct': pct,
                'project_status': proj_status,
                'work_status': summary_line
            },
            'cards': {
                'total_bids': projects_total,
                'live_bids': 0,
                'bids_won': 0,
                'projects_completed': 0
            },
            'bid_stats': bid_stats
        })
        
        cur.close()
        cur2.close()
        return jsonify({'success': f'Bid {bid_id} updated to {new_stage}'})
    
    except Exception as e:
        mysql.connection.rollback()
        if 'cur' in locals():
            cur.close()
        if 'cur2' in locals():
            cur2.close()
        return jsonify({'error': f'Error updating stage: {str(e)}'}), 500
# --- Main execution ---
def _ensure_tables_exist():
    """Create tables if they don't exist"""
    try:
        cur = mysql.connection.cursor()

        def _mysql_err_no(exc) -> int | None:
            try:
                if hasattr(exc, "args") and exc.args:
                    return int(exc.args[0])
            except Exception:
                return None
            return None

        def _mysql_datadir() -> str | None:
            c2 = None
            try:
                c2 = mysql.connection.cursor()
                c2.execute("SHOW VARIABLES LIKE 'datadir'")
                row = c2.fetchone()
                if isinstance(row, (list, tuple)) and len(row) >= 2:
                    return str(row[1])
                if isinstance(row, dict):
                    return str(row.get("Value") or row.get("value") or "")
            except Exception:
                return None
            finally:
                try:
                    if c2 is not None:
                        c2.close()
                except Exception:
                    pass
            return None

        def _quarantine_innodb_files(db_name: str, table_name: str) -> None:
            import time as _time
            data_dir = _mysql_datadir()
            if not data_dir:
                return
            db_dir = os.path.join(str(data_dir), str(db_name))
            for ext in (".ibd", ".cfg", ".frm"):
                p = os.path.join(db_dir, f"{table_name}{ext}")
                try:
                    if os.path.exists(p):
                        os.remove(p)
                except Exception:
                    try:
                        if os.path.exists(p):
                            os.rename(p, f"{p}.bak_{int(_time.time())}")
                    except Exception:
                        pass

        def _ensure_innodb_table_ok(table_name: str, create_sql: str) -> None:
            """
            Some installs end up with orphan/corrupt InnoDB tables (e.g. MySQL errno 1932 / 1813).
            CREATE TABLE IF NOT EXISTS won't repair those; we need to drop + recreate.
            """
            try:
                cur.execute(f"SELECT 1 FROM `{table_name}` LIMIT 1")
                cur.fetchone()
                return
            except Exception as e:
                err_no = _mysql_err_no(e)
                if err_no not in (1146, 1813, 1932):
                    raise

            db_name = app.config.get("MYSQL_DB", "esco")
            if err_no in (1813, 1932):
                _quarantine_innodb_files(str(db_name), table_name)

            try:
                cur.execute("SET FOREIGN_KEY_CHECKS=0")
            except Exception:
                pass
            try:
                cur.execute(f"DROP TABLE IF EXISTS `{table_name}`")
            except Exception as drop_err:
                # Best-effort: if drop fails, a subsequent CREATE TABLE (without IF NOT EXISTS)
                # will raise and surface the underlying issue.
                last_drop_err = drop_err
            finally:
                try:
                    cur.execute("SET FOREIGN_KEY_CHECKS=1")
                except Exception:
                    pass

            # If we are repairing, we must NOT keep IF NOT EXISTS; otherwise we'd silently
            # keep a broken table if the DROP didn't actually remove it.
            try:
                repair_sql = re.sub(
                    r"CREATE\\s+TABLE\\s+IF\\s+NOT\\s+EXISTS",
                    "CREATE TABLE",
                    create_sql,
                    flags=re.IGNORECASE,
                )
            except Exception:
                repair_sql = create_sql.replace("CREATE TABLE IF NOT EXISTS", "CREATE TABLE")

            try:
                cur.execute(repair_sql)
            except Exception as create_err:
                # If the table still exists, try one more hard drop + create.
                create_err_no = _mysql_err_no(create_err)
                # 1050 = table already exists (can happen if another init/migration created it
                # between our read-check and CREATE, or if DROP was blocked/ignored).
                if create_err_no == 1050:
                    try:
                        cur.execute(f"SELECT 1 FROM `{table_name}` LIMIT 1")
                        cur.fetchone()
                        mysql.connection.commit()
                        return
                    except Exception:
                        # If MySQL says "already exists" but we can't read it (or it doesn't
                        # actually exist in the data dictionary), it can be a leftover .ibd/.frm
                        # file situation. Try quarantining any on-disk artifacts before retrying.
                        try:
                            _quarantine_innodb_files(
                                str(app.config.get("MYSQL_DB", "esco")),
                                table_name,
                            )
                        except Exception:
                            pass
                        # Fall through to hard-drop attempt below.
                        pass
                if create_err_no in (1932, 1813, 1050):
                    if create_err_no in (1813, 1932):
                        _quarantine_innodb_files(str(app.config.get("MYSQL_DB", "esco")), table_name)
                    try:
                        cur.execute("SET FOREIGN_KEY_CHECKS=0")
                    except Exception:
                        pass
                    try:
                        cur.execute(f"DROP TABLE IF EXISTS `{table_name}`")
                    except Exception:
                        pass
                    finally:
                        try:
                            cur.execute("SET FOREIGN_KEY_CHECKS=1")
                        except Exception:
                            pass
                    try:
                        cur.execute(repair_sql)
                    except Exception as create_err_2:
                        # If the table exists and is readable, don't block startup.
                        if _mysql_err_no(create_err_2) == 1050:
                            try:
                                cur.execute(f"SELECT 1 FROM `{table_name}` LIMIT 1")
                                cur.fetchone()
                                mysql.connection.commit()
                                return
                            except Exception:
                                pass
                        raise
                else:
                    raise

            mysql.connection.commit()
        
        # Create users table
        create_users_sql = """
            CREATE TABLE IF NOT EXISTS users (
                id INT AUTO_INCREMENT PRIMARY KEY,
                email VARCHAR(100) UNIQUE NOT NULL,
                full_name VARCHAR(150) DEFAULT NULL,
                password VARCHAR(255) NOT NULL,
                is_admin BOOLEAN DEFAULT FALSE,
                role VARCHAR(50)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        _ensure_innodb_table_ok("users", create_users_sql)

        # Ensure users.password can store modern hashes (bcrypt ~60 chars, sha256 fallback ~136 chars)
        try:
            cur.execute("SHOW COLUMNS FROM users LIKE 'password'")
            pw_col = cur.fetchone()
            # pw_col can be tuple (Field, Type, ...) or dict depending on cursor type
            col_type = ''
            if isinstance(pw_col, (list, tuple)) and len(pw_col) >= 2:
                col_type = str(pw_col[1] or '')
            elif isinstance(pw_col, dict):
                col_type = str(pw_col.get('Type', '') or pw_col.get('type', '') or '')
            if col_type and 'varchar(255)' not in col_type.lower():
                cur.execute("ALTER TABLE users MODIFY COLUMN password VARCHAR(255) NOT NULL")
        except Exception:
            pass
        # Ensure the new full_name column exists for legacy databases
        try:
            cur.execute("SHOW COLUMNS FROM users LIKE 'full_name'")
            if not cur.fetchone():
                cur.execute("ALTER TABLE users ADD COLUMN full_name VARCHAR(150) DEFAULT NULL AFTER email")
        except Exception:
            pass

        # Track user login transfers for audit/history
        create_login_transfers_sql = """
            CREATE TABLE IF NOT EXISTS login_transfers (
                id INT AUTO_INCREMENT PRIMARY KEY,
                user_id INT NOT NULL,
                old_email VARCHAR(100) NOT NULL,
                new_email VARCHAR(100) NOT NULL,
                performed_by INT,
                note TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
                FOREIGN KEY (performed_by) REFERENCES users(id) ON DELETE SET NULL
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        _ensure_innodb_table_ok("login_transfers", create_login_transfers_sql)
        
        # Create bids table
        create_bids_sql = """
            CREATE TABLE IF NOT EXISTS bids (
                id INT AUTO_INCREMENT PRIMARY KEY,
                name VARCHAR(100) NOT NULL,
                current_stage VARCHAR(50) DEFAULT 'analyzer',
                user_id INT,
                company_id INT,
                FOREIGN KEY (user_id) REFERENCES users(id)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        _ensure_innodb_table_ok("bids", create_bids_sql)
        
        # Create bid_incoming table
        create_bid_incoming_sql = """
            CREATE TABLE IF NOT EXISTS bid_incoming (
                id INT AUTO_INCREMENT PRIMARY KEY,
                b_name VARCHAR(100),
                issue_date DATE NULL,
                due_date DATE NOT NULL DEFAULT CURRENT_TIMESTAMP,
                state VARCHAR(100),
                scope TEXT,
                type VARCHAR(100),
                scoring INT,
                comp_name VARCHAR(100),
                decision VARCHAR(100),
                bid_status VARCHAR(32),
                results VARCHAR(16),
                summary TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        _ensure_innodb_table_ok("bid_incoming", create_bid_incoming_sql)

        # Ensure created_at exists (older installs may not have it)
        try:
            cur.execute("SHOW COLUMNS FROM bid_incoming LIKE 'created_at'")
            if not cur.fetchone():
                cur.execute("ALTER TABLE bid_incoming ADD COLUMN created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP")
        except Exception:
            pass
        # Ensure issue_date exists
        try:
            cur.execute("SHOW COLUMNS FROM bid_incoming LIKE 'issue_date'")
            if not cur.fetchone():
                cur.execute("ALTER TABLE bid_incoming ADD COLUMN issue_date DATE NULL")
        except Exception:
            pass
        
        # Create go_bids table
        create_go_bids_sql = """
            CREATE TABLE IF NOT EXISTS go_bids (
                g_id INT AUTO_INCREMENT PRIMARY KEY,
                id INT,
                b_name VARCHAR(100),
               
                due_date DATE NOT NULL DEFAULT CURRENT_TIMESTAMP,
                state VARCHAR(100),
                scope TEXT,
                type VARCHAR(100),
                scoring INT,
                company TEXT,
                decision TEXT,
                summary TEXT,
                revenue DECIMAL(15,2) DEFAULT 0.00
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        _ensure_innodb_table_ok("go_bids", create_go_bids_sql)

        # Ensure go_bids.created_at exists (some queries expect gb.created_at).
        try:
            cur.execute("SHOW COLUMNS FROM go_bids LIKE 'created_at'")
            if not cur.fetchone():
                cur.execute("ALTER TABLE go_bids ADD COLUMN created_at TIMESTAMP NULL DEFAULT CURRENT_TIMESTAMP")
                # Best-effort backfill from bid_incoming when possible; fallback to NOW().
                try:
                    cur.execute(
                        """
                        UPDATE go_bids gb
                        JOIN bid_incoming bi ON bi.b_name = gb.b_name
                        SET gb.created_at = COALESCE(gb.created_at, bi.created_at)
                        WHERE gb.created_at IS NULL AND bi.created_at IS NOT NULL
                        """
                    )
                except Exception:
                    pass
                try:
                    cur.execute("UPDATE go_bids SET created_at = COALESCE(created_at, NOW()) WHERE created_at IS NULL")
                except Exception:
                    pass
                mysql.connection.commit()
        except Exception:
            pass
        
        # Ensure summary and scope columns exist and are TEXT type for detailed content
        # Check and alter go_bids table
        try:
            cur.execute("SHOW COLUMNS FROM go_bids LIKE 'summary'")
            summary_col = cur.fetchone()
            if not summary_col:
                cur.execute("ALTER TABLE go_bids ADD COLUMN summary TEXT")
            else:
                # Check if it's not TEXT type and alter it
                col_type = summary_col[1] if isinstance(summary_col, tuple) else summary_col.get('Type', '')
                if col_type and 'text' not in str(col_type).lower():
                    cur.execute("ALTER TABLE go_bids MODIFY COLUMN summary TEXT")
        except Exception:
            pass
        
        try:
            cur.execute("SHOW COLUMNS FROM go_bids LIKE 'scope'")
            scope_col = cur.fetchone()
            if not scope_col:
                cur.execute("ALTER TABLE go_bids ADD COLUMN scope TEXT")
            else:
                # Check if it's not TEXT type and alter it
                col_type = scope_col[1] if isinstance(scope_col, tuple) else scope_col.get('Type', '')
                if col_type and 'text' not in str(col_type).lower():
                    cur.execute("ALTER TABLE go_bids MODIFY COLUMN scope TEXT")
        except Exception:
            pass
        
        # Ensure summary and scope columns exist in bid_incoming table
        try:
            cur.execute("SHOW COLUMNS FROM bid_incoming LIKE 'summary'")
            summary_col = cur.fetchone()
            if not summary_col:
                cur.execute("ALTER TABLE bid_incoming ADD COLUMN summary TEXT")
            else:
                # Check if it's not TEXT type and alter it
                col_type = summary_col[1] if isinstance(summary_col, tuple) else summary_col.get('Type', '')
                if col_type and 'text' not in str(col_type).lower():
                    cur.execute("ALTER TABLE bid_incoming MODIFY COLUMN summary TEXT")
        except Exception:
            pass
        
        try:
            cur.execute("SHOW COLUMNS FROM bid_incoming LIKE 'scope'")
            scope_col = cur.fetchone()
            if not scope_col:
                cur.execute("ALTER TABLE bid_incoming ADD COLUMN scope TEXT")
            else:
                # Check if it's not TEXT type and alter it
                col_type = scope_col[1] if isinstance(scope_col, tuple) else scope_col.get('Type', '')
                if col_type and 'text' not in str(col_type).lower():
                    cur.execute("ALTER TABLE bid_incoming MODIFY COLUMN scope TEXT")
        except Exception:
            pass

        # Ensure bid_status and results columns exist in bid_incoming table
        try:
            cur.execute("SHOW COLUMNS FROM bid_incoming LIKE 'bid_status'")
            if not cur.fetchone():
                cur.execute("ALTER TABLE bid_incoming ADD COLUMN bid_status VARCHAR(32)")
            cur.execute("SHOW COLUMNS FROM bid_incoming LIKE 'results'")
            if not cur.fetchone():
                cur.execute("ALTER TABLE bid_incoming ADD COLUMN results VARCHAR(16)")
        except Exception:
            pass
        
        # Add submission_status column to go_bids if not exists
        try:
            cur.execute("SHOW COLUMNS FROM go_bids LIKE 'submission_status'")
            submission_col = cur.fetchone()
            if not submission_col:
                cur.execute("ALTER TABLE go_bids ADD COLUMN submission_status VARCHAR(50) DEFAULT 'Work Progress'")
        except Exception:
            pass
        
        # Add submission_reason column to go_bids if not exists
        try:
            cur.execute("SHOW COLUMNS FROM go_bids LIKE 'submission_reason'")
            reason_col = cur.fetchone()
            if not reason_col:
                cur.execute("ALTER TABLE go_bids ADD COLUMN submission_reason TEXT")
        except Exception:
            pass
        
        # Create bid_assign table
        cur.execute("""
            CREATE TABLE IF NOT EXISTS bid_assign (
                a_id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT,
                b_name VARCHAR(100),
               
                due_date DATE NOT NULL DEFAULT CURRENT_TIMESTAMP,
                state VARCHAR(100),
                scope VARCHAR(100),
                type VARCHAR(100),
                company TEXT,
                depart TEXT,
                person_name TEXT,
                assignee_email VARCHAR(100),
                status TEXT,
                value INT,
                revenue DECIMAL(15,2) DEFAULT 0.00
            )
        """)
        
        # Create win_lost_results table
        cur.execute("""
            CREATE TABLE IF NOT EXISTS win_lost_results (
                w_id INT AUTO_INCREMENT PRIMARY KEY,
                a_id INT,
                b_name TEXT,
              
                due_date INT,
                state TEXT,
                scope TEXT,
                value INT,
                company TEXT,
                department TEXT,
                person_name TEXT,
                status TEXT,
                result TEXT,
                feedback TEXT,
                g_id INT
            )
        """)
        
        # Add feedback and g_id columns to win_lost_results if not exists
        try:
            cur.execute("SHOW COLUMNS FROM win_lost_results LIKE 'feedback'")
            feedback_col = cur.fetchone()
            if not feedback_col:
                cur.execute("ALTER TABLE win_lost_results ADD COLUMN feedback TEXT")
        except Exception:
            pass
        try:
            cur.execute("SHOW COLUMNS FROM win_lost_results LIKE 'g_id'")
            gid_col = cur.fetchone()
            if not gid_col:
                cur.execute("ALTER TABLE win_lost_results ADD COLUMN g_id INT")
        except Exception:
            pass
        
        # Create won_bids_result table
        cur.execute("""
            CREATE TABLE IF NOT EXISTS won_bids_result (
                won_id INT AUTO_INCREMENT PRIMARY KEY,
                w_id INT,
                closure_status TEXT,
                work_progress_status TEXT
            )
        """)
        
        # Create assigned_bids table using the exact schema requested
        cur.execute("""
            CREATE TABLE IF NOT EXISTS assigned_bids (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT,
                b_name VARCHAR(100),
                company VARCHAR(100),
                revenue DECIMAL(15,2) DEFAULT 0.00,
                assigned_to VARCHAR(100),
                assigned_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # Create teamlead_assign_bids table for assigning bids to team leads
        cur.execute("""
            CREATE TABLE IF NOT EXISTS teamlead_assign_bids (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT,
                b_name VARCHAR(100),
                -- Some MySQL versions don't support CURRENT_TIMESTAMP as DATE default,
                -- and older data can have NULL due_date. Keep nullable to avoid (1048).
                due_date DATE NULL,
                state VARCHAR(100),
                scope TEXT,
                type VARCHAR(100),
                scoring INT,
                comp_name VARCHAR(100),
                company TEXT,
                summary TEXT,
                submission_status VARCHAR(50) DEFAULT 'Work Progress',
                submission_reason TEXT,
                task_completion_date DATE NULL,
                team_lead VARCHAR(100),
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                KEY idx_teamlead_assign_g_id (g_id),
                KEY idx_teamlead_assign_team_lead (team_lead)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """)

        # Ensure due_date is nullable on existing DBs too (prevents 1048 insert failures)
        try:
            cur.execute("SHOW COLUMNS FROM teamlead_assign_bids LIKE 'due_date'")
            _dc = cur.fetchone()
            _null_flag = None
            try:
                _null_flag = (_dc[2] if isinstance(_dc, (list, tuple)) and len(_dc) > 2 else _dc.get('Null')) if _dc else None
            except Exception:
                _null_flag = None
            if _null_flag and str(_null_flag).upper() == 'NO':
                cur.execute("ALTER TABLE teamlead_assign_bids MODIFY COLUMN due_date DATE NULL")
        except Exception:
            pass

        # Ensure a unique key on g_id so we can safely upsert/backfill
        try:
            cur.execute("SHOW INDEX FROM teamlead_assign_bids WHERE Key_name = 'uniq_teamlead_assign_g_id'")
            if cur.fetchone():
                cur.execute("ALTER TABLE teamlead_assign_bids DROP INDEX uniq_teamlead_assign_g_id")
            cur.execute("SHOW INDEX FROM teamlead_assign_bids WHERE Key_name = 'uniq_teamlead_assign_bid_lead'")
            if not cur.fetchone():
                cur.execute("ALTER TABLE teamlead_assign_bids ADD UNIQUE KEY uniq_teamlead_assign_bid_lead (g_id, team_lead)")
        except Exception:
            # If duplicates exist or older MySQL quirks, skip enforcing uniqueness
            pass

        # Backfill teamlead_assign_bids from existing tables (go_bids + bid_assign + bid_checklists)
        # - Uses latest assignment from bid_assign (by highest a_id)
        # - Uses completion date as latest updated_at of completed/100% tasks in bid_checklists
        # - Uses comp_name from latest bid_incoming row matching b_name (fallbacks to go_bids.company)
        try:
            cur.execute(
                """
                INSERT INTO teamlead_assign_bids (
                    g_id, b_name, due_date, state, scope, type, scoring,
                    comp_name, company, summary, submission_status, submission_reason,
                    task_completion_date, team_lead
                )
                SELECT
                    g.g_id,
                    g.b_name,
                    g.due_date,
                    g.state,
                    g.scope,
                    g.type,
                    g.scoring,
                    COALESCE(
                        (SELECT bi.comp_name
                         FROM bid_incoming bi
                         WHERE bi.b_name = g.b_name
                         ORDER BY bi.id DESC
                         LIMIT 1),
                        g.company
                    ) AS comp_name,
                    g.company,
                    g.summary,
                    COALESCE(g.submission_status, 'Work Progress') AS submission_status,
                    g.submission_reason,
                    (
                        SELECT DATE(MAX(bc.updated_at))
                        FROM bid_checklists bc
                        WHERE bc.g_id = g.g_id
                          AND (
                            LOWER(COALESCE(bc.status, '')) = 'completed'
                            OR COALESCE(bc.progress_pct, 0) >= 100
                          )
                    ) AS task_completion_date,
                    (
                        SELECT ba.assignee_email
                        FROM bid_assign ba
                        WHERE ba.g_id = g.g_id
                        ORDER BY ba.a_id DESC
                        LIMIT 1
                    ) AS team_lead
                FROM go_bids g
                ON DUPLICATE KEY UPDATE
                    b_name = VALUES(b_name),
                    due_date = VALUES(due_date),
                    state = VALUES(state),
                    scope = VALUES(scope),
                    type = VALUES(type),
                    scoring = VALUES(scoring),
                    comp_name = VALUES(comp_name),
                    company = VALUES(company),
                    summary = VALUES(summary),
                    submission_status = VALUES(submission_status),
                    submission_reason = VALUES(submission_reason),
                    task_completion_date = VALUES(task_completion_date),
                    team_lead = VALUES(team_lead),
                    updated_at = CURRENT_TIMESTAMP
                """
            )
        except Exception:
            # If the DB lacks some tables/columns in older installs, don't block app startup
            pass
        
        # Create work_progress_status table (extended schema used across the app)
        cur.execute("""
            CREATE TABLE IF NOT EXISTS work_progress_status (
                p_id INT AUTO_INCREMENT PRIMARY KEY,
                won_id INT,
                company TEXT,
                b_name TEXT,
                dept_bde TEXT,
                dept_m_d TEXT,
                dept_op TEXT,
                dept_site TEXT,
                pr_completion_status TEXT
            )
        """)

    
        
        # Create logs table for tracking user actions
        create_logs_sql = """
            CREATE TABLE IF NOT EXISTS logs (
                id INT AUTO_INCREMENT PRIMARY KEY,
                action VARCHAR(255) NOT NULL,
                user_id INT,
                timestamp DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users(id)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        _ensure_innodb_table_ok("logs", create_logs_sql)
        
        # Create companies table
        create_companies_sql = """
            CREATE TABLE IF NOT EXISTS companies (
                id INT AUTO_INCREMENT PRIMARY KEY,
                name VARCHAR(100) UNIQUE NOT NULL,
                description TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            ) ENGINE=InnoDB
        """
        _ensure_innodb_table_ok("companies", create_companies_sql)

        # --------------------------------------------------------------------
        # Multi-company + department-scoped access control (ESCO V23+)
        # --------------------------------------------------------------------
        # Departments are logical org units (business/marketing/operations/site_engineer).
        # A user can have multiple memberships across companies and departments.
        create_departments_sql = """
            CREATE TABLE IF NOT EXISTS departments (
                id INT AUTO_INCREMENT PRIMARY KEY,
                dept_key VARCHAR(50) UNIQUE NOT NULL,
                display_name VARCHAR(100) NOT NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        _ensure_innodb_table_ok("departments", create_departments_sql)

        # department_key NULL => access applies to ALL departments in that company.
        create_user_company_access_sql = """
            CREATE TABLE IF NOT EXISTS user_company_access (
                id INT AUTO_INCREMENT PRIMARY KEY,
                user_id INT NOT NULL,
                company_id INT NOT NULL,
                department_key VARCHAR(50) NULL,
                role VARCHAR(50) NOT NULL,
                is_active BOOLEAN DEFAULT TRUE,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_user_company_dept_role (user_id, company_id, department_key, role),
                FOREIGN KEY (user_id) REFERENCES users(id),
                FOREIGN KEY (company_id) REFERENCES companies(id)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        _ensure_innodb_table_ok("user_company_access", create_user_company_access_sql)
        
        # Create projects table
        create_projects_sql = """
            CREATE TABLE IF NOT EXISTS projects (
                id INT AUTO_INCREMENT PRIMARY KEY,
                name VARCHAR(200) NOT NULL,
                company_id INT NOT NULL,
                start_date DATETIME,
                due_date DATETIME NOT NULL,
                revenue FLOAT DEFAULT 0.0,
                status VARCHAR(50) DEFAULT 'active',
                progress INT DEFAULT 0,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (company_id) REFERENCES companies(id)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        _ensure_innodb_table_ok("projects", create_projects_sql)

        # Project manager assignments (project timeline ownership)
        try:
            cur.execute(
                """
                CREATE TABLE IF NOT EXISTS project_manager_assignments (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    project_id INT NOT NULL,
                    g_id INT NULL,
                    manager_user_id INT NOT NULL,
                    assigned_by_user_id INT NULL,
                    assigned_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE KEY uniq_project_manager (project_id),
                    INDEX idx_manager_user (manager_user_id),
                    INDEX idx_project_gid (g_id),
                    FOREIGN KEY (manager_user_id) REFERENCES users(id)
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
                """
            )
        except Exception:
            pass

        # Create NO-GO snapshot table (used by overdue rule automation)
        create_nogo_bids_sql = """
            CREATE TABLE IF NOT EXISTS nogo_bids (
                id INT AUTO_INCREMENT PRIMARY KEY,
                bid_incoming_id INT NOT NULL,
                b_name VARCHAR(100),
                due_date DATE,
                state VARCHAR(100),
                scope TEXT,
                type VARCHAR(100),
                scoring INT,
                comp_name VARCHAR(100),
                original_decision VARCHAR(100),
                summary TEXT,
                moved_reason VARCHAR(255),
                moved_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_bid_incoming (bid_incoming_id)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        try:
            cur.execute(create_nogo_bids_sql)
            _ensure_innodb_table_ok("nogo_bids", create_nogo_bids_sql)
        except Exception:
            # Best-effort: don't block startup if NO-GO history table can't be created/repaired.
            pass
        
        # Create tasks table
        create_tasks_sql = """
            CREATE TABLE IF NOT EXISTS tasks (
                id INT AUTO_INCREMENT PRIMARY KEY,
                name VARCHAR(200) NOT NULL,
                project_id INT NOT NULL,
                assigned_user_id INT,
                due_date DATETIME NOT NULL,
                status VARCHAR(50) DEFAULT 'pending',
                priority VARCHAR(20) DEFAULT 'medium',
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (project_id) REFERENCES projects(id),
                FOREIGN KEY (assigned_user_id) REFERENCES users(id)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """
        _ensure_innodb_table_ok("tasks", create_tasks_sql)
        
        # Create bid_timeline table
        cur.execute("""
            CREATE TABLE IF NOT EXISTS bid_timeline (
                id INT AUTO_INCREMENT PRIMARY KEY,
                bid_id INT,
                event VARCHAR(200) NOT NULL,
                details TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # Create employees table for team-specific employee management
        cur.execute("""
            CREATE TABLE IF NOT EXISTS employees (
                id INT AUTO_INCREMENT PRIMARY KEY,
                name VARCHAR(100) NOT NULL,
                email VARCHAR(100) UNIQUE NOT NULL,
                password VARCHAR(255) NOT NULL,
                department VARCHAR(50) NOT NULL,
                team_lead_id INT,
                is_active BOOLEAN DEFAULT TRUE,
                last_active DATETIME NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (team_lead_id) REFERENCES users(id)
            )
        """)
        # Create team_leads table (separate roster for team leads)
        cur.execute("""
            CREATE TABLE IF NOT EXISTS team_leads (
                id INT AUTO_INCREMENT PRIMARY KEY,
                name VARCHAR(100) NOT NULL,
                email VARCHAR(100) UNIQUE NOT NULL,
                password VARCHAR(255) NOT NULL,
                department VARCHAR(50) NOT NULL,
                role VARCHAR(50) DEFAULT 'Team Lead',
                user_id INT NULL,
                is_active BOOLEAN DEFAULT TRUE,
                last_active DATETIME NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users(id)
            )
        """)
        # Ensure last_active exists for legacy databases
        try:
            cur.execute("SELECT COUNT(*) AS cnt FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME='employees' AND COLUMN_NAME='last_active'")
            row = cur.fetchone()
            if not row or int(row.get('cnt', 0)) == 0:
                cur.execute("ALTER TABLE employees ADD COLUMN last_active DATETIME NULL AFTER is_active")
        except Exception:
            pass
        
        # Create bid_checklists table for task management per bid (with InnoDB orphan tablespace repair)
        create_sql = (
            """
            CREATE TABLE IF NOT EXISTS bid_checklists (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                task_code VARCHAR(20),
                task_name VARCHAR(200) NOT NULL,
                description TEXT,
                assigned_to INT,
                status VARCHAR(50) DEFAULT 'pending',
                progress_pct INT DEFAULT NULL,
                stage VARCHAR(50),
                priority VARCHAR(20) DEFAULT 'medium',
                due_date DATETIME,
                attachment_path VARCHAR(255),
                created_by INT,
                team_archive VARCHAR(50),
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                FOREIGN KEY (g_id) REFERENCES go_bids(g_id),
                FOREIGN KEY (assigned_to) REFERENCES employees(id),
                FOREIGN KEY (created_by) REFERENCES users(id)
            ) ENGINE=InnoDB
            """
        )
        try:
            cur.execute(create_sql)
        except Exception as e:
            try:
                err_no = e.args[0] if hasattr(e, 'args') and e.args else None
            except Exception:
                err_no = None
            # 1813: orphan tablespace exists on disk; attempt OS-level cleanup then recreate
            if err_no == 1813:
                try:
                    cur2 = mysql.connection.cursor()
                    cur2.execute("SHOW VARIABLES LIKE 'datadir'")
                    row = cur2.fetchone()
                    data_dir = None
                    if isinstance(row, (list, tuple)) and len(row) >= 2:
                        data_dir = row[1]
                    elif isinstance(row, dict):
                        data_dir = row.get('Value') or row.get('value')
                    cur2.close()
                    if data_dir:
                        db_name = app.config.get('MYSQL_DB', 'esco')
                        ibd_path = os.path.join(data_dir, db_name, 'bid_checklists.ibd')
                        cfg_path = os.path.join(data_dir, db_name, 'bid_checklists.cfg')
                        for p in (ibd_path, cfg_path):
                            try:
                                if os.path.exists(p):
                                    os.remove(p)
                            except Exception:
                                pass
                except Exception:
                    pass
                try:
                    cur.execute("DROP TABLE IF EXISTS bid_checklists")
                    mysql.connection.commit()
                except Exception:
                    pass
                # Retry create
                cur.execute(create_sql)
            else:
                raise

        # Ensure progress_pct column exists even on older databases
        cur.execute("SELECT COUNT(*) AS cnt FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME='bid_checklists' AND COLUMN_NAME='progress_pct'")
        row = cur.fetchone()
        if not row or int(row.get('cnt', 0)) == 0:
            try:
                cur.execute("ALTER TABLE bid_checklists ADD COLUMN progress_pct INT NULL AFTER status")
            except Exception:
                pass

        # Ensure stage column exists
        cur.execute("SELECT COUNT(*) AS cnt FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME='bid_checklists' AND COLUMN_NAME='stage'")
        row = cur.fetchone()
        if not row or int(row.get('cnt', 0)) == 0:
            try:
                cur.execute("ALTER TABLE bid_checklists ADD COLUMN stage VARCHAR(50) NULL AFTER progress_pct")
            except Exception:
                pass

        # Ensure attachment_path column exists
        cur.execute("SELECT COUNT(*) AS cnt FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME='bid_checklists' AND COLUMN_NAME='attachment_path'")
        row = cur.fetchone()
        if not row or int(row.get('cnt', 0)) == 0:
            try:
                cur.execute("ALTER TABLE bid_checklists ADD COLUMN attachment_path VARCHAR(255) NULL AFTER due_date")
            except Exception:
                pass
        # Ensure task_code column exists
        cur.execute("SELECT COUNT(*) AS cnt FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME='bid_checklists' AND COLUMN_NAME='task_code'")
        row = cur.fetchone()
        if not row or int(row.get('cnt', 0)) == 0:
            try:
                cur.execute("ALTER TABLE bid_checklists ADD COLUMN task_code VARCHAR(20) NULL AFTER g_id")
            except Exception:
                pass
        cur.execute("""
            CREATE TABLE IF NOT EXISTS task_time_logs (
                id INT AUTO_INCREMENT PRIMARY KEY,
                task_id INT NOT NULL,
                employee_id INT NOT NULL,
                start_time DATETIME NULL,
                end_time DATETIME NULL,
                duration_seconds INT NOT NULL DEFAULT 0,
                note TEXT,
                created_by INT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (task_id) REFERENCES bid_checklists(id),
                FOREIGN KEY (employee_id) REFERENCES employees(id),
                FOREIGN KEY (created_by) REFERENCES users(id),
                INDEX idx_task_time_task (task_id),
                INDEX idx_task_time_employee (employee_id)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """)
        task_time_columns = {
            'start_time': "DATETIME NULL",
            'end_time': "DATETIME NULL",
            'duration_seconds': "INT NOT NULL DEFAULT 0",
            'note': "TEXT",
            'created_by': "INT",
            'created_at': "DATETIME DEFAULT CURRENT_TIMESTAMP"
        }
        for column, definition in task_time_columns.items():
            cur.execute(
                "SELECT COUNT(*) AS cnt FROM INFORMATION_SCHEMA.COLUMNS "
                "WHERE TABLE_NAME='task_time_logs' AND COLUMN_NAME=%s",
                (column,)
            )
            col_row = cur.fetchone()
            if not col_row or int(col_row.get('cnt', 0)) == 0:
                try:
                    cur.execute(f"ALTER TABLE task_time_logs ADD COLUMN {column} {definition}")
                except Exception:
                    pass
        # Create dynamic stage tables used across dashboards
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS bid_stage_exclusions (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                stage VARCHAR(50) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_bid_stage (g_id, stage)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
            """
        )
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS bid_custom_stages (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                stage VARCHAR(50) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_custom_stage (g_id, stage)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
            """
        )

        # Create dynamic stage tables used across dashboards
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS bid_stage_exclusions (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                stage VARCHAR(50) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_bid_stage (g_id, stage)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
            """
        )
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS bid_custom_stages (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                stage VARCHAR(50) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_custom_stage (g_id, stage)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
            """
        )

        # Create project_transfers table for tracking project handoffs between teams
        cur.execute("""
            CREATE TABLE IF NOT EXISTS project_transfers (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                from_team VARCHAR(50) NOT NULL,
                to_team VARCHAR(50) NOT NULL,
                transferred_by INT,
                transfer_reason TEXT,
                status VARCHAR(50) DEFAULT 'pending',
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (g_id) REFERENCES go_bids(g_id),
                FOREIGN KEY (transferred_by) REFERENCES users(id)
            )
        """)

        # Comments table for board modal
        cur.execute("""
            CREATE TABLE IF NOT EXISTS bid_comments (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                user_id INT,
                comment_text TEXT NOT NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (g_id) REFERENCES go_bids(g_id),
                FOREIGN KEY (user_id) REFERENCES users(id)
            )
        """)

        # Comments table for board modal
        cur.execute("""
            CREATE TABLE IF NOT EXISTS bid_comments (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                user_id INT,
                comment_text TEXT NOT NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (g_id) REFERENCES go_bids(g_id),
                FOREIGN KEY (user_id) REFERENCES users(id)
            )
        """)

        # --- Profiling tables ---
        cur.execute("""
            CREATE TABLE IF NOT EXISTS company_preferences (
                id INT AUTO_INCREMENT PRIMARY KEY,
                registered_states TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        cur.execute("""
            CREATE TABLE IF NOT EXISTS company_capabilities (
                id INT AUTO_INCREMENT PRIMARY KEY,
                description TEXT,
                file_path VARCHAR(255),
                uploaded_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        cur.execute("""
            CREATE TABLE IF NOT EXISTS company_performance (
                id INT AUTO_INCREMENT PRIMARY KEY,
                project_name VARCHAR(200) NOT NULL,
                year INT NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        # Mapping table for multi-employee bid assignments
        cur.execute("""
            CREATE TABLE IF NOT EXISTS bid_assignment_members (
                id INT AUTO_INCREMENT PRIMARY KEY,
                g_id INT NOT NULL,
                employee_id INT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uniq_g_emp (g_id, employee_id)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """)

        # Extend bid_assignment_members to store Team Lead -> Employee assignment metadata
        # (employee-visible due date set by Team Lead)
        try:
            cur.execute("SHOW COLUMNS FROM bid_assignment_members LIKE 'task_completion_date'")
            if not cur.fetchone():
                cur.execute("ALTER TABLE bid_assignment_members ADD COLUMN task_completion_date DATE NULL")
        except Exception:
            pass
        try:
            cur.execute("SHOW COLUMNS FROM bid_assignment_members LIKE 'assigned_by_email'")
            if not cur.fetchone():
                cur.execute("ALTER TABLE bid_assignment_members ADD COLUMN assigned_by_email VARCHAR(100) NULL")
        except Exception:
            pass
        try:
            cur.execute("SHOW COLUMNS FROM bid_assignment_members LIKE 'updated_at'")
            if not cur.fetchone():
                cur.execute("ALTER TABLE bid_assignment_members ADD COLUMN updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP")
        except Exception:
            pass

        # Extend teamlead_assign_bids to store Manager -> Team Lead assignment metadata
        try:
            cur.execute("SHOW COLUMNS FROM teamlead_assign_bids LIKE 'assigned_by_email'")
            if not cur.fetchone():
                cur.execute("ALTER TABLE teamlead_assign_bids ADD COLUMN assigned_by_email VARCHAR(100) NULL")
        except Exception:
            pass
        try:
            cur.execute("SHOW COLUMNS FROM teamlead_assign_bids LIKE 'assigned_at'")
            if not cur.fetchone():
                cur.execute("ALTER TABLE teamlead_assign_bids ADD COLUMN assigned_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP")
        except Exception:
            pass

        # Company details (profile) table
        cur.execute("""
            CREATE TABLE IF NOT EXISTS company_details (
                id INT AUTO_INCREMENT PRIMARY KEY,
                name VARCHAR(200),
                website VARCHAR(255),
                email VARCHAR(255),
                phone VARCHAR(50),
                about TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)

        mysql.connection.commit()
        cur.close()
        print("Database tables created/verified successfully")
    except Exception as e:
        print(f"Error creating tables: {e}")
        try:
            mysql.connection.rollback()
        except Exception:
            pass
        if 'cur' in locals():
            try:
                cur.close()
            except Exception:
                pass
if __name__ == '__main__':
    from datetime import datetime, timedelta
    
    with app.app_context():
        _ensure_tables_exist()
        
        cur = mysql.connection.cursor(DictCursor)
        try:
            _backfill_bid_team_progress(cur)
            mysql.connection.commit()
        except Exception:
            try:
                mysql.connection.rollback()
            except Exception:
                pass
        
        # Always ensure companies exist
        try:
            cur.execute("SELECT COUNT(*) as count FROM companies")
            if cur.fetchone()['count'] == 0:
                cur.execute("""
                    INSERT INTO companies (name, description) VALUES 
                    ('Ikio', 'Renewable Energy Solutions'),
                    ('Metco', 'Industrial Energy Management'),
                    ('Sunsprint', 'Solar Power Systems')
                """)
                mysql.connection.commit()
                print("Companies created successfully")
        except Exception as e:
            # If initial schema verification failed for any reason, avoid crashing at startup.
            print(f"Companies seed skipped: {e}")

        # Ensure departments exist (new RBAC model)
        try:
            cur.execute("SELECT COUNT(*) as count FROM departments")
            if cur.fetchone()['count'] == 0:
                cur.execute(
                    """
                    INSERT INTO departments (dept_key, display_name) VALUES
                    ('business', 'Business'),
                    ('marketing', 'Marketing'),
                    ('operations', 'Operations'),
                    ('site_engineer', 'Site Engineer'),
                    ('engineering_team', 'Engineering Team'),
                    ('procurement_team', 'Procurement Team'),
                    ('accounts_finance', 'Accounts & Finance Team')
                    """
                )
                mysql.connection.commit()
                print("Departments created successfully")
            else:
                # Ensure required departments exist even on older installs.
                ensure_rows = [
                    ('engineering_team', 'Engineering Team'),
                    ('procurement_team', 'Procurement Team'),
                    ('accounts_finance', 'Accounts & Finance Team'),
                ]
                for dept_key, display_name in ensure_rows:
                    cur.execute("SELECT COUNT(*) AS cnt FROM departments WHERE dept_key=%s", (dept_key,))
                    if int((cur.fetchone() or {}).get('cnt') or 0) == 0:
                        cur.execute(
                            "INSERT INTO departments (dept_key, display_name) VALUES (%s, %s)",
                            (dept_key, display_name),
                        )
                mysql.connection.commit()
        except Exception as e:
            # older DBs may not have departments yet if ensure failed; ignore hard crash
            print(f"Departments seed skipped: {e}")

        # --------------------------------------------------------------------
        # Best-effort migration: populate user_company_access for existing users
        # so nobody loses access after enabling multi-company logic.
        # --------------------------------------------------------------------
        def _norm(s: str) -> str:
            return (s or '').strip().lower().replace('_', ' ')

        def _role_to_access(role_raw: str) -> tuple[str, str | None]:
            """
            Returns (access_role, department_key_or_none).
            department_key None means 'all departments'.
            """
            r = _norm(role_raw)
            # global-ish roles keep access_role as-is; dept None
            if r in {'top level admin', 'top_level_admin', 'topleveladmin'}:
                return 'topleveladmin', None
            if r in {'supervisor'}:
                return 'supervisor', None
            if r in {'manager', 'project manager', 'project_manager'}:
                return ('project manager' if r in {'project manager', 'project_manager'} else 'manager'), None
            # department managers (legacy)
            if r in {'business manager', 'business_manager'}:
                return 'manager', 'business'
            if r in {'design manager', 'design_manager', 'marketing manager', 'marketing_manager'}:
                return 'manager', 'marketing'
            if r in {'operation manager', 'operations manager', 'operation_manager', 'operations_manager'}:
                return 'manager', 'operations'
            if r in {'site manager', 'site_manager'}:
                return 'manager', 'site_engineer'
            # legacy department-as-role (treated as team lead)
            if r in {'business dev', 'business development', 'bdm', 'business'}:
                return 'teamlead', 'business'
            if r in {'design', 'marketing'}:
                return 'teamlead', 'marketing'
            if r in {'operations', 'operation'}:
                return 'teamlead', 'operations'
            if r in {'site engineer', 'site_engineer', 'engineer'}:
                return 'teamlead', 'site_engineer'
            if r in {'team lead', 'team_lead', 'teamlead'}:
                return 'teamlead', None
            # default
            return 'member', None

        try:
            # Only run migration if table exists and empty
            cur.execute("SELECT COUNT(*) as cnt FROM user_company_access")
            access_cnt = int(cur.fetchone().get('cnt', 0))
            if access_cnt == 0:
                cur.execute("SELECT id, role, is_admin FROM users")
                users_rows = cur.fetchall()
                cur.execute("SELECT id, name FROM companies WHERE name IN ('Ikio','Metco','Sunsprint')")
                company_rows = cur.fetchall()
                company_ids = [r['id'] for r in company_rows] if company_rows else []

                for u in users_rows:
                    # IT admins: skip scoped access (full system anyway)
                    if u.get('is_admin'):
                        continue
                    access_role, dept_key = _role_to_access(u.get('role'))
                    # default: grant across all main companies for backward compatibility
                    for cid in company_ids:
                        cur.execute(
                            """
                            INSERT IGNORE INTO user_company_access (user_id, company_id, department_key, role, is_active)
                            VALUES (%s, %s, %s, %s, TRUE)
                            """,
                            (u['id'], cid, dept_key, access_role),
                        )
                mysql.connection.commit()
                print("Migrated existing users into user_company_access (default all companies)")
        except Exception as e:
            print(f"Access migration skipped: {e}")

        # --------------------------------------------------------------------
        # Best-effort role normalization (DB values)
        # - users.role: itadmin / topleveladmin / supervisor / member
        #   (manager/teamlead are SCOPED and must live in user_company_access)
        # - user_company_access.role: same
        # - permissions tables: role_permissions/action_permissions
        # --------------------------------------------------------------------
        try:
            # Users table
            try:
                cur.execute("UPDATE users SET role='itadmin' WHERE COALESCE(is_admin,0)=1")
            except Exception:
                pass
            try:
                cur.execute(
                    """
                    UPDATE users
                    SET role='topleveladmin'
                    WHERE COALESCE(is_admin,0)=0
                      AND LOWER(REPLACE(REPLACE(COALESCE(role,''),'_',' '),'-',' ')) IN ('top level admin','top leveladmin')
                    """
                )
            except Exception:
                pass
            try:
                cur.execute(
                    """
                    UPDATE users
                    SET role='supervisor'
                    WHERE COALESCE(is_admin,0)=0
                      AND LOWER(REPLACE(REPLACE(COALESCE(role,''),'_',' '),'-',' ')) IN ('supervisor')
                    """
                )
            except Exception:
                pass
            try:
                cur.execute(
                    """
                    UPDATE users
                    SET role='member'
                    WHERE COALESCE(is_admin,0)=0
                      AND (COALESCE(TRIM(role),'') = '')
                    """
                )
            except Exception:
                pass

            # user_company_access roles
            try:
                cur.execute(
                    """
                    UPDATE user_company_access
                    SET role='topleveladmin'
                    WHERE LOWER(REPLACE(REPLACE(COALESCE(role,''),'_',' '),'-',' ')) IN ('top level admin','top leveladmin','top_level_admin')
                    """
                )
                cur.execute(
                    """
                    UPDATE user_company_access
                    SET role='teamlead'
                    WHERE LOWER(REPLACE(REPLACE(COALESCE(role,''),'_',' '),'-',' ')) IN ('team lead','teamlead','team_lead')
                    """
                )
                cur.execute(
                    """
                    UPDATE user_company_access
                    SET role='itadmin'
                    WHERE LOWER(REPLACE(REPLACE(COALESCE(role,''),'_',' '),'-',' ')) IN ('it admin','itadmin','admin','it_admin')
                    """
                )
            except Exception:
                pass

            # permissions tables
            try:
                cur.execute("UPDATE role_permissions SET role='itadmin' WHERE role IN ('admin','it administrator','it_admin')")
                cur.execute("UPDATE role_permissions SET role='topleveladmin' WHERE role IN ('top_level_admin','top level admin')")
                cur.execute("UPDATE role_permissions SET role='teamlead' WHERE role IN ('team_lead','team lead','business dev','design','operations','site_engineer','site engineer','engineering')")
            except Exception:
                pass
            try:
                cur.execute("UPDATE action_permissions SET role='itadmin' WHERE role IN ('admin','it administrator','it_admin')")
                cur.execute("UPDATE action_permissions SET role='topleveladmin' WHERE role IN ('top_level_admin','top level admin')")
                cur.execute("UPDATE action_permissions SET role='teamlead' WHERE role IN ('team_lead','team lead','business dev','design','operations','site_engineer','site engineer','engineering')")
            except Exception:
                pass

            mysql.connection.commit()
        except Exception as e:
            try:
                mysql.connection.rollback()
            except Exception:
                pass
            print(f"Role normalization skipped: {e}")

        # --------------------------------------------------------------------
        # Migrate legacy Business/Design/Operations checklist stages to new teams
        # and re-prefix task codes.
        # --------------------------------------------------------------------
        try:
            stage_map = {
                'business': 'engineering_team',
                'design': 'procurement_team',
                'operations': 'accounts_finance',
                'operation': 'accounts_finance',
                'ops': 'accounts_finance',
                'site_engineer': 'engineering_team',
                'engineer': 'engineering_team',
                'site engineer': 'engineering_team',
            }

            def _norm_stage(value: str) -> str:
                return (value or '').strip().lower().replace('-', ' ').replace('_', ' ')

            # Update bid_checklists.stage values
            try:
                cur.execute("SELECT id, stage FROM bid_checklists WHERE COALESCE(stage,'') <> ''")
                rows = cur.fetchall() or []
                for row in rows:
                    stage_raw = row.get('stage') if isinstance(row, dict) else None
                    stage_key = _norm_stage(stage_raw)
                    if not stage_key:
                        continue
                    mapped = stage_map.get(stage_key)
                    if mapped and mapped != stage_raw:
                        cur.execute("UPDATE bid_checklists SET stage=%s WHERE id=%s", (mapped, row.get('id')))
            except Exception:
                pass

            # Update bid_team_progress.stage_key values if table exists
            try:
                cur.execute("SELECT id, stage_key FROM bid_team_progress")
                rows = cur.fetchall() or []
                for row in rows:
                    stage_raw = row.get('stage_key') if isinstance(row, dict) else None
                    stage_key = _norm_stage(stage_raw)
                    if not stage_key:
                        continue
                    mapped = stage_map.get(stage_key)
                    if mapped and mapped != stage_raw:
                        cur.execute("UPDATE bid_team_progress SET stage_key=%s WHERE id=%s", (mapped, row.get('id')))
            except Exception:
                pass

            # Re-prefix task codes for the new departments
            try:
                cur.execute("SELECT DISTINCT g_id FROM bid_checklists WHERE COALESCE(g_id,0) > 0")
                g_ids = [r.get('g_id') for r in (cur.fetchall() or []) if r.get('g_id')]
                new_stages = ['engineering_team', 'procurement_team', 'accounts_finance']
                for g_id in g_ids:
                    for stage_key in new_stages:
                        prefix, _ = _task_code_prefix(stage_key)
                        if not prefix:
                            continue
                        cur.execute(
                            """
                            SELECT id
                            FROM bid_checklists
                            WHERE g_id=%s AND LOWER(COALESCE(stage,''))=%s
                            ORDER BY created_at ASC, id ASC
                            """,
                            (int(g_id), stage_key),
                        )
                        task_rows = cur.fetchall() or []
                        next_num = 1
                        for tr in task_rows:
                            task_id = tr.get('id') if isinstance(tr, dict) else None
                            if not task_id:
                                continue
                            new_code = f"{prefix}-{next_num:03d}"
                            cur.execute(
                                "UPDATE bid_checklists SET task_code=%s WHERE id=%s",
                                (new_code, int(task_id)),
                            )
                            next_num += 1
            except Exception:
                pass

            mysql.connection.commit()
        except Exception as e:
            try:
                mysql.connection.rollback()
            except Exception:
                pass
            print(f"Legacy stage migration skipped: {e}")

        # --------------------------------------------------------------------
        # Seed department-scoped dummy users for new departments (if missing)
        # --------------------------------------------------------------------
        try:
            cur.execute("SELECT id, name FROM companies ORDER BY id")
            company_rows = cur.fetchall() or []
            preferred_company_id = None
            for row in company_rows:
                name_l = (row.get('name') or '').lower()
                if 'ikio' in name_l:
                    preferred_company_id = int(row['id'])
                    break
            if preferred_company_id is None and company_rows:
                preferred_company_id = int(company_rows[0]['id'])

            def _ensure_user(email: str, full_name: str, role: str = 'member') -> int | None:
                cur.execute("SELECT id FROM users WHERE LOWER(email)=LOWER(%s) LIMIT 1", (email,))
                row = cur.fetchone()
                if row and row.get('id'):
                    return int(row['id'])
                cur.execute(
                    "INSERT INTO users (email, full_name, password, is_admin, role) VALUES (%s, %s, %s, 0, %s)",
                    (email, full_name, 'user', role),
                )
                return int(cur.lastrowid)

            def _ensure_user_company_access(user_id: int, department_key: str, role: str) -> None:
                if not preferred_company_id:
                    return
                cur.execute(
                    """
                    INSERT IGNORE INTO user_company_access (user_id, company_id, department_key, role, is_active)
                    VALUES (%s, %s, %s, %s, TRUE)
                    """,
                    (int(user_id), int(preferred_company_id), department_key, role),
                )

            def _ensure_team_lead(name: str, email: str, department: str, user_id: int) -> None:
                cur.execute("SELECT id FROM team_leads WHERE LOWER(email)=LOWER(%s) LIMIT 1", (email,))
                row = cur.fetchone()
                if row and row.get('id'):
                    return
                cur.execute(
                    """
                    INSERT INTO team_leads (name, email, password, department, role, user_id, is_active)
                    VALUES (%s, %s, %s, %s, 'Team Lead', %s, TRUE)
                    """,
                    (name, email, 'user', department, int(user_id)),
                )

            def _ensure_employee(name: str, email: str, department: str, team_lead_user_id: int | None) -> None:
                cur.execute("SELECT id FROM employees WHERE LOWER(email)=LOWER(%s) LIMIT 1", (email,))
                row = cur.fetchone()
                if row and row.get('id'):
                    return
                cur.execute(
                    """
                    INSERT INTO employees (name, email, password, department, team_lead_id, is_active)
                    VALUES (%s, %s, %s, %s, %s, TRUE)
                    """,
                    (name, email, 'user', department, team_lead_user_id),
                )

            dept_seed = [
                {
                    'dept_key': 'engineering_team',
                    'dept_label': 'Engineering Team',
                    'manager_email': 'eng.manager@ikio.com',
                    'manager_name': 'Engineering Manager',
                    'lead_email': 'eng.lead@ikio.com',
                    'lead_name': 'Engineering Team Lead',
                    'employees': [
                        ('eng.exec@ikio.com', 'Engineering Executive'),
                        ('eng.associate@ikio.com', 'Engineering Associate'),
                    ],
                },
                {
                    'dept_key': 'procurement_team',
                    'dept_label': 'Procurement Team',
                    'manager_email': 'proc.manager@ikio.com',
                    'manager_name': 'Procurement Manager',
                    'lead_email': 'proc.lead@ikio.com',
                    'lead_name': 'Procurement Team Lead',
                    'employees': [
                        ('proc.exec@ikio.com', 'Procurement Executive'),
                        ('proc.associate@ikio.com', 'Procurement Associate'),
                    ],
                },
                {
                    'dept_key': 'accounts_finance',
                    'dept_label': 'Accounts & Finance Team',
                    'manager_email': 'accounts.manager@ikio.com',
                    'manager_name': 'Accounts & Finance Manager',
                    'lead_email': 'accounts.lead@ikio.com',
                    'lead_name': 'Accounts & Finance Team Lead',
                    'employees': [
                        ('accounts.exec@ikio.com', 'Accounts Executive'),
                        ('finance.exec@ikio.com', 'Finance Executive'),
                    ],
                },
            ]

            for spec in dept_seed:
                manager_id = _ensure_user(spec['manager_email'], spec['manager_name'], role='member')
                if manager_id:
                    _ensure_user_company_access(manager_id, spec['dept_key'], 'manager')

                lead_id = _ensure_user(spec['lead_email'], spec['lead_name'], role='member')
                if lead_id:
                    _ensure_user_company_access(lead_id, spec['dept_key'], 'teamlead')
                    _ensure_team_lead(spec['lead_name'], spec['lead_email'], spec['dept_key'], lead_id)

                for emp_email, emp_name in spec['employees']:
                    _ensure_employee(emp_name, emp_email, spec['dept_key'], lead_id)

            mysql.connection.commit()
        except Exception as e:
            try:
                mysql.connection.rollback()
            except Exception:
                pass
            print(f"Department dummy users seed skipped: {e}")
        
        # Check if users exist
        cur.execute("SELECT COUNT(*) as count FROM users")
        if cur.fetchone()['count'] == 0:
            # Create admin user
            cur.execute("""
                INSERT INTO users (email, password, is_admin, role) VALUES 
                ('admin@example.com', 'admin', 1, 'admin')
            """)
            admin_user_id = cur.lastrowid
            
            # Create other users
            cur.execute("""
                INSERT INTO users (email, password, is_admin, role) VALUES 
                ('manager@example.com', 'manager', 0, 'manager'),
                ('bd@example.com', 'user', 0, 'business dev'),
                ('designer@example.com', 'designer', 0, 'design'),
                ('ops@example.com', 'ops', 0, 'operations'),
                ('sitemgr@example.com', 'site', 0, 'site manager')
            """)
            # Fetch exact user IDs by email to avoid relying on lastrowid math
            cur.execute("SELECT id FROM users WHERE email=%s", ('bd@example.com',))
            user_bdm_id = cur.fetchone()['id']
            cur.execute("SELECT id FROM users WHERE email=%s", ('designer@example.com',))
            user_design_id = cur.fetchone()['id']
            cur.execute("SELECT id FROM users WHERE email=%s", ('ops@example.com',))
            user_ops_id = cur.fetchone()['id']
            cur.execute("SELECT id FROM users WHERE email=%s", ('sitemgr@example.com',))
            user_site_id = cur.fetchone()['id']
            
            # Get company ids for linking bids
            cur.execute("SELECT id FROM companies WHERE name='Ikio'")
            ikio_id = cur.fetchone()['id']
            cur.execute("SELECT id FROM companies WHERE name='Metco'")
            metco_id = cur.fetchone()['id']
            cur.execute("SELECT id FROM companies WHERE name='Sunsprint'")
            sunsprint_id = cur.fetchone()['id']

            # Create sample bids linked to companies
            cur.execute("""
            INSERT INTO bids (name, current_stage, user_id, company_id) VALUES 
            ('Project Alpha', 'business', %s, %s),
            ('Project Beta', 'design', %s, %s),
            ('Project Gamma', 'operations', %s, %s)
        """, (user_bdm_id, ikio_id, user_design_id, metco_id, user_ops_id, sunsprint_id))
            # Create sample bid_incoming data
            cur.execute("""
                INSERT INTO bid_incoming (b_name, due_date, state, scope, type, scoring, comp_name, decision, summary) VALUES 
                ('Solar Energy Project', %s, 'submitted', 'Installation of 500kW solar panels for commercial building', 'Renewable Energy', 85, 'Ikio', 'GO', 'High potential project with good ROI'),
                ('Wind Farm Development', %s, 'under_review', 'Development of 2MW wind farm in rural area', 'Wind Energy', 72, 'Metco', 'NO-GO', 'Land acquisition issues identified'),
                ('Energy Efficiency Audit', %s, 'pending', 'Comprehensive energy audit for manufacturing facility', 'Energy Management', 90, 'Sunsprint', 'WON', 'Excellent technical proposal with competitive pricing'),
                ('Battery Storage System', %s, 'submitted', 'Installation of 1MWh battery storage system', 'Energy Storage', 78, 'Ikio', 'LOST', 'Lost to competitor with lower bid'),
                ('Smart Grid Implementation', %s, 'completed', 'Implementation of smart grid technology for city', 'Smart Grid', 95, 'Metco', 'WON', 'Successfully completed project ahead of schedule')
            """, (
                datetime.now() + timedelta(days=30),
                datetime.now() + timedelta(days=45),
                datetime.now() + timedelta(days=15),
                datetime.now() + timedelta(days=60),
                datetime.now() + timedelta(days=90)
            ))
            
            # One sample bid ready for site manager handover
            cur.execute("UPDATE bids SET current_stage='site_manager' WHERE name='Project Beta'")
            
            mysql.connection.commit()
            
            # Company ids already loaded above
            
            # Create sample projects
            cur.execute("""
                INSERT INTO projects (name, company_id, start_date, due_date, status, progress) VALUES 
                ('Solar Farm Installation', %s, %s, %s, 50000, 'active', 45),
                ('Wind Energy Project', %s, %s, %s, 75000, 'active', 70),
                ('Energy Efficiency Audit', %s, %s, %s, 25000, 'active', 30),
                ('Industrial Solar Setup', %s, %s, %s, 100000, 'active', 15),
                ('Residential Solar Panel', %s, %s, %s, 30000, 'active', 80),
                ('Commercial Solar System', %s, %s, %s, 60000, 'active', 25)
            """, (
                ikio_id, datetime.now(), datetime.now() + timedelta(days=90),
                ikio_id, datetime.now() - timedelta(days=30), datetime.now() + timedelta(days=60),
                metco_id, datetime.now() - timedelta(days=15), datetime.now() + timedelta(days=45),
                metco_id, datetime.now(), datetime.now() + timedelta(days=120),
                sunsprint_id, datetime.now() - timedelta(days=10), datetime.now() + timedelta(days=30),
                sunsprint_id, datetime.now(), datetime.now() + timedelta(days=75)
            ))
            
            # Get project IDs for tasks
            cur.execute("SELECT id FROM projects ORDER BY id")
            project_ids = [row['id'] for row in cur.fetchall()]
            
            # Create sample tasks
            cur.execute("""
                INSERT INTO tasks (name, project_id, assigned_user_id, due_date, status, priority) VALUES 
                ('Site Survey', %s, %s, %s, 'in_progress', 'high'),
                ('Equipment Procurement', %s, %s, %s, 'pending', 'medium'),
                ('Installation Planning', %s, %s, %s, 'completed', 'high'),
                ('Energy Assessment', %s, %s, %s, 'in_progress', 'urgent'),
                ('Client Consultation', %s, %s, %s, 'pending', 'high'),
                ('System Testing', %s, %s, %s, 'in_progress', 'medium'),
                ('Documentation', %s, %s, %s, 'pending', 'low')
            """, (
                project_ids[0], user_bdm_id, datetime.now() + timedelta(days=5),
                project_ids[0], user_design_id, datetime.now() + timedelta(days=15),
                project_ids[1], admin_user_id, datetime.now() + timedelta(days=10),
                project_ids[2], user_ops_id, datetime.now() + timedelta(days=7),
                project_ids[3], user_site_id, datetime.now() + timedelta(days=3),
                project_ids[4], admin_user_id, datetime.now() + timedelta(days=2),
                project_ids[5], user_bdm_id, datetime.now() + timedelta(days=20)
            ))
            
            mysql.connection.commit()
            
        # Seed at least one log if none exist
        cur.execute("SELECT COUNT(*) as count FROM logs")
        if cur.fetchone()['count'] == 0:
            cur.execute("INSERT INTO logs (action) VALUES ('System initialized and sample data seeded.')")
            mysql.connection.commit()
        
        cur.close()
    
    # Avoid watchdog reload loops caused by changes in site-packages/venv on Windows.
    socketio.run(app, debug=True, port=5001, use_reloader=False)
